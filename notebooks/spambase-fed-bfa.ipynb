{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For IoT IDS\n",
    "csv_path = 'spambase.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "#print(df.columns)\n",
    "#print(df.shape)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
       "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
       "       'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28', 'F29', 'F30', 'F31',\n",
       "       'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40', 'F41',\n",
       "       'F42', 'F43', 'F44', 'F45', 'F46', 'F47', 'F48', 'F49', 'F50', 'F51',\n",
       "       'F52', 'F53', 'F54', 'F55', 'F56', 'F57', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F49</th>\n",
       "      <th>F50</th>\n",
       "      <th>F51</th>\n",
       "      <th>F52</th>\n",
       "      <th>F53</th>\n",
       "      <th>F54</th>\n",
       "      <th>F55</th>\n",
       "      <th>F56</th>\n",
       "      <th>F57</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     F1    F2    F3   F4    F5    F6    F7    F8    F9   F10  ...   F49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "     F50  F51    F52    F53    F54    F55  F56   F57  Class  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278      1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028      1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259      1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191      1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['Class']\n",
    "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "label_col = 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Separate features\n",
    "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "X_df = df[feature_cols].copy()\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for col in categorical_cols:\n",
    "    le_col = LabelEncoder()\n",
    "    X_df[col] = le_col.fit_transform(X_df[col].astype(str))  # convert to string in case of NaNs or mixed types\n",
    "\n",
    "# Now scale only numerical + encoded categorical columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_df)\n",
    "\n",
    "# Encode the target variable\n",
    "le_target = LabelEncoder()\n",
    "y = le_target.fit_transform(df[label_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features removed: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.0)\n",
    "X_var = var_thresh.fit_transform(X)\n",
    "print(f\"Constant features removed: {X.shape[1] - X_var.shape[1]}\")\n",
    "X = X_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 class distribution: [641 632]\n",
      "Client 2 class distribution: [629 278]\n",
      "Client 3 class distribution: [ 70 399]\n",
      "Client 4 class distribution: [560 115]\n",
      "Client 5 class distribution: [330  26]\n"
     ]
    }
   ],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "full_dataset = TabularDataset(X, y)\n",
    "train_idx, test_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, stratify=y, random_state=42)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "def partition_tabular_dataset(dataset, labels, train_idx, num_clients=10, alpha=0.5):\n",
    "    np.random.seed(42)\n",
    "    targets = np.array(labels)[train_idx]\n",
    "    num_classes = np.max(targets) + 1\n",
    "    idxs = np.arange(len(targets))\n",
    "    client_idx = [[] for _ in range(num_clients)]\n",
    "    for c in range(num_classes):\n",
    "        idx_c = idxs[targets == c]\n",
    "        np.random.shuffle(idx_c)\n",
    "        proportions = np.random.dirichlet([alpha]*num_clients)\n",
    "        proportions = (np.cumsum(proportions) * len(idx_c)).astype(int)[:-1]\n",
    "        split_idxs = np.split(idx_c, proportions)\n",
    "        for i, idx in enumerate(split_idxs):\n",
    "            client_idx[i].extend(idx)\n",
    "    return client_idx\n",
    "\n",
    "num_clients = 5\n",
    "alpha = 0.8\n",
    "client_indices = partition_tabular_dataset(train_dataset, y, train_idx, num_clients, alpha)\n",
    "\n",
    "client_data_np = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    X_client = X[train_idx][idxs]\n",
    "    y_client = y[train_idx][idxs]\n",
    "    client_data_np.append((X_client, y_client))\n",
    "\n",
    "for i, (Xc, yc) in enumerate(client_data_np):\n",
    "    print(f\"Client {i+1} class distribution:\", np.bincount(yc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_scores(X, y):\n",
    "    scores, _ = f_classif(X, y)\n",
    "    # Normalize scores to [0,1]\n",
    "    min_val = np.min(scores)\n",
    "    max_val = np.max(scores)\n",
    "    if max_val > min_val:\n",
    "        normalized_scores = (scores - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_scores = np.zeros_like(scores)\n",
    "    return normalized_scores\n",
    "\n",
    "def compute_corr_matrix(X):\n",
    "    corr = np.corrcoef(X, rowvar=False)\n",
    "    return np.abs(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_feature_subset(subset, fisher_scores, corr_matrix, penalty_lambda=0.7):\n",
    "    if len(subset) == 0:\n",
    "        return 0\n",
    "    fisher_sum = np.sum(fisher_scores[subset])\n",
    "    if len(subset) > 1:\n",
    "        corr_penalty = np.sum(corr_matrix[np.ix_(subset, subset)]) - np.sum(np.diag(corr_matrix[subset][:, subset]))\n",
    "        corr_penalty /= 2\n",
    "    else:\n",
    "        corr_penalty = 0.0\n",
    "    return penalty_lambda * fisher_sum - (1 - penalty_lambda) * corr_penalty\n",
    "\n",
    "def one_step_binary_firefly(\n",
    "    firefly_mask_prev, global_mask_prev, local_best_mask_prev,\n",
    "    fisher_scores, corr_matrix, penalty_lambda=0.7, p_global=0.3, p_local=0.3, mutation_rate=0.05, verbose=False\n",
    "):\n",
    "    n_features = len(firefly_mask_prev)\n",
    "    new_mask = firefly_mask_prev.copy()\n",
    "    for i in range(n_features):\n",
    "        r = np.random.rand()\n",
    "        if r < p_global:\n",
    "            new_mask[i] = global_mask_prev[i]\n",
    "        elif r < p_global + p_local:\n",
    "            new_mask[i] = local_best_mask_prev[i]\n",
    "        elif np.random.rand() < mutation_rate:\n",
    "            new_mask[i] = 1 - new_mask[i]  # mutate\n",
    "\n",
    "    # Optional: flip one bit with small probability for extra exploration\n",
    "    if np.random.rand() < 0.2:\n",
    "        idx = np.random.randint(n_features)\n",
    "        new_mask[idx] = 1 - new_mask[idx]\n",
    "\n",
    "    if verbose:\n",
    "        sel = np.where(new_mask)[0]\n",
    "        fit = evaluate_feature_subset(sel, fisher_scores, corr_matrix, penalty_lambda)\n",
    "        print(f\"    - New mask: {np.sum(new_mask)} features, Fitness: {fit:.4f}\")\n",
    "\n",
    "    return new_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Federated BFA Round 1 ================\n",
      "  Adaptive rho for this round: 0.20\n",
      "    - New mask: 37 features, Fitness: -2.2457\n",
      "    - New mask: 33 features, Fitness: -1.8370\n",
      "    - New mask: 33 features, Fitness: -2.6276\n",
      "    - New mask: 38 features, Fitness: -6.4212\n",
      "    - New mask: 35 features, Fitness: -2.2091\n",
      "    - New mask: 35 features, Fitness: -3.7665\n",
      "    - New mask: 33 features, Fitness: -0.6632\n",
      "    - New mask: 34 features, Fitness: -0.5378\n",
      "    - New mask: 37 features, Fitness: -3.2623\n",
      "    - New mask: 35 features, Fitness: -0.8818\n",
      "    - New mask: 33 features, Fitness: -1.2583\n",
      "    - New mask: 41 features, Fitness: -4.0498\n",
      "    - New mask: 38 features, Fitness: -2.3196\n",
      "    - New mask: 36 features, Fitness: -2.8116\n",
      "    - New mask: 34 features, Fitness: -0.4865\n",
      "    - New mask: 33 features, Fitness: -1.0933\n",
      "    - New mask: 37 features, Fitness: -2.6919\n",
      "    - New mask: 32 features, Fitness: -0.3989\n",
      "    - New mask: 36 features, Fitness: -1.8290\n",
      "    - New mask: 37 features, Fitness: -3.3372\n",
      "    - New mask: 35 features, Fitness: -1.1702\n",
      "    - New mask: 36 features, Fitness: 0.4673\n",
      "    - New mask: 34 features, Fitness: 0.0237\n",
      "    - New mask: 38 features, Fitness: -2.1241\n",
      "    - New mask: 33 features, Fitness: 1.4787\n",
      "    - New mask: 34 features, Fitness: 0.0764\n",
      "    - New mask: 39 features, Fitness: -0.9422\n",
      "    - New mask: 40 features, Fitness: -2.1373\n",
      "    - New mask: 46 features, Fitness: -1.9150\n",
      "    - New mask: 35 features, Fitness: 0.8647\n",
      "    - New mask: 37 features, Fitness: -0.0265\n",
      "    - New mask: 34 features, Fitness: 0.6460\n",
      "    - New mask: 43 features, Fitness: -2.9846\n",
      "    - New mask: 34 features, Fitness: -0.5324\n",
      "    - New mask: 33 features, Fitness: 0.9131\n",
      "    - New mask: 33 features, Fitness: 1.1795\n",
      "    - New mask: 42 features, Fitness: -0.8690\n",
      "    - New mask: 38 features, Fitness: -2.3888\n",
      "    - New mask: 36 features, Fitness: 0.9563\n",
      "    - New mask: 30 features, Fitness: -0.4326\n",
      "    - New mask: 43 features, Fitness: -4.6793\n",
      "    - New mask: 36 features, Fitness: -2.2008\n",
      "    - New mask: 35 features, Fitness: -2.3723\n",
      "    - New mask: 37 features, Fitness: -3.9451\n",
      "    - New mask: 27 features, Fitness: -1.6909\n",
      "    - New mask: 37 features, Fitness: -3.2537\n",
      "    - New mask: 37 features, Fitness: -2.8445\n",
      "    - New mask: 37 features, Fitness: -3.0339\n",
      "    - New mask: 34 features, Fitness: -4.1535\n",
      "    - New mask: 39 features, Fitness: -5.8753\n",
      "    - New mask: 36 features, Fitness: -3.2768\n",
      "    - New mask: 34 features, Fitness: -2.0216\n",
      "    - New mask: 34 features, Fitness: -1.5515\n",
      "    - New mask: 37 features, Fitness: -3.0259\n",
      "    - New mask: 32 features, Fitness: -1.5715\n",
      "    - New mask: 35 features, Fitness: -3.3042\n",
      "    - New mask: 34 features, Fitness: -3.0300\n",
      "    - New mask: 37 features, Fitness: -3.1584\n",
      "    - New mask: 30 features, Fitness: -1.0756\n",
      "    - New mask: 31 features, Fitness: -2.6854\n",
      "    - New mask: 32 features, Fitness: -1.3082\n",
      "    - New mask: 34 features, Fitness: -3.5290\n",
      "    - New mask: 34 features, Fitness: -1.9111\n",
      "    - New mask: 36 features, Fitness: -5.4207\n",
      "    - New mask: 34 features, Fitness: -2.2695\n",
      "    - New mask: 35 features, Fitness: -3.5431\n",
      "    - New mask: 36 features, Fitness: -3.8770\n",
      "    - New mask: 35 features, Fitness: -2.1388\n",
      "    - New mask: 35 features, Fitness: -1.4072\n",
      "    - New mask: 29 features, Fitness: -0.1003\n",
      "    - New mask: 33 features, Fitness: -1.2311\n",
      "    - New mask: 31 features, Fitness: -2.1589\n",
      "    - New mask: 36 features, Fitness: -2.3510\n",
      "    - New mask: 31 features, Fitness: -0.8980\n",
      "    - New mask: 38 features, Fitness: -3.8131\n",
      "    - New mask: 35 features, Fitness: -4.0358\n",
      "    - New mask: 35 features, Fitness: -2.5468\n",
      "    - New mask: 27 features, Fitness: -0.8047\n",
      "    - New mask: 33 features, Fitness: -3.9697\n",
      "    - New mask: 42 features, Fitness: -5.1397\n",
      "    - New mask: 40 features, Fitness: -6.0044\n",
      "    - New mask: 36 features, Fitness: -6.2126\n",
      "    - New mask: 32 features, Fitness: -6.6058\n",
      "    - New mask: 33 features, Fitness: -4.1934\n",
      "    - New mask: 36 features, Fitness: -5.1242\n",
      "    - New mask: 36 features, Fitness: -5.6825\n",
      "    - New mask: 39 features, Fitness: -6.7590\n",
      "    - New mask: 32 features, Fitness: -3.9065\n",
      "    - New mask: 35 features, Fitness: -6.1805\n",
      "    - New mask: 32 features, Fitness: -3.7677\n",
      "    - New mask: 36 features, Fitness: -4.4150\n",
      "    - New mask: 31 features, Fitness: -2.1998\n",
      "    - New mask: 37 features, Fitness: -5.5737\n",
      "    - New mask: 30 features, Fitness: -3.1041\n",
      "    - New mask: 37 features, Fitness: -4.5215\n",
      "    - New mask: 32 features, Fitness: -4.2236\n",
      "    - New mask: 33 features, Fitness: -6.1183\n",
      "    - New mask: 35 features, Fitness: -5.3470\n",
      "    - New mask: 29 features, Fitness: -3.8329\n",
      "    - New mask: 33 features, Fitness: -4.3539\n",
      "=== End of Round 1: Vote mask selects 57 features (rho: 0.20)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 2 ================\n",
      "  Adaptive rho for this round: 0.23\n",
      "    - New mask: 38 features, Fitness: -2.8203\n",
      "    - New mask: 39 features, Fitness: -2.9821\n",
      "    - New mask: 38 features, Fitness: -3.1176\n",
      "    - New mask: 46 features, Fitness: -6.9249\n",
      "    - New mask: 45 features, Fitness: -4.5088\n",
      "    - New mask: 39 features, Fitness: -3.2675\n",
      "    - New mask: 40 features, Fitness: -3.7953\n",
      "    - New mask: 41 features, Fitness: -2.6505\n",
      "    - New mask: 43 features, Fitness: -5.2472\n",
      "    - New mask: 37 features, Fitness: -0.8535\n",
      "    - New mask: 41 features, Fitness: -3.3915\n",
      "    - New mask: 45 features, Fitness: -6.8250\n",
      "    - New mask: 41 features, Fitness: -3.7474\n",
      "    - New mask: 41 features, Fitness: -4.3011\n",
      "    - New mask: 38 features, Fitness: -1.3501\n",
      "    - New mask: 42 features, Fitness: -4.9374\n",
      "    - New mask: 42 features, Fitness: -4.4098\n",
      "    - New mask: 42 features, Fitness: -3.2875\n",
      "    - New mask: 46 features, Fitness: -8.3546\n",
      "    - New mask: 44 features, Fitness: -6.7908\n",
      "    - New mask: 38 features, Fitness: -0.9399\n",
      "    - New mask: 42 features, Fitness: -0.3696\n",
      "    - New mask: 47 features, Fitness: -3.5614\n",
      "    - New mask: 44 features, Fitness: -2.1463\n",
      "    - New mask: 37 features, Fitness: 0.7709\n",
      "    - New mask: 38 features, Fitness: 0.2479\n",
      "    - New mask: 43 features, Fitness: -0.9566\n",
      "    - New mask: 47 features, Fitness: -2.6343\n",
      "    - New mask: 44 features, Fitness: -2.3982\n",
      "    - New mask: 34 features, Fitness: 0.6501\n",
      "    - New mask: 43 features, Fitness: -1.2272\n",
      "    - New mask: 38 features, Fitness: 1.5489\n",
      "    - New mask: 46 features, Fitness: -3.1955\n",
      "    - New mask: 42 features, Fitness: -2.0487\n",
      "    - New mask: 37 features, Fitness: 1.0142\n",
      "    - New mask: 40 features, Fitness: -3.0540\n",
      "    - New mask: 43 features, Fitness: -2.0899\n",
      "    - New mask: 41 features, Fitness: -2.9119\n",
      "    - New mask: 41 features, Fitness: -2.4048\n",
      "    - New mask: 35 features, Fitness: 0.7589\n",
      "    - New mask: 46 features, Fitness: -7.1672\n",
      "    - New mask: 39 features, Fitness: -3.5249\n",
      "    - New mask: 40 features, Fitness: -5.3924\n",
      "    - New mask: 42 features, Fitness: -5.8406\n",
      "    - New mask: 32 features, Fitness: -2.4336\n",
      "    - New mask: 45 features, Fitness: -7.7247\n",
      "    - New mask: 40 features, Fitness: -6.2831\n",
      "    - New mask: 46 features, Fitness: -7.0741\n",
      "    - New mask: 36 features, Fitness: -5.5939\n",
      "    - New mask: 43 features, Fitness: -5.9043\n",
      "    - New mask: 39 features, Fitness: -4.3407\n",
      "    - New mask: 39 features, Fitness: -6.7412\n",
      "    - New mask: 41 features, Fitness: -3.7887\n",
      "    - New mask: 38 features, Fitness: -4.2537\n",
      "    - New mask: 36 features, Fitness: -1.9119\n",
      "    - New mask: 37 features, Fitness: -2.5572\n",
      "    - New mask: 44 features, Fitness: -6.9646\n",
      "    - New mask: 42 features, Fitness: -6.2154\n",
      "    - New mask: 41 features, Fitness: -5.5055\n",
      "    - New mask: 34 features, Fitness: -3.6857\n",
      "    - New mask: 36 features, Fitness: -2.8804\n",
      "    - New mask: 39 features, Fitness: -3.4746\n",
      "    - New mask: 38 features, Fitness: -3.0905\n",
      "    - New mask: 44 features, Fitness: -7.5782\n",
      "    - New mask: 36 features, Fitness: -2.6577\n",
      "    - New mask: 37 features, Fitness: -4.6585\n",
      "    - New mask: 42 features, Fitness: -5.1311\n",
      "    - New mask: 47 features, Fitness: -7.7591\n",
      "    - New mask: 38 features, Fitness: -2.7846\n",
      "    - New mask: 36 features, Fitness: -2.5559\n",
      "    - New mask: 39 features, Fitness: -1.9604\n",
      "    - New mask: 39 features, Fitness: -3.8956\n",
      "    - New mask: 42 features, Fitness: -4.6196\n",
      "    - New mask: 35 features, Fitness: -3.0900\n",
      "    - New mask: 42 features, Fitness: -6.0680\n",
      "    - New mask: 36 features, Fitness: -3.2028\n",
      "    - New mask: 40 features, Fitness: -4.5159\n",
      "    - New mask: 36 features, Fitness: -3.1130\n",
      "    - New mask: 39 features, Fitness: -6.9344\n",
      "    - New mask: 40 features, Fitness: -3.2109\n",
      "    - New mask: 40 features, Fitness: -6.5995\n",
      "    - New mask: 39 features, Fitness: -6.9381\n",
      "    - New mask: 35 features, Fitness: -4.6335\n",
      "    - New mask: 36 features, Fitness: -4.6304\n",
      "    - New mask: 40 features, Fitness: -5.0231\n",
      "    - New mask: 41 features, Fitness: -7.9494\n",
      "    - New mask: 44 features, Fitness: -7.5191\n",
      "    - New mask: 39 features, Fitness: -5.7800\n",
      "    - New mask: 36 features, Fitness: -5.4489\n",
      "    - New mask: 34 features, Fitness: -4.4326\n",
      "    - New mask: 44 features, Fitness: -8.0735\n",
      "    - New mask: 40 features, Fitness: -5.6919\n",
      "    - New mask: 33 features, Fitness: -2.7317\n",
      "    - New mask: 32 features, Fitness: -3.5179\n",
      "    - New mask: 37 features, Fitness: -5.2551\n",
      "    - New mask: 32 features, Fitness: -4.6141\n",
      "    - New mask: 37 features, Fitness: -7.4254\n",
      "    - New mask: 35 features, Fitness: -5.0545\n",
      "    - New mask: 37 features, Fitness: -5.4087\n",
      "    - New mask: 41 features, Fitness: -6.9827\n",
      "=== End of Round 2: Vote mask selects 51 features (rho: 0.23)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "\n",
      "================ Federated BFA Round 3 ================\n",
      "  Adaptive rho for this round: 0.26\n",
      "    - New mask: 42 features, Fitness: -3.3219\n",
      "    - New mask: 44 features, Fitness: -5.9108\n",
      "    - New mask: 38 features, Fitness: -1.8701\n",
      "    - New mask: 46 features, Fitness: -3.8497\n",
      "    - New mask: 40 features, Fitness: -2.4997\n",
      "    - New mask: 43 features, Fitness: -3.8542\n",
      "    - New mask: 42 features, Fitness: -3.2217\n",
      "    - New mask: 45 features, Fitness: -5.2841\n",
      "    - New mask: 41 features, Fitness: -3.2933\n",
      "    - New mask: 40 features, Fitness: -2.2931\n",
      "    - New mask: 42 features, Fitness: -3.3784\n",
      "    - New mask: 48 features, Fitness: -5.6233\n",
      "    - New mask: 45 features, Fitness: -4.3036\n",
      "    - New mask: 44 features, Fitness: -3.7187\n",
      "    - New mask: 38 features, Fitness: -0.4990\n",
      "    - New mask: 42 features, Fitness: -2.3020\n",
      "    - New mask: 45 features, Fitness: -5.2509\n",
      "    - New mask: 42 features, Fitness: -4.3665\n",
      "    - New mask: 43 features, Fitness: -4.3145\n",
      "    - New mask: 39 features, Fitness: -3.5371\n",
      "    - New mask: 41 features, Fitness: -2.2783\n",
      "    - New mask: 41 features, Fitness: -0.3408\n",
      "    - New mask: 43 features, Fitness: -1.4027\n",
      "    - New mask: 41 features, Fitness: 0.1932\n",
      "    - New mask: 37 features, Fitness: 1.1365\n",
      "    - New mask: 40 features, Fitness: 1.1870\n",
      "    - New mask: 44 features, Fitness: -0.2307\n",
      "    - New mask: 44 features, Fitness: -1.7301\n",
      "    - New mask: 43 features, Fitness: -0.8168\n",
      "    - New mask: 38 features, Fitness: 0.6372\n",
      "    - New mask: 41 features, Fitness: -0.9911\n",
      "    - New mask: 42 features, Fitness: 0.1282\n",
      "    - New mask: 44 features, Fitness: -0.3433\n",
      "    - New mask: 41 features, Fitness: -1.7781\n",
      "    - New mask: 38 features, Fitness: 1.1756\n",
      "    - New mask: 40 features, Fitness: -2.9648\n",
      "    - New mask: 43 features, Fitness: -2.8537\n",
      "    - New mask: 44 features, Fitness: -2.6765\n",
      "    - New mask: 43 features, Fitness: -0.8205\n",
      "    - New mask: 45 features, Fitness: -1.6998\n",
      "    - New mask: 45 features, Fitness: -5.6548\n",
      "    - New mask: 42 features, Fitness: -3.8132\n",
      "    - New mask: 45 features, Fitness: -5.6021\n",
      "    - New mask: 42 features, Fitness: -4.8152\n",
      "    - New mask: 35 features, Fitness: -3.1896\n",
      "    - New mask: 43 features, Fitness: -5.9587\n",
      "    - New mask: 48 features, Fitness: -8.9557\n",
      "    - New mask: 44 features, Fitness: -4.8100\n",
      "    - New mask: 39 features, Fitness: -4.0670\n",
      "    - New mask: 43 features, Fitness: -5.0177\n",
      "    - New mask: 39 features, Fitness: -3.5139\n",
      "    - New mask: 39 features, Fitness: -3.7642\n",
      "    - New mask: 44 features, Fitness: -4.8457\n",
      "    - New mask: 42 features, Fitness: -3.8322\n",
      "    - New mask: 38 features, Fitness: -2.2861\n",
      "    - New mask: 39 features, Fitness: -3.1559\n",
      "    - New mask: 43 features, Fitness: -4.9694\n",
      "    - New mask: 39 features, Fitness: -3.4186\n",
      "    - New mask: 41 features, Fitness: -4.6818\n",
      "    - New mask: 39 features, Fitness: -5.3328\n",
      "    - New mask: 41 features, Fitness: -4.0990\n",
      "    - New mask: 35 features, Fitness: -2.5379\n",
      "    - New mask: 41 features, Fitness: -3.6747\n",
      "    - New mask: 43 features, Fitness: -5.1361\n",
      "    - New mask: 42 features, Fitness: -4.9704\n",
      "    - New mask: 40 features, Fitness: -3.4805\n",
      "    - New mask: 44 features, Fitness: -4.4729\n",
      "    - New mask: 42 features, Fitness: -3.6653\n",
      "    - New mask: 40 features, Fitness: -2.2372\n",
      "    - New mask: 42 features, Fitness: -3.6840\n",
      "    - New mask: 42 features, Fitness: -3.9062\n",
      "    - New mask: 43 features, Fitness: -6.7342\n",
      "    - New mask: 44 features, Fitness: -5.9538\n",
      "    - New mask: 42 features, Fitness: -3.9509\n",
      "    - New mask: 46 features, Fitness: -6.0825\n",
      "    - New mask: 43 features, Fitness: -5.6320\n",
      "    - New mask: 46 features, Fitness: -5.6468\n",
      "    - New mask: 34 features, Fitness: -2.3835\n",
      "    - New mask: 40 features, Fitness: -4.5486\n",
      "    - New mask: 40 features, Fitness: -3.1255\n",
      "    - New mask: 39 features, Fitness: -6.0479\n",
      "    - New mask: 38 features, Fitness: -6.5120\n",
      "    - New mask: 41 features, Fitness: -7.7784\n",
      "    - New mask: 41 features, Fitness: -7.8804\n",
      "    - New mask: 42 features, Fitness: -5.5035\n",
      "    - New mask: 39 features, Fitness: -5.8923\n",
      "    - New mask: 41 features, Fitness: -6.7704\n",
      "    - New mask: 39 features, Fitness: -4.3731\n",
      "    - New mask: 35 features, Fitness: -4.3375\n",
      "    - New mask: 36 features, Fitness: -4.6436\n",
      "    - New mask: 38 features, Fitness: -4.6334\n",
      "    - New mask: 41 features, Fitness: -6.4937\n",
      "    - New mask: 35 features, Fitness: -3.3033\n",
      "    - New mask: 38 features, Fitness: -4.9161\n",
      "    - New mask: 42 features, Fitness: -7.9910\n",
      "    - New mask: 35 features, Fitness: -4.7072\n",
      "    - New mask: 39 features, Fitness: -7.1322\n",
      "    - New mask: 36 features, Fitness: -4.3396\n",
      "    - New mask: 43 features, Fitness: -7.1856\n",
      "    - New mask: 46 features, Fitness: -8.8689\n",
      "=== End of Round 3: Vote mask selects 49 features (rho: 0.26)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 4 ================\n",
      "  Adaptive rho for this round: 0.29\n",
      "    - New mask: 43 features, Fitness: -2.2765\n",
      "    - New mask: 43 features, Fitness: -4.5155\n",
      "    - New mask: 40 features, Fitness: -1.1678\n",
      "    - New mask: 43 features, Fitness: -2.6296\n",
      "    - New mask: 39 features, Fitness: -1.8834\n",
      "    - New mask: 43 features, Fitness: -2.7659\n",
      "    - New mask: 45 features, Fitness: -4.6030\n",
      "    - New mask: 45 features, Fitness: -5.1378\n",
      "    - New mask: 42 features, Fitness: -1.8421\n",
      "    - New mask: 43 features, Fitness: -3.9411\n",
      "    - New mask: 44 features, Fitness: -4.2074\n",
      "    - New mask: 44 features, Fitness: -2.5971\n",
      "    - New mask: 47 features, Fitness: -4.8814\n",
      "    - New mask: 45 features, Fitness: -4.0257\n",
      "    - New mask: 40 features, Fitness: -1.1050\n",
      "    - New mask: 41 features, Fitness: -1.7114\n",
      "    - New mask: 45 features, Fitness: -4.9315\n",
      "    - New mask: 44 features, Fitness: -3.9423\n",
      "    - New mask: 41 features, Fitness: -3.0648\n",
      "    - New mask: 45 features, Fitness: -5.0184\n",
      "    - New mask: 45 features, Fitness: -1.0717\n",
      "    - New mask: 40 features, Fitness: 0.9832\n",
      "    - New mask: 41 features, Fitness: -0.4767\n",
      "    - New mask: 43 features, Fitness: -0.5971\n",
      "    - New mask: 40 features, Fitness: -0.5632\n",
      "    - New mask: 42 features, Fitness: 0.9069\n",
      "    - New mask: 42 features, Fitness: -0.5480\n",
      "    - New mask: 45 features, Fitness: -1.6365\n",
      "    - New mask: 42 features, Fitness: -0.0571\n",
      "    - New mask: 40 features, Fitness: 1.1068\n",
      "    - New mask: 44 features, Fitness: 0.0163\n",
      "    - New mask: 46 features, Fitness: -1.0089\n",
      "    - New mask: 43 features, Fitness: 0.3338\n",
      "    - New mask: 41 features, Fitness: 0.2113\n",
      "    - New mask: 39 features, Fitness: 0.8240\n",
      "    - New mask: 41 features, Fitness: -0.3653\n",
      "    - New mask: 42 features, Fitness: -0.4392\n",
      "    - New mask: 44 features, Fitness: -1.9153\n",
      "    - New mask: 40 features, Fitness: 0.1894\n",
      "    - New mask: 46 features, Fitness: -1.9606\n",
      "    - New mask: 45 features, Fitness: -5.6411\n",
      "    - New mask: 42 features, Fitness: -3.6282\n",
      "    - New mask: 46 features, Fitness: -5.5950\n",
      "    - New mask: 43 features, Fitness: -4.5431\n",
      "    - New mask: 38 features, Fitness: -3.4882\n",
      "    - New mask: 43 features, Fitness: -5.1812\n",
      "    - New mask: 44 features, Fitness: -5.9926\n",
      "    - New mask: 44 features, Fitness: -4.9139\n",
      "    - New mask: 40 features, Fitness: -2.9306\n",
      "    - New mask: 44 features, Fitness: -5.9166\n",
      "    - New mask: 38 features, Fitness: -3.1013\n",
      "    - New mask: 44 features, Fitness: -5.2379\n",
      "    - New mask: 45 features, Fitness: -5.5185\n",
      "    - New mask: 40 features, Fitness: -3.4041\n",
      "    - New mask: 38 features, Fitness: -2.4718\n",
      "    - New mask: 44 features, Fitness: -4.5525\n",
      "    - New mask: 43 features, Fitness: -3.5467\n",
      "    - New mask: 39 features, Fitness: -2.6131\n",
      "    - New mask: 40 features, Fitness: -4.0038\n",
      "    - New mask: 40 features, Fitness: -4.4239\n",
      "    - New mask: 38 features, Fitness: -2.4318\n",
      "    - New mask: 43 features, Fitness: -3.8613\n",
      "    - New mask: 45 features, Fitness: -4.2943\n",
      "    - New mask: 43 features, Fitness: -4.6402\n",
      "    - New mask: 47 features, Fitness: -6.9113\n",
      "    - New mask: 43 features, Fitness: -4.5158\n",
      "    - New mask: 44 features, Fitness: -4.5291\n",
      "    - New mask: 45 features, Fitness: -4.4658\n",
      "    - New mask: 41 features, Fitness: -2.7636\n",
      "    - New mask: 43 features, Fitness: -4.4041\n",
      "    - New mask: 43 features, Fitness: -3.8304\n",
      "    - New mask: 45 features, Fitness: -4.7935\n",
      "    - New mask: 43 features, Fitness: -4.3787\n",
      "    - New mask: 44 features, Fitness: -3.9279\n",
      "    - New mask: 45 features, Fitness: -4.5783\n",
      "    - New mask: 44 features, Fitness: -3.9456\n",
      "    - New mask: 45 features, Fitness: -4.1958\n",
      "    - New mask: 36 features, Fitness: -2.3077\n",
      "    - New mask: 44 features, Fitness: -4.5031\n",
      "    - New mask: 42 features, Fitness: -3.0255\n",
      "    - New mask: 35 features, Fitness: -4.4504\n",
      "    - New mask: 42 features, Fitness: -7.6379\n",
      "    - New mask: 42 features, Fitness: -6.1290\n",
      "    - New mask: 44 features, Fitness: -7.4839\n",
      "    - New mask: 40 features, Fitness: -5.2288\n",
      "    - New mask: 41 features, Fitness: -5.3769\n",
      "    - New mask: 47 features, Fitness: -9.9675\n",
      "    - New mask: 41 features, Fitness: -5.3808\n",
      "    - New mask: 36 features, Fitness: -4.2095\n",
      "    - New mask: 37 features, Fitness: -4.3902\n",
      "    - New mask: 42 features, Fitness: -6.3054\n",
      "    - New mask: 35 features, Fitness: -3.6960\n",
      "    - New mask: 36 features, Fitness: -3.5265\n",
      "    - New mask: 39 features, Fitness: -5.7148\n",
      "    - New mask: 42 features, Fitness: -7.2915\n",
      "    - New mask: 37 features, Fitness: -4.4625\n",
      "    - New mask: 41 features, Fitness: -6.6388\n",
      "    - New mask: 39 features, Fitness: -4.9950\n",
      "    - New mask: 40 features, Fitness: -4.7019\n",
      "    - New mask: 40 features, Fitness: -5.3058\n",
      "=== End of Round 4: Vote mask selects 50 features (rho: 0.29)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 5 ================\n",
      "  Adaptive rho for this round: 0.33\n",
      "    - New mask: 43 features, Fitness: -2.4740\n",
      "    - New mask: 44 features, Fitness: -2.9324\n",
      "    - New mask: 42 features, Fitness: -1.1994\n",
      "    - New mask: 46 features, Fitness: -3.8804\n",
      "    - New mask: 41 features, Fitness: -1.4996\n",
      "    - New mask: 45 features, Fitness: -2.9714\n",
      "    - New mask: 46 features, Fitness: -3.6008\n",
      "    - New mask: 45 features, Fitness: -6.3484\n",
      "    - New mask: 42 features, Fitness: -2.7106\n",
      "    - New mask: 42 features, Fitness: -2.6548\n",
      "    - New mask: 44 features, Fitness: -3.0478\n",
      "    - New mask: 48 features, Fitness: -4.1960\n",
      "    - New mask: 47 features, Fitness: -4.1662\n",
      "    - New mask: 45 features, Fitness: -4.9495\n",
      "    - New mask: 43 features, Fitness: -1.9035\n",
      "    - New mask: 40 features, Fitness: -2.1452\n",
      "    - New mask: 43 features, Fitness: -2.8205\n",
      "    - New mask: 44 features, Fitness: -3.7942\n",
      "    - New mask: 40 features, Fitness: -2.4761\n",
      "    - New mask: 40 features, Fitness: -1.9195\n",
      "    - New mask: 43 features, Fitness: -1.3922\n",
      "    - New mask: 43 features, Fitness: -0.5749\n",
      "    - New mask: 43 features, Fitness: -0.7621\n",
      "    - New mask: 44 features, Fitness: -0.9607\n",
      "    - New mask: 44 features, Fitness: -0.7898\n",
      "    - New mask: 49 features, Fitness: -3.2039\n",
      "    - New mask: 42 features, Fitness: 0.4963\n",
      "    - New mask: 41 features, Fitness: 0.3783\n",
      "    - New mask: 42 features, Fitness: 0.7769\n",
      "    - New mask: 42 features, Fitness: 0.0989\n",
      "    - New mask: 45 features, Fitness: -0.2534\n",
      "    - New mask: 49 features, Fitness: -2.6469\n",
      "    - New mask: 45 features, Fitness: -0.0427\n",
      "    - New mask: 43 features, Fitness: 0.2201\n",
      "    - New mask: 48 features, Fitness: -2.7058\n",
      "    - New mask: 43 features, Fitness: -2.0920\n",
      "    - New mask: 45 features, Fitness: -1.3011\n",
      "    - New mask: 44 features, Fitness: -0.4954\n",
      "    - New mask: 42 features, Fitness: -0.2343\n",
      "    - New mask: 46 features, Fitness: -1.0942\n",
      "    - New mask: 41 features, Fitness: -4.2330\n",
      "    - New mask: 37 features, Fitness: -1.7759\n",
      "    - New mask: 43 features, Fitness: -5.0784\n",
      "    - New mask: 44 features, Fitness: -5.0277\n",
      "    - New mask: 40 features, Fitness: -3.6513\n",
      "    - New mask: 45 features, Fitness: -6.4382\n",
      "    - New mask: 46 features, Fitness: -5.7606\n",
      "    - New mask: 46 features, Fitness: -5.2710\n",
      "    - New mask: 45 features, Fitness: -5.5189\n",
      "    - New mask: 45 features, Fitness: -5.5907\n",
      "    - New mask: 46 features, Fitness: -6.3607\n",
      "    - New mask: 43 features, Fitness: -5.3264\n",
      "    - New mask: 42 features, Fitness: -4.1107\n",
      "    - New mask: 42 features, Fitness: -3.2976\n",
      "    - New mask: 38 features, Fitness: -2.8404\n",
      "    - New mask: 45 features, Fitness: -5.1866\n",
      "    - New mask: 40 features, Fitness: -2.7792\n",
      "    - New mask: 44 features, Fitness: -4.7794\n",
      "    - New mask: 42 features, Fitness: -3.9063\n",
      "    - New mask: 45 features, Fitness: -5.4829\n",
      "    - New mask: 41 features, Fitness: -3.4058\n",
      "    - New mask: 40 features, Fitness: -2.8826\n",
      "    - New mask: 40 features, Fitness: -2.8452\n",
      "    - New mask: 40 features, Fitness: -2.8768\n",
      "    - New mask: 46 features, Fitness: -6.2681\n",
      "    - New mask: 39 features, Fitness: -2.1489\n",
      "    - New mask: 43 features, Fitness: -4.1051\n",
      "    - New mask: 41 features, Fitness: -2.9096\n",
      "    - New mask: 44 features, Fitness: -5.2204\n",
      "    - New mask: 47 features, Fitness: -5.4720\n",
      "    - New mask: 44 features, Fitness: -5.3443\n",
      "    - New mask: 43 features, Fitness: -4.2788\n",
      "    - New mask: 39 features, Fitness: -3.3478\n",
      "    - New mask: 45 features, Fitness: -4.0233\n",
      "    - New mask: 42 features, Fitness: -3.0155\n",
      "    - New mask: 38 features, Fitness: -1.7725\n",
      "    - New mask: 45 features, Fitness: -4.8439\n",
      "    - New mask: 45 features, Fitness: -6.3774\n",
      "    - New mask: 44 features, Fitness: -4.6411\n",
      "    - New mask: 42 features, Fitness: -3.9848\n",
      "    - New mask: 41 features, Fitness: -6.0740\n",
      "    - New mask: 44 features, Fitness: -7.8218\n",
      "    - New mask: 38 features, Fitness: -4.1988\n",
      "    - New mask: 45 features, Fitness: -7.9540\n",
      "    - New mask: 38 features, Fitness: -4.3825\n",
      "    - New mask: 39 features, Fitness: -4.7350\n",
      "    - New mask: 43 features, Fitness: -7.2209\n",
      "    - New mask: 37 features, Fitness: -3.8835\n",
      "    - New mask: 43 features, Fitness: -6.5926\n",
      "    - New mask: 42 features, Fitness: -7.1085\n",
      "    - New mask: 40 features, Fitness: -4.9278\n",
      "    - New mask: 43 features, Fitness: -6.7708\n",
      "    - New mask: 39 features, Fitness: -5.4649\n",
      "    - New mask: 45 features, Fitness: -8.1558\n",
      "    - New mask: 43 features, Fitness: -6.7008\n",
      "    - New mask: 43 features, Fitness: -6.4159\n",
      "    - New mask: 42 features, Fitness: -6.2116\n",
      "    - New mask: 40 features, Fitness: -5.4698\n",
      "    - New mask: 44 features, Fitness: -7.7455\n",
      "    - New mask: 44 features, Fitness: -7.2190\n",
      "=== End of Round 5: Vote mask selects 48 features (rho: 0.33)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 6 ================\n",
      "  Adaptive rho for this round: 0.36\n",
      "    - New mask: 46 features, Fitness: -4.8158\n",
      "    - New mask: 46 features, Fitness: -3.3271\n",
      "    - New mask: 44 features, Fitness: -2.3860\n",
      "    - New mask: 47 features, Fitness: -3.4899\n",
      "    - New mask: 42 features, Fitness: -2.0849\n",
      "    - New mask: 49 features, Fitness: -4.7960\n",
      "    - New mask: 46 features, Fitness: -2.5345\n",
      "    - New mask: 43 features, Fitness: -1.9377\n",
      "    - New mask: 42 features, Fitness: -1.5988\n",
      "    - New mask: 45 features, Fitness: -2.2428\n",
      "    - New mask: 45 features, Fitness: -3.8548\n",
      "    - New mask: 41 features, Fitness: -1.3768\n",
      "    - New mask: 48 features, Fitness: -4.5447\n",
      "    - New mask: 45 features, Fitness: -2.8431\n",
      "    - New mask: 41 features, Fitness: -1.1062\n",
      "    - New mask: 41 features, Fitness: -1.7121\n",
      "    - New mask: 43 features, Fitness: -1.8930\n",
      "    - New mask: 50 features, Fitness: -5.8482\n",
      "    - New mask: 45 features, Fitness: -2.6155\n",
      "    - New mask: 43 features, Fitness: -1.8001\n",
      "    - New mask: 46 features, Fitness: -0.7919\n",
      "    - New mask: 40 features, Fitness: 0.9257\n",
      "    - New mask: 41 features, Fitness: -0.3904\n",
      "    - New mask: 48 features, Fitness: -1.2927\n",
      "    - New mask: 44 features, Fitness: -1.2484\n",
      "    - New mask: 47 features, Fitness: -1.0728\n",
      "    - New mask: 43 features, Fitness: -0.5655\n",
      "    - New mask: 40 features, Fitness: 0.8798\n",
      "    - New mask: 45 features, Fitness: -0.0650\n",
      "    - New mask: 41 features, Fitness: 1.1694\n",
      "    - New mask: 43 features, Fitness: 0.4639\n",
      "    - New mask: 45 features, Fitness: -1.5453\n",
      "    - New mask: 41 features, Fitness: 1.0500\n",
      "    - New mask: 43 features, Fitness: -0.1940\n",
      "    - New mask: 48 features, Fitness: -1.8403\n",
      "    - New mask: 45 features, Fitness: -1.4972\n",
      "    - New mask: 44 features, Fitness: -1.0206\n",
      "    - New mask: 46 features, Fitness: -1.2440\n",
      "    - New mask: 44 features, Fitness: 0.1104\n",
      "    - New mask: 47 features, Fitness: -1.3615\n",
      "    - New mask: 42 features, Fitness: -3.9328\n",
      "    - New mask: 43 features, Fitness: -4.4898\n",
      "    - New mask: 45 features, Fitness: -4.9027\n",
      "    - New mask: 42 features, Fitness: -4.0478\n",
      "    - New mask: 44 features, Fitness: -4.6416\n",
      "    - New mask: 41 features, Fitness: -4.3683\n",
      "    - New mask: 45 features, Fitness: -4.9331\n",
      "    - New mask: 43 features, Fitness: -3.6376\n",
      "    - New mask: 40 features, Fitness: -3.2690\n",
      "    - New mask: 41 features, Fitness: -3.3477\n",
      "    - New mask: 46 features, Fitness: -6.0682\n",
      "    - New mask: 41 features, Fitness: -3.8112\n",
      "    - New mask: 40 features, Fitness: -2.8293\n",
      "    - New mask: 41 features, Fitness: -3.2261\n",
      "    - New mask: 43 features, Fitness: -3.9116\n",
      "    - New mask: 44 features, Fitness: -5.2130\n",
      "    - New mask: 37 features, Fitness: -1.4761\n",
      "    - New mask: 41 features, Fitness: -3.4667\n",
      "    - New mask: 39 features, Fitness: -3.0645\n",
      "    - New mask: 42 features, Fitness: -4.0842\n",
      "    - New mask: 43 features, Fitness: -3.9683\n",
      "    - New mask: 44 features, Fitness: -3.9054\n",
      "    - New mask: 37 features, Fitness: -1.7803\n",
      "    - New mask: 41 features, Fitness: -3.1820\n",
      "    - New mask: 46 features, Fitness: -4.9895\n",
      "    - New mask: 39 features, Fitness: -1.8922\n",
      "    - New mask: 41 features, Fitness: -2.8762\n",
      "    - New mask: 47 features, Fitness: -4.9600\n",
      "    - New mask: 40 features, Fitness: -2.5193\n",
      "    - New mask: 42 features, Fitness: -2.8082\n",
      "    - New mask: 47 features, Fitness: -5.5690\n",
      "    - New mask: 43 features, Fitness: -3.2501\n",
      "    - New mask: 42 features, Fitness: -4.3549\n",
      "    - New mask: 41 features, Fitness: -3.6223\n",
      "    - New mask: 43 features, Fitness: -3.9427\n",
      "    - New mask: 39 features, Fitness: -2.2818\n",
      "    - New mask: 44 features, Fitness: -3.7529\n",
      "    - New mask: 41 features, Fitness: -3.4100\n",
      "    - New mask: 40 features, Fitness: -2.7023\n",
      "    - New mask: 41 features, Fitness: -3.2271\n",
      "    - New mask: 38 features, Fitness: -5.1379\n",
      "    - New mask: 43 features, Fitness: -7.6011\n",
      "    - New mask: 41 features, Fitness: -5.5476\n",
      "    - New mask: 41 features, Fitness: -5.2961\n",
      "    - New mask: 38 features, Fitness: -4.2986\n",
      "    - New mask: 39 features, Fitness: -4.8186\n",
      "    - New mask: 43 features, Fitness: -6.0927\n",
      "    - New mask: 38 features, Fitness: -4.5299\n",
      "    - New mask: 40 features, Fitness: -4.7679\n",
      "    - New mask: 42 features, Fitness: -5.7920\n",
      "    - New mask: 37 features, Fitness: -4.0893\n",
      "    - New mask: 43 features, Fitness: -5.7862\n",
      "    - New mask: 39 features, Fitness: -4.8191\n",
      "    - New mask: 40 features, Fitness: -5.2681\n",
      "    - New mask: 43 features, Fitness: -6.6014\n",
      "    - New mask: 39 features, Fitness: -4.7487\n",
      "    - New mask: 42 features, Fitness: -5.6679\n",
      "    - New mask: 40 features, Fitness: -5.5165\n",
      "    - New mask: 44 features, Fitness: -8.3300\n",
      "    - New mask: 40 features, Fitness: -5.6927\n",
      "=== End of Round 6: Vote mask selects 48 features (rho: 0.36)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 7 ================\n",
      "  Adaptive rho for this round: 0.39\n",
      "    - New mask: 46 features, Fitness: -3.6168\n",
      "    - New mask: 44 features, Fitness: -2.5706\n",
      "    - New mask: 46 features, Fitness: -3.3163\n",
      "    - New mask: 44 features, Fitness: -3.1259\n",
      "    - New mask: 43 features, Fitness: -2.4793\n",
      "    - New mask: 49 features, Fitness: -4.7625\n",
      "    - New mask: 43 features, Fitness: -1.4760\n",
      "    - New mask: 43 features, Fitness: -1.8281\n",
      "    - New mask: 45 features, Fitness: -1.9464\n",
      "    - New mask: 47 features, Fitness: -3.3243\n",
      "    - New mask: 45 features, Fitness: -2.5856\n",
      "    - New mask: 45 features, Fitness: -2.6025\n",
      "    - New mask: 43 features, Fitness: -2.9752\n",
      "    - New mask: 41 features, Fitness: -1.2340\n",
      "    - New mask: 41 features, Fitness: -1.5644\n",
      "    - New mask: 44 features, Fitness: -2.9928\n",
      "    - New mask: 45 features, Fitness: -2.6827\n",
      "    - New mask: 46 features, Fitness: -4.7253\n",
      "    - New mask: 45 features, Fitness: -2.8513\n",
      "    - New mask: 44 features, Fitness: -2.8127\n",
      "    - New mask: 45 features, Fitness: -0.7627\n",
      "    - New mask: 42 features, Fitness: -0.2015\n",
      "    - New mask: 41 features, Fitness: 1.5079\n",
      "    - New mask: 43 features, Fitness: 0.1923\n",
      "    - New mask: 41 features, Fitness: 0.9072\n",
      "    - New mask: 48 features, Fitness: -1.7654\n",
      "    - New mask: 44 features, Fitness: -0.1395\n",
      "    - New mask: 43 features, Fitness: 0.1963\n",
      "    - New mask: 44 features, Fitness: 0.3312\n",
      "    - New mask: 42 features, Fitness: 0.6266\n",
      "    - New mask: 42 features, Fitness: 0.6410\n",
      "    - New mask: 41 features, Fitness: 0.0712\n",
      "    - New mask: 43 features, Fitness: -0.3517\n",
      "    - New mask: 42 features, Fitness: 0.2120\n",
      "    - New mask: 44 features, Fitness: 0.2472\n",
      "    - New mask: 47 features, Fitness: -1.6182\n",
      "    - New mask: 47 features, Fitness: -1.4346\n",
      "    - New mask: 46 features, Fitness: -0.4038\n",
      "    - New mask: 45 features, Fitness: -0.1423\n",
      "    - New mask: 40 features, Fitness: 0.4288\n",
      "    - New mask: 41 features, Fitness: -3.0344\n",
      "    - New mask: 40 features, Fitness: -2.9896\n",
      "    - New mask: 41 features, Fitness: -3.6229\n",
      "    - New mask: 41 features, Fitness: -2.9887\n",
      "    - New mask: 44 features, Fitness: -3.7799\n",
      "    - New mask: 36 features, Fitness: -2.2000\n",
      "    - New mask: 43 features, Fitness: -4.5683\n",
      "    - New mask: 40 features, Fitness: -2.7342\n",
      "    - New mask: 40 features, Fitness: -2.1595\n",
      "    - New mask: 42 features, Fitness: -3.3197\n",
      "    - New mask: 45 features, Fitness: -5.1821\n",
      "    - New mask: 42 features, Fitness: -3.8264\n",
      "    - New mask: 40 features, Fitness: -2.9313\n",
      "    - New mask: 40 features, Fitness: -3.4111\n",
      "    - New mask: 43 features, Fitness: -4.4737\n",
      "    - New mask: 40 features, Fitness: -3.2585\n",
      "    - New mask: 41 features, Fitness: -3.1067\n",
      "    - New mask: 41 features, Fitness: -3.1561\n",
      "    - New mask: 40 features, Fitness: -2.4605\n",
      "    - New mask: 43 features, Fitness: -3.8043\n",
      "    - New mask: 43 features, Fitness: -3.5199\n",
      "    - New mask: 40 features, Fitness: -2.1605\n",
      "    - New mask: 39 features, Fitness: -2.2973\n",
      "    - New mask: 44 features, Fitness: -4.5034\n",
      "    - New mask: 43 features, Fitness: -4.6484\n",
      "    - New mask: 43 features, Fitness: -3.7056\n",
      "    - New mask: 42 features, Fitness: -2.9911\n",
      "    - New mask: 42 features, Fitness: -2.6750\n",
      "    - New mask: 43 features, Fitness: -3.6718\n",
      "    - New mask: 45 features, Fitness: -4.4900\n",
      "    - New mask: 46 features, Fitness: -5.6890\n",
      "    - New mask: 41 features, Fitness: -2.4466\n",
      "    - New mask: 45 features, Fitness: -3.9722\n",
      "    - New mask: 43 features, Fitness: -4.0135\n",
      "    - New mask: 41 features, Fitness: -2.4960\n",
      "    - New mask: 42 features, Fitness: -3.2458\n",
      "    - New mask: 46 features, Fitness: -4.7915\n",
      "    - New mask: 40 features, Fitness: -2.4610\n",
      "    - New mask: 38 features, Fitness: -2.4103\n",
      "    - New mask: 44 features, Fitness: -3.9604\n",
      "    - New mask: 41 features, Fitness: -6.3210\n",
      "    - New mask: 39 features, Fitness: -5.3037\n",
      "    - New mask: 43 features, Fitness: -6.2719\n",
      "    - New mask: 39 features, Fitness: -5.2363\n",
      "    - New mask: 41 features, Fitness: -5.2654\n",
      "    - New mask: 42 features, Fitness: -5.5983\n",
      "    - New mask: 42 features, Fitness: -5.7408\n",
      "    - New mask: 40 features, Fitness: -4.8864\n",
      "    - New mask: 39 features, Fitness: -4.2136\n",
      "    - New mask: 42 features, Fitness: -5.8616\n",
      "    - New mask: 37 features, Fitness: -3.7007\n",
      "    - New mask: 38 features, Fitness: -4.6670\n",
      "    - New mask: 44 features, Fitness: -7.2296\n",
      "    - New mask: 42 features, Fitness: -6.0409\n",
      "    - New mask: 42 features, Fitness: -6.2966\n",
      "    - New mask: 40 features, Fitness: -5.6035\n",
      "    - New mask: 42 features, Fitness: -5.8722\n",
      "    - New mask: 41 features, Fitness: -6.0231\n",
      "    - New mask: 44 features, Fitness: -7.0359\n",
      "    - New mask: 41 features, Fitness: -5.9318\n",
      "=== End of Round 7: Vote mask selects 48 features (rho: 0.39)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 8 ================\n",
      "  Adaptive rho for this round: 0.42\n",
      "    - New mask: 46 features, Fitness: -4.0103\n",
      "    - New mask: 47 features, Fitness: -3.6512\n",
      "    - New mask: 45 features, Fitness: -2.7195\n",
      "    - New mask: 43 features, Fitness: -2.2855\n",
      "    - New mask: 42 features, Fitness: -2.3864\n",
      "    - New mask: 46 features, Fitness: -3.2508\n",
      "    - New mask: 40 features, Fitness: -1.3306\n",
      "    - New mask: 44 features, Fitness: -2.1625\n",
      "    - New mask: 42 features, Fitness: -1.7512\n",
      "    - New mask: 45 features, Fitness: -2.8736\n",
      "    - New mask: 44 features, Fitness: -2.0817\n",
      "    - New mask: 41 features, Fitness: -1.4981\n",
      "    - New mask: 44 features, Fitness: -2.6714\n",
      "    - New mask: 43 features, Fitness: -1.9663\n",
      "    - New mask: 39 features, Fitness: -1.2546\n",
      "    - New mask: 43 features, Fitness: -2.6130\n",
      "    - New mask: 46 features, Fitness: -2.5070\n",
      "    - New mask: 44 features, Fitness: -3.0773\n",
      "    - New mask: 45 features, Fitness: -2.3343\n",
      "    - New mask: 48 features, Fitness: -4.0789\n",
      "    - New mask: 44 features, Fitness: 0.4349\n",
      "    - New mask: 44 features, Fitness: -0.5566\n",
      "    - New mask: 41 features, Fitness: 0.7185\n",
      "    - New mask: 45 features, Fitness: -0.9156\n",
      "    - New mask: 42 features, Fitness: 0.4503\n",
      "    - New mask: 45 features, Fitness: -0.9245\n",
      "    - New mask: 43 features, Fitness: 0.3326\n",
      "    - New mask: 45 features, Fitness: -0.2170\n",
      "    - New mask: 44 features, Fitness: -0.6207\n",
      "    - New mask: 41 features, Fitness: 1.3794\n",
      "    - New mask: 43 features, Fitness: 0.3586\n",
      "    - New mask: 44 features, Fitness: 0.3129\n",
      "    - New mask: 41 features, Fitness: 0.7013\n",
      "    - New mask: 43 features, Fitness: 1.0179\n",
      "    - New mask: 46 features, Fitness: -0.8434\n",
      "    - New mask: 45 features, Fitness: -1.0543\n",
      "    - New mask: 44 features, Fitness: 0.6539\n",
      "    - New mask: 45 features, Fitness: -0.1496\n",
      "    - New mask: 45 features, Fitness: -0.4912\n",
      "    - New mask: 41 features, Fitness: 0.4333\n",
      "    - New mask: 40 features, Fitness: -2.5961\n",
      "    - New mask: 45 features, Fitness: -5.0606\n",
      "    - New mask: 39 features, Fitness: -2.8115\n",
      "    - New mask: 43 features, Fitness: -3.5270\n",
      "    - New mask: 43 features, Fitness: -3.3647\n",
      "    - New mask: 41 features, Fitness: -3.2782\n",
      "    - New mask: 43 features, Fitness: -4.2937\n",
      "    - New mask: 38 features, Fitness: -2.2982\n",
      "    - New mask: 41 features, Fitness: -2.7572\n",
      "    - New mask: 44 features, Fitness: -4.1404\n",
      "    - New mask: 46 features, Fitness: -5.8723\n",
      "    - New mask: 45 features, Fitness: -4.7288\n",
      "    - New mask: 41 features, Fitness: -3.4167\n",
      "    - New mask: 44 features, Fitness: -4.3828\n",
      "    - New mask: 44 features, Fitness: -3.7910\n",
      "    - New mask: 45 features, Fitness: -5.0399\n",
      "    - New mask: 39 features, Fitness: -1.8135\n",
      "    - New mask: 39 features, Fitness: -2.8183\n",
      "    - New mask: 44 features, Fitness: -3.5202\n",
      "    - New mask: 44 features, Fitness: -3.9342\n",
      "    - New mask: 45 features, Fitness: -4.5169\n",
      "    - New mask: 43 features, Fitness: -3.7976\n",
      "    - New mask: 40 features, Fitness: -2.5384\n",
      "    - New mask: 46 features, Fitness: -4.9640\n",
      "    - New mask: 45 features, Fitness: -4.0448\n",
      "    - New mask: 43 features, Fitness: -4.3692\n",
      "    - New mask: 42 features, Fitness: -3.7216\n",
      "    - New mask: 43 features, Fitness: -3.4335\n",
      "    - New mask: 41 features, Fitness: -3.3649\n",
      "    - New mask: 44 features, Fitness: -4.0062\n",
      "    - New mask: 46 features, Fitness: -5.4010\n",
      "    - New mask: 44 features, Fitness: -3.5931\n",
      "    - New mask: 45 features, Fitness: -3.6101\n",
      "    - New mask: 39 features, Fitness: -2.0453\n",
      "    - New mask: 43 features, Fitness: -3.3619\n",
      "    - New mask: 43 features, Fitness: -3.4804\n",
      "    - New mask: 44 features, Fitness: -3.5626\n",
      "    - New mask: 44 features, Fitness: -3.6694\n",
      "    - New mask: 40 features, Fitness: -3.0304\n",
      "    - New mask: 43 features, Fitness: -3.4866\n",
      "    - New mask: 43 features, Fitness: -5.6242\n",
      "    - New mask: 41 features, Fitness: -5.4140\n",
      "    - New mask: 44 features, Fitness: -7.2092\n",
      "    - New mask: 43 features, Fitness: -5.7032\n",
      "    - New mask: 41 features, Fitness: -5.3120\n",
      "    - New mask: 41 features, Fitness: -5.1995\n",
      "    - New mask: 41 features, Fitness: -5.0749\n",
      "    - New mask: 41 features, Fitness: -5.4232\n",
      "    - New mask: 41 features, Fitness: -5.1845\n",
      "    - New mask: 42 features, Fitness: -5.6704\n",
      "    - New mask: 42 features, Fitness: -5.6192\n",
      "    - New mask: 41 features, Fitness: -5.7857\n",
      "    - New mask: 39 features, Fitness: -4.7188\n",
      "    - New mask: 43 features, Fitness: -6.6396\n",
      "    - New mask: 41 features, Fitness: -5.1275\n",
      "    - New mask: 42 features, Fitness: -6.5522\n",
      "    - New mask: 39 features, Fitness: -4.1448\n",
      "    - New mask: 42 features, Fitness: -5.3256\n",
      "    - New mask: 44 features, Fitness: -7.0808\n",
      "    - New mask: 40 features, Fitness: -4.8999\n",
      "=== End of Round 8: Vote mask selects 47 features (rho: 0.42)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56]\n",
      "\n",
      "================ Federated BFA Round 9 ================\n",
      "  Adaptive rho for this round: 0.45\n",
      "    - New mask: 44 features, Fitness: -2.5744\n",
      "    - New mask: 45 features, Fitness: -2.8597\n",
      "    - New mask: 43 features, Fitness: -2.0946\n",
      "    - New mask: 44 features, Fitness: -3.0730\n",
      "    - New mask: 45 features, Fitness: -2.7879\n",
      "    - New mask: 44 features, Fitness: -2.7043\n",
      "    - New mask: 44 features, Fitness: -2.6247\n",
      "    - New mask: 41 features, Fitness: -1.8049\n",
      "    - New mask: 42 features, Fitness: -1.7005\n",
      "    - New mask: 42 features, Fitness: -1.5388\n",
      "    - New mask: 42 features, Fitness: -1.4526\n",
      "    - New mask: 42 features, Fitness: -1.9186\n",
      "    - New mask: 42 features, Fitness: -2.8605\n",
      "    - New mask: 38 features, Fitness: -0.7398\n",
      "    - New mask: 40 features, Fitness: -1.5152\n",
      "    - New mask: 42 features, Fitness: -2.9262\n",
      "    - New mask: 45 features, Fitness: -2.3734\n",
      "    - New mask: 43 features, Fitness: -1.7545\n",
      "    - New mask: 43 features, Fitness: -2.3579\n",
      "    - New mask: 41 features, Fitness: -1.3880\n",
      "    - New mask: 40 features, Fitness: 1.8829\n",
      "    - New mask: 43 features, Fitness: -0.1780\n",
      "    - New mask: 40 features, Fitness: 1.9775\n",
      "    - New mask: 41 features, Fitness: 0.8591\n",
      "    - New mask: 41 features, Fitness: 1.3187\n",
      "    - New mask: 46 features, Fitness: -0.7572\n",
      "    - New mask: 41 features, Fitness: 1.2109\n",
      "    - New mask: 42 features, Fitness: 1.1504\n",
      "    - New mask: 45 features, Fitness: -0.2728\n",
      "    - New mask: 43 features, Fitness: 0.7196\n",
      "    - New mask: 43 features, Fitness: 0.1748\n",
      "    - New mask: 42 features, Fitness: 0.9566\n",
      "    - New mask: 43 features, Fitness: 0.4572\n",
      "    - New mask: 42 features, Fitness: 1.2197\n",
      "    - New mask: 46 features, Fitness: -0.5533\n",
      "    - New mask: 46 features, Fitness: -0.9537\n",
      "    - New mask: 41 features, Fitness: 1.4340\n",
      "    - New mask: 43 features, Fitness: 0.4176\n",
      "    - New mask: 40 features, Fitness: 1.3829\n",
      "    - New mask: 43 features, Fitness: 0.7409\n",
      "    - New mask: 37 features, Fitness: -1.2084\n",
      "    - New mask: 44 features, Fitness: -4.1630\n",
      "    - New mask: 40 features, Fitness: -3.0275\n",
      "    - New mask: 39 features, Fitness: -1.6781\n",
      "    - New mask: 42 features, Fitness: -3.0434\n",
      "    - New mask: 45 features, Fitness: -4.3309\n",
      "    - New mask: 41 features, Fitness: -3.4855\n",
      "    - New mask: 38 features, Fitness: -2.2634\n",
      "    - New mask: 42 features, Fitness: -3.6051\n",
      "    - New mask: 44 features, Fitness: -3.8011\n",
      "    - New mask: 45 features, Fitness: -4.8964\n",
      "    - New mask: 43 features, Fitness: -4.1582\n",
      "    - New mask: 41 features, Fitness: -2.2376\n",
      "    - New mask: 40 features, Fitness: -2.4047\n",
      "    - New mask: 44 features, Fitness: -4.1234\n",
      "    - New mask: 44 features, Fitness: -4.6568\n",
      "    - New mask: 41 features, Fitness: -2.7785\n",
      "    - New mask: 40 features, Fitness: -2.2042\n",
      "    - New mask: 43 features, Fitness: -3.7596\n",
      "    - New mask: 43 features, Fitness: -3.4162\n",
      "    - New mask: 40 features, Fitness: -2.4731\n",
      "    - New mask: 39 features, Fitness: -2.1694\n",
      "    - New mask: 40 features, Fitness: -2.6800\n",
      "    - New mask: 44 features, Fitness: -4.3915\n",
      "    - New mask: 43 features, Fitness: -3.3087\n",
      "    - New mask: 38 features, Fitness: -2.5389\n",
      "    - New mask: 43 features, Fitness: -3.0881\n",
      "    - New mask: 41 features, Fitness: -2.4079\n",
      "    - New mask: 46 features, Fitness: -5.1937\n",
      "    - New mask: 41 features, Fitness: -2.9033\n",
      "    - New mask: 42 features, Fitness: -2.8835\n",
      "    - New mask: 41 features, Fitness: -2.6672\n",
      "    - New mask: 48 features, Fitness: -6.1144\n",
      "    - New mask: 43 features, Fitness: -2.9826\n",
      "    - New mask: 42 features, Fitness: -3.1332\n",
      "    - New mask: 44 features, Fitness: -3.0216\n",
      "    - New mask: 43 features, Fitness: -3.2611\n",
      "    - New mask: 44 features, Fitness: -3.1273\n",
      "    - New mask: 43 features, Fitness: -3.4448\n",
      "    - New mask: 45 features, Fitness: -4.1489\n",
      "    - New mask: 43 features, Fitness: -5.5797\n",
      "    - New mask: 42 features, Fitness: -5.7521\n",
      "    - New mask: 40 features, Fitness: -5.1522\n",
      "    - New mask: 42 features, Fitness: -5.4342\n",
      "    - New mask: 40 features, Fitness: -4.9446\n",
      "    - New mask: 43 features, Fitness: -5.5751\n",
      "    - New mask: 38 features, Fitness: -4.1536\n",
      "    - New mask: 41 features, Fitness: -5.1786\n",
      "    - New mask: 43 features, Fitness: -6.3480\n",
      "    - New mask: 44 features, Fitness: -6.7236\n",
      "    - New mask: 42 features, Fitness: -6.5552\n",
      "    - New mask: 43 features, Fitness: -6.4717\n",
      "    - New mask: 42 features, Fitness: -5.5060\n",
      "    - New mask: 42 features, Fitness: -5.7353\n",
      "    - New mask: 41 features, Fitness: -5.3783\n",
      "    - New mask: 42 features, Fitness: -5.6127\n",
      "    - New mask: 39 features, Fitness: -3.9713\n",
      "    - New mask: 43 features, Fitness: -5.8575\n",
      "    - New mask: 41 features, Fitness: -5.2666\n",
      "    - New mask: 43 features, Fitness: -5.9755\n",
      "=== End of Round 9: Vote mask selects 45 features (rho: 0.45)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55]\n",
      "\n",
      "================ Federated BFA Round 10 ================\n",
      "  Adaptive rho for this round: 0.48\n",
      "    - New mask: 41 features, Fitness: -1.5968\n",
      "    - New mask: 42 features, Fitness: -1.6892\n",
      "    - New mask: 43 features, Fitness: -1.4794\n",
      "    - New mask: 45 features, Fitness: -3.2423\n",
      "    - New mask: 44 features, Fitness: -2.0328\n",
      "    - New mask: 41 features, Fitness: -1.8677\n",
      "    - New mask: 43 features, Fitness: -2.2381\n",
      "    - New mask: 43 features, Fitness: -2.2706\n",
      "    - New mask: 39 features, Fitness: -0.7933\n",
      "    - New mask: 39 features, Fitness: -1.5179\n",
      "    - New mask: 43 features, Fitness: -2.0436\n",
      "    - New mask: 36 features, Fitness: -0.4223\n",
      "    - New mask: 42 features, Fitness: -1.7423\n",
      "    - New mask: 39 features, Fitness: -0.9436\n",
      "    - New mask: 41 features, Fitness: -1.3343\n",
      "    - New mask: 40 features, Fitness: -1.2885\n",
      "    - New mask: 42 features, Fitness: -1.5081\n",
      "    - New mask: 44 features, Fitness: -2.2508\n",
      "    - New mask: 43 features, Fitness: -1.8308\n",
      "    - New mask: 38 features, Fitness: -0.4393\n",
      "    - New mask: 42 features, Fitness: 0.6682\n",
      "    - New mask: 41 features, Fitness: 0.7941\n",
      "    - New mask: 40 features, Fitness: 1.4725\n",
      "    - New mask: 40 features, Fitness: 1.8077\n",
      "    - New mask: 44 features, Fitness: -0.5158\n",
      "    - New mask: 44 features, Fitness: 0.4442\n",
      "    - New mask: 44 features, Fitness: -0.1567\n",
      "    - New mask: 42 features, Fitness: 1.3736\n",
      "    - New mask: 38 features, Fitness: 2.1822\n",
      "    - New mask: 40 features, Fitness: 1.4031\n",
      "    - New mask: 43 features, Fitness: 0.4458\n",
      "    - New mask: 43 features, Fitness: 0.6151\n",
      "    - New mask: 42 features, Fitness: 0.6184\n",
      "    - New mask: 44 features, Fitness: -0.0372\n",
      "    - New mask: 43 features, Fitness: 0.6119\n",
      "    - New mask: 44 features, Fitness: -0.3250\n",
      "    - New mask: 42 features, Fitness: 0.5536\n",
      "    - New mask: 43 features, Fitness: 0.4223\n",
      "    - New mask: 42 features, Fitness: 0.9227\n",
      "    - New mask: 44 features, Fitness: 0.7689\n",
      "    - New mask: 39 features, Fitness: -1.5444\n",
      "    - New mask: 42 features, Fitness: -3.3309\n",
      "    - New mask: 41 features, Fitness: -2.8189\n",
      "    - New mask: 39 features, Fitness: -1.6477\n",
      "    - New mask: 38 features, Fitness: -1.8779\n",
      "    - New mask: 44 features, Fitness: -5.0097\n",
      "    - New mask: 43 features, Fitness: -4.0719\n",
      "    - New mask: 42 features, Fitness: -2.9722\n",
      "    - New mask: 41 features, Fitness: -2.4351\n",
      "    - New mask: 42 features, Fitness: -3.2236\n",
      "    - New mask: 43 features, Fitness: -3.7710\n",
      "    - New mask: 39 features, Fitness: -1.8881\n",
      "    - New mask: 39 features, Fitness: -2.0103\n",
      "    - New mask: 40 features, Fitness: -2.8785\n",
      "    - New mask: 41 features, Fitness: -2.5074\n",
      "    - New mask: 40 features, Fitness: -2.9639\n",
      "    - New mask: 41 features, Fitness: -2.8646\n",
      "    - New mask: 38 features, Fitness: -1.8705\n",
      "    - New mask: 41 features, Fitness: -2.6280\n",
      "    - New mask: 42 features, Fitness: -3.6301\n",
      "    - New mask: 43 features, Fitness: -4.2975\n",
      "    - New mask: 39 features, Fitness: -2.2788\n",
      "    - New mask: 39 features, Fitness: -1.7653\n",
      "    - New mask: 44 features, Fitness: -4.1980\n",
      "    - New mask: 46 features, Fitness: -4.6923\n",
      "    - New mask: 35 features, Fitness: -1.4477\n",
      "    - New mask: 40 features, Fitness: -2.4082\n",
      "    - New mask: 39 features, Fitness: -2.5692\n",
      "    - New mask: 42 features, Fitness: -3.2112\n",
      "    - New mask: 39 features, Fitness: -2.9668\n",
      "    - New mask: 38 features, Fitness: -2.0188\n",
      "    - New mask: 37 features, Fitness: -1.2238\n",
      "    - New mask: 42 features, Fitness: -2.7809\n",
      "    - New mask: 42 features, Fitness: -3.2141\n",
      "    - New mask: 41 features, Fitness: -2.8987\n",
      "    - New mask: 45 features, Fitness: -3.8191\n",
      "    - New mask: 43 features, Fitness: -4.2981\n",
      "    - New mask: 39 features, Fitness: -2.2302\n",
      "    - New mask: 44 features, Fitness: -4.0896\n",
      "    - New mask: 44 features, Fitness: -3.2848\n",
      "    - New mask: 41 features, Fitness: -5.1983\n",
      "    - New mask: 43 features, Fitness: -6.4422\n",
      "    - New mask: 40 features, Fitness: -4.5243\n",
      "    - New mask: 43 features, Fitness: -5.8302\n",
      "    - New mask: 42 features, Fitness: -5.7388\n",
      "    - New mask: 40 features, Fitness: -4.7521\n",
      "    - New mask: 39 features, Fitness: -3.9664\n",
      "    - New mask: 43 features, Fitness: -6.2199\n",
      "    - New mask: 44 features, Fitness: -6.8639\n",
      "    - New mask: 41 features, Fitness: -5.3824\n",
      "    - New mask: 43 features, Fitness: -6.1600\n",
      "    - New mask: 43 features, Fitness: -5.6099\n",
      "    - New mask: 41 features, Fitness: -5.1365\n",
      "    - New mask: 44 features, Fitness: -6.9468\n",
      "    - New mask: 45 features, Fitness: -7.0259\n",
      "    - New mask: 40 features, Fitness: -4.9161\n",
      "    - New mask: 39 features, Fitness: -3.9722\n",
      "    - New mask: 42 features, Fitness: -5.8657\n",
      "    - New mask: 43 features, Fitness: -6.0917\n",
      "    - New mask: 42 features, Fitness: -5.8229\n",
      "=== End of Round 10: Vote mask selects 44 features (rho: 0.48)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55]\n",
      "\n",
      "================ Federated BFA Round 11 ================\n",
      "  Adaptive rho for this round: 0.52\n",
      "    - New mask: 40 features, Fitness: -1.4529\n",
      "    - New mask: 40 features, Fitness: -1.0084\n",
      "    - New mask: 41 features, Fitness: -1.0593\n",
      "    - New mask: 43 features, Fitness: -2.5347\n",
      "    - New mask: 44 features, Fitness: -2.0718\n",
      "    - New mask: 39 features, Fitness: -0.9151\n",
      "    - New mask: 42 features, Fitness: -1.6485\n",
      "    - New mask: 42 features, Fitness: -1.8457\n",
      "    - New mask: 36 features, Fitness: -0.4225\n",
      "    - New mask: 39 features, Fitness: -1.2601\n",
      "    - New mask: 43 features, Fitness: -1.8959\n",
      "    - New mask: 35 features, Fitness: 0.1144\n",
      "    - New mask: 37 features, Fitness: -0.2697\n",
      "    - New mask: 42 features, Fitness: -2.3226\n",
      "    - New mask: 42 features, Fitness: -1.6692\n",
      "    - New mask: 41 features, Fitness: -1.1193\n",
      "    - New mask: 38 features, Fitness: -0.6099\n",
      "    - New mask: 43 features, Fitness: -2.1408\n",
      "    - New mask: 38 features, Fitness: -0.3521\n",
      "    - New mask: 40 features, Fitness: -1.2323\n",
      "    - New mask: 39 features, Fitness: 1.5506\n",
      "    - New mask: 38 features, Fitness: 1.9309\n",
      "    - New mask: 40 features, Fitness: 1.8822\n",
      "    - New mask: 40 features, Fitness: 1.5736\n",
      "    - New mask: 43 features, Fitness: 0.5370\n",
      "    - New mask: 41 features, Fitness: 0.9362\n",
      "    - New mask: 40 features, Fitness: 1.3338\n",
      "    - New mask: 40 features, Fitness: 1.7402\n",
      "    - New mask: 39 features, Fitness: 1.8992\n",
      "    - New mask: 38 features, Fitness: 1.6045\n",
      "    - New mask: 40 features, Fitness: 1.1775\n",
      "    - New mask: 42 features, Fitness: 0.8935\n",
      "    - New mask: 43 features, Fitness: 0.7006\n",
      "    - New mask: 45 features, Fitness: -0.5496\n",
      "    - New mask: 44 features, Fitness: 0.7134\n",
      "    - New mask: 39 features, Fitness: 2.0972\n",
      "    - New mask: 44 features, Fitness: 0.6193\n",
      "    - New mask: 38 features, Fitness: 1.6604\n",
      "    - New mask: 38 features, Fitness: 1.6664\n",
      "    - New mask: 39 features, Fitness: 1.5943\n",
      "    - New mask: 40 features, Fitness: -2.4065\n",
      "    - New mask: 41 features, Fitness: -2.6869\n",
      "    - New mask: 41 features, Fitness: -2.8255\n",
      "    - New mask: 39 features, Fitness: -1.7112\n",
      "    - New mask: 40 features, Fitness: -2.4824\n",
      "    - New mask: 42 features, Fitness: -3.3611\n",
      "    - New mask: 44 features, Fitness: -3.9028\n",
      "    - New mask: 42 features, Fitness: -2.9802\n",
      "    - New mask: 40 features, Fitness: -2.2061\n",
      "    - New mask: 42 features, Fitness: -3.0263\n",
      "    - New mask: 41 features, Fitness: -2.8551\n",
      "    - New mask: 39 features, Fitness: -2.0476\n",
      "    - New mask: 41 features, Fitness: -2.6299\n",
      "    - New mask: 41 features, Fitness: -2.6932\n",
      "    - New mask: 39 features, Fitness: -2.3438\n",
      "    - New mask: 36 features, Fitness: -0.7652\n",
      "    - New mask: 42 features, Fitness: -3.4534\n",
      "    - New mask: 40 features, Fitness: -2.2762\n",
      "    - New mask: 40 features, Fitness: -2.2096\n",
      "    - New mask: 37 features, Fitness: -1.1800\n",
      "    - New mask: 38 features, Fitness: -1.8720\n",
      "    - New mask: 39 features, Fitness: -2.0517\n",
      "    - New mask: 40 features, Fitness: -2.1246\n",
      "    - New mask: 46 features, Fitness: -5.4723\n",
      "    - New mask: 44 features, Fitness: -3.2077\n",
      "    - New mask: 34 features, Fitness: -0.9443\n",
      "    - New mask: 36 features, Fitness: -1.7511\n",
      "    - New mask: 39 features, Fitness: -1.7915\n",
      "    - New mask: 41 features, Fitness: -2.3061\n",
      "    - New mask: 39 features, Fitness: -2.0409\n",
      "    - New mask: 42 features, Fitness: -3.0901\n",
      "    - New mask: 37 features, Fitness: -0.7932\n",
      "    - New mask: 41 features, Fitness: -2.6872\n",
      "    - New mask: 41 features, Fitness: -2.4274\n",
      "    - New mask: 40 features, Fitness: -1.8214\n",
      "    - New mask: 41 features, Fitness: -2.1143\n",
      "    - New mask: 42 features, Fitness: -3.5872\n",
      "    - New mask: 38 features, Fitness: -1.4161\n",
      "    - New mask: 43 features, Fitness: -3.8971\n",
      "    - New mask: 41 features, Fitness: -1.8395\n",
      "    - New mask: 39 features, Fitness: -4.2877\n",
      "    - New mask: 37 features, Fitness: -3.5741\n",
      "    - New mask: 38 features, Fitness: -3.9373\n",
      "    - New mask: 43 features, Fitness: -5.5090\n",
      "    - New mask: 43 features, Fitness: -5.6105\n",
      "    - New mask: 40 features, Fitness: -4.7923\n",
      "    - New mask: 41 features, Fitness: -4.9420\n",
      "    - New mask: 43 features, Fitness: -6.0449\n",
      "    - New mask: 41 features, Fitness: -4.9091\n",
      "    - New mask: 40 features, Fitness: -4.9287\n",
      "    - New mask: 41 features, Fitness: -5.7703\n",
      "    - New mask: 42 features, Fitness: -5.2403\n",
      "    - New mask: 43 features, Fitness: -5.4777\n",
      "    - New mask: 43 features, Fitness: -6.2841\n",
      "    - New mask: 40 features, Fitness: -4.8108\n",
      "    - New mask: 40 features, Fitness: -4.4967\n",
      "    - New mask: 39 features, Fitness: -4.1305\n",
      "    - New mask: 42 features, Fitness: -5.2515\n",
      "    - New mask: 42 features, Fitness: -5.7536\n",
      "    - New mask: 45 features, Fitness: -7.6650\n",
      "=== End of Round 11: Vote mask selects 42 features (rho: 0.52)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55]\n",
      "\n",
      "================ Federated BFA Round 12 ================\n",
      "  Adaptive rho for this round: 0.55\n",
      "    - New mask: 38 features, Fitness: -0.6345\n",
      "    - New mask: 39 features, Fitness: -0.8393\n",
      "    - New mask: 40 features, Fitness: -1.1548\n",
      "    - New mask: 37 features, Fitness: -0.4757\n",
      "    - New mask: 40 features, Fitness: -0.7457\n",
      "    - New mask: 35 features, Fitness: -0.2127\n",
      "    - New mask: 42 features, Fitness: -1.5304\n",
      "    - New mask: 40 features, Fitness: -1.2681\n",
      "    - New mask: 38 features, Fitness: -0.3532\n",
      "    - New mask: 36 features, Fitness: -0.4942\n",
      "    - New mask: 41 features, Fitness: -1.6686\n",
      "    - New mask: 35 features, Fitness: -0.0882\n",
      "    - New mask: 38 features, Fitness: -0.3669\n",
      "    - New mask: 40 features, Fitness: -1.5122\n",
      "    - New mask: 37 features, Fitness: -0.1657\n",
      "    - New mask: 42 features, Fitness: -1.7923\n",
      "    - New mask: 38 features, Fitness: -0.8530\n",
      "    - New mask: 38 features, Fitness: -0.7610\n",
      "    - New mask: 42 features, Fitness: -1.5121\n",
      "    - New mask: 41 features, Fitness: -1.7859\n",
      "    - New mask: 42 features, Fitness: 1.0263\n",
      "    - New mask: 40 features, Fitness: 1.7407\n",
      "    - New mask: 39 features, Fitness: 2.1727\n",
      "    - New mask: 38 features, Fitness: 1.6432\n",
      "    - New mask: 38 features, Fitness: 1.7166\n",
      "    - New mask: 40 features, Fitness: 1.1749\n",
      "    - New mask: 39 features, Fitness: 1.8732\n",
      "    - New mask: 41 features, Fitness: 1.2825\n",
      "    - New mask: 37 features, Fitness: 2.4240\n",
      "    - New mask: 40 features, Fitness: 1.4164\n",
      "    - New mask: 40 features, Fitness: 1.7396\n",
      "    - New mask: 41 features, Fitness: 1.4175\n",
      "    - New mask: 42 features, Fitness: 1.2647\n",
      "    - New mask: 46 features, Fitness: -0.0001\n",
      "    - New mask: 40 features, Fitness: 1.4639\n",
      "    - New mask: 39 features, Fitness: 1.9014\n",
      "    - New mask: 39 features, Fitness: 2.0547\n",
      "    - New mask: 41 features, Fitness: 1.1516\n",
      "    - New mask: 41 features, Fitness: 0.3649\n",
      "    - New mask: 40 features, Fitness: 1.6255\n",
      "    - New mask: 40 features, Fitness: -2.6106\n",
      "    - New mask: 42 features, Fitness: -3.6380\n",
      "    - New mask: 38 features, Fitness: -1.6610\n",
      "    - New mask: 37 features, Fitness: -1.7316\n",
      "    - New mask: 36 features, Fitness: -1.6131\n",
      "    - New mask: 38 features, Fitness: -2.0872\n",
      "    - New mask: 39 features, Fitness: -2.4920\n",
      "    - New mask: 39 features, Fitness: -2.1045\n",
      "    - New mask: 37 features, Fitness: -1.2380\n",
      "    - New mask: 40 features, Fitness: -2.8197\n",
      "    - New mask: 41 features, Fitness: -2.9247\n",
      "    - New mask: 40 features, Fitness: -2.4498\n",
      "    - New mask: 38 features, Fitness: -1.9799\n",
      "    - New mask: 36 features, Fitness: -0.8405\n",
      "    - New mask: 40 features, Fitness: -2.4003\n",
      "    - New mask: 41 features, Fitness: -2.7171\n",
      "    - New mask: 41 features, Fitness: -2.8203\n",
      "    - New mask: 39 features, Fitness: -2.0856\n",
      "    - New mask: 32 features, Fitness: -0.0377\n",
      "    - New mask: 36 features, Fitness: -1.3117\n",
      "    - New mask: 40 features, Fitness: -1.8188\n",
      "    - New mask: 41 features, Fitness: -2.3073\n",
      "    - New mask: 38 features, Fitness: -1.8262\n",
      "    - New mask: 41 features, Fitness: -3.0706\n",
      "    - New mask: 38 features, Fitness: -1.1936\n",
      "    - New mask: 42 features, Fitness: -2.2964\n",
      "    - New mask: 37 features, Fitness: -1.3613\n",
      "    - New mask: 41 features, Fitness: -2.7026\n",
      "    - New mask: 39 features, Fitness: -1.5853\n",
      "    - New mask: 39 features, Fitness: -1.8360\n",
      "    - New mask: 37 features, Fitness: -1.0944\n",
      "    - New mask: 37 features, Fitness: -1.1731\n",
      "    - New mask: 40 features, Fitness: -1.9229\n",
      "    - New mask: 42 features, Fitness: -2.5146\n",
      "    - New mask: 42 features, Fitness: -2.5924\n",
      "    - New mask: 42 features, Fitness: -2.7968\n",
      "    - New mask: 44 features, Fitness: -3.6885\n",
      "    - New mask: 41 features, Fitness: -1.9554\n",
      "    - New mask: 43 features, Fitness: -3.5082\n",
      "    - New mask: 42 features, Fitness: -2.4246\n",
      "    - New mask: 37 features, Fitness: -3.6681\n",
      "    - New mask: 39 features, Fitness: -4.0082\n",
      "    - New mask: 38 features, Fitness: -4.0551\n",
      "    - New mask: 42 features, Fitness: -5.5174\n",
      "    - New mask: 40 features, Fitness: -4.7191\n",
      "    - New mask: 41 features, Fitness: -5.2854\n",
      "    - New mask: 37 features, Fitness: -3.5361\n",
      "    - New mask: 41 features, Fitness: -4.5538\n",
      "    - New mask: 41 features, Fitness: -4.8395\n",
      "    - New mask: 37 features, Fitness: -3.6570\n",
      "    - New mask: 40 features, Fitness: -5.2978\n",
      "    - New mask: 38 features, Fitness: -4.3084\n",
      "    - New mask: 41 features, Fitness: -4.6155\n",
      "    - New mask: 37 features, Fitness: -3.5628\n",
      "    - New mask: 38 features, Fitness: -3.9777\n",
      "    - New mask: 40 features, Fitness: -4.8199\n",
      "    - New mask: 38 features, Fitness: -4.0406\n",
      "    - New mask: 43 features, Fitness: -6.2015\n",
      "    - New mask: 39 features, Fitness: -4.7517\n",
      "    - New mask: 39 features, Fitness: -5.9280\n",
      "=== End of Round 12: Vote mask selects 41 features (rho: 0.55)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 29, 32, 34, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55]\n",
      "\n",
      "================ Federated BFA Round 13 ================\n",
      "  Adaptive rho for this round: 0.58\n",
      "    - New mask: 39 features, Fitness: -1.0668\n",
      "    - New mask: 38 features, Fitness: -0.5046\n",
      "    - New mask: 39 features, Fitness: -1.1376\n",
      "    - New mask: 39 features, Fitness: -0.8054\n",
      "    - New mask: 41 features, Fitness: -1.3472\n",
      "    - New mask: 35 features, Fitness: -0.2941\n",
      "    - New mask: 35 features, Fitness: 0.4955\n",
      "    - New mask: 38 features, Fitness: -0.5052\n",
      "    - New mask: 36 features, Fitness: -0.0505\n",
      "    - New mask: 36 features, Fitness: 0.0096\n",
      "    - New mask: 39 features, Fitness: -0.9646\n",
      "    - New mask: 36 features, Fitness: -0.5166\n",
      "    - New mask: 39 features, Fitness: -0.9246\n",
      "    - New mask: 39 features, Fitness: -1.2681\n",
      "    - New mask: 36 features, Fitness: -0.0738\n",
      "    - New mask: 38 features, Fitness: -0.2608\n",
      "    - New mask: 36 features, Fitness: 0.3627\n",
      "    - New mask: 36 features, Fitness: -0.5368\n",
      "    - New mask: 39 features, Fitness: -0.8921\n",
      "    - New mask: 40 features, Fitness: -1.6166\n",
      "    - New mask: 39 features, Fitness: 2.0897\n",
      "    - New mask: 40 features, Fitness: 1.7494\n",
      "    - New mask: 38 features, Fitness: 2.3582\n",
      "    - New mask: 40 features, Fitness: 1.5124\n",
      "    - New mask: 36 features, Fitness: 2.2625\n",
      "    - New mask: 38 features, Fitness: 1.7943\n",
      "    - New mask: 39 features, Fitness: 1.5147\n",
      "    - New mask: 40 features, Fitness: 1.1455\n",
      "    - New mask: 41 features, Fitness: 1.3434\n",
      "    - New mask: 38 features, Fitness: 2.1562\n",
      "    - New mask: 40 features, Fitness: 1.7495\n",
      "    - New mask: 39 features, Fitness: 1.4501\n",
      "    - New mask: 39 features, Fitness: 1.6838\n",
      "    - New mask: 41 features, Fitness: 1.5418\n",
      "    - New mask: 41 features, Fitness: 0.5331\n",
      "    - New mask: 39 features, Fitness: 1.5352\n",
      "    - New mask: 39 features, Fitness: 1.8726\n",
      "    - New mask: 39 features, Fitness: 1.3429\n",
      "    - New mask: 39 features, Fitness: 1.6956\n",
      "    - New mask: 41 features, Fitness: 1.2581\n",
      "    - New mask: 39 features, Fitness: -1.9670\n",
      "    - New mask: 40 features, Fitness: -2.7585\n",
      "    - New mask: 38 features, Fitness: -1.8217\n",
      "    - New mask: 37 features, Fitness: -1.3499\n",
      "    - New mask: 34 features, Fitness: -0.8472\n",
      "    - New mask: 35 features, Fitness: -1.4993\n",
      "    - New mask: 37 features, Fitness: -2.0991\n",
      "    - New mask: 37 features, Fitness: -1.7190\n",
      "    - New mask: 36 features, Fitness: -0.7404\n",
      "    - New mask: 38 features, Fitness: -2.1772\n",
      "    - New mask: 38 features, Fitness: -2.1163\n",
      "    - New mask: 41 features, Fitness: -3.1724\n",
      "    - New mask: 35 features, Fitness: -1.3438\n",
      "    - New mask: 35 features, Fitness: -0.9812\n",
      "    - New mask: 39 features, Fitness: -2.2222\n",
      "    - New mask: 37 features, Fitness: -1.5132\n",
      "    - New mask: 39 features, Fitness: -2.3628\n",
      "    - New mask: 38 features, Fitness: -2.2557\n",
      "    - New mask: 37 features, Fitness: -1.3840\n",
      "    - New mask: 36 features, Fitness: -1.1445\n",
      "    - New mask: 40 features, Fitness: -1.9092\n",
      "    - New mask: 40 features, Fitness: -2.1402\n",
      "    - New mask: 36 features, Fitness: -1.4315\n",
      "    - New mask: 40 features, Fitness: -1.7678\n",
      "    - New mask: 36 features, Fitness: -0.9510\n",
      "    - New mask: 40 features, Fitness: -1.8792\n",
      "    - New mask: 36 features, Fitness: -1.1850\n",
      "    - New mask: 38 features, Fitness: -1.4913\n",
      "    - New mask: 35 features, Fitness: -0.8028\n",
      "    - New mask: 35 features, Fitness: -1.0067\n",
      "    - New mask: 37 features, Fitness: -1.1470\n",
      "    - New mask: 38 features, Fitness: -1.3442\n",
      "    - New mask: 40 features, Fitness: -2.2303\n",
      "    - New mask: 41 features, Fitness: -2.2612\n",
      "    - New mask: 41 features, Fitness: -2.4426\n",
      "    - New mask: 41 features, Fitness: -2.8942\n",
      "    - New mask: 40 features, Fitness: -3.0660\n",
      "    - New mask: 42 features, Fitness: -2.4972\n",
      "    - New mask: 43 features, Fitness: -3.2929\n",
      "    - New mask: 41 features, Fitness: -2.4138\n",
      "    - New mask: 40 features, Fitness: -4.9684\n",
      "    - New mask: 36 features, Fitness: -3.0603\n",
      "    - New mask: 38 features, Fitness: -3.9175\n",
      "    - New mask: 39 features, Fitness: -4.2170\n",
      "    - New mask: 39 features, Fitness: -4.5323\n",
      "    - New mask: 39 features, Fitness: -4.7526\n",
      "    - New mask: 37 features, Fitness: -3.5361\n",
      "    - New mask: 36 features, Fitness: -2.9073\n",
      "    - New mask: 41 features, Fitness: -5.5597\n",
      "    - New mask: 39 features, Fitness: -4.3982\n",
      "    - New mask: 38 features, Fitness: -4.8432\n",
      "    - New mask: 36 features, Fitness: -3.2287\n",
      "    - New mask: 37 features, Fitness: -3.1352\n",
      "    - New mask: 36 features, Fitness: -3.1968\n",
      "    - New mask: 37 features, Fitness: -3.7531\n",
      "    - New mask: 39 features, Fitness: -4.1984\n",
      "    - New mask: 40 features, Fitness: -4.5465\n",
      "    - New mask: 39 features, Fitness: -4.2748\n",
      "    - New mask: 41 features, Fitness: -5.2424\n",
      "    - New mask: 37 features, Fitness: -4.1179\n",
      "=== End of Round 13: Vote mask selects 40 features (rho: 0.58)\n",
      "    Indices: [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55]\n",
      "\n",
      "================ Federated BFA Round 14 ================\n",
      "  Adaptive rho for this round: 0.61\n",
      "    - New mask: 39 features, Fitness: -1.0146\n",
      "    - New mask: 36 features, Fitness: 0.0914\n",
      "    - New mask: 40 features, Fitness: -1.2161\n",
      "    - New mask: 38 features, Fitness: -0.0833\n",
      "    - New mask: 39 features, Fitness: -0.5010\n",
      "    - New mask: 32 features, Fitness: 1.0598\n",
      "    - New mask: 36 features, Fitness: 0.3491\n",
      "    - New mask: 37 features, Fitness: -0.2919\n",
      "    - New mask: 36 features, Fitness: 0.4257\n",
      "    - New mask: 38 features, Fitness: -0.3866\n",
      "    - New mask: 36 features, Fitness: 0.3404\n",
      "    - New mask: 38 features, Fitness: -0.7304\n",
      "    - New mask: 37 features, Fitness: 0.0970\n",
      "    - New mask: 36 features, Fitness: -0.0559\n",
      "    - New mask: 38 features, Fitness: -0.7141\n",
      "    - New mask: 38 features, Fitness: -0.1776\n",
      "    - New mask: 34 features, Fitness: 0.5701\n",
      "    - New mask: 40 features, Fitness: -0.9994\n",
      "    - New mask: 36 features, Fitness: -0.0817\n",
      "    - New mask: 37 features, Fitness: 0.1632\n",
      "    - New mask: 40 features, Fitness: 1.8609\n",
      "    - New mask: 38 features, Fitness: 1.8501\n",
      "    - New mask: 39 features, Fitness: 2.2315\n",
      "    - New mask: 38 features, Fitness: 2.0206\n",
      "    - New mask: 39 features, Fitness: 1.5643\n",
      "    - New mask: 38 features, Fitness: 2.4536\n",
      "    - New mask: 41 features, Fitness: 1.3993\n",
      "    - New mask: 38 features, Fitness: 1.9472\n",
      "    - New mask: 38 features, Fitness: 2.1000\n",
      "    - New mask: 39 features, Fitness: 1.8389\n",
      "    - New mask: 41 features, Fitness: 1.5396\n",
      "    - New mask: 38 features, Fitness: 1.9446\n",
      "    - New mask: 36 features, Fitness: 1.7026\n",
      "    - New mask: 39 features, Fitness: 2.0761\n",
      "    - New mask: 42 features, Fitness: 1.1593\n",
      "    - New mask: 39 features, Fitness: 2.1835\n",
      "    - New mask: 38 features, Fitness: 2.4847\n",
      "    - New mask: 35 features, Fitness: 2.0201\n",
      "    - New mask: 39 features, Fitness: 1.7550\n",
      "    - New mask: 40 features, Fitness: 1.9181\n",
      "    - New mask: 43 features, Fitness: -3.5925\n",
      "    - New mask: 38 features, Fitness: -2.2204\n",
      "    - New mask: 41 features, Fitness: -2.6618\n",
      "    - New mask: 35 features, Fitness: -0.4461\n",
      "    - New mask: 37 features, Fitness: -1.5782\n",
      "    - New mask: 37 features, Fitness: -1.0545\n",
      "    - New mask: 39 features, Fitness: -2.4915\n",
      "    - New mask: 34 features, Fitness: -0.2187\n",
      "    - New mask: 39 features, Fitness: -2.0694\n",
      "    - New mask: 38 features, Fitness: -1.5631\n",
      "    - New mask: 38 features, Fitness: -2.1977\n",
      "    - New mask: 36 features, Fitness: -1.5044\n",
      "    - New mask: 36 features, Fitness: -1.7249\n",
      "    - New mask: 37 features, Fitness: -1.2248\n",
      "    - New mask: 36 features, Fitness: -1.0460\n",
      "    - New mask: 34 features, Fitness: -0.6536\n",
      "    - New mask: 35 features, Fitness: -0.7128\n",
      "    - New mask: 40 features, Fitness: -3.1775\n",
      "    - New mask: 37 features, Fitness: -1.3427\n",
      "    - New mask: 38 features, Fitness: -1.4929\n",
      "    - New mask: 40 features, Fitness: -1.8249\n",
      "    - New mask: 40 features, Fitness: -1.7343\n",
      "    - New mask: 34 features, Fitness: -1.2095\n",
      "    - New mask: 37 features, Fitness: -1.2013\n",
      "    - New mask: 38 features, Fitness: -1.6759\n",
      "    - New mask: 39 features, Fitness: -1.5242\n",
      "    - New mask: 35 features, Fitness: -0.7904\n",
      "    - New mask: 40 features, Fitness: -2.4116\n",
      "    - New mask: 36 features, Fitness: -0.9829\n",
      "    - New mask: 33 features, Fitness: 0.2134\n",
      "    - New mask: 33 features, Fitness: -0.3889\n",
      "    - New mask: 36 features, Fitness: -0.8446\n",
      "    - New mask: 40 features, Fitness: -2.3391\n",
      "    - New mask: 40 features, Fitness: -2.1271\n",
      "    - New mask: 38 features, Fitness: -1.8781\n",
      "    - New mask: 41 features, Fitness: -2.6488\n",
      "    - New mask: 39 features, Fitness: -2.0770\n",
      "    - New mask: 39 features, Fitness: -1.8874\n",
      "    - New mask: 41 features, Fitness: -2.6417\n",
      "    - New mask: 39 features, Fitness: -2.0460\n",
      "    - New mask: 40 features, Fitness: -4.5330\n",
      "    - New mask: 40 features, Fitness: -4.0627\n",
      "    - New mask: 36 features, Fitness: -3.2330\n",
      "    - New mask: 37 features, Fitness: -3.2640\n",
      "    - New mask: 36 features, Fitness: -3.2094\n",
      "    - New mask: 37 features, Fitness: -3.4829\n",
      "    - New mask: 35 features, Fitness: -2.5408\n",
      "    - New mask: 37 features, Fitness: -3.1982\n",
      "    - New mask: 35 features, Fitness: -2.8153\n",
      "    - New mask: 36 features, Fitness: -3.2072\n",
      "    - New mask: 41 features, Fitness: -4.9584\n",
      "    - New mask: 34 features, Fitness: -3.1822\n",
      "    - New mask: 39 features, Fitness: -4.2214\n",
      "    - New mask: 38 features, Fitness: -4.2459\n",
      "    - New mask: 37 features, Fitness: -3.1148\n",
      "    - New mask: 39 features, Fitness: -4.3412\n",
      "    - New mask: 40 features, Fitness: -4.3383\n",
      "    - New mask: 37 features, Fitness: -3.2606\n",
      "    - New mask: 36 features, Fitness: -2.9522\n",
      "    - New mask: 39 features, Fitness: -4.2617\n",
      "=== End of Round 14: Vote mask selects 33 features (rho: 0.61)\n",
      "    Indices: [3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 20, 22, 23, 24, 25, 26, 32, 34, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 55]\n",
      "\n",
      "================ Federated BFA Round 15 ================\n",
      "  Adaptive rho for this round: 0.64\n",
      "    - New mask: 33 features, Fitness: 1.3013\n",
      "    - New mask: 31 features, Fitness: 1.3316\n",
      "    - New mask: 37 features, Fitness: -0.1915\n",
      "    - New mask: 32 features, Fitness: 1.1686\n",
      "    - New mask: 36 features, Fitness: 0.6411\n",
      "    - New mask: 35 features, Fitness: 0.4094\n",
      "    - New mask: 33 features, Fitness: 0.9171\n",
      "    - New mask: 34 features, Fitness: 0.6164\n",
      "    - New mask: 31 features, Fitness: 1.3546\n",
      "    - New mask: 35 features, Fitness: 1.0451\n",
      "    - New mask: 32 features, Fitness: 1.6162\n",
      "    - New mask: 36 features, Fitness: -0.1080\n",
      "    - New mask: 31 features, Fitness: 1.7037\n",
      "    - New mask: 34 features, Fitness: 0.5208\n",
      "    - New mask: 35 features, Fitness: 0.4874\n",
      "    - New mask: 34 features, Fitness: 0.8604\n",
      "    - New mask: 33 features, Fitness: 1.3120\n",
      "    - New mask: 39 features, Fitness: -0.5603\n",
      "    - New mask: 31 features, Fitness: 1.0842\n",
      "    - New mask: 32 features, Fitness: 0.8095\n",
      "    - New mask: 39 features, Fitness: 2.0008\n",
      "    - New mask: 38 features, Fitness: 1.7450\n",
      "    - New mask: 36 features, Fitness: 2.8238\n",
      "    - New mask: 38 features, Fitness: 2.1715\n",
      "    - New mask: 34 features, Fitness: 2.8333\n",
      "    - New mask: 33 features, Fitness: 3.1998\n",
      "    - New mask: 36 features, Fitness: 2.7564\n",
      "    - New mask: 37 features, Fitness: 2.1571\n",
      "    - New mask: 36 features, Fitness: 2.7125\n",
      "    - New mask: 34 features, Fitness: 2.6436\n",
      "    - New mask: 38 features, Fitness: 2.2206\n",
      "    - New mask: 36 features, Fitness: 2.3007\n",
      "    - New mask: 36 features, Fitness: 2.2411\n",
      "    - New mask: 32 features, Fitness: 2.9265\n",
      "    - New mask: 38 features, Fitness: 1.5542\n",
      "    - New mask: 38 features, Fitness: 2.3264\n",
      "    - New mask: 35 features, Fitness: 2.5883\n",
      "    - New mask: 36 features, Fitness: 1.9363\n",
      "    - New mask: 35 features, Fitness: 2.5664\n",
      "    - New mask: 40 features, Fitness: 1.7803\n",
      "    - New mask: 34 features, Fitness: -0.1956\n",
      "    - New mask: 38 features, Fitness: -1.8048\n",
      "    - New mask: 38 features, Fitness: -1.6346\n",
      "    - New mask: 31 features, Fitness: 0.3551\n",
      "    - New mask: 36 features, Fitness: -0.9523\n",
      "    - New mask: 37 features, Fitness: -1.1641\n",
      "    - New mask: 34 features, Fitness: -0.4069\n",
      "    - New mask: 36 features, Fitness: -1.0231\n",
      "    - New mask: 36 features, Fitness: -1.0860\n",
      "    - New mask: 34 features, Fitness: -0.9329\n",
      "    - New mask: 35 features, Fitness: -0.8313\n",
      "    - New mask: 31 features, Fitness: 0.3477\n",
      "    - New mask: 35 features, Fitness: -1.1438\n",
      "    - New mask: 35 features, Fitness: -0.7903\n",
      "    - New mask: 33 features, Fitness: -0.2752\n",
      "    - New mask: 31 features, Fitness: 0.4175\n",
      "    - New mask: 35 features, Fitness: -1.1253\n",
      "    - New mask: 31 features, Fitness: -0.5872\n",
      "    - New mask: 34 features, Fitness: -0.2422\n",
      "    - New mask: 34 features, Fitness: -0.4598\n",
      "    - New mask: 38 features, Fitness: -0.9949\n",
      "    - New mask: 35 features, Fitness: -0.5479\n",
      "    - New mask: 37 features, Fitness: -1.2166\n",
      "    - New mask: 33 features, Fitness: -0.0439\n",
      "    - New mask: 38 features, Fitness: -1.4063\n",
      "    - New mask: 36 features, Fitness: -0.5725\n",
      "    - New mask: 35 features, Fitness: -0.8618\n",
      "    - New mask: 36 features, Fitness: -1.2196\n",
      "    - New mask: 38 features, Fitness: -1.6302\n",
      "    - New mask: 33 features, Fitness: 0.0344\n",
      "    - New mask: 32 features, Fitness: 0.2566\n",
      "    - New mask: 33 features, Fitness: -0.2552\n",
      "    - New mask: 39 features, Fitness: -1.6611\n",
      "    - New mask: 36 features, Fitness: -0.8988\n",
      "    - New mask: 33 features, Fitness: -0.0713\n",
      "    - New mask: 35 features, Fitness: -0.5303\n",
      "    - New mask: 35 features, Fitness: -0.3802\n",
      "    - New mask: 35 features, Fitness: -0.8295\n",
      "    - New mask: 36 features, Fitness: -1.1445\n",
      "    - New mask: 34 features, Fitness: -0.7971\n",
      "    - New mask: 37 features, Fitness: -3.8915\n",
      "    - New mask: 36 features, Fitness: -2.5232\n",
      "    - New mask: 37 features, Fitness: -3.4374\n",
      "    - New mask: 34 features, Fitness: -2.4343\n",
      "    - New mask: 37 features, Fitness: -3.8775\n",
      "    - New mask: 35 features, Fitness: -2.6562\n",
      "    - New mask: 34 features, Fitness: -2.3647\n",
      "    - New mask: 35 features, Fitness: -2.7370\n",
      "    - New mask: 34 features, Fitness: -2.4099\n",
      "    - New mask: 32 features, Fitness: -1.8130\n",
      "    - New mask: 35 features, Fitness: -2.4125\n",
      "    - New mask: 36 features, Fitness: -3.7962\n",
      "    - New mask: 34 features, Fitness: -2.6304\n",
      "    - New mask: 35 features, Fitness: -2.8922\n",
      "    - New mask: 35 features, Fitness: -2.8037\n",
      "    - New mask: 36 features, Fitness: -3.5755\n",
      "    - New mask: 32 features, Fitness: -1.5332\n",
      "    - New mask: 31 features, Fitness: -1.8855\n",
      "    - New mask: 36 features, Fitness: -2.6284\n",
      "    - New mask: 35 features, Fitness: -2.9074\n",
      "=== End of Round 15: Vote mask selects 30 features (rho: 0.64)\n",
      "    Indices: [3, 4, 5, 6, 7, 11, 13, 15, 16, 17, 20, 22, 23, 24, 25, 26, 32, 34, 37, 38, 40, 41, 44, 46, 47, 50, 51, 52, 53, 55]\n",
      "\n",
      "================ Federated BFA Round 16 ================\n",
      "  Adaptive rho for this round: 0.67\n",
      "    - New mask: 27 features, Fitness: 2.4741\n",
      "    - New mask: 35 features, Fitness: 0.4044\n",
      "    - New mask: 32 features, Fitness: 1.1909\n",
      "    - New mask: 34 features, Fitness: 0.8009\n",
      "    - New mask: 31 features, Fitness: 1.4746\n",
      "    - New mask: 28 features, Fitness: 1.8718\n",
      "    - New mask: 32 features, Fitness: 1.0063\n",
      "    - New mask: 28 features, Fitness: 2.0436\n",
      "    - New mask: 33 features, Fitness: 1.2028\n",
      "    - New mask: 32 features, Fitness: 1.6380\n",
      "    - New mask: 30 features, Fitness: 1.9899\n",
      "    - New mask: 29 features, Fitness: 2.1445\n",
      "    - New mask: 33 features, Fitness: 0.8014\n",
      "    - New mask: 28 features, Fitness: 1.9147\n",
      "    - New mask: 30 features, Fitness: 1.4013\n",
      "    - New mask: 35 features, Fitness: 0.3966\n",
      "    - New mask: 32 features, Fitness: 1.4439\n",
      "    - New mask: 35 features, Fitness: 0.4499\n",
      "    - New mask: 33 features, Fitness: 1.1333\n",
      "    - New mask: 36 features, Fitness: 0.2892\n",
      "    - New mask: 34 features, Fitness: 2.8667\n",
      "    - New mask: 35 features, Fitness: 2.5799\n",
      "    - New mask: 35 features, Fitness: 2.7443\n",
      "    - New mask: 34 features, Fitness: 2.8155\n",
      "    - New mask: 31 features, Fitness: 2.0476\n",
      "    - New mask: 33 features, Fitness: 3.1181\n",
      "    - New mask: 33 features, Fitness: 2.8957\n",
      "    - New mask: 35 features, Fitness: 2.3445\n",
      "    - New mask: 32 features, Fitness: 3.4870\n",
      "    - New mask: 32 features, Fitness: 2.8738\n",
      "    - New mask: 32 features, Fitness: 3.4248\n",
      "    - New mask: 35 features, Fitness: 2.7597\n",
      "    - New mask: 31 features, Fitness: 2.8321\n",
      "    - New mask: 33 features, Fitness: 2.6429\n",
      "    - New mask: 34 features, Fitness: 2.4724\n",
      "    - New mask: 33 features, Fitness: 3.1691\n",
      "    - New mask: 33 features, Fitness: 3.3963\n",
      "    - New mask: 34 features, Fitness: 2.9825\n",
      "    - New mask: 33 features, Fitness: 3.0921\n",
      "    - New mask: 33 features, Fitness: 3.0649\n",
      "    - New mask: 30 features, Fitness: 0.4078\n",
      "    - New mask: 33 features, Fitness: -0.1573\n",
      "    - New mask: 34 features, Fitness: -0.4831\n",
      "    - New mask: 30 features, Fitness: 0.6054\n",
      "    - New mask: 33 features, Fitness: -0.4522\n",
      "    - New mask: 34 features, Fitness: -0.4055\n",
      "    - New mask: 30 features, Fitness: -0.0416\n",
      "    - New mask: 31 features, Fitness: 0.5030\n",
      "    - New mask: 33 features, Fitness: -0.1741\n",
      "    - New mask: 31 features, Fitness: 0.0011\n",
      "    - New mask: 32 features, Fitness: 0.0292\n",
      "    - New mask: 26 features, Fitness: 0.8615\n",
      "    - New mask: 31 features, Fitness: 0.2473\n",
      "    - New mask: 34 features, Fitness: -0.3619\n",
      "    - New mask: 31 features, Fitness: 0.1630\n",
      "    - New mask: 30 features, Fitness: 0.6977\n",
      "    - New mask: 31 features, Fitness: -0.2224\n",
      "    - New mask: 31 features, Fitness: 0.0399\n",
      "    - New mask: 30 features, Fitness: 0.1969\n",
      "    - New mask: 36 features, Fitness: -1.3826\n",
      "    - New mask: 33 features, Fitness: 0.0433\n",
      "    - New mask: 31 features, Fitness: 0.4580\n",
      "    - New mask: 33 features, Fitness: 0.3993\n",
      "    - New mask: 34 features, Fitness: -0.2219\n",
      "    - New mask: 33 features, Fitness: -0.0389\n",
      "    - New mask: 35 features, Fitness: -0.4758\n",
      "    - New mask: 34 features, Fitness: -0.4493\n",
      "    - New mask: 38 features, Fitness: -1.1057\n",
      "    - New mask: 37 features, Fitness: -2.1659\n",
      "    - New mask: 31 features, Fitness: 0.4090\n",
      "    - New mask: 31 features, Fitness: 0.4273\n",
      "    - New mask: 30 features, Fitness: 0.1991\n",
      "    - New mask: 35 features, Fitness: -1.1737\n",
      "    - New mask: 31 features, Fitness: -0.0669\n",
      "    - New mask: 31 features, Fitness: 0.5037\n",
      "    - New mask: 32 features, Fitness: 0.1617\n",
      "    - New mask: 34 features, Fitness: -0.1580\n",
      "    - New mask: 34 features, Fitness: -0.8297\n",
      "    - New mask: 33 features, Fitness: 0.0060\n",
      "    - New mask: 33 features, Fitness: -0.2347\n",
      "    - New mask: 34 features, Fitness: -2.4237\n",
      "    - New mask: 32 features, Fitness: -1.4868\n",
      "    - New mask: 32 features, Fitness: -1.7372\n",
      "    - New mask: 34 features, Fitness: -2.0776\n",
      "    - New mask: 33 features, Fitness: -2.2006\n",
      "    - New mask: 31 features, Fitness: -1.3611\n",
      "    - New mask: 30 features, Fitness: -1.2281\n",
      "    - New mask: 36 features, Fitness: -3.0760\n",
      "    - New mask: 32 features, Fitness: -1.9044\n",
      "    - New mask: 34 features, Fitness: -2.2251\n",
      "    - New mask: 35 features, Fitness: -2.5189\n",
      "    - New mask: 33 features, Fitness: -2.4070\n",
      "    - New mask: 32 features, Fitness: -2.1640\n",
      "    - New mask: 32 features, Fitness: -2.2514\n",
      "    - New mask: 32 features, Fitness: -1.6945\n",
      "    - New mask: 31 features, Fitness: -1.8275\n",
      "    - New mask: 34 features, Fitness: -2.2106\n",
      "    - New mask: 31 features, Fitness: -1.2112\n",
      "    - New mask: 29 features, Fitness: -0.5569\n",
      "    - New mask: 35 features, Fitness: -3.2879\n",
      "=== End of Round 16: Vote mask selects 26 features (rho: 0.67)\n",
      "    Indices: [3, 4, 5, 6, 7, 11, 13, 15, 16, 17, 20, 22, 23, 25, 26, 32, 37, 38, 40, 41, 44, 46, 50, 51, 52, 55]\n",
      "\n",
      "================ Federated BFA Round 17 ================\n",
      "  Adaptive rho for this round: 0.71\n",
      "    - New mask: 25 features, Fitness: 2.7362\n",
      "    - New mask: 29 features, Fitness: 1.9066\n",
      "    - New mask: 30 features, Fitness: 1.7924\n",
      "    - New mask: 28 features, Fitness: 1.8893\n",
      "    - New mask: 27 features, Fitness: 2.2911\n",
      "    - New mask: 30 features, Fitness: 1.7871\n",
      "    - New mask: 29 features, Fitness: 1.6316\n",
      "    - New mask: 25 features, Fitness: 2.5609\n",
      "    - New mask: 27 features, Fitness: 2.1988\n",
      "    - New mask: 28 features, Fitness: 2.1826\n",
      "    - New mask: 29 features, Fitness: 2.0916\n",
      "    - New mask: 24 features, Fitness: 2.4495\n",
      "    - New mask: 31 features, Fitness: 1.2740\n",
      "    - New mask: 25 features, Fitness: 2.1525\n",
      "    - New mask: 28 features, Fitness: 2.3858\n",
      "    - New mask: 33 features, Fitness: 1.0869\n",
      "    - New mask: 30 features, Fitness: 1.9248\n",
      "    - New mask: 29 features, Fitness: 1.7223\n",
      "    - New mask: 26 features, Fitness: 2.1690\n",
      "    - New mask: 28 features, Fitness: 1.9003\n",
      "    - New mask: 29 features, Fitness: 3.2263\n",
      "    - New mask: 32 features, Fitness: 3.2863\n",
      "    - New mask: 30 features, Fitness: 3.1031\n",
      "    - New mask: 31 features, Fitness: 3.3237\n",
      "    - New mask: 26 features, Fitness: 3.7585\n",
      "    - New mask: 29 features, Fitness: 3.8311\n",
      "    - New mask: 31 features, Fitness: 3.4046\n",
      "    - New mask: 34 features, Fitness: 2.9789\n",
      "    - New mask: 31 features, Fitness: 3.5521\n",
      "    - New mask: 27 features, Fitness: 3.6540\n",
      "    - New mask: 31 features, Fitness: 3.2722\n",
      "    - New mask: 31 features, Fitness: 3.3995\n",
      "    - New mask: 25 features, Fitness: 3.7120\n",
      "    - New mask: 33 features, Fitness: 3.1460\n",
      "    - New mask: 35 features, Fitness: 2.7212\n",
      "    - New mask: 30 features, Fitness: 3.7245\n",
      "    - New mask: 35 features, Fitness: 2.6755\n",
      "    - New mask: 31 features, Fitness: 3.4115\n",
      "    - New mask: 31 features, Fitness: 3.6323\n",
      "    - New mask: 27 features, Fitness: 3.8046\n",
      "    - New mask: 29 features, Fitness: 0.4384\n",
      "    - New mask: 30 features, Fitness: 0.6204\n",
      "    - New mask: 33 features, Fitness: 0.2303\n",
      "    - New mask: 29 features, Fitness: 0.0324\n",
      "    - New mask: 32 features, Fitness: -0.4821\n",
      "    - New mask: 27 features, Fitness: 0.5549\n",
      "    - New mask: 28 features, Fitness: 0.7354\n",
      "    - New mask: 31 features, Fitness: -0.0199\n",
      "    - New mask: 34 features, Fitness: -0.7546\n",
      "    - New mask: 24 features, Fitness: 0.6281\n",
      "    - New mask: 27 features, Fitness: 0.0947\n",
      "    - New mask: 27 features, Fitness: 0.5323\n",
      "    - New mask: 28 features, Fitness: 0.2871\n",
      "    - New mask: 30 features, Fitness: 0.3844\n",
      "    - New mask: 29 features, Fitness: -0.1873\n",
      "    - New mask: 28 features, Fitness: 1.0963\n",
      "    - New mask: 31 features, Fitness: -0.3637\n",
      "    - New mask: 27 features, Fitness: 0.5794\n",
      "    - New mask: 27 features, Fitness: 0.2139\n",
      "    - New mask: 29 features, Fitness: -0.2309\n",
      "    - New mask: 26 features, Fitness: 0.8286\n",
      "    - New mask: 30 features, Fitness: 0.5580\n",
      "    - New mask: 27 features, Fitness: 0.6961\n",
      "    - New mask: 33 features, Fitness: 0.0885\n",
      "    - New mask: 30 features, Fitness: 0.6490\n",
      "    - New mask: 33 features, Fitness: 0.2163\n",
      "    - New mask: 28 features, Fitness: 1.0276\n",
      "    - New mask: 30 features, Fitness: 0.4829\n",
      "    - New mask: 28 features, Fitness: 0.6075\n",
      "    - New mask: 29 features, Fitness: 0.5525\n",
      "    - New mask: 29 features, Fitness: 0.7938\n",
      "    - New mask: 28 features, Fitness: 0.8836\n",
      "    - New mask: 34 features, Fitness: -0.1828\n",
      "    - New mask: 31 features, Fitness: 0.0700\n",
      "    - New mask: 28 features, Fitness: 0.9377\n",
      "    - New mask: 28 features, Fitness: 0.9305\n",
      "    - New mask: 36 features, Fitness: -1.2006\n",
      "    - New mask: 28 features, Fitness: 0.7906\n",
      "    - New mask: 28 features, Fitness: 0.8591\n",
      "    - New mask: 30 features, Fitness: 0.4279\n",
      "    - New mask: 29 features, Fitness: -0.9809\n",
      "    - New mask: 29 features, Fitness: -0.6239\n",
      "    - New mask: 28 features, Fitness: -0.4569\n",
      "    - New mask: 29 features, Fitness: -0.9669\n",
      "    - New mask: 32 features, Fitness: -1.6168\n",
      "    - New mask: 28 features, Fitness: -0.6019\n",
      "    - New mask: 26 features, Fitness: -0.8793\n",
      "    - New mask: 32 features, Fitness: -1.3845\n",
      "    - New mask: 25 features, Fitness: 0.0511\n",
      "    - New mask: 32 features, Fitness: -1.4365\n",
      "    - New mask: 29 features, Fitness: -0.8090\n",
      "    - New mask: 29 features, Fitness: -0.5050\n",
      "    - New mask: 32 features, Fitness: -1.5398\n",
      "    - New mask: 28 features, Fitness: -0.5363\n",
      "    - New mask: 26 features, Fitness: -0.1788\n",
      "    - New mask: 30 features, Fitness: -1.0412\n",
      "    - New mask: 28 features, Fitness: -0.3329\n",
      "    - New mask: 27 features, Fitness: -0.1488\n",
      "    - New mask: 33 features, Fitness: -1.6959\n",
      "    - New mask: 31 features, Fitness: -2.1608\n",
      "=== End of Round 17: Vote mask selects 25 features (rho: 0.71)\n",
      "    Indices: [3, 4, 5, 6, 7, 13, 15, 16, 17, 20, 22, 23, 25, 26, 32, 37, 38, 40, 41, 46, 50, 51, 52, 53, 55]\n",
      "\n",
      "================ Federated BFA Round 18 ================\n",
      "  Adaptive rho for this round: 0.74\n",
      "    - New mask: 25 features, Fitness: 2.7362\n",
      "    - New mask: 26 features, Fitness: 2.4703\n",
      "    - New mask: 26 features, Fitness: 2.4016\n",
      "    - New mask: 26 features, Fitness: 2.5826\n",
      "    - New mask: 26 features, Fitness: 2.2735\n",
      "    - New mask: 25 features, Fitness: 2.4338\n",
      "    - New mask: 28 features, Fitness: 2.3838\n",
      "    - New mask: 25 features, Fitness: 2.5418\n",
      "    - New mask: 23 features, Fitness: 2.5667\n",
      "    - New mask: 28 features, Fitness: 2.1688\n",
      "    - New mask: 26 features, Fitness: 2.4818\n",
      "    - New mask: 22 features, Fitness: 2.3722\n",
      "    - New mask: 26 features, Fitness: 2.0914\n",
      "    - New mask: 26 features, Fitness: 2.4590\n",
      "    - New mask: 27 features, Fitness: 2.0922\n",
      "    - New mask: 30 features, Fitness: 1.6842\n",
      "    - New mask: 29 features, Fitness: 2.1210\n",
      "    - New mask: 26 features, Fitness: 2.3054\n",
      "    - New mask: 28 features, Fitness: 1.8648\n",
      "    - New mask: 24 features, Fitness: 2.4648\n",
      "    - New mask: 28 features, Fitness: 3.5123\n",
      "    - New mask: 27 features, Fitness: 3.7280\n",
      "    - New mask: 24 features, Fitness: 3.8440\n",
      "    - New mask: 32 features, Fitness: 3.4453\n",
      "    - New mask: 25 features, Fitness: 3.4894\n",
      "    - New mask: 30 features, Fitness: 3.7225\n",
      "    - New mask: 31 features, Fitness: 3.6685\n",
      "    - New mask: 28 features, Fitness: 3.7248\n",
      "    - New mask: 29 features, Fitness: 3.9430\n",
      "    - New mask: 29 features, Fitness: 3.3993\n",
      "    - New mask: 27 features, Fitness: 4.1030\n",
      "    - New mask: 31 features, Fitness: 3.3995\n",
      "    - New mask: 28 features, Fitness: 3.5793\n",
      "    - New mask: 27 features, Fitness: 3.9164\n",
      "    - New mask: 29 features, Fitness: 3.6809\n",
      "    - New mask: 32 features, Fitness: 3.3356\n",
      "    - New mask: 30 features, Fitness: 3.6611\n",
      "    - New mask: 30 features, Fitness: 3.3946\n",
      "    - New mask: 31 features, Fitness: 3.4050\n",
      "    - New mask: 28 features, Fitness: 3.7123\n",
      "    - New mask: 27 features, Fitness: 0.2707\n",
      "    - New mask: 29 features, Fitness: 0.8634\n",
      "    - New mask: 27 features, Fitness: 0.9029\n",
      "    - New mask: 28 features, Fitness: 0.4554\n",
      "    - New mask: 30 features, Fitness: 0.2844\n",
      "    - New mask: 28 features, Fitness: 0.9329\n",
      "    - New mask: 28 features, Fitness: 0.7885\n",
      "    - New mask: 29 features, Fitness: 0.2398\n",
      "    - New mask: 27 features, Fitness: 0.1806\n",
      "    - New mask: 25 features, Fitness: 0.6600\n",
      "    - New mask: 26 features, Fitness: 0.2780\n",
      "    - New mask: 28 features, Fitness: 0.5926\n",
      "    - New mask: 26 features, Fitness: 0.6826\n",
      "    - New mask: 25 features, Fitness: 1.3730\n",
      "    - New mask: 27 features, Fitness: 0.9821\n",
      "    - New mask: 30 features, Fitness: 0.2002\n",
      "    - New mask: 31 features, Fitness: -0.2082\n",
      "    - New mask: 26 features, Fitness: 0.7795\n",
      "    - New mask: 26 features, Fitness: 0.7304\n",
      "    - New mask: 30 features, Fitness: -0.0961\n",
      "    - New mask: 25 features, Fitness: 1.2742\n",
      "    - New mask: 25 features, Fitness: 1.4489\n",
      "    - New mask: 26 features, Fitness: 0.9454\n",
      "    - New mask: 29 features, Fitness: 0.8441\n",
      "    - New mask: 29 features, Fitness: 0.8559\n",
      "    - New mask: 32 features, Fitness: 0.3360\n",
      "    - New mask: 28 features, Fitness: 1.1141\n",
      "    - New mask: 32 features, Fitness: 0.0191\n",
      "    - New mask: 28 features, Fitness: 1.0743\n",
      "    - New mask: 30 features, Fitness: 0.5732\n",
      "    - New mask: 27 features, Fitness: 1.2184\n",
      "    - New mask: 25 features, Fitness: 0.9886\n",
      "    - New mask: 28 features, Fitness: 1.1215\n",
      "    - New mask: 27 features, Fitness: 0.7384\n",
      "    - New mask: 30 features, Fitness: 0.3207\n",
      "    - New mask: 27 features, Fitness: 1.2133\n",
      "    - New mask: 29 features, Fitness: 0.9631\n",
      "    - New mask: 29 features, Fitness: 0.9445\n",
      "    - New mask: 28 features, Fitness: 0.9217\n",
      "    - New mask: 26 features, Fitness: 1.2869\n",
      "    - New mask: 25 features, Fitness: 0.0410\n",
      "    - New mask: 28 features, Fitness: -0.3730\n",
      "    - New mask: 27 features, Fitness: -0.4907\n",
      "    - New mask: 25 features, Fitness: -0.2421\n",
      "    - New mask: 26 features, Fitness: -0.2212\n",
      "    - New mask: 24 features, Fitness: 0.2242\n",
      "    - New mask: 26 features, Fitness: -0.4957\n",
      "    - New mask: 31 features, Fitness: -0.8901\n",
      "    - New mask: 23 features, Fitness: 0.2025\n",
      "    - New mask: 28 features, Fitness: -0.6376\n",
      "    - New mask: 26 features, Fitness: -0.0571\n",
      "    - New mask: 24 features, Fitness: 0.4133\n",
      "    - New mask: 29 features, Fitness: -0.9917\n",
      "    - New mask: 24 features, Fitness: 0.3870\n",
      "    - New mask: 26 features, Fitness: -0.0810\n",
      "    - New mask: 26 features, Fitness: -0.1537\n",
      "    - New mask: 25 features, Fitness: -0.2865\n",
      "    - New mask: 27 features, Fitness: -0.1092\n",
      "    - New mask: 27 features, Fitness: -0.3429\n",
      "    - New mask: 28 features, Fitness: -1.2233\n",
      "=== End of Round 18: Vote mask selects 24 features (rho: 0.74)\n",
      "    Indices: [3, 4, 5, 6, 7, 13, 15, 16, 17, 20, 22, 23, 25, 26, 32, 37, 38, 40, 41, 46, 50, 51, 52, 55]\n",
      "\n",
      "================ Federated BFA Round 19 ================\n",
      "  Adaptive rho for this round: 0.77\n",
      "    - New mask: 24 features, Fitness: 2.7243\n",
      "    - New mask: 26 features, Fitness: 2.5128\n",
      "    - New mask: 22 features, Fitness: 2.5613\n",
      "    - New mask: 24 features, Fitness: 2.8387\n",
      "    - New mask: 26 features, Fitness: 2.2224\n",
      "    - New mask: 24 features, Fitness: 2.4889\n",
      "    - New mask: 25 features, Fitness: 2.8235\n",
      "    - New mask: 22 features, Fitness: 2.6771\n",
      "    - New mask: 23 features, Fitness: 2.5710\n",
      "    - New mask: 26 features, Fitness: 2.5801\n",
      "    - New mask: 24 features, Fitness: 2.6794\n",
      "    - New mask: 25 features, Fitness: 1.7121\n",
      "    - New mask: 23 features, Fitness: 2.7679\n",
      "    - New mask: 23 features, Fitness: 2.6990\n",
      "    - New mask: 24 features, Fitness: 2.2402\n",
      "    - New mask: 25 features, Fitness: 2.6221\n",
      "    - New mask: 26 features, Fitness: 2.6296\n",
      "    - New mask: 26 features, Fitness: 2.1427\n",
      "    - New mask: 28 features, Fitness: 2.0560\n",
      "    - New mask: 24 features, Fitness: 2.3319\n",
      "    - New mask: 25 features, Fitness: 4.1340\n",
      "    - New mask: 24 features, Fitness: 4.0908\n",
      "    - New mask: 25 features, Fitness: 3.8326\n",
      "    - New mask: 27 features, Fitness: 2.8611\n",
      "    - New mask: 29 features, Fitness: 3.8336\n",
      "    - New mask: 27 features, Fitness: 3.7949\n",
      "    - New mask: 30 features, Fitness: 3.7578\n",
      "    - New mask: 31 features, Fitness: 2.8805\n",
      "    - New mask: 26 features, Fitness: 4.1212\n",
      "    - New mask: 27 features, Fitness: 3.8468\n",
      "    - New mask: 24 features, Fitness: 4.2262\n",
      "    - New mask: 27 features, Fitness: 3.9751\n",
      "    - New mask: 25 features, Fitness: 3.7034\n",
      "    - New mask: 28 features, Fitness: 3.9110\n",
      "    - New mask: 30 features, Fitness: 3.5286\n",
      "    - New mask: 27 features, Fitness: 4.0666\n",
      "    - New mask: 27 features, Fitness: 3.4318\n",
      "    - New mask: 25 features, Fitness: 4.2418\n",
      "    - New mask: 29 features, Fitness: 3.6956\n",
      "    - New mask: 27 features, Fitness: 4.0704\n",
      "    - New mask: 27 features, Fitness: -0.0579\n",
      "    - New mask: 25 features, Fitness: 0.8395\n",
      "    - New mask: 25 features, Fitness: 1.1234\n",
      "    - New mask: 24 features, Fitness: 1.3318\n",
      "    - New mask: 27 features, Fitness: 0.3094\n",
      "    - New mask: 25 features, Fitness: 0.9480\n",
      "    - New mask: 26 features, Fitness: 0.9124\n",
      "    - New mask: 28 features, Fitness: 0.1523\n",
      "    - New mask: 26 features, Fitness: 0.5349\n",
      "    - New mask: 26 features, Fitness: 0.7343\n",
      "    - New mask: 23 features, Fitness: 1.4697\n",
      "    - New mask: 24 features, Fitness: 0.9789\n",
      "    - New mask: 26 features, Fitness: 0.7679\n",
      "    - New mask: 25 features, Fitness: 0.9724\n",
      "    - New mask: 26 features, Fitness: 1.2379\n",
      "    - New mask: 28 features, Fitness: 1.0628\n",
      "    - New mask: 28 features, Fitness: 0.5126\n",
      "    - New mask: 24 features, Fitness: 0.8607\n",
      "    - New mask: 26 features, Fitness: 1.2088\n",
      "    - New mask: 25 features, Fitness: 0.3831\n",
      "    - New mask: 24 features, Fitness: 1.7239\n",
      "    - New mask: 23 features, Fitness: 1.7022\n",
      "    - New mask: 27 features, Fitness: 0.3761\n",
      "    - New mask: 26 features, Fitness: 1.1373\n",
      "    - New mask: 27 features, Fitness: 1.1605\n",
      "    - New mask: 28 features, Fitness: 1.0679\n",
      "    - New mask: 22 features, Fitness: 1.9005\n",
      "    - New mask: 26 features, Fitness: 1.0377\n",
      "    - New mask: 29 features, Fitness: 0.7956\n",
      "    - New mask: 27 features, Fitness: 0.8358\n",
      "    - New mask: 26 features, Fitness: 0.9598\n",
      "    - New mask: 26 features, Fitness: 1.0934\n",
      "    - New mask: 24 features, Fitness: 1.2778\n",
      "    - New mask: 29 features, Fitness: 1.0111\n",
      "    - New mask: 26 features, Fitness: 1.0952\n",
      "    - New mask: 25 features, Fitness: 1.5165\n",
      "    - New mask: 26 features, Fitness: 1.4737\n",
      "    - New mask: 27 features, Fitness: 1.3779\n",
      "    - New mask: 26 features, Fitness: 1.3538\n",
      "    - New mask: 23 features, Fitness: 1.6279\n",
      "    - New mask: 23 features, Fitness: 0.4651\n",
      "    - New mask: 24 features, Fitness: 0.4040\n",
      "    - New mask: 24 features, Fitness: 0.2766\n",
      "    - New mask: 24 features, Fitness: 0.2311\n",
      "    - New mask: 23 features, Fitness: 0.5795\n",
      "    - New mask: 25 features, Fitness: -0.1885\n",
      "    - New mask: 28 features, Fitness: -0.6581\n",
      "    - New mask: 24 features, Fitness: 0.4933\n",
      "    - New mask: 27 features, Fitness: -0.3665\n",
      "    - New mask: 30 features, Fitness: -1.1613\n",
      "    - New mask: 25 features, Fitness: 0.1144\n",
      "    - New mask: 20 features, Fitness: 1.0510\n",
      "    - New mask: 25 features, Fitness: 0.1159\n",
      "    - New mask: 25 features, Fitness: 0.1396\n",
      "    - New mask: 22 features, Fitness: 0.5491\n",
      "    - New mask: 25 features, Fitness: -0.0622\n",
      "    - New mask: 21 features, Fitness: 0.4051\n",
      "    - New mask: 26 features, Fitness: 0.1421\n",
      "    - New mask: 23 features, Fitness: 0.2770\n",
      "    - New mask: 27 features, Fitness: -0.2869\n",
      "=== End of Round 19: Vote mask selects 23 features (rho: 0.77)\n",
      "    Indices: [4, 5, 6, 7, 13, 15, 16, 17, 20, 22, 23, 25, 26, 32, 37, 38, 40, 41, 46, 50, 51, 52, 55]\n",
      "\n",
      "================ Federated BFA Round 20 ================\n",
      "  Adaptive rho for this round: 0.80\n",
      "    - New mask: 26 features, Fitness: 2.6109\n",
      "    - New mask: 22 features, Fitness: 3.0145\n",
      "    - New mask: 23 features, Fitness: 2.5285\n",
      "    - New mask: 23 features, Fitness: 2.7414\n",
      "    - New mask: 25 features, Fitness: 2.3772\n",
      "    - New mask: 25 features, Fitness: 2.1271\n",
      "    - New mask: 25 features, Fitness: 2.7373\n",
      "    - New mask: 26 features, Fitness: 2.3367\n",
      "    - New mask: 26 features, Fitness: 2.6132\n",
      "    - New mask: 27 features, Fitness: 2.3518\n",
      "    - New mask: 24 features, Fitness: 2.7706\n",
      "    - New mask: 22 features, Fitness: 3.0700\n",
      "    - New mask: 25 features, Fitness: 2.7689\n",
      "    - New mask: 21 features, Fitness: 2.5847\n",
      "    - New mask: 26 features, Fitness: 2.5147\n",
      "    - New mask: 25 features, Fitness: 2.1727\n",
      "    - New mask: 27 features, Fitness: 2.3160\n",
      "    - New mask: 23 features, Fitness: 2.5446\n",
      "    - New mask: 25 features, Fitness: 2.5295\n",
      "    - New mask: 23 features, Fitness: 2.6023\n",
      "    - New mask: 22 features, Fitness: 4.3281\n",
      "    - New mask: 26 features, Fitness: 3.9368\n",
      "    - New mask: 25 features, Fitness: 3.7910\n",
      "    - New mask: 28 features, Fitness: 2.9696\n",
      "    - New mask: 25 features, Fitness: 3.8631\n",
      "    - New mask: 24 features, Fitness: 4.3318\n",
      "    - New mask: 28 features, Fitness: 3.9436\n",
      "    - New mask: 27 features, Fitness: 3.8098\n",
      "    - New mask: 25 features, Fitness: 4.0457\n",
      "    - New mask: 27 features, Fitness: 4.0281\n",
      "    - New mask: 26 features, Fitness: 3.9094\n",
      "    - New mask: 27 features, Fitness: 3.9751\n",
      "    - New mask: 27 features, Fitness: 3.3667\n",
      "    - New mask: 25 features, Fitness: 4.3345\n",
      "    - New mask: 28 features, Fitness: 3.8724\n",
      "    - New mask: 27 features, Fitness: 4.1832\n",
      "    - New mask: 25 features, Fitness: 3.4577\n",
      "    - New mask: 25 features, Fitness: 4.2418\n",
      "    - New mask: 26 features, Fitness: 4.0726\n",
      "    - New mask: 24 features, Fitness: 3.8991\n",
      "    - New mask: 24 features, Fitness: 1.1606\n",
      "    - New mask: 22 features, Fitness: 1.0560\n",
      "    - New mask: 24 features, Fitness: 1.2207\n",
      "    - New mask: 23 features, Fitness: 1.0107\n",
      "    - New mask: 26 features, Fitness: 1.0022\n",
      "    - New mask: 20 features, Fitness: 1.7215\n",
      "    - New mask: 24 features, Fitness: 1.2475\n",
      "    - New mask: 23 features, Fitness: 0.7213\n",
      "    - New mask: 24 features, Fitness: 0.7747\n",
      "    - New mask: 24 features, Fitness: 1.0542\n",
      "    - New mask: 22 features, Fitness: 1.5573\n",
      "    - New mask: 25 features, Fitness: 1.2500\n",
      "    - New mask: 25 features, Fitness: 0.7394\n",
      "    - New mask: 24 features, Fitness: 0.7453\n",
      "    - New mask: 24 features, Fitness: 1.3506\n",
      "    - New mask: 25 features, Fitness: 0.8114\n",
      "    - New mask: 25 features, Fitness: 1.1069\n",
      "    - New mask: 24 features, Fitness: 1.0007\n",
      "    - New mask: 27 features, Fitness: 0.4795\n",
      "    - New mask: 21 features, Fitness: 0.9267\n",
      "    - New mask: 24 features, Fitness: 1.7790\n",
      "    - New mask: 22 features, Fitness: 1.7211\n",
      "    - New mask: 27 features, Fitness: 0.8384\n",
      "    - New mask: 26 features, Fitness: 1.4856\n",
      "    - New mask: 24 features, Fitness: 1.6715\n",
      "    - New mask: 24 features, Fitness: 1.5760\n",
      "    - New mask: 22 features, Fitness: 1.8025\n",
      "    - New mask: 24 features, Fitness: 0.7676\n",
      "    - New mask: 26 features, Fitness: 1.1227\n",
      "    - New mask: 23 features, Fitness: 1.8597\n",
      "    - New mask: 25 features, Fitness: 1.3749\n",
      "    - New mask: 25 features, Fitness: 1.5272\n",
      "    - New mask: 22 features, Fitness: 1.9005\n",
      "    - New mask: 26 features, Fitness: 1.3860\n",
      "    - New mask: 25 features, Fitness: 1.2705\n",
      "    - New mask: 24 features, Fitness: 1.7059\n",
      "    - New mask: 25 features, Fitness: 1.2822\n",
      "    - New mask: 25 features, Fitness: 1.6646\n",
      "    - New mask: 25 features, Fitness: 1.4836\n",
      "    - New mask: 25 features, Fitness: 1.3300\n",
      "    - New mask: 22 features, Fitness: 0.8166\n",
      "    - New mask: 28 features, Fitness: -0.4973\n",
      "    - New mask: 24 features, Fitness: 0.3062\n",
      "    - New mask: 25 features, Fitness: 0.1601\n",
      "    - New mask: 20 features, Fitness: 1.0094\n",
      "    - New mask: 24 features, Fitness: 0.3746\n",
      "    - New mask: 26 features, Fitness: -0.2818\n",
      "    - New mask: 27 features, Fitness: -0.2630\n",
      "    - New mask: 23 features, Fitness: -0.1013\n",
      "    - New mask: 24 features, Fitness: 0.2383\n",
      "    - New mask: 25 features, Fitness: -0.0959\n",
      "    - New mask: 19 features, Fitness: 1.0730\n",
      "    - New mask: 25 features, Fitness: 0.2573\n",
      "    - New mask: 23 features, Fitness: 0.4927\n",
      "    - New mask: 21 features, Fitness: 0.8943\n",
      "    - New mask: 23 features, Fitness: 0.6377\n",
      "    - New mask: 20 features, Fitness: 0.3789\n",
      "    - New mask: 25 features, Fitness: 0.2742\n",
      "    - New mask: 23 features, Fitness: 0.5949\n",
      "    - New mask: 23 features, Fitness: 0.3888\n",
      "=== End of Round 20: Vote mask selects 20 features (rho: 0.80)\n",
      "    Indices: [4, 6, 7, 13, 16, 17, 20, 22, 23, 25, 26, 32, 38, 40, 41, 46, 50, 51, 52, 55]\n",
      "\n",
      "Final federated feature count: 20\n",
      "Selected feature names: ['F5', 'F7', 'F8', 'F14', 'F17', 'F18', 'F21', 'F23', 'F24', 'F26', 'F27', 'F33', 'F39', 'F41', 'F42', 'F47', 'F51', 'F52', 'F53', 'F56']\n"
     ]
    }
   ],
   "source": [
    "n_feat_select_rounds = 20\n",
    "n_fireflies = 20           # Number of fireflies per client\n",
    "n_features = X.shape[1]\n",
    "num_clients = len(client_data_np)\n",
    "rho_start, rho_end = 0.2, 0.8\n",
    "penalty_lambda = 0.8\n",
    "\n",
    "# Precompute Fisher scores and correlation matrix for each client\n",
    "client_fisher_scores = []\n",
    "client_corr_matrix = []\n",
    "for Xc, yc in client_data_np:\n",
    "    fisher_scores = compute_fisher_scores(Xc, yc)\n",
    "    corr_matrix = compute_corr_matrix(Xc)\n",
    "    client_fisher_scores.append(fisher_scores)\n",
    "    client_corr_matrix.append(corr_matrix)\n",
    "\n",
    "# Initialize fireflies for each client at round 1\n",
    "client_fireflies = []\n",
    "client_local_bests = []\n",
    "for cid in range(num_clients):\n",
    "    fireflies = []\n",
    "    for _ in range(n_fireflies):\n",
    "        mask = np.random.choice([0, 1], size=n_features)\n",
    "        if np.sum(mask) == 0:\n",
    "            mask[np.random.randint(n_features)] = 1  # Ensure at least one feature is selected\n",
    "        fireflies.append(mask)\n",
    "    # Evaluate and store best\n",
    "    best_fitness = -np.inf\n",
    "    best_mask = None\n",
    "    for mask in fireflies:\n",
    "        sel = np.where(mask)[0]\n",
    "        fit = evaluate_feature_subset(sel, client_fisher_scores[cid], client_corr_matrix[cid], penalty_lambda)\n",
    "        if fit > best_fitness or best_mask is None:\n",
    "            best_fitness = fit\n",
    "            best_mask = mask.copy()\n",
    "    # Fallback: all features if somehow none was found\n",
    "    if best_mask is None:\n",
    "        best_mask = np.ones(n_features, dtype=int)\n",
    "    client_fireflies.append(fireflies)\n",
    "    client_local_bests.append(best_mask.copy())\n",
    "\n",
    "# Start with all features selected in global mask\n",
    "global_mask = np.ones(n_features, dtype=int)\n",
    "\n",
    "for round_fs in range(n_feat_select_rounds):\n",
    "    print(f\"\\n================ Federated BFA Round {round_fs+1} ================\")\n",
    "    # Linear schedule for rho\n",
    "    rho = rho_start + (rho_end - rho_start) * (round_fs / (n_feat_select_rounds - 1))\n",
    "    print(f\"  Adaptive rho for this round: {rho:.2f}\")\n",
    "\n",
    "    client_best_masks = []\n",
    "    # For each client, update fireflies and find new local best\n",
    "    for cid in range(num_clients):\n",
    "        fireflies = client_fireflies[cid]\n",
    "        fisher_scores = client_fisher_scores[cid]\n",
    "        corr_matrix = client_corr_matrix[cid]\n",
    "        local_best = client_local_bests[cid]\n",
    "        new_fireflies = []\n",
    "        best_fitness = -np.inf\n",
    "        best_mask = None\n",
    "        for f in range(n_fireflies):\n",
    "            new_mask = one_step_binary_firefly(\n",
    "                fireflies[f],\n",
    "                global_mask,\n",
    "                local_best,\n",
    "                fisher_scores,\n",
    "                corr_matrix,\n",
    "                penalty_lambda=penalty_lambda,\n",
    "                verbose=True\n",
    "            )\n",
    "            # Ensure at least one feature\n",
    "            if np.sum(new_mask) == 0:\n",
    "                new_mask[np.random.randint(n_features)] = 1\n",
    "            new_fireflies.append(new_mask)\n",
    "            sel = np.where(new_mask)[0]\n",
    "            fit = evaluate_feature_subset(sel, fisher_scores, corr_matrix, penalty_lambda)\n",
    "            if fit > best_fitness or best_mask is None:\n",
    "                best_fitness = fit\n",
    "                best_mask = new_mask.copy()\n",
    "        # Fallback: all features if somehow none was found\n",
    "        if best_mask is None:\n",
    "            best_mask = np.ones(n_features, dtype=int)\n",
    "        # Update client's fireflies and local best\n",
    "        client_fireflies[cid] = new_fireflies\n",
    "        client_local_bests[cid] = best_mask.copy()\n",
    "        client_best_masks.append(best_mask.copy())\n",
    "    client_best_masks = np.array(client_best_masks)\n",
    "    vote_counts = np.sum(client_best_masks, axis=0)\n",
    "    vote_mask = (vote_counts >= (rho * num_clients)).astype(int)\n",
    "    print(f\"=== End of Round {round_fs+1}: Vote mask selects {vote_mask.sum()} features (rho: {rho:.2f})\\n\"\n",
    "          f\"    Indices: {np.where(vote_mask)[0].tolist()}\")\n",
    "    global_mask = vote_mask.copy()\n",
    "\n",
    "selected_indices = np.where(global_mask == 1)[0]\n",
    "print(f\"\\nFinal federated feature count: {len(selected_indices)}\")\n",
    "selected_feature_names = [feature_cols[i] for i in selected_indices]\n",
    "print(\"Selected feature names:\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final federated feature count: 20\n",
      "Selected feature names: ['F5', 'F7', 'F8', 'F14', 'F17', 'F18', 'F21', 'F23', 'F24', 'F26', 'F27', 'F33', 'F39', 'F41', 'F42', 'F47', 'F51', 'F52', 'F53', 'F56']\n"
     ]
    }
   ],
   "source": [
    "selected_indices = np.where(global_mask == 1)[0]\n",
    "print(f\"\\nFinal federated feature count: {len(selected_indices)}\")\n",
    "selected_feature_names = [feature_cols[i] for i in selected_indices]\n",
    "print(\"Selected feature names:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel = X[:, selected_indices]\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.fc5 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        features = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(features)\n",
    "\n",
    "        out = self.fc5(x)\n",
    "\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 51.22% | Acc After: 91.32%\n",
      "  Client  2 | Samples:  907 | Acc Before: 69.08% | Acc After: 90.62%\n",
      "  Client  3 | Samples:  469 | Acc Before: 16.15% | Acc After: 88.80%\n",
      "  Client  4 | Samples:  675 | Acc Before: 82.19% | Acc After: 93.59%\n",
      "  Client  5 | Samples:  356 | Acc Before: 93.75% | Acc After: 92.19%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 82.52%\n",
      "Client Acc BEFORE (mean Â± std): 62.48% Â± 27.14%\n",
      "Client Acc AFTER  (mean Â± std): 91.31% Â± 1.60%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 81.34% | Acc After: 91.15%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.72% | Acc After: 91.63%\n",
      "  Client  3 | Samples:  469 | Acc Before: 72.14% | Acc After: 91.15%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.81% | Acc After: 95.62%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.92% | Acc After: 94.92%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 90.01%\n",
      "Client Acc BEFORE (mean Â± std): 85.59% Â± 8.24%\n",
      "Client Acc AFTER  (mean Â± std): 92.89% Â± 1.96%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.32% | Acc After: 91.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.74% | Acc After: 91.18%\n",
      "  Client  3 | Samples:  469 | Acc Before: 85.68% | Acc After: 92.71%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.78% | Acc After: 96.09%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.70% | Acc After: 96.88%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 90.12%\n",
      "Client Acc BEFORE (mean Â± std): 91.44% Â± 3.88%\n",
      "Client Acc AFTER  (mean Â± std): 93.72% Â± 2.32%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.84% | Acc After: 91.15%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.51% | Acc After: 91.74%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.72% | Acc After: 94.27%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.31% | Acc After: 96.09%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 95.70%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 90.34%\n",
      "Client Acc BEFORE (mean Â± std): 91.70% Â± 3.52%\n",
      "Client Acc AFTER  (mean Â± std): 93.79% Â± 2.02%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.93% | Acc After: 91.23%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.07% | Acc After: 91.52%\n",
      "  Client  3 | Samples:  469 | Acc Before: 88.02% | Acc After: 92.19%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.47% | Acc After: 95.78%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 94.53%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 90.23%\n",
      "Client Acc BEFORE (mean Â± std): 92.35% Â± 3.47%\n",
      "Client Acc AFTER  (mean Â± std): 93.05% Â± 1.79%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.36% | Acc After: 91.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.85% | Acc After: 92.52%\n",
      "  Client  3 | Samples:  469 | Acc Before: 88.80% | Acc After: 92.19%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.31% | Acc After: 95.62%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 97.27%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 90.77%\n",
      "Client Acc BEFORE (mean Â± std): 92.44% Â± 3.10%\n",
      "Client Acc AFTER  (mean Â± std): 93.87% Â± 2.18%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.02% | Acc After: 91.32%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.85% | Acc After: 91.74%\n",
      "  Client  3 | Samples:  469 | Acc Before: 88.28% | Acc After: 91.41%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 95.62%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 94.92%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 90.66%\n",
      "Client Acc BEFORE (mean Â± std): 92.27% Â± 3.23%\n",
      "Client Acc AFTER  (mean Â± std): 93.00% Â± 1.87%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.19% | Acc After: 90.80%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.96% | Acc After: 92.19%\n",
      "  Client  3 | Samples:  469 | Acc Before: 88.28% | Acc After: 90.89%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.62% | Acc After: 95.62%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 95.70%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 90.88%\n",
      "Client Acc BEFORE (mean Â± std): 92.46% Â± 3.41%\n",
      "Client Acc AFTER  (mean Â± std): 93.04% Â± 2.20%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.02% | Acc After: 91.23%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.74% | Acc After: 92.08%\n",
      "  Client  3 | Samples:  469 | Acc Before: 89.32% | Acc After: 89.58%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.94% | Acc After: 95.47%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 95.70%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 90.55%\n",
      "Client Acc BEFORE (mean Â± std): 92.73% Â± 3.39%\n",
      "Client Acc AFTER  (mean Â± std): 92.81% Â± 2.40%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.93% | Acc After: 90.89%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.85% | Acc After: 91.63%\n",
      "  Client  3 | Samples:  469 | Acc Before: 88.54% | Acc After: 90.89%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.94% | Acc After: 96.09%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 95.70%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 90.23%\n",
      "Client Acc BEFORE (mean Â± std): 92.50% Â± 3.45%\n",
      "Client Acc AFTER  (mean Â± std): 93.04% Â± 2.35%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.58% | Acc After: 91.41%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.07% | Acc After: 91.96%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.72% | Acc After: 89.84%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.94% | Acc After: 96.09%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 96.09%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 90.23%\n",
      "Client Acc BEFORE (mean Â± std): 92.12% Â± 3.94%\n",
      "Client Acc AFTER  (mean Â± std): 93.08% Â± 2.56%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.58% | Acc After: 91.06%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.07% | Acc After: 92.08%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.20% | Acc After: 90.10%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.25% | Acc After: 95.94%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 96.09%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 90.01%\n",
      "Client Acc BEFORE (mean Â± std): 92.00% Â± 4.05%\n",
      "Client Acc AFTER  (mean Â± std): 93.05% Â± 2.50%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.93% | Acc After: 92.27%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.85% | Acc After: 91.63%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.98% | Acc After: 88.54%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.25% | Acc After: 95.78%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.31% | Acc After: 96.48%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 90.12%\n",
      "Client Acc BEFORE (mean Â± std): 91.86% Â± 3.46%\n",
      "Client Acc AFTER  (mean Â± std): 92.94% Â± 2.90%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.02% | Acc After: 91.32%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.18% | Acc After: 91.63%\n",
      "  Client  3 | Samples:  469 | Acc Before: 87.76% | Acc After: 92.97%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.78% | Acc After: 96.09%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 96.88%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 90.34%\n",
      "Client Acc BEFORE (mean Â± std): 92.32% Â± 3.47%\n",
      "Client Acc AFTER  (mean Â± std): 93.78% Â± 2.29%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.76% | Acc After: 92.01%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.96% | Acc After: 91.96%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.98% | Acc After: 92.45%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 95.31%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 96.48%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 90.34%\n",
      "Client Acc BEFORE (mean Â± std): 92.29% Â± 3.99%\n",
      "Client Acc AFTER  (mean Â± std): 93.64% Â± 1.88%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 89.84% | Acc After: 92.19%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.41% | Acc After: 91.07%\n",
      "  Client  3 | Samples:  469 | Acc Before: 85.16% | Acc After: 91.93%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.94% | Acc After: 95.78%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 96.48%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 90.55%\n",
      "Client Acc BEFORE (mean Â± std): 91.69% Â± 4.09%\n",
      "Client Acc AFTER  (mean Â± std): 93.49% Â± 2.20%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.10% | Acc After: 91.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.07% | Acc After: 91.18%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.98% | Acc After: 90.89%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 95.94%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 96.88%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 90.66%\n",
      "Client Acc BEFORE (mean Â± std): 92.30% Â± 3.84%\n",
      "Client Acc AFTER  (mean Â± std): 93.33% Â± 2.55%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.36% | Acc After: 91.06%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.96% | Acc After: 91.41%\n",
      "  Client  3 | Samples:  469 | Acc Before: 87.76% | Acc After: 85.16%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.78% | Acc After: 96.25%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.48% | Acc After: 97.66%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 90.77%\n",
      "Client Acc BEFORE (mean Â± std): 92.27% Â± 3.34%\n",
      "Client Acc AFTER  (mean Â± std): 92.31% Â± 4.42%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.62% | Acc After: 90.45%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.96% | Acc After: 91.41%\n",
      "  Client  3 | Samples:  469 | Acc Before: 86.72% | Acc After: 85.42%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.78% | Acc After: 95.78%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 98.05%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 90.77%\n",
      "Client Acc BEFORE (mean Â± std): 92.35% Â± 3.91%\n",
      "Client Acc AFTER  (mean Â± std): 92.22% Â± 4.40%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 90.71% | Acc After: 90.36%\n",
      "  Client  2 | Samples:  907 | Acc Before: 90.96% | Acc After: 91.18%\n",
      "  Client  3 | Samples:  469 | Acc Before: 87.24% | Acc After: 84.64%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.25% | Acc After: 95.47%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 96.88%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 90.66%\n",
      "Client Acc BEFORE (mean Â± std): 92.41% Â± 3.64%\n",
      "Client Acc AFTER  (mean Â± std): 91.71% Â± 4.31%\n",
      "Client sample count (min, max): 356, 1273\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.66%\n",
      "Confusion Matrix:\n",
      " [[538  20]\n",
      " [ 66 297]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_modelv2(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "    acc = 100. * correct / total\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    return acc, cm\n",
    "\n",
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def frhc_local_feature_selection(X, max_clusters=None, comp_feat=1):\n",
    "    \"\"\"\n",
    "    Local representative feature selection by hierarchical clustering of features.\n",
    "    \n",
    "    Parameters:\n",
    "        X: [n_samples, n_features] numpy array (client's local data)\n",
    "        max_clusters: int or None, maximum clusters to try for optimal selection\n",
    "        comp_feat: int, number of compensation features to add\n",
    "\n",
    "    Returns:\n",
    "        selected_feature_indices: list of selected feature indices\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    # Step 1: Compute absolute correlation distance between features\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    dist_matrix = 1 - np.abs(corr_matrix)\n",
    "    # Ensure distance matrix is valid\n",
    "    np.fill_diagonal(dist_matrix, 0)\n",
    "    # Convert to condensed form for linkage\n",
    "    condensed = squareform(dist_matrix, checks=False)\n",
    "    # Step 2: Hierarchical clustering\n",
    "    Z = linkage(condensed, method='average')\n",
    "    # Step 3: Optimal number of clusters (can be determined by a method, here use max_clusters or sqrt rule)\n",
    "    if max_clusters is None:\n",
    "        K = int(np.sqrt(n_features))\n",
    "    else:\n",
    "        K = min(max_clusters, n_features)\n",
    "    clusters = fcluster(Z, K, criterion='maxclust')\n",
    "    # Step 4: Find the two largest clusters\n",
    "    cluster_sizes = [(c, np.sum(clusters == c)) for c in np.unique(clusters)]\n",
    "    cluster_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_features = []\n",
    "    for i in range(min(2, len(cluster_sizes))):\n",
    "        c = cluster_sizes[i][0]\n",
    "        selected_features.extend(np.where(clusters == c)[0].tolist())\n",
    "    # Step 5: Optionally add compensation feature(s)\n",
    "    if comp_feat > 0:\n",
    "        feature_counts = [(c, np.sum(clusters == c)) for c in np.unique(clusters)]\n",
    "        cluster_sorted = sorted(feature_counts, key=lambda x: x[1], reverse=True)\n",
    "        # Add features from next largest clusters if needed\n",
    "        for i in range(2, min(2 + comp_feat, len(cluster_sorted))):\n",
    "            c = cluster_sorted[i][0]\n",
    "            selected_features.append(np.where(clusters == c)[0][0])\n",
    "    # Remove duplicates\n",
    "    selected_features = list(sorted(set(selected_features)))\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frhc_global_intersection(selected_lists):\n",
    "    \"\"\"\n",
    "    Compute global overlapping federated features as intersection of local sets.\n",
    "    Parameters:\n",
    "        selected_lists: list of list of feature indices (from each client)\n",
    "    Returns:\n",
    "        final_indices: list of feature indices present in all clients\n",
    "    \"\"\"\n",
    "    # Convert all to set for intersection\n",
    "    final_indices = set(selected_lists[0])\n",
    "    for feat_set in selected_lists[1:]:\n",
    "        final_indices &= set(feat_set)\n",
    "    return sorted(list(final_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 20\n",
      "Global federated feature indices (FRHC): [8, 9, 14, 22, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 39, 49, 52, 54, 55, 56]\n",
      "Selected feature names: ['F9', 'F10', 'F15', 'F23', 'F25', 'F26', 'F28', 'F29', 'F30', 'F31', 'F32', 'F34', 'F35', 'F36', 'F40', 'F50', 'F53', 'F55', 'F56', 'F57']\n"
     ]
    }
   ],
   "source": [
    "# Suppose client_data_np is a list of (X_local, y_local) for all clients\n",
    "selected_lists = []\n",
    "for Xc, yc in client_data_np:\n",
    "    feats = frhc_local_feature_selection(Xc,max_clusters=13,comp_feat=1)\n",
    "    selected_lists.append(feats)\n",
    "\n",
    "# Global intersection at the server\n",
    "global_frhc_indices = frhc_global_intersection(selected_lists)\n",
    "print(\"Count:\",len(global_frhc_indices))\n",
    "print(\"Global federated feature indices (FRHC):\", global_frhc_indices)\n",
    "print(\"Selected feature names:\", [feature_cols[i] for i in global_frhc_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices=global_frhc_indices\n",
    "X_sel = X[:, selected_indices]\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 50.61% | Acc After: 84.20%\n",
      "  Client  2 | Samples:  907 | Acc Before: 31.14% | Acc After: 86.27%\n",
      "  Client  3 | Samples:  469 | Acc Before: 85.16% | Acc After: 86.72%\n",
      "  Client  4 | Samples:  675 | Acc Before: 17.81% | Acc After: 90.47%\n",
      "  Client  5 | Samples:  356 | Acc Before:  7.42% | Acc After: 92.58%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 79.15%\n",
      "Client Acc BEFORE (mean Â± std): 38.43% Â± 27.46%\n",
      "Client Acc AFTER  (mean Â± std): 88.05% Â± 3.04%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 74.91% | Acc After: 85.85%\n",
      "  Client  2 | Samples:  907 | Acc Before: 83.26% | Acc After: 86.83%\n",
      "  Client  3 | Samples:  469 | Acc Before: 58.85% | Acc After: 89.06%\n",
      "  Client  4 | Samples:  675 | Acc Before: 91.09% | Acc After: 92.34%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.70% | Acc After: 94.92%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 82.41%\n",
      "Client Acc BEFORE (mean Â± std): 80.76% Â± 13.04%\n",
      "Client Acc AFTER  (mean Â± std): 89.80% Â± 3.40%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 82.90% | Acc After: 86.46%\n",
      "  Client  2 | Samples:  907 | Acc Before: 85.94% | Acc After: 87.61%\n",
      "  Client  3 | Samples:  469 | Acc Before: 72.66% | Acc After: 88.80%\n",
      "  Client  4 | Samples:  675 | Acc Before: 91.41% | Acc After: 92.50%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.92% | Acc After: 96.09%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 82.41%\n",
      "Client Acc BEFORE (mean Â± std): 85.56% Â± 7.69%\n",
      "Client Acc AFTER  (mean Â± std): 90.29% Â± 3.54%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 82.29% | Acc After: 85.94%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.16% | Acc After: 86.50%\n",
      "  Client  3 | Samples:  469 | Acc Before: 76.04% | Acc After: 89.06%\n",
      "  Client  4 | Samples:  675 | Acc Before: 90.94% | Acc After: 92.34%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 95.31%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 82.84%\n",
      "Client Acc BEFORE (mean Â± std): 86.31% Â± 6.91%\n",
      "Client Acc AFTER  (mean Â± std): 89.83% Â± 3.56%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 83.51% | Acc After: 86.98%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.05% | Acc After: 87.39%\n",
      "  Client  3 | Samples:  469 | Acc Before: 74.48% | Acc After: 88.28%\n",
      "  Client  4 | Samples:  675 | Acc Before: 91.56% | Acc After: 92.97%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.70% | Acc After: 93.75%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 83.06%\n",
      "Client Acc BEFORE (mean Â± std): 86.26% Â± 7.26%\n",
      "Client Acc AFTER  (mean Â± std): 89.87% Â± 2.89%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.11% | Acc After: 86.28%\n",
      "  Client  2 | Samples:  907 | Acc Before: 85.71% | Acc After: 87.17%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.78% | Acc After: 89.84%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.19% | Acc After: 93.28%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.14% | Acc After: 96.09%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 83.06%\n",
      "Client Acc BEFORE (mean Â± std): 86.39% Â± 6.51%\n",
      "Client Acc AFTER  (mean Â± std): 90.53% Â± 3.70%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.98% | Acc After: 86.37%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.16% | Acc After: 87.17%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.00% | Acc After: 89.84%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.19% | Acc After: 93.28%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.92% | Acc After: 95.70%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 83.28%\n",
      "Client Acc BEFORE (mean Â± std): 86.65% Â± 6.90%\n",
      "Client Acc AFTER  (mean Â± std): 90.47% Â± 3.56%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.03% | Acc After: 86.20%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.27% | Acc After: 87.17%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.78% | Acc After: 88.54%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.34% | Acc After: 92.66%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.31% | Acc After: 96.88%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 83.39%\n",
      "Client Acc BEFORE (mean Â± std): 86.75% Â± 6.82%\n",
      "Client Acc AFTER  (mean Â± std): 90.29% Â± 3.96%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.11% | Acc After: 86.11%\n",
      "  Client  2 | Samples:  907 | Acc Before: 85.94% | Acc After: 87.50%\n",
      "  Client  3 | Samples:  469 | Acc Before: 76.30% | Acc After: 89.32%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.66% | Acc After: 92.66%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.92% | Acc After: 97.66%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 83.50%\n",
      "Client Acc BEFORE (mean Â± std): 86.79% Â± 6.61%\n",
      "Client Acc AFTER  (mean Â± std): 90.65% Â± 4.13%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.72% | Acc After: 86.63%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.50% | Acc After: 86.72%\n",
      "  Client  3 | Samples:  469 | Acc Before: 77.34% | Acc After: 88.02%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.81% | Acc After: 92.81%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.14% | Acc After: 96.09%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 83.28%\n",
      "Client Acc BEFORE (mean Â± std): 87.10% Â± 6.06%\n",
      "Client Acc AFTER  (mean Â± std): 90.06% Â± 3.77%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.98% | Acc After: 86.37%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.05% | Acc After: 87.17%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.26% | Acc After: 89.84%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.66% | Acc After: 92.34%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.70% | Acc After: 96.09%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 83.39%\n",
      "Client Acc BEFORE (mean Â± std): 86.93% Â± 7.08%\n",
      "Client Acc AFTER  (mean Â± std): 90.36% Â± 3.56%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.55% | Acc After: 86.72%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.50% | Acc After: 87.17%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.00% | Acc After: 89.58%\n",
      "  Client  4 | Samples:  675 | Acc Before: 93.12% | Acc After: 92.50%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.31% | Acc After: 96.09%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 83.39%\n",
      "Client Acc BEFORE (mean Â± std): 86.90% Â± 7.17%\n",
      "Client Acc AFTER  (mean Â± std): 90.41% Â± 3.51%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.81% | Acc After: 86.89%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.38% | Acc After: 87.05%\n",
      "  Client  3 | Samples:  469 | Acc Before: 76.30% | Acc After: 89.32%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.66% | Acc After: 92.66%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.53% | Acc After: 96.09%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 83.39%\n",
      "Client Acc BEFORE (mean Â± std): 86.94% Â± 6.45%\n",
      "Client Acc AFTER  (mean Â± std): 90.40% Â± 3.53%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.03% | Acc After: 86.98%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.16% | Acc After: 87.05%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.78% | Acc After: 89.84%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.81% | Acc After: 91.88%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.31% | Acc After: 95.31%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 83.50%\n",
      "Client Acc BEFORE (mean Â± std): 86.82% Â± 6.90%\n",
      "Client Acc AFTER  (mean Â± std): 90.21% Â± 3.14%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 83.59% | Acc After: 86.11%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.16% | Acc After: 86.94%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.52% | Acc After: 89.32%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.66% | Acc After: 92.03%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.92% | Acc After: 94.53%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 83.60%\n",
      "Client Acc BEFORE (mean Â± std): 86.57% Â± 6.90%\n",
      "Client Acc AFTER  (mean Â± std): 89.79% Â± 3.14%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.03% | Acc After: 86.28%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.38% | Acc After: 87.05%\n",
      "  Client  3 | Samples:  469 | Acc Before: 74.48% | Acc After: 83.59%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.81% | Acc After: 92.81%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.48% | Acc After: 95.31%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 83.28%\n",
      "Client Acc BEFORE (mean Â± std): 86.84% Â± 7.61%\n",
      "Client Acc AFTER  (mean Â± std): 89.01% Â± 4.35%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 85.16% | Acc After: 86.11%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.16% | Acc After: 86.94%\n",
      "  Client  3 | Samples:  469 | Acc Before: 76.04% | Acc After: 84.11%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.97% | Acc After: 92.66%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 96.48%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 83.39%\n",
      "Client Acc BEFORE (mean Â± std): 87.28% Â± 6.96%\n",
      "Client Acc AFTER  (mean Â± std): 89.26% Â± 4.59%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.98% | Acc After: 85.85%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.27% | Acc After: 86.61%\n",
      "  Client  3 | Samples:  469 | Acc Before: 74.22% | Acc After: 73.44%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.97% | Acc After: 92.03%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.31% | Acc After: 95.31%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 83.50%\n",
      "Client Acc BEFORE (mean Â± std): 86.75% Â± 7.38%\n",
      "Client Acc AFTER  (mean Â± std): 86.65% Â± 7.47%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.55% | Acc After: 86.28%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.27% | Acc After: 86.38%\n",
      "  Client  3 | Samples:  469 | Acc Before: 75.26% | Acc After: 75.78%\n",
      "  Client  4 | Samples:  675 | Acc Before: 92.97% | Acc After: 91.88%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.48% | Acc After: 96.09%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 83.50%\n",
      "Client Acc BEFORE (mean Â± std): 87.11% Â± 7.35%\n",
      "Client Acc AFTER  (mean Â± std): 87.28% Â± 6.82%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 85.16% | Acc After: 86.20%\n",
      "  Client  2 | Samples:  907 | Acc Before: 86.05% | Acc After: 86.27%\n",
      "  Client  3 | Samples:  469 | Acc Before: 76.30% | Acc After: 77.86%\n",
      "  Client  4 | Samples:  675 | Acc Before: 93.12% | Acc After: 92.50%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.70% | Acc After: 95.31%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 83.39%\n",
      "Client Acc BEFORE (mean Â± std): 87.27% Â± 6.81%\n",
      "Client Acc AFTER  (mean Â± std): 87.63% Â± 6.03%\n",
      "Client sample count (min, max): 356, 1273\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.39%\n",
      "Confusion Matrix:\n",
      " [[507  51]\n",
      " [102 261]]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_sel = X\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 47.92% | Acc After: 93.84%\n",
      "  Client  2 | Samples:  907 | Acc Before: 65.29% | Acc After: 93.08%\n",
      "  Client  3 | Samples:  469 | Acc Before: 19.53% | Acc After: 87.76%\n",
      "  Client  4 | Samples:  675 | Acc Before: 76.41% | Acc After: 94.69%\n",
      "  Client  5 | Samples:  356 | Acc Before: 87.89% | Acc After: 92.97%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 87.08%\n",
      "Client Acc BEFORE (mean Â± std): 59.41% Â± 23.90%\n",
      "Client Acc AFTER  (mean Â± std): 92.47% Â± 2.43%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 84.55% | Acc After: 94.53%\n",
      "  Client  2 | Samples:  907 | Acc Before: 89.73% | Acc After: 94.64%\n",
      "  Client  3 | Samples:  469 | Acc Before: 77.86% | Acc After: 95.05%\n",
      "  Client  4 | Samples:  675 | Acc Before: 94.06% | Acc After: 96.56%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.53% | Acc After: 95.31%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 92.18%\n",
      "Client Acc BEFORE (mean Â± std): 88.15% Â± 6.28%\n",
      "Client Acc AFTER  (mean Â± std): 95.22% Â± 0.73%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 91.93% | Acc After: 94.88%\n",
      "  Client  2 | Samples:  907 | Acc Before: 91.63% | Acc After: 95.31%\n",
      "  Client  3 | Samples:  469 | Acc Before: 92.71% | Acc After: 97.66%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.31% | Acc After: 96.25%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 94.92%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 92.29%\n",
      "Client Acc BEFORE (mean Â± std): 93.53% Â± 1.82%\n",
      "Client Acc AFTER  (mean Â± std): 95.80% Â± 1.05%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 92.97% | Acc After: 95.23%\n",
      "  Client  2 | Samples:  907 | Acc Before: 92.75% | Acc After: 95.31%\n",
      "  Client  3 | Samples:  469 | Acc Before: 93.75% | Acc After: 95.31%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.47% | Acc After: 95.94%\n",
      "  Client  5 | Samples:  356 | Acc Before: 94.92% | Acc After: 97.27%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 92.40%\n",
      "Client Acc BEFORE (mean Â± std): 93.97% Â± 1.07%\n",
      "Client Acc AFTER  (mean Â± std): 95.81% Â± 0.77%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 92.71% | Acc After: 95.05%\n",
      "  Client  2 | Samples:  907 | Acc Before: 93.42% | Acc After: 95.09%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.01% | Acc After: 95.83%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.62% | Acc After: 97.03%\n",
      "  Client  5 | Samples:  356 | Acc Before: 95.70% | Acc After: 96.48%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 92.73%\n",
      "Client Acc BEFORE (mean Â± std): 94.29% Â± 1.19%\n",
      "Client Acc AFTER  (mean Â± std): 95.90% Â± 0.77%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.40% | Acc After: 95.66%\n",
      "  Client  2 | Samples:  907 | Acc Before: 93.86% | Acc After: 94.98%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.53% | Acc After: 95.83%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.16% | Acc After: 97.03%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.48% | Acc After: 96.48%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 92.62%\n",
      "Client Acc BEFORE (mean Â± std): 94.69% Â± 1.08%\n",
      "Client Acc AFTER  (mean Â± std): 96.00% Â± 0.71%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.66% | Acc After: 95.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 93.64% | Acc After: 94.87%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.79% | Acc After: 94.27%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.16% | Acc After: 96.88%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 95.31%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 92.83%\n",
      "Client Acc BEFORE (mean Â± std): 94.98% Â± 1.47%\n",
      "Client Acc AFTER  (mean Â± std): 95.41% Â± 0.88%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 94.36% | Acc After: 95.05%\n",
      "  Client  2 | Samples:  907 | Acc Before: 93.75% | Acc After: 95.31%\n",
      "  Client  3 | Samples:  469 | Acc Before: 95.05% | Acc After: 94.53%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.16% | Acc After: 97.50%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 95.70%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 92.83%\n",
      "Client Acc BEFORE (mean Â± std): 95.12% Â± 1.19%\n",
      "Client Acc AFTER  (mean Â± std): 95.62% Â± 1.01%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.84% | Acc After: 95.49%\n",
      "  Client  2 | Samples:  907 | Acc Before: 93.97% | Acc After: 95.42%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.27% | Acc After: 94.01%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.47% | Acc After: 97.19%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 96.48%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 93.05%\n",
      "Client Acc BEFORE (mean Â± std): 94.88% Â± 1.15%\n",
      "Client Acc AFTER  (mean Â± std): 95.72% Â± 1.08%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.66% | Acc After: 95.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.20% | Acc After: 95.65%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.27% | Acc After: 94.27%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.62% | Acc After: 97.19%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 96.48%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 92.94%\n",
      "Client Acc BEFORE (mean Â± std): 94.93% Â± 1.17%\n",
      "Client Acc AFTER  (mean Â± std): 95.87% Â± 0.97%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.75% | Acc After: 95.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.08% | Acc After: 95.65%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.79% | Acc After: 93.75%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.62% | Acc After: 96.88%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 98.44%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 93.05%\n",
      "Client Acc BEFORE (mean Â± std): 95.18% Â± 1.39%\n",
      "Client Acc AFTER  (mean Â± std): 96.09% Â± 1.54%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.40% | Acc After: 95.14%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.20% | Acc After: 95.76%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.27% | Acc After: 95.83%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 96.72%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.48% | Acc After: 97.27%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 93.27%\n",
      "Client Acc BEFORE (mean Â± std): 94.89% Â± 1.19%\n",
      "Client Acc AFTER  (mean Â± std): 96.14% Â± 0.75%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.66% | Acc After: 95.66%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.42% | Acc After: 96.21%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.27% | Acc After: 95.57%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 96.56%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 98.44%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 93.05%\n",
      "Client Acc BEFORE (mean Â± std): 95.06% Â± 1.21%\n",
      "Client Acc AFTER  (mean Â± std): 96.49% Â± 1.04%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.75% | Acc After: 95.83%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.64% | Acc After: 95.54%\n",
      "  Client  3 | Samples:  469 | Acc Before: 93.75% | Acc After: 95.31%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.78% | Acc After: 96.56%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 96.09%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 93.16%\n",
      "Client Acc BEFORE (mean Â± std): 94.80% Â± 0.99%\n",
      "Client Acc AFTER  (mean Â± std): 95.87% Â± 0.44%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.84% | Acc After: 95.40%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.75% | Acc After: 95.87%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.79% | Acc After: 95.57%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.94% | Acc After: 97.66%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 97.66%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 93.27%\n",
      "Client Acc BEFORE (mean Â± std): 95.24% Â± 1.06%\n",
      "Client Acc AFTER  (mean Â± std): 96.43% Â± 1.01%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.66% | Acc After: 95.66%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.75% | Acc After: 94.87%\n",
      "  Client  3 | Samples:  469 | Acc Before: 92.97% | Acc After: 94.79%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.94% | Acc After: 97.03%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.88% | Acc After: 96.09%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 93.16%\n",
      "Client Acc BEFORE (mean Â± std): 94.84% Â± 1.43%\n",
      "Client Acc AFTER  (mean Â± std): 95.69% Â± 0.83%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.92% | Acc After: 95.75%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.75% | Acc After: 95.09%\n",
      "  Client  3 | Samples:  469 | Acc Before: 95.05% | Acc After: 93.49%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.41% | Acc After: 96.88%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 95.70%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 93.16%\n",
      "Client Acc BEFORE (mean Â± std): 95.56% Â± 1.32%\n",
      "Client Acc AFTER  (mean Â± std): 95.38% Â± 1.11%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.66% | Acc After: 94.62%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.87% | Acc After: 94.64%\n",
      "  Client  3 | Samples:  469 | Acc Before: 92.45% | Acc After: 90.89%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 95.62%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.27% | Acc After: 95.31%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 93.16%\n",
      "Client Acc BEFORE (mean Â± std): 94.87% Â± 1.71%\n",
      "Client Acc AFTER  (mean Â± std): 94.22% Â± 1.71%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.92% | Acc After: 94.70%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.75% | Acc After: 94.75%\n",
      "  Client  3 | Samples:  469 | Acc Before: 92.45% | Acc After: 91.67%\n",
      "  Client  4 | Samples:  675 | Acc Before: 95.78% | Acc After: 95.47%\n",
      "  Client  5 | Samples:  356 | Acc Before: 97.66% | Acc After: 96.09%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 93.05%\n",
      "Client Acc BEFORE (mean Â± std): 94.91% Â± 1.75%\n",
      "Client Acc AFTER  (mean Â± std): 94.54% Â± 1.52%\n",
      "Client sample count (min, max): 356, 1273\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 1273 | Acc Before: 93.92% | Acc After: 95.05%\n",
      "  Client  2 | Samples:  907 | Acc Before: 94.53% | Acc After: 94.64%\n",
      "  Client  3 | Samples:  469 | Acc Before: 94.27% | Acc After: 91.93%\n",
      "  Client  4 | Samples:  675 | Acc Before: 96.09% | Acc After: 95.94%\n",
      "  Client  5 | Samples:  356 | Acc Before: 96.09% | Acc After: 96.09%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 93.05%\n",
      "Client Acc BEFORE (mean Â± std): 94.98% Â± 0.93%\n",
      "Client Acc AFTER  (mean Â± std): 94.73% Â± 1.50%\n",
      "Client sample count (min, max): 356, 1273\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.05%\n",
      "Confusion Matrix:\n",
      " [[528  30]\n",
      " [ 34 329]]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1303049,
     "sourceId": 2260912,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
