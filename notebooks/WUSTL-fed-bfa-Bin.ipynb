{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For IoT IDS\n",
    "csv_path = 'wustl_corrected.csv'\n",
    "df = pd.read_csv(csv_path,low_memory=False)\n",
    "#print(df.columns)\n",
    "#print(df.shape)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartTime', 'LastTime', 'SrcAddr', 'DstAddr', 'Mean', 'Sport', 'Dport',\n",
       "       'SrcPkts', 'DstPkts', 'TotPkts', 'DstBytes', 'SrcBytes', 'TotBytes',\n",
       "       'SrcLoad', 'DstLoad', 'Load', 'SrcRate', 'DstRate', 'Rate', 'SrcLoss',\n",
       "       'DstLoss', 'Loss', 'pLoss', 'SrcJitter', 'DstJitter', 'SIntPkt',\n",
       "       'DIntPkt', 'Proto', 'Dur', 'TcpRtt', 'Sum', 'Min', 'Max', 'sDSb',\n",
       "       'sTtl', 'dTtl', 'sIpId', 'dIpId', 'SAppBytes', 'DAppBytes',\n",
       "       'TotAppByte', 'SynAck', 'RunTime', 'sTos', 'SrcJitAct', 'DstJitAct',\n",
       "       'Traffic', 'Target', 'IdleTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LastTime</th>\n",
       "      <th>SrcAddr</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dport</th>\n",
       "      <th>SrcPkts</th>\n",
       "      <th>DstPkts</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>...</th>\n",
       "      <th>DAppBytes</th>\n",
       "      <th>TotAppByte</th>\n",
       "      <th>SynAck</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>sTos</th>\n",
       "      <th>SrcJitAct</th>\n",
       "      <th>DstJitAct</th>\n",
       "      <th>Traffic</th>\n",
       "      <th>Target</th>\n",
       "      <th>IdleTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-19 09:46:08</td>\n",
       "      <td>2019-08-19 14:14:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-19 13:24:34</td>\n",
       "      <td>2019-08-19 14:14:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-19 11:05:18</td>\n",
       "      <td>2019-08-19 11:04:18</td>\n",
       "      <td>0</td>\n",
       "      <td>14740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>90864</td>\n",
       "      <td>11501</td>\n",
       "      <td>90864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019535332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-19 12:30:18</td>\n",
       "      <td>2019-08-19 12:29:18</td>\n",
       "      <td>0</td>\n",
       "      <td>15046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11560267</td>\n",
       "      <td>154248</td>\n",
       "      <td>11560267</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3488030376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-19 11:10:18</td>\n",
       "      <td>2019-08-19 11:09:18</td>\n",
       "      <td>0</td>\n",
       "      <td>16274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93115</td>\n",
       "      <td>14011</td>\n",
       "      <td>93115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2138927796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartTime             LastTime SrcAddr DstAddr  Mean  Sport  \\\n",
       "0  2019-08-19 09:46:08  2019-08-19 14:14:18       0       0     0      0   \n",
       "1  2019-08-19 13:24:34  2019-08-19 14:14:18       0       0     0      0   \n",
       "2  2019-08-19 11:05:18  2019-08-19 11:04:18       0   14740     0      0   \n",
       "3  2019-08-19 12:30:18  2019-08-19 12:29:18       0   15046     0      0   \n",
       "4  2019-08-19 11:10:18  2019-08-19 11:09:18       0   16274     0      0   \n",
       "\n",
       "   Dport   SrcPkts  DstPkts   TotPkts  ...  DAppBytes  TotAppByte  SynAck  \\\n",
       "0      0         0        0         0  ...          0           0     0.0   \n",
       "1      0         0        0         0  ...          0           0     0.0   \n",
       "2      2     90864    11501     90864  ...          0  2019535332     0.0   \n",
       "3      2  11560267   154248  11560267  ...          0  3488030376     0.0   \n",
       "4      2     93115    14011     93115  ...          0  2138927796     0.0   \n",
       "\n",
       "   RunTime  sTos  SrcJitAct  DstJitAct  Traffic  Target  IdleTime  \n",
       "0      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "1      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "2      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "3      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "4      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "0    1107448\n",
      "1      87016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Target'].value_counts())\n",
    "# Now, remap your classes as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['StartTime', 'LastTime', 'SrcAddr', 'DstAddr','Traffic','Target']\n",
    "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "label_col = 'Target'\n",
    "print(len(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "X = df[feature_cols].values\n",
    "y = df[label_col].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features removed: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.0)\n",
    "X_var = var_thresh.fit_transform(X)\n",
    "print(f\"Constant features removed: {X.shape[1] - X_var.shape[1]}\")\n",
    "X = X_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 class distribution: [64998 18798]\n",
      "Client 2 class distribution: [34419  7673]\n",
      "Client 3 class distribution: [42858  4370]\n",
      "Client 4 class distribution: [557407   4074]\n",
      "Client 5 class distribution: [14885   121]\n",
      "Client 6 class distribution: [6136    1]\n",
      "Client 7 class distribution: [78000 18532]\n",
      "Client 8 class distribution: [4175  475]\n",
      "Client 9 class distribution: [16449 12111]\n",
      "Client 10 class distribution: [66631  3458]\n"
     ]
    }
   ],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "full_dataset = TabularDataset(X, y)\n",
    "train_idx, test_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, stratify=y, random_state=6)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "def partition_tabular_dataset(dataset, labels, train_idx, num_clients=10, alpha=0.5):\n",
    "    np.random.seed(6)\n",
    "    targets = np.array(labels)[train_idx]\n",
    "    num_classes = np.max(targets) + 1\n",
    "    idxs = np.arange(len(targets))\n",
    "    client_idx = [[] for _ in range(num_clients)]\n",
    "    for c in range(num_classes):\n",
    "        idx_c = idxs[targets == c]\n",
    "        np.random.shuffle(idx_c)\n",
    "        proportions = np.random.dirichlet([alpha]*num_clients)\n",
    "        proportions = (np.cumsum(proportions) * len(idx_c)).astype(int)[:-1]\n",
    "        split_idxs = np.split(idx_c, proportions)\n",
    "        for i, idx in enumerate(split_idxs):\n",
    "            client_idx[i].extend(idx)\n",
    "    return client_idx\n",
    "\n",
    "num_clients = 10\n",
    "alpha = 0.5\n",
    "client_indices = partition_tabular_dataset(train_dataset, y, train_idx, num_clients, alpha)\n",
    "\n",
    "client_data_np = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    X_client = X[train_idx][idxs]\n",
    "    y_client = y[train_idx][idxs]\n",
    "    client_data_np.append((X_client, y_client))\n",
    "\n",
    "for i, (Xc, yc) in enumerate(client_data_np):\n",
    "    print(f\"Client {i+1} class distribution:\", np.bincount(yc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_scores(X, y):\n",
    "    scores, _ = f_classif(X, y)\n",
    "    # Normalize scores to [0,1]\n",
    "    min_val = np.min(scores)\n",
    "    max_val = np.max(scores)\n",
    "    if max_val > min_val:\n",
    "        normalized_scores = (scores - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_scores = np.zeros_like(scores)\n",
    "    return normalized_scores\n",
    "\n",
    "def compute_corr_matrix(X):\n",
    "    corr = np.corrcoef(X, rowvar=False)\n",
    "    return np.abs(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_feature_subset(subset, fisher_scores, corr_matrix, penalty_lambda=0.7):\n",
    "    if len(subset) == 0:\n",
    "        return 0\n",
    "    fisher_sum = np.sum(fisher_scores[subset])\n",
    "    if len(subset) > 1:\n",
    "        corr_penalty = np.sum(corr_matrix[np.ix_(subset, subset)]) - np.sum(np.diag(corr_matrix[subset][:, subset]))\n",
    "        corr_penalty /= 2\n",
    "    else:\n",
    "        corr_penalty = 0.0\n",
    "    return penalty_lambda * fisher_sum - (1 - penalty_lambda) * corr_penalty\n",
    "\n",
    "def one_step_binary_firefly(\n",
    "    firefly_mask_prev, global_mask_prev, local_best_mask_prev,\n",
    "    fisher_scores, corr_matrix, penalty_lambda=0.7, p_global=0.3, p_local=0.3, mutation_rate=0.05, verbose=False\n",
    "):\n",
    "    n_features = len(firefly_mask_prev)\n",
    "    new_mask = firefly_mask_prev.copy()\n",
    "    for i in range(n_features):\n",
    "        r = np.random.rand()\n",
    "        if r < p_global:\n",
    "            new_mask[i] = global_mask_prev[i]\n",
    "        elif r < p_global + p_local:\n",
    "            new_mask[i] = local_best_mask_prev[i]\n",
    "        elif np.random.rand() < mutation_rate:\n",
    "            new_mask[i] = 1 - new_mask[i]  # mutate\n",
    "\n",
    "    # Optional: flip one bit with small probability for extra exploration\n",
    "    if np.random.rand() < 0.2:\n",
    "        idx = np.random.randint(n_features)\n",
    "        new_mask[idx] = 1 - new_mask[idx]\n",
    "\n",
    "    if verbose:\n",
    "        sel = np.where(new_mask)[0]\n",
    "        fit = evaluate_feature_subset(sel, fisher_scores, corr_matrix, penalty_lambda)\n",
    "        print(f\"    - New mask: {np.sum(new_mask)} features, Fitness: {fit:.4f}\")\n",
    "\n",
    "    return new_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Federated BFA Round 1 ================\n",
      "  Adaptive rho for this round: 0.20\n",
      "    - New mask: 20 features, Fitness: -1.2818\n",
      "    - New mask: 26 features, Fitness: -1.9679\n",
      "    - New mask: 24 features, Fitness: -1.9773\n",
      "    - New mask: 23 features, Fitness: -2.2161\n",
      "    - New mask: 22 features, Fitness: -1.6795\n",
      "    - New mask: 27 features, Fitness: -3.0962\n",
      "    - New mask: 21 features, Fitness: -2.0651\n",
      "    - New mask: 26 features, Fitness: -2.4394\n",
      "    - New mask: 21 features, Fitness: -1.2013\n",
      "    - New mask: 31 features, Fitness: -4.9730\n",
      "    - New mask: 23 features, Fitness: -1.5508\n",
      "    - New mask: 28 features, Fitness: -2.3302\n",
      "    - New mask: 29 features, Fitness: -2.9604\n",
      "    - New mask: 26 features, Fitness: -2.4212\n",
      "    - New mask: 30 features, Fitness: -3.7272\n",
      "    - New mask: 24 features, Fitness: -1.9452\n",
      "    - New mask: 22 features, Fitness: -1.9119\n",
      "    - New mask: 21 features, Fitness: -1.6368\n",
      "    - New mask: 29 features, Fitness: -3.8317\n",
      "    - New mask: 28 features, Fitness: -4.0018\n",
      "    - New mask: 21 features, Fitness: -0.5693\n",
      "    - New mask: 32 features, Fitness: -3.0156\n",
      "    - New mask: 28 features, Fitness: -2.1331\n",
      "    - New mask: 28 features, Fitness: -2.1561\n",
      "    - New mask: 22 features, Fitness: -1.4291\n",
      "    - New mask: 27 features, Fitness: -2.1459\n",
      "    - New mask: 27 features, Fitness: -2.7334\n",
      "    - New mask: 25 features, Fitness: -1.4426\n",
      "    - New mask: 26 features, Fitness: -1.4966\n",
      "    - New mask: 24 features, Fitness: -0.7952\n",
      "    - New mask: 27 features, Fitness: -2.4387\n",
      "    - New mask: 30 features, Fitness: -2.3695\n",
      "    - New mask: 27 features, Fitness: -2.4183\n",
      "    - New mask: 26 features, Fitness: -1.9773\n",
      "    - New mask: 27 features, Fitness: -2.4850\n",
      "    - New mask: 29 features, Fitness: -2.5451\n",
      "    - New mask: 22 features, Fitness: -1.9971\n",
      "    - New mask: 23 features, Fitness: -0.8471\n",
      "    - New mask: 28 features, Fitness: -2.2733\n",
      "    - New mask: 26 features, Fitness: -1.7048\n",
      "    - New mask: 24 features, Fitness: -1.5172\n",
      "    - New mask: 28 features, Fitness: -1.8195\n",
      "    - New mask: 30 features, Fitness: -2.2973\n",
      "    - New mask: 29 features, Fitness: -2.2040\n",
      "    - New mask: 26 features, Fitness: -1.9378\n",
      "    - New mask: 23 features, Fitness: -1.8328\n",
      "    - New mask: 31 features, Fitness: -3.8569\n",
      "    - New mask: 21 features, Fitness: -0.7962\n",
      "    - New mask: 22 features, Fitness: -1.0822\n",
      "    - New mask: 31 features, Fitness: -3.1039\n",
      "    - New mask: 22 features, Fitness: -0.5377\n",
      "    - New mask: 19 features, Fitness: -1.0401\n",
      "    - New mask: 36 features, Fitness: -3.6510\n",
      "    - New mask: 30 features, Fitness: -3.1885\n",
      "    - New mask: 31 features, Fitness: -2.8398\n",
      "    - New mask: 27 features, Fitness: -1.4327\n",
      "    - New mask: 28 features, Fitness: -2.7200\n",
      "    - New mask: 27 features, Fitness: -3.0606\n",
      "    - New mask: 23 features, Fitness: -0.6755\n",
      "    - New mask: 28 features, Fitness: -1.6171\n",
      "    - New mask: 25 features, Fitness: 0.8293\n",
      "    - New mask: 32 features, Fitness: -0.1782\n",
      "    - New mask: 28 features, Fitness: 0.2258\n",
      "    - New mask: 27 features, Fitness: 0.0314\n",
      "    - New mask: 25 features, Fitness: 1.0311\n",
      "    - New mask: 22 features, Fitness: 1.5277\n",
      "    - New mask: 19 features, Fitness: 1.9541\n",
      "    - New mask: 26 features, Fitness: 1.1681\n",
      "    - New mask: 19 features, Fitness: 1.8705\n",
      "    - New mask: 22 features, Fitness: 1.6481\n",
      "    - New mask: 26 features, Fitness: 1.2882\n",
      "    - New mask: 28 features, Fitness: -0.1247\n",
      "    - New mask: 28 features, Fitness: 0.7176\n",
      "    - New mask: 24 features, Fitness: 1.4888\n",
      "    - New mask: 26 features, Fitness: 1.0867\n",
      "    - New mask: 27 features, Fitness: 0.7412\n",
      "    - New mask: 27 features, Fitness: 0.2581\n",
      "    - New mask: 23 features, Fitness: 0.4981\n",
      "    - New mask: 26 features, Fitness: 0.7881\n",
      "    - New mask: 26 features, Fitness: 0.8266\n",
      "    - New mask: 28 features, Fitness: 1.2258\n",
      "    - New mask: 24 features, Fitness: 0.3978\n",
      "    - New mask: 25 features, Fitness: -0.7449\n",
      "    - New mask: 32 features, Fitness: -0.5013\n",
      "    - New mask: 30 features, Fitness: 0.4606\n",
      "    - New mask: 28 features, Fitness: -0.3631\n",
      "    - New mask: 31 features, Fitness: -0.2657\n",
      "    - New mask: 32 features, Fitness: -1.4974\n",
      "    - New mask: 28 features, Fitness: -0.2456\n",
      "    - New mask: 28 features, Fitness: -0.7491\n",
      "    - New mask: 30 features, Fitness: -0.3934\n",
      "    - New mask: 28 features, Fitness: 0.9204\n",
      "    - New mask: 29 features, Fitness: 0.6065\n",
      "    - New mask: 27 features, Fitness: 0.5446\n",
      "    - New mask: 31 features, Fitness: -0.1891\n",
      "    - New mask: 27 features, Fitness: -0.1033\n",
      "    - New mask: 24 features, Fitness: 0.5253\n",
      "    - New mask: 23 features, Fitness: 1.5901\n",
      "    - New mask: 31 features, Fitness: -0.5581\n",
      "    - New mask: 27 features, Fitness: 0.9031\n",
      "    - New mask: 28 features, Fitness: -4.3668\n",
      "    - New mask: 30 features, Fitness: -6.4766\n",
      "    - New mask: 22 features, Fitness: -2.6178\n",
      "    - New mask: 23 features, Fitness: -3.0835\n",
      "    - New mask: 25 features, Fitness: -4.3327\n",
      "    - New mask: 27 features, Fitness: -4.5927\n",
      "    - New mask: 20 features, Fitness: -3.3300\n",
      "    - New mask: 25 features, Fitness: -2.8626\n",
      "    - New mask: 26 features, Fitness: -5.1261\n",
      "    - New mask: 28 features, Fitness: -5.4511\n",
      "    - New mask: 29 features, Fitness: -4.2362\n",
      "    - New mask: 24 features, Fitness: -3.3887\n",
      "    - New mask: 29 features, Fitness: -4.6422\n",
      "    - New mask: 24 features, Fitness: -2.6355\n",
      "    - New mask: 26 features, Fitness: -4.7480\n",
      "    - New mask: 30 features, Fitness: -4.7449\n",
      "    - New mask: 25 features, Fitness: -3.2901\n",
      "    - New mask: 21 features, Fitness: -1.7225\n",
      "    - New mask: 28 features, Fitness: -4.9948\n",
      "    - New mask: 23 features, Fitness: -4.0667\n",
      "    - New mask: 19 features, Fitness: -1.5402\n",
      "    - New mask: 25 features, Fitness: -2.3523\n",
      "    - New mask: 25 features, Fitness: -1.5721\n",
      "    - New mask: 25 features, Fitness: -1.5778\n",
      "    - New mask: 28 features, Fitness: -1.4044\n",
      "    - New mask: 28 features, Fitness: -2.6266\n",
      "    - New mask: 29 features, Fitness: -2.5268\n",
      "    - New mask: 24 features, Fitness: -1.1152\n",
      "    - New mask: 29 features, Fitness: -3.3711\n",
      "    - New mask: 26 features, Fitness: -1.7064\n",
      "    - New mask: 25 features, Fitness: -2.1922\n",
      "    - New mask: 21 features, Fitness: -0.5519\n",
      "    - New mask: 31 features, Fitness: -2.5416\n",
      "    - New mask: 21 features, Fitness: -1.6600\n",
      "    - New mask: 22 features, Fitness: -0.6990\n",
      "    - New mask: 25 features, Fitness: -1.2651\n",
      "    - New mask: 27 features, Fitness: -2.1048\n",
      "    - New mask: 25 features, Fitness: -2.2254\n",
      "    - New mask: 31 features, Fitness: -3.0447\n",
      "    - New mask: 20 features, Fitness: -0.4378\n",
      "    - New mask: 35 features, Fitness: -8.6654\n",
      "    - New mask: 28 features, Fitness: -4.0002\n",
      "    - New mask: 24 features, Fitness: -3.1661\n",
      "    - New mask: 29 features, Fitness: -5.7923\n",
      "    - New mask: 21 features, Fitness: -1.9240\n",
      "    - New mask: 23 features, Fitness: -2.3767\n",
      "    - New mask: 28 features, Fitness: -4.5690\n",
      "    - New mask: 27 features, Fitness: -3.2526\n",
      "    - New mask: 23 features, Fitness: -2.8310\n",
      "    - New mask: 22 features, Fitness: -2.3450\n",
      "    - New mask: 23 features, Fitness: -2.7577\n",
      "    - New mask: 24 features, Fitness: -2.4439\n",
      "    - New mask: 30 features, Fitness: -4.2816\n",
      "    - New mask: 26 features, Fitness: -3.1205\n",
      "    - New mask: 30 features, Fitness: -5.5422\n",
      "    - New mask: 29 features, Fitness: -6.2398\n",
      "    - New mask: 24 features, Fitness: -2.0212\n",
      "    - New mask: 26 features, Fitness: -4.8094\n",
      "    - New mask: 24 features, Fitness: -2.6724\n",
      "    - New mask: 25 features, Fitness: -4.0074\n",
      "    - New mask: 23 features, Fitness: -2.9976\n",
      "    - New mask: 31 features, Fitness: -4.5403\n",
      "    - New mask: 30 features, Fitness: -3.6907\n",
      "    - New mask: 25 features, Fitness: -2.7071\n",
      "    - New mask: 32 features, Fitness: -5.0627\n",
      "    - New mask: 25 features, Fitness: -3.3632\n",
      "    - New mask: 29 features, Fitness: -4.3879\n",
      "    - New mask: 21 features, Fitness: -1.4090\n",
      "    - New mask: 26 features, Fitness: -2.5111\n",
      "    - New mask: 26 features, Fitness: -2.4956\n",
      "    - New mask: 27 features, Fitness: -3.1090\n",
      "    - New mask: 23 features, Fitness: -2.5346\n",
      "    - New mask: 26 features, Fitness: -3.2654\n",
      "    - New mask: 29 features, Fitness: -3.9001\n",
      "    - New mask: 29 features, Fitness: -4.0587\n",
      "    - New mask: 26 features, Fitness: -2.3944\n",
      "    - New mask: 30 features, Fitness: -4.2351\n",
      "    - New mask: 29 features, Fitness: -3.6349\n",
      "    - New mask: 29 features, Fitness: -3.4803\n",
      "    - New mask: 30 features, Fitness: -4.8693\n",
      "    - New mask: 26 features, Fitness: -0.6862\n",
      "    - New mask: 26 features, Fitness: -1.1470\n",
      "    - New mask: 30 features, Fitness: -2.0850\n",
      "    - New mask: 29 features, Fitness: -1.5467\n",
      "    - New mask: 29 features, Fitness: -1.0945\n",
      "    - New mask: 25 features, Fitness: -1.1348\n",
      "    - New mask: 25 features, Fitness: -1.5106\n",
      "    - New mask: 29 features, Fitness: -2.6504\n",
      "    - New mask: 28 features, Fitness: -1.5211\n",
      "    - New mask: 27 features, Fitness: -1.6265\n",
      "    - New mask: 23 features, Fitness: -0.9182\n",
      "    - New mask: 31 features, Fitness: -1.5773\n",
      "    - New mask: 29 features, Fitness: -1.9806\n",
      "    - New mask: 26 features, Fitness: -0.7529\n",
      "    - New mask: 29 features, Fitness: -1.8158\n",
      "    - New mask: 29 features, Fitness: -1.2628\n",
      "    - New mask: 31 features, Fitness: -2.4267\n",
      "    - New mask: 25 features, Fitness: -0.7985\n",
      "    - New mask: 26 features, Fitness: -0.1936\n",
      "    - New mask: 26 features, Fitness: -1.2343\n",
      "=== End of Round 1: Vote mask selects 42 features (rho: 0.20)\n",
      "    Indices: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 2 ================\n",
      "  Adaptive rho for this round: 0.23\n",
      "    - New mask: 23 features, Fitness: -1.5617\n",
      "    - New mask: 28 features, Fitness: -3.3480\n",
      "    - New mask: 31 features, Fitness: -3.7040\n",
      "    - New mask: 27 features, Fitness: -2.8000\n",
      "    - New mask: 26 features, Fitness: -2.5148\n",
      "    - New mask: 30 features, Fitness: -3.4595\n",
      "    - New mask: 25 features, Fitness: -2.5383\n",
      "    - New mask: 26 features, Fitness: -1.9076\n",
      "    - New mask: 29 features, Fitness: -3.1620\n",
      "    - New mask: 27 features, Fitness: -3.1703\n",
      "    - New mask: 22 features, Fitness: -1.3899\n",
      "    - New mask: 33 features, Fitness: -3.7828\n",
      "    - New mask: 29 features, Fitness: -2.7753\n",
      "    - New mask: 25 features, Fitness: -1.8187\n",
      "    - New mask: 32 features, Fitness: -4.6809\n",
      "    - New mask: 26 features, Fitness: -2.1534\n",
      "    - New mask: 31 features, Fitness: -3.8477\n",
      "    - New mask: 31 features, Fitness: -3.4255\n",
      "    - New mask: 27 features, Fitness: -2.6205\n",
      "    - New mask: 28 features, Fitness: -3.3997\n",
      "    - New mask: 25 features, Fitness: -1.4323\n",
      "    - New mask: 35 features, Fitness: -4.6283\n",
      "    - New mask: 30 features, Fitness: -3.0351\n",
      "    - New mask: 31 features, Fitness: -3.0123\n",
      "    - New mask: 18 features, Fitness: -0.6132\n",
      "    - New mask: 29 features, Fitness: -2.9850\n",
      "    - New mask: 32 features, Fitness: -4.6528\n",
      "    - New mask: 29 features, Fitness: -2.5743\n",
      "    - New mask: 29 features, Fitness: -2.8958\n",
      "    - New mask: 28 features, Fitness: -1.7451\n",
      "    - New mask: 32 features, Fitness: -4.0264\n",
      "    - New mask: 29 features, Fitness: -2.1173\n",
      "    - New mask: 31 features, Fitness: -3.0777\n",
      "    - New mask: 28 features, Fitness: -2.9685\n",
      "    - New mask: 28 features, Fitness: -2.3189\n",
      "    - New mask: 31 features, Fitness: -3.6259\n",
      "    - New mask: 29 features, Fitness: -3.8502\n",
      "    - New mask: 24 features, Fitness: -1.0731\n",
      "    - New mask: 25 features, Fitness: -1.6891\n",
      "    - New mask: 27 features, Fitness: -2.2789\n",
      "    - New mask: 32 features, Fitness: -3.0382\n",
      "    - New mask: 30 features, Fitness: -2.2966\n",
      "    - New mask: 28 features, Fitness: -1.7658\n",
      "    - New mask: 29 features, Fitness: -1.9823\n",
      "    - New mask: 29 features, Fitness: -2.3033\n",
      "    - New mask: 31 features, Fitness: -2.7646\n",
      "    - New mask: 32 features, Fitness: -2.8280\n",
      "    - New mask: 27 features, Fitness: -1.7508\n",
      "    - New mask: 30 features, Fitness: -3.3059\n",
      "    - New mask: 34 features, Fitness: -4.3816\n",
      "    - New mask: 24 features, Fitness: -1.6504\n",
      "    - New mask: 24 features, Fitness: -1.5718\n",
      "    - New mask: 35 features, Fitness: -3.7840\n",
      "    - New mask: 29 features, Fitness: -2.4485\n",
      "    - New mask: 32 features, Fitness: -2.6412\n",
      "    - New mask: 27 features, Fitness: -1.3173\n",
      "    - New mask: 28 features, Fitness: -2.3016\n",
      "    - New mask: 26 features, Fitness: -2.0060\n",
      "    - New mask: 28 features, Fitness: -1.7964\n",
      "    - New mask: 33 features, Fitness: -2.9718\n",
      "    - New mask: 26 features, Fitness: 1.9289\n",
      "    - New mask: 37 features, Fitness: -0.3111\n",
      "    - New mask: 23 features, Fitness: 1.0652\n",
      "    - New mask: 31 features, Fitness: -0.2557\n",
      "    - New mask: 30 features, Fitness: 0.2611\n",
      "    - New mask: 26 features, Fitness: 1.0580\n",
      "    - New mask: 28 features, Fitness: 0.7604\n",
      "    - New mask: 23 features, Fitness: 1.2455\n",
      "    - New mask: 24 features, Fitness: 0.6996\n",
      "    - New mask: 29 features, Fitness: 0.6192\n",
      "    - New mask: 27 features, Fitness: 0.7074\n",
      "    - New mask: 27 features, Fitness: 0.3177\n",
      "    - New mask: 31 features, Fitness: 0.0822\n",
      "    - New mask: 27 features, Fitness: 0.5789\n",
      "    - New mask: 31 features, Fitness: 0.1430\n",
      "    - New mask: 28 features, Fitness: 0.7373\n",
      "    - New mask: 25 features, Fitness: 1.1595\n",
      "    - New mask: 24 features, Fitness: 0.6652\n",
      "    - New mask: 25 features, Fitness: 1.4320\n",
      "    - New mask: 25 features, Fitness: 1.7536\n",
      "    - New mask: 32 features, Fitness: -0.3528\n",
      "    - New mask: 27 features, Fitness: -0.3007\n",
      "    - New mask: 30 features, Fitness: -0.5230\n",
      "    - New mask: 35 features, Fitness: -2.5031\n",
      "    - New mask: 31 features, Fitness: -0.5900\n",
      "    - New mask: 33 features, Fitness: -0.9760\n",
      "    - New mask: 33 features, Fitness: -0.3694\n",
      "    - New mask: 32 features, Fitness: -1.1584\n",
      "    - New mask: 33 features, Fitness: -0.5764\n",
      "    - New mask: 27 features, Fitness: -0.1467\n",
      "    - New mask: 34 features, Fitness: -1.3528\n",
      "    - New mask: 30 features, Fitness: -0.7060\n",
      "    - New mask: 31 features, Fitness: 0.3730\n",
      "    - New mask: 35 features, Fitness: -1.2462\n",
      "    - New mask: 28 features, Fitness: 1.0360\n",
      "    - New mask: 26 features, Fitness: 0.3178\n",
      "    - New mask: 30 features, Fitness: -1.0956\n",
      "    - New mask: 28 features, Fitness: 0.9633\n",
      "    - New mask: 31 features, Fitness: 0.0176\n",
      "    - New mask: 27 features, Fitness: 0.3739\n",
      "    - New mask: 33 features, Fitness: -6.2976\n",
      "    - New mask: 28 features, Fitness: -3.9466\n",
      "    - New mask: 23 features, Fitness: -2.5824\n",
      "    - New mask: 27 features, Fitness: -5.3303\n",
      "    - New mask: 29 features, Fitness: -4.2095\n",
      "    - New mask: 34 features, Fitness: -7.7744\n",
      "    - New mask: 30 features, Fitness: -5.1712\n",
      "    - New mask: 30 features, Fitness: -4.1151\n",
      "    - New mask: 29 features, Fitness: -5.2847\n",
      "    - New mask: 34 features, Fitness: -8.1922\n",
      "    - New mask: 27 features, Fitness: -3.9388\n",
      "    - New mask: 26 features, Fitness: -5.9883\n",
      "    - New mask: 31 features, Fitness: -5.5713\n",
      "    - New mask: 29 features, Fitness: -6.1581\n",
      "    - New mask: 29 features, Fitness: -5.2984\n",
      "    - New mask: 28 features, Fitness: -3.2877\n",
      "    - New mask: 28 features, Fitness: -5.5325\n",
      "    - New mask: 30 features, Fitness: -5.5307\n",
      "    - New mask: 30 features, Fitness: -6.9421\n",
      "    - New mask: 26 features, Fitness: -3.8410\n",
      "    - New mask: 30 features, Fitness: -2.5498\n",
      "    - New mask: 26 features, Fitness: -2.3309\n",
      "    - New mask: 27 features, Fitness: -2.0236\n",
      "    - New mask: 28 features, Fitness: -2.9371\n",
      "    - New mask: 29 features, Fitness: -2.7315\n",
      "    - New mask: 30 features, Fitness: -2.8870\n",
      "    - New mask: 29 features, Fitness: -2.7735\n",
      "    - New mask: 33 features, Fitness: -4.5785\n",
      "    - New mask: 29 features, Fitness: -3.4773\n",
      "    - New mask: 27 features, Fitness: -1.7810\n",
      "    - New mask: 25 features, Fitness: -1.9873\n",
      "    - New mask: 22 features, Fitness: -1.3309\n",
      "    - New mask: 29 features, Fitness: -1.8877\n",
      "    - New mask: 25 features, Fitness: -1.9141\n",
      "    - New mask: 23 features, Fitness: -1.2669\n",
      "    - New mask: 30 features, Fitness: -2.6584\n",
      "    - New mask: 27 features, Fitness: -1.8830\n",
      "    - New mask: 32 features, Fitness: -3.0007\n",
      "    - New mask: 28 features, Fitness: -2.1558\n",
      "    - New mask: 27 features, Fitness: -2.1020\n",
      "    - New mask: 36 features, Fitness: -9.8238\n",
      "    - New mask: 28 features, Fitness: -4.9665\n",
      "    - New mask: 24 features, Fitness: -2.7604\n",
      "    - New mask: 26 features, Fitness: -3.6819\n",
      "    - New mask: 27 features, Fitness: -4.5114\n",
      "    - New mask: 33 features, Fitness: -6.7071\n",
      "    - New mask: 29 features, Fitness: -3.9629\n",
      "    - New mask: 26 features, Fitness: -3.2211\n",
      "    - New mask: 27 features, Fitness: -4.1999\n",
      "    - New mask: 29 features, Fitness: -4.5213\n",
      "    - New mask: 32 features, Fitness: -5.7139\n",
      "    - New mask: 32 features, Fitness: -6.7994\n",
      "    - New mask: 27 features, Fitness: -3.7914\n",
      "    - New mask: 25 features, Fitness: -2.9363\n",
      "    - New mask: 32 features, Fitness: -5.6958\n",
      "    - New mask: 36 features, Fitness: -8.9194\n",
      "    - New mask: 30 features, Fitness: -4.9520\n",
      "    - New mask: 31 features, Fitness: -6.1579\n",
      "    - New mask: 28 features, Fitness: -4.7288\n",
      "    - New mask: 29 features, Fitness: -5.0138\n",
      "    - New mask: 29 features, Fitness: -3.8199\n",
      "    - New mask: 31 features, Fitness: -4.8018\n",
      "    - New mask: 33 features, Fitness: -5.8230\n",
      "    - New mask: 32 features, Fitness: -4.5715\n",
      "    - New mask: 31 features, Fitness: -5.0117\n",
      "    - New mask: 30 features, Fitness: -3.0663\n",
      "    - New mask: 31 features, Fitness: -5.0845\n",
      "    - New mask: 29 features, Fitness: -4.0119\n",
      "    - New mask: 29 features, Fitness: -4.0561\n",
      "    - New mask: 29 features, Fitness: -4.0186\n",
      "    - New mask: 28 features, Fitness: -3.8056\n",
      "    - New mask: 24 features, Fitness: -1.9760\n",
      "    - New mask: 26 features, Fitness: -3.3435\n",
      "    - New mask: 28 features, Fitness: -3.8401\n",
      "    - New mask: 30 features, Fitness: -4.6795\n",
      "    - New mask: 24 features, Fitness: -2.2474\n",
      "    - New mask: 25 features, Fitness: -2.5979\n",
      "    - New mask: 29 features, Fitness: -3.4286\n",
      "    - New mask: 25 features, Fitness: -2.3450\n",
      "    - New mask: 27 features, Fitness: -3.9945\n",
      "    - New mask: 33 features, Fitness: -2.4817\n",
      "    - New mask: 29 features, Fitness: -1.4061\n",
      "    - New mask: 34 features, Fitness: -3.0392\n",
      "    - New mask: 31 features, Fitness: -1.7689\n",
      "    - New mask: 31 features, Fitness: -1.9016\n",
      "    - New mask: 29 features, Fitness: -1.7133\n",
      "    - New mask: 32 features, Fitness: -1.5756\n",
      "    - New mask: 33 features, Fitness: -2.4862\n",
      "    - New mask: 29 features, Fitness: -1.0224\n",
      "    - New mask: 34 features, Fitness: -2.6715\n",
      "    - New mask: 34 features, Fitness: -2.4293\n",
      "    - New mask: 29 features, Fitness: -1.2098\n",
      "    - New mask: 37 features, Fitness: -4.2577\n",
      "    - New mask: 30 features, Fitness: -1.4128\n",
      "    - New mask: 35 features, Fitness: -3.4859\n",
      "    - New mask: 32 features, Fitness: -2.0696\n",
      "    - New mask: 31 features, Fitness: -1.9269\n",
      "    - New mask: 31 features, Fitness: -1.9115\n",
      "    - New mask: 28 features, Fitness: -1.1909\n",
      "    - New mask: 34 features, Fitness: -2.1803\n",
      "=== End of Round 2: Vote mask selects 41 features (rho: 0.23)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 3 ================\n",
      "  Adaptive rho for this round: 0.26\n",
      "    - New mask: 31 features, Fitness: -3.6752\n",
      "    - New mask: 32 features, Fitness: -5.2903\n",
      "    - New mask: 30 features, Fitness: -3.1405\n",
      "    - New mask: 30 features, Fitness: -3.7658\n",
      "    - New mask: 30 features, Fitness: -3.2508\n",
      "    - New mask: 30 features, Fitness: -3.1700\n",
      "    - New mask: 30 features, Fitness: -4.1721\n",
      "    - New mask: 27 features, Fitness: -2.6643\n",
      "    - New mask: 30 features, Fitness: -3.1593\n",
      "    - New mask: 33 features, Fitness: -4.6987\n",
      "    - New mask: 26 features, Fitness: -2.5023\n",
      "    - New mask: 34 features, Fitness: -4.8843\n",
      "    - New mask: 29 features, Fitness: -3.1016\n",
      "    - New mask: 31 features, Fitness: -4.1014\n",
      "    - New mask: 27 features, Fitness: -2.4763\n",
      "    - New mask: 31 features, Fitness: -3.6314\n",
      "    - New mask: 27 features, Fitness: -2.5341\n",
      "    - New mask: 32 features, Fitness: -3.6202\n",
      "    - New mask: 27 features, Fitness: -3.1088\n",
      "    - New mask: 36 features, Fitness: -5.4241\n",
      "    - New mask: 29 features, Fitness: -2.6496\n",
      "    - New mask: 32 features, Fitness: -3.3446\n",
      "    - New mask: 32 features, Fitness: -3.8747\n",
      "    - New mask: 32 features, Fitness: -3.1849\n",
      "    - New mask: 25 features, Fitness: -2.0164\n",
      "    - New mask: 28 features, Fitness: -2.2052\n",
      "    - New mask: 28 features, Fitness: -2.1500\n",
      "    - New mask: 24 features, Fitness: -1.6616\n",
      "    - New mask: 31 features, Fitness: -3.7746\n",
      "    - New mask: 28 features, Fitness: -2.7521\n",
      "    - New mask: 29 features, Fitness: -3.7254\n",
      "    - New mask: 33 features, Fitness: -3.7813\n",
      "    - New mask: 32 features, Fitness: -3.2092\n",
      "    - New mask: 26 features, Fitness: -1.5911\n",
      "    - New mask: 32 features, Fitness: -4.2598\n",
      "    - New mask: 27 features, Fitness: -2.5225\n",
      "    - New mask: 28 features, Fitness: -2.6241\n",
      "    - New mask: 27 features, Fitness: -1.9251\n",
      "    - New mask: 22 features, Fitness: -1.6164\n",
      "    - New mask: 32 features, Fitness: -3.6543\n",
      "    - New mask: 32 features, Fitness: -2.7289\n",
      "    - New mask: 35 features, Fitness: -3.9238\n",
      "    - New mask: 29 features, Fitness: -2.1532\n",
      "    - New mask: 35 features, Fitness: -4.2304\n",
      "    - New mask: 28 features, Fitness: -1.9812\n",
      "    - New mask: 30 features, Fitness: -2.4843\n",
      "    - New mask: 30 features, Fitness: -2.1872\n",
      "    - New mask: 29 features, Fitness: -2.1947\n",
      "    - New mask: 31 features, Fitness: -2.5719\n",
      "    - New mask: 34 features, Fitness: -3.3462\n",
      "    - New mask: 29 features, Fitness: -3.1796\n",
      "    - New mask: 39 features, Fitness: -5.4639\n",
      "    - New mask: 34 features, Fitness: -3.7742\n",
      "    - New mask: 31 features, Fitness: -3.2216\n",
      "    - New mask: 38 features, Fitness: -5.0442\n",
      "    - New mask: 34 features, Fitness: -3.2284\n",
      "    - New mask: 32 features, Fitness: -3.6516\n",
      "    - New mask: 29 features, Fitness: -1.9097\n",
      "    - New mask: 33 features, Fitness: -2.9498\n",
      "    - New mask: 32 features, Fitness: -2.9845\n",
      "    - New mask: 34 features, Fitness: 0.6158\n",
      "    - New mask: 31 features, Fitness: 0.8353\n",
      "    - New mask: 32 features, Fitness: -0.6088\n",
      "    - New mask: 31 features, Fitness: 0.3001\n",
      "    - New mask: 27 features, Fitness: 1.4597\n",
      "    - New mask: 31 features, Fitness: 0.8486\n",
      "    - New mask: 33 features, Fitness: 0.5544\n",
      "    - New mask: 28 features, Fitness: 0.9456\n",
      "    - New mask: 29 features, Fitness: -0.3132\n",
      "    - New mask: 33 features, Fitness: 0.6042\n",
      "    - New mask: 30 features, Fitness: 0.4612\n",
      "    - New mask: 31 features, Fitness: 0.1532\n",
      "    - New mask: 34 features, Fitness: 0.3006\n",
      "    - New mask: 33 features, Fitness: -0.3503\n",
      "    - New mask: 30 features, Fitness: 0.6530\n",
      "    - New mask: 31 features, Fitness: 0.2523\n",
      "    - New mask: 35 features, Fitness: -0.0410\n",
      "    - New mask: 31 features, Fitness: 0.7435\n",
      "    - New mask: 29 features, Fitness: 0.3809\n",
      "    - New mask: 29 features, Fitness: 1.2325\n",
      "    - New mask: 33 features, Fitness: -0.3583\n",
      "    - New mask: 35 features, Fitness: -0.9099\n",
      "    - New mask: 32 features, Fitness: -0.6186\n",
      "    - New mask: 31 features, Fitness: -0.1657\n",
      "    - New mask: 32 features, Fitness: -0.4604\n",
      "    - New mask: 35 features, Fitness: -1.5784\n",
      "    - New mask: 34 features, Fitness: -1.5094\n",
      "    - New mask: 33 features, Fitness: -1.4417\n",
      "    - New mask: 35 features, Fitness: -1.8247\n",
      "    - New mask: 30 features, Fitness: 0.1231\n",
      "    - New mask: 34 features, Fitness: -0.9182\n",
      "    - New mask: 28 features, Fitness: 0.8076\n",
      "    - New mask: 31 features, Fitness: -0.1799\n",
      "    - New mask: 37 features, Fitness: -2.0109\n",
      "    - New mask: 32 features, Fitness: -0.8726\n",
      "    - New mask: 32 features, Fitness: -0.6706\n",
      "    - New mask: 32 features, Fitness: -1.0644\n",
      "    - New mask: 28 features, Fitness: 1.2529\n",
      "    - New mask: 33 features, Fitness: -0.6337\n",
      "    - New mask: 28 features, Fitness: 0.5310\n",
      "    - New mask: 31 features, Fitness: -5.1402\n",
      "    - New mask: 30 features, Fitness: -5.2100\n",
      "    - New mask: 27 features, Fitness: -3.4924\n",
      "    - New mask: 29 features, Fitness: -5.6625\n",
      "    - New mask: 29 features, Fitness: -4.1215\n",
      "    - New mask: 30 features, Fitness: -4.9781\n",
      "    - New mask: 33 features, Fitness: -6.3662\n",
      "    - New mask: 31 features, Fitness: -5.6352\n",
      "    - New mask: 30 features, Fitness: -5.9222\n",
      "    - New mask: 37 features, Fitness: -10.8466\n",
      "    - New mask: 27 features, Fitness: -4.1412\n",
      "    - New mask: 28 features, Fitness: -5.2514\n",
      "    - New mask: 33 features, Fitness: -8.8126\n",
      "    - New mask: 34 features, Fitness: -8.2518\n",
      "    - New mask: 29 features, Fitness: -4.1356\n",
      "    - New mask: 29 features, Fitness: -4.0297\n",
      "    - New mask: 33 features, Fitness: -5.2315\n",
      "    - New mask: 32 features, Fitness: -6.0484\n",
      "    - New mask: 31 features, Fitness: -6.2722\n",
      "    - New mask: 30 features, Fitness: -5.7163\n",
      "    - New mask: 28 features, Fitness: -2.3225\n",
      "    - New mask: 27 features, Fitness: -1.7386\n",
      "    - New mask: 28 features, Fitness: -3.0895\n",
      "    - New mask: 28 features, Fitness: -2.9203\n",
      "    - New mask: 30 features, Fitness: -3.7071\n",
      "    - New mask: 33 features, Fitness: -4.8559\n",
      "    - New mask: 34 features, Fitness: -4.0996\n",
      "    - New mask: 30 features, Fitness: -3.4064\n",
      "    - New mask: 34 features, Fitness: -4.7475\n",
      "    - New mask: 24 features, Fitness: -1.5930\n",
      "    - New mask: 27 features, Fitness: -2.8155\n",
      "    - New mask: 24 features, Fitness: -1.4150\n",
      "    - New mask: 37 features, Fitness: -5.8581\n",
      "    - New mask: 25 features, Fitness: -2.1485\n",
      "    - New mask: 28 features, Fitness: -2.3824\n",
      "    - New mask: 34 features, Fitness: -5.1924\n",
      "    - New mask: 26 features, Fitness: -1.8386\n",
      "    - New mask: 34 features, Fitness: -4.3271\n",
      "    - New mask: 33 features, Fitness: -4.2386\n",
      "    - New mask: 29 features, Fitness: -2.9779\n",
      "    - New mask: 37 features, Fitness: -10.0296\n",
      "    - New mask: 32 features, Fitness: -6.6497\n",
      "    - New mask: 30 features, Fitness: -6.1693\n",
      "    - New mask: 30 features, Fitness: -4.7890\n",
      "    - New mask: 26 features, Fitness: -3.9502\n",
      "    - New mask: 33 features, Fitness: -6.3404\n",
      "    - New mask: 30 features, Fitness: -4.4782\n",
      "    - New mask: 29 features, Fitness: -4.4171\n",
      "    - New mask: 27 features, Fitness: -4.1506\n",
      "    - New mask: 32 features, Fitness: -5.3501\n",
      "    - New mask: 31 features, Fitness: -5.0490\n",
      "    - New mask: 34 features, Fitness: -7.4756\n",
      "    - New mask: 28 features, Fitness: -4.3389\n",
      "    - New mask: 27 features, Fitness: -3.7358\n",
      "    - New mask: 32 features, Fitness: -4.9935\n",
      "    - New mask: 30 features, Fitness: -4.8417\n",
      "    - New mask: 29 features, Fitness: -5.3134\n",
      "    - New mask: 31 features, Fitness: -5.1548\n",
      "    - New mask: 30 features, Fitness: -4.7509\n",
      "    - New mask: 32 features, Fitness: -6.4462\n",
      "    - New mask: 30 features, Fitness: -4.3834\n",
      "    - New mask: 29 features, Fitness: -4.5972\n",
      "    - New mask: 32 features, Fitness: -4.9852\n",
      "    - New mask: 29 features, Fitness: -3.3873\n",
      "    - New mask: 31 features, Fitness: -4.9795\n",
      "    - New mask: 33 features, Fitness: -4.7259\n",
      "    - New mask: 35 features, Fitness: -5.8101\n",
      "    - New mask: 33 features, Fitness: -5.8838\n",
      "    - New mask: 30 features, Fitness: -4.7769\n",
      "    - New mask: 29 features, Fitness: -4.1348\n",
      "    - New mask: 27 features, Fitness: -2.5275\n",
      "    - New mask: 28 features, Fitness: -3.7083\n",
      "    - New mask: 27 features, Fitness: -3.3434\n",
      "    - New mask: 35 features, Fitness: -5.6357\n",
      "    - New mask: 32 features, Fitness: -4.2804\n",
      "    - New mask: 32 features, Fitness: -4.7203\n",
      "    - New mask: 32 features, Fitness: -4.9315\n",
      "    - New mask: 31 features, Fitness: -4.9230\n",
      "    - New mask: 30 features, Fitness: -4.0608\n",
      "    - New mask: 26 features, Fitness: -4.2808\n",
      "    - New mask: 35 features, Fitness: -3.4171\n",
      "    - New mask: 33 features, Fitness: -1.8453\n",
      "    - New mask: 35 features, Fitness: -3.2116\n",
      "    - New mask: 30 features, Fitness: -0.8995\n",
      "    - New mask: 31 features, Fitness: -1.3199\n",
      "    - New mask: 28 features, Fitness: -1.4485\n",
      "    - New mask: 32 features, Fitness: -1.8229\n",
      "    - New mask: 36 features, Fitness: -3.5898\n",
      "    - New mask: 31 features, Fitness: -1.6210\n",
      "    - New mask: 32 features, Fitness: -1.6819\n",
      "    - New mask: 33 features, Fitness: -1.9334\n",
      "    - New mask: 30 features, Fitness: -1.8864\n",
      "    - New mask: 35 features, Fitness: -2.4980\n",
      "    - New mask: 35 features, Fitness: -3.1575\n",
      "    - New mask: 33 features, Fitness: -1.8486\n",
      "    - New mask: 36 features, Fitness: -2.9491\n",
      "    - New mask: 36 features, Fitness: -2.9639\n",
      "    - New mask: 34 features, Fitness: -3.1767\n",
      "    - New mask: 32 features, Fitness: -2.0685\n",
      "    - New mask: 34 features, Fitness: -2.5293\n",
      "=== End of Round 3: Vote mask selects 42 features (rho: 0.26)\n",
      "    Indices: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 4 ================\n",
      "  Adaptive rho for this round: 0.29\n",
      "    - New mask: 29 features, Fitness: -3.1005\n",
      "    - New mask: 33 features, Fitness: -4.5354\n",
      "    - New mask: 32 features, Fitness: -4.1915\n",
      "    - New mask: 36 features, Fitness: -5.4473\n",
      "    - New mask: 29 features, Fitness: -2.3429\n",
      "    - New mask: 35 features, Fitness: -4.5360\n",
      "    - New mask: 33 features, Fitness: -4.8652\n",
      "    - New mask: 28 features, Fitness: -2.6001\n",
      "    - New mask: 30 features, Fitness: -3.3595\n",
      "    - New mask: 34 features, Fitness: -4.7635\n",
      "    - New mask: 28 features, Fitness: -3.0152\n",
      "    - New mask: 34 features, Fitness: -4.9832\n",
      "    - New mask: 34 features, Fitness: -4.3396\n",
      "    - New mask: 33 features, Fitness: -5.4103\n",
      "    - New mask: 31 features, Fitness: -3.5926\n",
      "    - New mask: 31 features, Fitness: -3.3704\n",
      "    - New mask: 34 features, Fitness: -4.3779\n",
      "    - New mask: 33 features, Fitness: -3.7861\n",
      "    - New mask: 29 features, Fitness: -3.8652\n",
      "    - New mask: 37 features, Fitness: -6.1466\n",
      "    - New mask: 33 features, Fitness: -3.6337\n",
      "    - New mask: 34 features, Fitness: -3.7692\n",
      "    - New mask: 33 features, Fitness: -3.6397\n",
      "    - New mask: 32 features, Fitness: -2.8226\n",
      "    - New mask: 32 features, Fitness: -2.8951\n",
      "    - New mask: 30 features, Fitness: -2.9126\n",
      "    - New mask: 30 features, Fitness: -2.3580\n",
      "    - New mask: 29 features, Fitness: -2.1700\n",
      "    - New mask: 33 features, Fitness: -3.5837\n",
      "    - New mask: 27 features, Fitness: -2.1707\n",
      "    - New mask: 32 features, Fitness: -3.7172\n",
      "    - New mask: 33 features, Fitness: -3.7148\n",
      "    - New mask: 31 features, Fitness: -3.1898\n",
      "    - New mask: 30 features, Fitness: -2.7184\n",
      "    - New mask: 30 features, Fitness: -3.4071\n",
      "    - New mask: 34 features, Fitness: -4.2515\n",
      "    - New mask: 35 features, Fitness: -4.1868\n",
      "    - New mask: 27 features, Fitness: -2.0185\n",
      "    - New mask: 29 features, Fitness: -2.1588\n",
      "    - New mask: 34 features, Fitness: -4.0824\n",
      "    - New mask: 34 features, Fitness: -4.0251\n",
      "    - New mask: 36 features, Fitness: -4.2732\n",
      "    - New mask: 35 features, Fitness: -3.5142\n",
      "    - New mask: 34 features, Fitness: -4.4482\n",
      "    - New mask: 32 features, Fitness: -2.8653\n",
      "    - New mask: 33 features, Fitness: -3.2855\n",
      "    - New mask: 36 features, Fitness: -3.6259\n",
      "    - New mask: 32 features, Fitness: -3.7432\n",
      "    - New mask: 35 features, Fitness: -3.6157\n",
      "    - New mask: 35 features, Fitness: -3.4384\n",
      "    - New mask: 32 features, Fitness: -3.7795\n",
      "    - New mask: 37 features, Fitness: -4.6228\n",
      "    - New mask: 38 features, Fitness: -5.1750\n",
      "    - New mask: 32 features, Fitness: -3.1043\n",
      "    - New mask: 37 features, Fitness: -3.9232\n",
      "    - New mask: 32 features, Fitness: -2.6829\n",
      "    - New mask: 31 features, Fitness: -2.9935\n",
      "    - New mask: 31 features, Fitness: -2.7559\n",
      "    - New mask: 38 features, Fitness: -4.5313\n",
      "    - New mask: 34 features, Fitness: -3.3111\n",
      "    - New mask: 34 features, Fitness: 0.7239\n",
      "    - New mask: 37 features, Fitness: -0.5273\n",
      "    - New mask: 36 features, Fitness: -0.9081\n",
      "    - New mask: 29 features, Fitness: 0.4776\n",
      "    - New mask: 32 features, Fitness: 0.2607\n",
      "    - New mask: 30 features, Fitness: 0.9626\n",
      "    - New mask: 34 features, Fitness: -0.3187\n",
      "    - New mask: 34 features, Fitness: 0.5060\n",
      "    - New mask: 31 features, Fitness: 0.2469\n",
      "    - New mask: 35 features, Fitness: 0.1225\n",
      "    - New mask: 33 features, Fitness: -0.1120\n",
      "    - New mask: 32 features, Fitness: 0.4607\n",
      "    - New mask: 32 features, Fitness: 0.4614\n",
      "    - New mask: 30 features, Fitness: 0.6819\n",
      "    - New mask: 31 features, Fitness: 0.8513\n",
      "    - New mask: 33 features, Fitness: 0.5179\n",
      "    - New mask: 30 features, Fitness: 1.1039\n",
      "    - New mask: 31 features, Fitness: 1.1212\n",
      "    - New mask: 34 features, Fitness: 0.1447\n",
      "    - New mask: 31 features, Fitness: 0.3868\n",
      "    - New mask: 36 features, Fitness: -2.7742\n",
      "    - New mask: 36 features, Fitness: -1.5738\n",
      "    - New mask: 34 features, Fitness: -0.2831\n",
      "    - New mask: 36 features, Fitness: -1.9601\n",
      "    - New mask: 33 features, Fitness: -0.5193\n",
      "    - New mask: 32 features, Fitness: -0.1008\n",
      "    - New mask: 34 features, Fitness: -0.9015\n",
      "    - New mask: 36 features, Fitness: -2.1737\n",
      "    - New mask: 33 features, Fitness: 0.2995\n",
      "    - New mask: 30 features, Fitness: 0.7579\n",
      "    - New mask: 36 features, Fitness: -1.4988\n",
      "    - New mask: 30 features, Fitness: 0.5704\n",
      "    - New mask: 31 features, Fitness: 0.0640\n",
      "    - New mask: 33 features, Fitness: -0.5701\n",
      "    - New mask: 31 features, Fitness: 0.3430\n",
      "    - New mask: 33 features, Fitness: -0.5141\n",
      "    - New mask: 34 features, Fitness: -1.0252\n",
      "    - New mask: 30 features, Fitness: 0.0953\n",
      "    - New mask: 31 features, Fitness: 0.4546\n",
      "    - New mask: 31 features, Fitness: 0.1356\n",
      "    - New mask: 38 features, Fitness: -9.6416\n",
      "    - New mask: 31 features, Fitness: -5.2860\n",
      "    - New mask: 30 features, Fitness: -4.9683\n",
      "    - New mask: 32 features, Fitness: -5.0831\n",
      "    - New mask: 33 features, Fitness: -9.1505\n",
      "    - New mask: 33 features, Fitness: -7.1801\n",
      "    - New mask: 32 features, Fitness: -5.2066\n",
      "    - New mask: 34 features, Fitness: -6.7867\n",
      "    - New mask: 31 features, Fitness: -7.0850\n",
      "    - New mask: 37 features, Fitness: -10.4690\n",
      "    - New mask: 31 features, Fitness: -4.2000\n",
      "    - New mask: 32 features, Fitness: -6.4086\n",
      "    - New mask: 35 features, Fitness: -8.4585\n",
      "    - New mask: 37 features, Fitness: -9.5188\n",
      "    - New mask: 31 features, Fitness: -5.5612\n",
      "    - New mask: 31 features, Fitness: -4.0546\n",
      "    - New mask: 34 features, Fitness: -7.5541\n",
      "    - New mask: 32 features, Fitness: -8.0066\n",
      "    - New mask: 34 features, Fitness: -5.5860\n",
      "    - New mask: 35 features, Fitness: -7.1595\n",
      "    - New mask: 28 features, Fitness: -2.5591\n",
      "    - New mask: 25 features, Fitness: -1.2523\n",
      "    - New mask: 35 features, Fitness: -4.0546\n",
      "    - New mask: 27 features, Fitness: -2.0109\n",
      "    - New mask: 28 features, Fitness: -3.2242\n",
      "    - New mask: 33 features, Fitness: -4.0442\n",
      "    - New mask: 32 features, Fitness: -3.1650\n",
      "    - New mask: 30 features, Fitness: -3.1699\n",
      "    - New mask: 29 features, Fitness: -2.9693\n",
      "    - New mask: 26 features, Fitness: -1.3864\n",
      "    - New mask: 34 features, Fitness: -4.9032\n",
      "    - New mask: 30 features, Fitness: -3.0904\n",
      "    - New mask: 34 features, Fitness: -4.2988\n",
      "    - New mask: 28 features, Fitness: -1.7749\n",
      "    - New mask: 30 features, Fitness: -3.9080\n",
      "    - New mask: 36 features, Fitness: -5.3676\n",
      "    - New mask: 31 features, Fitness: -3.4109\n",
      "    - New mask: 32 features, Fitness: -4.3482\n",
      "    - New mask: 29 features, Fitness: -3.1465\n",
      "    - New mask: 29 features, Fitness: -2.5383\n",
      "    - New mask: 34 features, Fitness: -6.5883\n",
      "    - New mask: 33 features, Fitness: -6.9491\n",
      "    - New mask: 31 features, Fitness: -4.4390\n",
      "    - New mask: 34 features, Fitness: -6.4931\n",
      "    - New mask: 30 features, Fitness: -5.5933\n",
      "    - New mask: 32 features, Fitness: -6.9468\n",
      "    - New mask: 30 features, Fitness: -5.6128\n",
      "    - New mask: 34 features, Fitness: -7.1723\n",
      "    - New mask: 30 features, Fitness: -5.2271\n",
      "    - New mask: 35 features, Fitness: -6.7895\n",
      "    - New mask: 36 features, Fitness: -7.7513\n",
      "    - New mask: 35 features, Fitness: -8.2216\n",
      "    - New mask: 30 features, Fitness: -5.5241\n",
      "    - New mask: 33 features, Fitness: -6.0724\n",
      "    - New mask: 36 features, Fitness: -8.2045\n",
      "    - New mask: 31 features, Fitness: -5.2544\n",
      "    - New mask: 24 features, Fitness: -2.9246\n",
      "    - New mask: 33 features, Fitness: -5.9622\n",
      "    - New mask: 33 features, Fitness: -6.1467\n",
      "    - New mask: 31 features, Fitness: -6.4709\n",
      "    - New mask: 32 features, Fitness: -4.6797\n",
      "    - New mask: 31 features, Fitness: -4.7337\n",
      "    - New mask: 34 features, Fitness: -6.2885\n",
      "    - New mask: 36 features, Fitness: -6.0977\n",
      "    - New mask: 33 features, Fitness: -5.0060\n",
      "    - New mask: 32 features, Fitness: -4.3789\n",
      "    - New mask: 32 features, Fitness: -4.3800\n",
      "    - New mask: 34 features, Fitness: -5.8554\n",
      "    - New mask: 32 features, Fitness: -4.8579\n",
      "    - New mask: 27 features, Fitness: -3.4744\n",
      "    - New mask: 33 features, Fitness: -5.1350\n",
      "    - New mask: 29 features, Fitness: -3.3608\n",
      "    - New mask: 35 features, Fitness: -6.5734\n",
      "    - New mask: 32 features, Fitness: -4.7066\n",
      "    - New mask: 30 features, Fitness: -3.6219\n",
      "    - New mask: 34 features, Fitness: -6.0969\n",
      "    - New mask: 33 features, Fitness: -5.0330\n",
      "    - New mask: 31 features, Fitness: -4.5145\n",
      "    - New mask: 34 features, Fitness: -4.9656\n",
      "    - New mask: 32 features, Fitness: -4.9182\n",
      "    - New mask: 36 features, Fitness: -3.1664\n",
      "    - New mask: 36 features, Fitness: -2.6402\n",
      "    - New mask: 36 features, Fitness: -3.4294\n",
      "    - New mask: 32 features, Fitness: -1.5333\n",
      "    - New mask: 36 features, Fitness: -3.0282\n",
      "    - New mask: 30 features, Fitness: -1.6406\n",
      "    - New mask: 33 features, Fitness: -2.1291\n",
      "    - New mask: 37 features, Fitness: -3.2770\n",
      "    - New mask: 33 features, Fitness: -2.1907\n",
      "    - New mask: 33 features, Fitness: -1.7927\n",
      "    - New mask: 34 features, Fitness: -2.9049\n",
      "    - New mask: 31 features, Fitness: -1.4298\n",
      "    - New mask: 33 features, Fitness: -2.1694\n",
      "    - New mask: 34 features, Fitness: -2.2005\n",
      "    - New mask: 34 features, Fitness: -2.4542\n",
      "    - New mask: 36 features, Fitness: -2.7992\n",
      "    - New mask: 36 features, Fitness: -3.1632\n",
      "    - New mask: 37 features, Fitness: -3.5379\n",
      "    - New mask: 33 features, Fitness: -2.3854\n",
      "    - New mask: 35 features, Fitness: -2.4885\n",
      "=== End of Round 4: Vote mask selects 41 features (rho: 0.29)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 5 ================\n",
      "  Adaptive rho for this round: 0.33\n",
      "    - New mask: 33 features, Fitness: -3.9287\n",
      "    - New mask: 33 features, Fitness: -4.3901\n",
      "    - New mask: 32 features, Fitness: -3.7233\n",
      "    - New mask: 35 features, Fitness: -4.8704\n",
      "    - New mask: 35 features, Fitness: -4.2087\n",
      "    - New mask: 35 features, Fitness: -4.7291\n",
      "    - New mask: 31 features, Fitness: -3.6557\n",
      "    - New mask: 33 features, Fitness: -3.6560\n",
      "    - New mask: 31 features, Fitness: -2.9459\n",
      "    - New mask: 34 features, Fitness: -4.3533\n",
      "    - New mask: 29 features, Fitness: -3.2707\n",
      "    - New mask: 32 features, Fitness: -4.7503\n",
      "    - New mask: 34 features, Fitness: -4.5533\n",
      "    - New mask: 28 features, Fitness: -3.3306\n",
      "    - New mask: 36 features, Fitness: -5.0820\n",
      "    - New mask: 35 features, Fitness: -4.5330\n",
      "    - New mask: 33 features, Fitness: -3.4732\n",
      "    - New mask: 35 features, Fitness: -4.4962\n",
      "    - New mask: 30 features, Fitness: -3.3832\n",
      "    - New mask: 31 features, Fitness: -4.1495\n",
      "    - New mask: 34 features, Fitness: -5.0815\n",
      "    - New mask: 32 features, Fitness: -3.6311\n",
      "    - New mask: 35 features, Fitness: -3.9319\n",
      "    - New mask: 31 features, Fitness: -2.8523\n",
      "    - New mask: 33 features, Fitness: -3.5561\n",
      "    - New mask: 35 features, Fitness: -4.7277\n",
      "    - New mask: 26 features, Fitness: -1.8397\n",
      "    - New mask: 29 features, Fitness: -2.2528\n",
      "    - New mask: 33 features, Fitness: -3.5625\n",
      "    - New mask: 30 features, Fitness: -2.7226\n",
      "    - New mask: 33 features, Fitness: -3.7513\n",
      "    - New mask: 33 features, Fitness: -4.0263\n",
      "    - New mask: 32 features, Fitness: -3.3300\n",
      "    - New mask: 30 features, Fitness: -3.5201\n",
      "    - New mask: 30 features, Fitness: -3.1593\n",
      "    - New mask: 34 features, Fitness: -4.3799\n",
      "    - New mask: 33 features, Fitness: -4.3595\n",
      "    - New mask: 28 features, Fitness: -2.3493\n",
      "    - New mask: 30 features, Fitness: -2.8173\n",
      "    - New mask: 34 features, Fitness: -4.0827\n",
      "    - New mask: 34 features, Fitness: -3.5136\n",
      "    - New mask: 35 features, Fitness: -3.9283\n",
      "    - New mask: 37 features, Fitness: -5.1511\n",
      "    - New mask: 35 features, Fitness: -4.2145\n",
      "    - New mask: 34 features, Fitness: -3.6838\n",
      "    - New mask: 36 features, Fitness: -4.2119\n",
      "    - New mask: 36 features, Fitness: -3.7007\n",
      "    - New mask: 34 features, Fitness: -4.0180\n",
      "    - New mask: 36 features, Fitness: -3.7849\n",
      "    - New mask: 37 features, Fitness: -4.7864\n",
      "    - New mask: 34 features, Fitness: -3.9866\n",
      "    - New mask: 38 features, Fitness: -4.7468\n",
      "    - New mask: 35 features, Fitness: -3.5368\n",
      "    - New mask: 36 features, Fitness: -4.0039\n",
      "    - New mask: 36 features, Fitness: -4.5957\n",
      "    - New mask: 33 features, Fitness: -3.3207\n",
      "    - New mask: 34 features, Fitness: -4.3816\n",
      "    - New mask: 38 features, Fitness: -5.3324\n",
      "    - New mask: 36 features, Fitness: -3.9253\n",
      "    - New mask: 34 features, Fitness: -2.9592\n",
      "    - New mask: 37 features, Fitness: -0.2884\n",
      "    - New mask: 36 features, Fitness: -0.0296\n",
      "    - New mask: 31 features, Fitness: 0.8181\n",
      "    - New mask: 34 features, Fitness: -0.0491\n",
      "    - New mask: 35 features, Fitness: -0.1546\n",
      "    - New mask: 37 features, Fitness: -0.1442\n",
      "    - New mask: 32 features, Fitness: -0.3056\n",
      "    - New mask: 34 features, Fitness: 0.1267\n",
      "    - New mask: 37 features, Fitness: -0.9926\n",
      "    - New mask: 39 features, Fitness: -1.3380\n",
      "    - New mask: 34 features, Fitness: 0.4951\n",
      "    - New mask: 32 features, Fitness: 0.6482\n",
      "    - New mask: 33 features, Fitness: -0.2030\n",
      "    - New mask: 33 features, Fitness: -0.6394\n",
      "    - New mask: 35 features, Fitness: 0.2725\n",
      "    - New mask: 37 features, Fitness: -0.3744\n",
      "    - New mask: 31 features, Fitness: 0.8678\n",
      "    - New mask: 32 features, Fitness: 0.1618\n",
      "    - New mask: 32 features, Fitness: 0.6054\n",
      "    - New mask: 32 features, Fitness: 0.3620\n",
      "    - New mask: 36 features, Fitness: -2.1346\n",
      "    - New mask: 37 features, Fitness: -2.1508\n",
      "    - New mask: 33 features, Fitness: -0.4673\n",
      "    - New mask: 36 features, Fitness: -1.5825\n",
      "    - New mask: 35 features, Fitness: -0.5726\n",
      "    - New mask: 33 features, Fitness: -0.1076\n",
      "    - New mask: 34 features, Fitness: -0.8271\n",
      "    - New mask: 34 features, Fitness: -0.9133\n",
      "    - New mask: 35 features, Fitness: -1.1246\n",
      "    - New mask: 32 features, Fitness: -0.6427\n",
      "    - New mask: 33 features, Fitness: -0.3163\n",
      "    - New mask: 32 features, Fitness: 0.2083\n",
      "    - New mask: 35 features, Fitness: -0.9109\n",
      "    - New mask: 36 features, Fitness: -1.2220\n",
      "    - New mask: 36 features, Fitness: -1.8048\n",
      "    - New mask: 31 features, Fitness: -0.1596\n",
      "    - New mask: 39 features, Fitness: -2.5567\n",
      "    - New mask: 35 features, Fitness: -0.8954\n",
      "    - New mask: 36 features, Fitness: -0.9809\n",
      "    - New mask: 33 features, Fitness: -0.3893\n",
      "    - New mask: 32 features, Fitness: -5.8929\n",
      "    - New mask: 30 features, Fitness: -4.0700\n",
      "    - New mask: 33 features, Fitness: -6.1768\n",
      "    - New mask: 35 features, Fitness: -7.2807\n",
      "    - New mask: 33 features, Fitness: -7.1089\n",
      "    - New mask: 35 features, Fitness: -6.5822\n",
      "    - New mask: 32 features, Fitness: -5.8352\n",
      "    - New mask: 39 features, Fitness: -11.2578\n",
      "    - New mask: 32 features, Fitness: -6.2034\n",
      "    - New mask: 36 features, Fitness: -6.5779\n",
      "    - New mask: 37 features, Fitness: -7.0769\n",
      "    - New mask: 32 features, Fitness: -5.0119\n",
      "    - New mask: 34 features, Fitness: -5.8785\n",
      "    - New mask: 36 features, Fitness: -8.1512\n",
      "    - New mask: 30 features, Fitness: -4.2685\n",
      "    - New mask: 35 features, Fitness: -6.8897\n",
      "    - New mask: 35 features, Fitness: -6.9269\n",
      "    - New mask: 32 features, Fitness: -6.5139\n",
      "    - New mask: 34 features, Fitness: -5.8651\n",
      "    - New mask: 34 features, Fitness: -6.3712\n",
      "    - New mask: 27 features, Fitness: -1.9246\n",
      "    - New mask: 28 features, Fitness: -2.7315\n",
      "    - New mask: 30 features, Fitness: -3.7173\n",
      "    - New mask: 30 features, Fitness: -3.3074\n",
      "    - New mask: 31 features, Fitness: -3.3507\n",
      "    - New mask: 35 features, Fitness: -4.4124\n",
      "    - New mask: 30 features, Fitness: -2.5988\n",
      "    - New mask: 30 features, Fitness: -3.2629\n",
      "    - New mask: 30 features, Fitness: -2.5789\n",
      "    - New mask: 31 features, Fitness: -2.3175\n",
      "    - New mask: 35 features, Fitness: -4.7514\n",
      "    - New mask: 30 features, Fitness: -2.9387\n",
      "    - New mask: 33 features, Fitness: -3.0854\n",
      "    - New mask: 31 features, Fitness: -2.9129\n",
      "    - New mask: 29 features, Fitness: -3.2619\n",
      "    - New mask: 34 features, Fitness: -4.2196\n",
      "    - New mask: 32 features, Fitness: -3.4057\n",
      "    - New mask: 31 features, Fitness: -3.1942\n",
      "    - New mask: 34 features, Fitness: -4.4723\n",
      "    - New mask: 33 features, Fitness: -3.3691\n",
      "    - New mask: 32 features, Fitness: -5.2871\n",
      "    - New mask: 32 features, Fitness: -6.8877\n",
      "    - New mask: 36 features, Fitness: -8.4102\n",
      "    - New mask: 32 features, Fitness: -6.5905\n",
      "    - New mask: 30 features, Fitness: -5.7164\n",
      "    - New mask: 34 features, Fitness: -7.7148\n",
      "    - New mask: 30 features, Fitness: -5.0523\n",
      "    - New mask: 28 features, Fitness: -4.3346\n",
      "    - New mask: 32 features, Fitness: -7.3312\n",
      "    - New mask: 31 features, Fitness: -4.8944\n",
      "    - New mask: 33 features, Fitness: -6.4637\n",
      "    - New mask: 34 features, Fitness: -7.8052\n",
      "    - New mask: 31 features, Fitness: -5.8476\n",
      "    - New mask: 34 features, Fitness: -6.8140\n",
      "    - New mask: 34 features, Fitness: -7.8815\n",
      "    - New mask: 34 features, Fitness: -6.8498\n",
      "    - New mask: 32 features, Fitness: -7.1687\n",
      "    - New mask: 32 features, Fitness: -5.7718\n",
      "    - New mask: 31 features, Fitness: -5.3015\n",
      "    - New mask: 33 features, Fitness: -6.1919\n",
      "    - New mask: 36 features, Fitness: -6.2081\n",
      "    - New mask: 31 features, Fitness: -4.1148\n",
      "    - New mask: 36 features, Fitness: -6.6841\n",
      "    - New mask: 34 features, Fitness: -6.0674\n",
      "    - New mask: 32 features, Fitness: -4.8289\n",
      "    - New mask: 32 features, Fitness: -5.0482\n",
      "    - New mask: 33 features, Fitness: -4.4079\n",
      "    - New mask: 33 features, Fitness: -5.0205\n",
      "    - New mask: 31 features, Fitness: -3.9328\n",
      "    - New mask: 30 features, Fitness: -4.3584\n",
      "    - New mask: 32 features, Fitness: -5.1027\n",
      "    - New mask: 32 features, Fitness: -4.4957\n",
      "    - New mask: 35 features, Fitness: -6.0446\n",
      "    - New mask: 30 features, Fitness: -4.2731\n",
      "    - New mask: 33 features, Fitness: -5.3999\n",
      "    - New mask: 34 features, Fitness: -5.5682\n",
      "    - New mask: 30 features, Fitness: -4.9180\n",
      "    - New mask: 26 features, Fitness: -2.4654\n",
      "    - New mask: 34 features, Fitness: -5.0999\n",
      "    - New mask: 33 features, Fitness: -5.4511\n",
      "    - New mask: 38 features, Fitness: -4.1124\n",
      "    - New mask: 35 features, Fitness: -2.8459\n",
      "    - New mask: 34 features, Fitness: -3.2741\n",
      "    - New mask: 36 features, Fitness: -3.0999\n",
      "    - New mask: 36 features, Fitness: -3.7454\n",
      "    - New mask: 34 features, Fitness: -2.5193\n",
      "    - New mask: 33 features, Fitness: -1.9893\n",
      "    - New mask: 36 features, Fitness: -3.0226\n",
      "    - New mask: 34 features, Fitness: -2.8155\n",
      "    - New mask: 31 features, Fitness: -1.5374\n",
      "    - New mask: 34 features, Fitness: -3.0323\n",
      "    - New mask: 35 features, Fitness: -2.3384\n",
      "    - New mask: 33 features, Fitness: -2.1408\n",
      "    - New mask: 38 features, Fitness: -4.0718\n",
      "    - New mask: 32 features, Fitness: -2.3335\n",
      "    - New mask: 32 features, Fitness: -1.7403\n",
      "    - New mask: 35 features, Fitness: -2.4933\n",
      "    - New mask: 39 features, Fitness: -4.3658\n",
      "    - New mask: 33 features, Fitness: -2.2113\n",
      "    - New mask: 34 features, Fitness: -2.0564\n",
      "=== End of Round 5: Vote mask selects 40 features (rho: 0.33)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 6 ================\n",
      "  Adaptive rho for this round: 0.36\n",
      "    - New mask: 33 features, Fitness: -4.0403\n",
      "    - New mask: 35 features, Fitness: -4.1076\n",
      "    - New mask: 33 features, Fitness: -4.3869\n",
      "    - New mask: 37 features, Fitness: -5.8822\n",
      "    - New mask: 35 features, Fitness: -4.4559\n",
      "    - New mask: 33 features, Fitness: -3.5407\n",
      "    - New mask: 35 features, Fitness: -4.3021\n",
      "    - New mask: 32 features, Fitness: -3.4592\n",
      "    - New mask: 32 features, Fitness: -3.4483\n",
      "    - New mask: 32 features, Fitness: -3.5338\n",
      "    - New mask: 35 features, Fitness: -4.6524\n",
      "    - New mask: 33 features, Fitness: -4.2692\n",
      "    - New mask: 31 features, Fitness: -3.6850\n",
      "    - New mask: 28 features, Fitness: -3.2582\n",
      "    - New mask: 33 features, Fitness: -3.6541\n",
      "    - New mask: 37 features, Fitness: -5.4516\n",
      "    - New mask: 36 features, Fitness: -4.8278\n",
      "    - New mask: 34 features, Fitness: -4.0135\n",
      "    - New mask: 30 features, Fitness: -3.1974\n",
      "    - New mask: 36 features, Fitness: -5.4820\n",
      "    - New mask: 35 features, Fitness: -4.4274\n",
      "    - New mask: 34 features, Fitness: -3.9245\n",
      "    - New mask: 31 features, Fitness: -2.9038\n",
      "    - New mask: 26 features, Fitness: -1.6709\n",
      "    - New mask: 31 features, Fitness: -3.2406\n",
      "    - New mask: 32 features, Fitness: -3.9214\n",
      "    - New mask: 29 features, Fitness: -2.9613\n",
      "    - New mask: 31 features, Fitness: -2.9862\n",
      "    - New mask: 31 features, Fitness: -3.4824\n",
      "    - New mask: 29 features, Fitness: -3.2267\n",
      "    - New mask: 35 features, Fitness: -4.3095\n",
      "    - New mask: 28 features, Fitness: -2.1197\n",
      "    - New mask: 33 features, Fitness: -4.0415\n",
      "    - New mask: 35 features, Fitness: -4.8413\n",
      "    - New mask: 32 features, Fitness: -4.3397\n",
      "    - New mask: 34 features, Fitness: -4.5784\n",
      "    - New mask: 29 features, Fitness: -2.7579\n",
      "    - New mask: 31 features, Fitness: -3.5182\n",
      "    - New mask: 36 features, Fitness: -5.4674\n",
      "    - New mask: 31 features, Fitness: -3.0223\n",
      "    - New mask: 34 features, Fitness: -3.2584\n",
      "    - New mask: 36 features, Fitness: -4.0518\n",
      "    - New mask: 39 features, Fitness: -4.9362\n",
      "    - New mask: 35 features, Fitness: -3.4863\n",
      "    - New mask: 32 features, Fitness: -3.4600\n",
      "    - New mask: 36 features, Fitness: -4.2042\n",
      "    - New mask: 33 features, Fitness: -2.9087\n",
      "    - New mask: 39 features, Fitness: -5.4212\n",
      "    - New mask: 36 features, Fitness: -3.8333\n",
      "    - New mask: 33 features, Fitness: -3.3254\n",
      "    - New mask: 32 features, Fitness: -3.3967\n",
      "    - New mask: 38 features, Fitness: -4.6679\n",
      "    - New mask: 34 features, Fitness: -3.1590\n",
      "    - New mask: 37 features, Fitness: -4.7001\n",
      "    - New mask: 38 features, Fitness: -4.9044\n",
      "    - New mask: 34 features, Fitness: -3.4467\n",
      "    - New mask: 38 features, Fitness: -4.7183\n",
      "    - New mask: 32 features, Fitness: -3.2937\n",
      "    - New mask: 36 features, Fitness: -4.1176\n",
      "    - New mask: 37 features, Fitness: -4.6055\n",
      "    - New mask: 33 features, Fitness: 0.5624\n",
      "    - New mask: 37 features, Fitness: -0.6895\n",
      "    - New mask: 32 features, Fitness: 0.5174\n",
      "    - New mask: 33 features, Fitness: 0.3466\n",
      "    - New mask: 33 features, Fitness: 0.7152\n",
      "    - New mask: 35 features, Fitness: 0.3231\n",
      "    - New mask: 35 features, Fitness: -0.1258\n",
      "    - New mask: 35 features, Fitness: -0.0075\n",
      "    - New mask: 36 features, Fitness: -0.1435\n",
      "    - New mask: 37 features, Fitness: -0.8102\n",
      "    - New mask: 31 features, Fitness: 0.8999\n",
      "    - New mask: 31 features, Fitness: 1.1371\n",
      "    - New mask: 34 features, Fitness: 0.0181\n",
      "    - New mask: 34 features, Fitness: -0.5537\n",
      "    - New mask: 33 features, Fitness: 0.3074\n",
      "    - New mask: 35 features, Fitness: 0.4480\n",
      "    - New mask: 34 features, Fitness: 0.5462\n",
      "    - New mask: 38 features, Fitness: -0.5942\n",
      "    - New mask: 33 features, Fitness: 0.4625\n",
      "    - New mask: 33 features, Fitness: 0.0138\n",
      "    - New mask: 36 features, Fitness: -1.9176\n",
      "    - New mask: 36 features, Fitness: -2.2719\n",
      "    - New mask: 36 features, Fitness: -1.2520\n",
      "    - New mask: 34 features, Fitness: -0.4640\n",
      "    - New mask: 36 features, Fitness: -1.8881\n",
      "    - New mask: 37 features, Fitness: -1.2349\n",
      "    - New mask: 32 features, Fitness: 0.3308\n",
      "    - New mask: 30 features, Fitness: 0.5334\n",
      "    - New mask: 38 features, Fitness: -1.9628\n",
      "    - New mask: 34 features, Fitness: -0.8944\n",
      "    - New mask: 35 features, Fitness: -0.9457\n",
      "    - New mask: 33 features, Fitness: -0.1347\n",
      "    - New mask: 33 features, Fitness: 0.0530\n",
      "    - New mask: 37 features, Fitness: -2.1809\n",
      "    - New mask: 33 features, Fitness: -0.7041\n",
      "    - New mask: 35 features, Fitness: -0.9556\n",
      "    - New mask: 38 features, Fitness: -2.0030\n",
      "    - New mask: 37 features, Fitness: -2.2046\n",
      "    - New mask: 36 features, Fitness: -1.3748\n",
      "    - New mask: 36 features, Fitness: -1.2942\n",
      "    - New mask: 36 features, Fitness: -8.2394\n",
      "    - New mask: 31 features, Fitness: -5.0779\n",
      "    - New mask: 34 features, Fitness: -6.1697\n",
      "    - New mask: 37 features, Fitness: -8.8356\n",
      "    - New mask: 34 features, Fitness: -6.7127\n",
      "    - New mask: 31 features, Fitness: -4.1911\n",
      "    - New mask: 33 features, Fitness: -6.6790\n",
      "    - New mask: 38 features, Fitness: -10.6702\n",
      "    - New mask: 34 features, Fitness: -7.5680\n",
      "    - New mask: 35 features, Fitness: -6.4206\n",
      "    - New mask: 33 features, Fitness: -6.3695\n",
      "    - New mask: 33 features, Fitness: -5.4556\n",
      "    - New mask: 35 features, Fitness: -6.3472\n",
      "    - New mask: 38 features, Fitness: -10.0869\n",
      "    - New mask: 34 features, Fitness: -6.5190\n",
      "    - New mask: 36 features, Fitness: -8.0690\n",
      "    - New mask: 33 features, Fitness: -5.4980\n",
      "    - New mask: 35 features, Fitness: -8.5315\n",
      "    - New mask: 37 features, Fitness: -7.7153\n",
      "    - New mask: 32 features, Fitness: -5.0360\n",
      "    - New mask: 30 features, Fitness: -2.5391\n",
      "    - New mask: 27 features, Fitness: -1.3228\n",
      "    - New mask: 29 features, Fitness: -2.5999\n",
      "    - New mask: 32 features, Fitness: -4.0152\n",
      "    - New mask: 31 features, Fitness: -2.6888\n",
      "    - New mask: 32 features, Fitness: -3.0549\n",
      "    - New mask: 29 features, Fitness: -2.2141\n",
      "    - New mask: 31 features, Fitness: -3.6411\n",
      "    - New mask: 29 features, Fitness: -2.7884\n",
      "    - New mask: 30 features, Fitness: -2.7706\n",
      "    - New mask: 34 features, Fitness: -4.5217\n",
      "    - New mask: 35 features, Fitness: -4.8316\n",
      "    - New mask: 31 features, Fitness: -2.8941\n",
      "    - New mask: 33 features, Fitness: -3.5453\n",
      "    - New mask: 30 features, Fitness: -2.8042\n",
      "    - New mask: 33 features, Fitness: -3.5172\n",
      "    - New mask: 34 features, Fitness: -4.7977\n",
      "    - New mask: 33 features, Fitness: -4.0331\n",
      "    - New mask: 32 features, Fitness: -3.6474\n",
      "    - New mask: 32 features, Fitness: -2.9954\n",
      "    - New mask: 34 features, Fitness: -6.3232\n",
      "    - New mask: 34 features, Fitness: -6.2059\n",
      "    - New mask: 35 features, Fitness: -8.0359\n",
      "    - New mask: 33 features, Fitness: -7.6625\n",
      "    - New mask: 29 features, Fitness: -4.8408\n",
      "    - New mask: 33 features, Fitness: -6.6384\n",
      "    - New mask: 35 features, Fitness: -7.6738\n",
      "    - New mask: 29 features, Fitness: -5.0583\n",
      "    - New mask: 35 features, Fitness: -9.1545\n",
      "    - New mask: 35 features, Fitness: -7.2016\n",
      "    - New mask: 32 features, Fitness: -5.7685\n",
      "    - New mask: 33 features, Fitness: -7.5285\n",
      "    - New mask: 35 features, Fitness: -7.7674\n",
      "    - New mask: 34 features, Fitness: -7.0057\n",
      "    - New mask: 33 features, Fitness: -6.8153\n",
      "    - New mask: 33 features, Fitness: -6.8046\n",
      "    - New mask: 33 features, Fitness: -6.5497\n",
      "    - New mask: 34 features, Fitness: -7.7487\n",
      "    - New mask: 30 features, Fitness: -5.5827\n",
      "    - New mask: 31 features, Fitness: -5.9922\n",
      "    - New mask: 28 features, Fitness: -3.0446\n",
      "    - New mask: 30 features, Fitness: -3.9310\n",
      "    - New mask: 37 features, Fitness: -6.4295\n",
      "    - New mask: 33 features, Fitness: -5.4474\n",
      "    - New mask: 31 features, Fitness: -4.7106\n",
      "    - New mask: 33 features, Fitness: -5.0659\n",
      "    - New mask: 31 features, Fitness: -4.3088\n",
      "    - New mask: 32 features, Fitness: -5.1144\n",
      "    - New mask: 29 features, Fitness: -3.5752\n",
      "    - New mask: 36 features, Fitness: -6.6108\n",
      "    - New mask: 35 features, Fitness: -6.1050\n",
      "    - New mask: 29 features, Fitness: -3.4381\n",
      "    - New mask: 34 features, Fitness: -5.5819\n",
      "    - New mask: 30 features, Fitness: -3.9398\n",
      "    - New mask: 30 features, Fitness: -4.7431\n",
      "    - New mask: 34 features, Fitness: -5.3262\n",
      "    - New mask: 31 features, Fitness: -3.8374\n",
      "    - New mask: 31 features, Fitness: -3.8728\n",
      "    - New mask: 35 features, Fitness: -6.0660\n",
      "    - New mask: 32 features, Fitness: -4.8303\n",
      "    - New mask: 36 features, Fitness: -3.1371\n",
      "    - New mask: 34 features, Fitness: -1.9993\n",
      "    - New mask: 33 features, Fitness: -2.3152\n",
      "    - New mask: 37 features, Fitness: -3.5893\n",
      "    - New mask: 36 features, Fitness: -2.9606\n",
      "    - New mask: 35 features, Fitness: -3.0272\n",
      "    - New mask: 31 features, Fitness: -1.6623\n",
      "    - New mask: 38 features, Fitness: -3.6437\n",
      "    - New mask: 32 features, Fitness: -2.4090\n",
      "    - New mask: 34 features, Fitness: -2.6956\n",
      "    - New mask: 37 features, Fitness: -3.5614\n",
      "    - New mask: 36 features, Fitness: -2.9762\n",
      "    - New mask: 34 features, Fitness: -2.2355\n",
      "    - New mask: 38 features, Fitness: -3.8439\n",
      "    - New mask: 35 features, Fitness: -2.5973\n",
      "    - New mask: 34 features, Fitness: -3.1868\n",
      "    - New mask: 36 features, Fitness: -2.8730\n",
      "    - New mask: 39 features, Fitness: -3.9696\n",
      "    - New mask: 34 features, Fitness: -2.2815\n",
      "    - New mask: 33 features, Fitness: -2.7335\n",
      "=== End of Round 6: Vote mask selects 40 features (rho: 0.36)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 7 ================\n",
      "  Adaptive rho for this round: 0.39\n",
      "    - New mask: 29 features, Fitness: -2.7173\n",
      "    - New mask: 34 features, Fitness: -4.4633\n",
      "    - New mask: 32 features, Fitness: -3.5378\n",
      "    - New mask: 35 features, Fitness: -4.7619\n",
      "    - New mask: 34 features, Fitness: -4.0455\n",
      "    - New mask: 33 features, Fitness: -4.2063\n",
      "    - New mask: 34 features, Fitness: -4.0863\n",
      "    - New mask: 34 features, Fitness: -4.4878\n",
      "    - New mask: 31 features, Fitness: -3.1531\n",
      "    - New mask: 35 features, Fitness: -4.6797\n",
      "    - New mask: 33 features, Fitness: -4.1453\n",
      "    - New mask: 34 features, Fitness: -4.1284\n",
      "    - New mask: 31 features, Fitness: -2.9376\n",
      "    - New mask: 33 features, Fitness: -4.3606\n",
      "    - New mask: 33 features, Fitness: -4.2099\n",
      "    - New mask: 38 features, Fitness: -5.9525\n",
      "    - New mask: 34 features, Fitness: -4.4571\n",
      "    - New mask: 34 features, Fitness: -4.3283\n",
      "    - New mask: 32 features, Fitness: -3.9725\n",
      "    - New mask: 34 features, Fitness: -4.5696\n",
      "    - New mask: 33 features, Fitness: -4.1202\n",
      "    - New mask: 33 features, Fitness: -4.1857\n",
      "    - New mask: 31 features, Fitness: -2.6966\n",
      "    - New mask: 28 features, Fitness: -2.3449\n",
      "    - New mask: 33 features, Fitness: -3.3714\n",
      "    - New mask: 33 features, Fitness: -3.5149\n",
      "    - New mask: 31 features, Fitness: -3.6689\n",
      "    - New mask: 31 features, Fitness: -3.2268\n",
      "    - New mask: 30 features, Fitness: -2.7313\n",
      "    - New mask: 34 features, Fitness: -4.1199\n",
      "    - New mask: 37 features, Fitness: -4.5624\n",
      "    - New mask: 33 features, Fitness: -3.7193\n",
      "    - New mask: 31 features, Fitness: -3.1958\n",
      "    - New mask: 30 features, Fitness: -2.9598\n",
      "    - New mask: 29 features, Fitness: -3.1180\n",
      "    - New mask: 37 features, Fitness: -5.6036\n",
      "    - New mask: 31 features, Fitness: -3.4333\n",
      "    - New mask: 31 features, Fitness: -4.0276\n",
      "    - New mask: 34 features, Fitness: -5.2630\n",
      "    - New mask: 32 features, Fitness: -2.9477\n",
      "    - New mask: 31 features, Fitness: -3.1754\n",
      "    - New mask: 34 features, Fitness: -3.3225\n",
      "    - New mask: 38 features, Fitness: -4.6125\n",
      "    - New mask: 36 features, Fitness: -4.2388\n",
      "    - New mask: 36 features, Fitness: -4.7100\n",
      "    - New mask: 36 features, Fitness: -4.0656\n",
      "    - New mask: 34 features, Fitness: -3.0529\n",
      "    - New mask: 37 features, Fitness: -4.1070\n",
      "    - New mask: 36 features, Fitness: -4.0428\n",
      "    - New mask: 36 features, Fitness: -4.5243\n",
      "    - New mask: 34 features, Fitness: -3.8333\n",
      "    - New mask: 35 features, Fitness: -3.6541\n",
      "    - New mask: 35 features, Fitness: -4.0709\n",
      "    - New mask: 36 features, Fitness: -3.8868\n",
      "    - New mask: 35 features, Fitness: -4.1094\n",
      "    - New mask: 35 features, Fitness: -3.4579\n",
      "    - New mask: 35 features, Fitness: -3.7717\n",
      "    - New mask: 35 features, Fitness: -4.6319\n",
      "    - New mask: 34 features, Fitness: -3.2964\n",
      "    - New mask: 35 features, Fitness: -3.6557\n",
      "    - New mask: 34 features, Fitness: 0.4269\n",
      "    - New mask: 34 features, Fitness: -0.3880\n",
      "    - New mask: 35 features, Fitness: -0.0005\n",
      "    - New mask: 36 features, Fitness: -0.4414\n",
      "    - New mask: 33 features, Fitness: 0.5424\n",
      "    - New mask: 38 features, Fitness: -1.0626\n",
      "    - New mask: 35 features, Fitness: 0.3282\n",
      "    - New mask: 35 features, Fitness: 0.3819\n",
      "    - New mask: 33 features, Fitness: 0.1897\n",
      "    - New mask: 34 features, Fitness: 0.1248\n",
      "    - New mask: 35 features, Fitness: 0.2656\n",
      "    - New mask: 35 features, Fitness: 0.4692\n",
      "    - New mask: 37 features, Fitness: -0.5648\n",
      "    - New mask: 35 features, Fitness: -0.0481\n",
      "    - New mask: 33 features, Fitness: 0.9571\n",
      "    - New mask: 33 features, Fitness: 0.5564\n",
      "    - New mask: 32 features, Fitness: 0.7446\n",
      "    - New mask: 37 features, Fitness: -0.2546\n",
      "    - New mask: 34 features, Fitness: 0.0026\n",
      "    - New mask: 36 features, Fitness: -0.2007\n",
      "    - New mask: 36 features, Fitness: -1.8077\n",
      "    - New mask: 32 features, Fitness: -0.2299\n",
      "    - New mask: 33 features, Fitness: -0.0766\n",
      "    - New mask: 35 features, Fitness: -1.2612\n",
      "    - New mask: 34 features, Fitness: -0.6974\n",
      "    - New mask: 40 features, Fitness: -2.5205\n",
      "    - New mask: 33 features, Fitness: -0.2694\n",
      "    - New mask: 31 features, Fitness: -0.2259\n",
      "    - New mask: 36 features, Fitness: -2.2549\n",
      "    - New mask: 34 features, Fitness: -0.5834\n",
      "    - New mask: 35 features, Fitness: -1.3960\n",
      "    - New mask: 31 features, Fitness: -0.0136\n",
      "    - New mask: 34 features, Fitness: 0.0219\n",
      "    - New mask: 33 features, Fitness: -2.0825\n",
      "    - New mask: 34 features, Fitness: -1.2654\n",
      "    - New mask: 33 features, Fitness: -0.2019\n",
      "    - New mask: 35 features, Fitness: -1.2450\n",
      "    - New mask: 35 features, Fitness: -1.5590\n",
      "    - New mask: 32 features, Fitness: -0.1009\n",
      "    - New mask: 37 features, Fitness: -2.4533\n",
      "    - New mask: 38 features, Fitness: -8.7520\n",
      "    - New mask: 32 features, Fitness: -6.6332\n",
      "    - New mask: 31 features, Fitness: -4.2452\n",
      "    - New mask: 34 features, Fitness: -5.7890\n",
      "    - New mask: 32 features, Fitness: -5.2455\n",
      "    - New mask: 36 features, Fitness: -7.7470\n",
      "    - New mask: 36 features, Fitness: -7.8565\n",
      "    - New mask: 36 features, Fitness: -8.6345\n",
      "    - New mask: 31 features, Fitness: -5.2788\n",
      "    - New mask: 38 features, Fitness: -9.0688\n",
      "    - New mask: 33 features, Fitness: -6.6198\n",
      "    - New mask: 34 features, Fitness: -6.6381\n",
      "    - New mask: 37 features, Fitness: -7.4649\n",
      "    - New mask: 37 features, Fitness: -8.3463\n",
      "    - New mask: 34 features, Fitness: -6.2087\n",
      "    - New mask: 34 features, Fitness: -8.0318\n",
      "    - New mask: 35 features, Fitness: -7.5306\n",
      "    - New mask: 34 features, Fitness: -7.1437\n",
      "    - New mask: 38 features, Fitness: -9.6337\n",
      "    - New mask: 31 features, Fitness: -4.7299\n",
      "    - New mask: 35 features, Fitness: -4.0012\n",
      "    - New mask: 28 features, Fitness: -1.8637\n",
      "    - New mask: 33 features, Fitness: -2.9930\n",
      "    - New mask: 31 features, Fitness: -2.7149\n",
      "    - New mask: 33 features, Fitness: -3.6777\n",
      "    - New mask: 35 features, Fitness: -4.1660\n",
      "    - New mask: 29 features, Fitness: -2.4973\n",
      "    - New mask: 33 features, Fitness: -3.8950\n",
      "    - New mask: 30 features, Fitness: -2.3450\n",
      "    - New mask: 27 features, Fitness: -2.5849\n",
      "    - New mask: 29 features, Fitness: -2.2429\n",
      "    - New mask: 34 features, Fitness: -4.1274\n",
      "    - New mask: 33 features, Fitness: -3.7029\n",
      "    - New mask: 33 features, Fitness: -3.4942\n",
      "    - New mask: 30 features, Fitness: -2.8884\n",
      "    - New mask: 32 features, Fitness: -3.4569\n",
      "    - New mask: 33 features, Fitness: -3.9129\n",
      "    - New mask: 34 features, Fitness: -3.4663\n",
      "    - New mask: 35 features, Fitness: -4.4399\n",
      "    - New mask: 36 features, Fitness: -4.1335\n",
      "    - New mask: 32 features, Fitness: -5.5927\n",
      "    - New mask: 30 features, Fitness: -4.4212\n",
      "    - New mask: 31 features, Fitness: -6.0674\n",
      "    - New mask: 31 features, Fitness: -5.4197\n",
      "    - New mask: 33 features, Fitness: -7.1859\n",
      "    - New mask: 35 features, Fitness: -6.7028\n",
      "    - New mask: 35 features, Fitness: -7.2623\n",
      "    - New mask: 32 features, Fitness: -5.3165\n",
      "    - New mask: 33 features, Fitness: -6.4416\n",
      "    - New mask: 35 features, Fitness: -8.4674\n",
      "    - New mask: 35 features, Fitness: -8.4090\n",
      "    - New mask: 34 features, Fitness: -8.1338\n",
      "    - New mask: 33 features, Fitness: -6.2504\n",
      "    - New mask: 36 features, Fitness: -7.6577\n",
      "    - New mask: 31 features, Fitness: -5.8350\n",
      "    - New mask: 34 features, Fitness: -8.1526\n",
      "    - New mask: 34 features, Fitness: -7.7951\n",
      "    - New mask: 28 features, Fitness: -4.3730\n",
      "    - New mask: 31 features, Fitness: -5.6226\n",
      "    - New mask: 30 features, Fitness: -4.0511\n",
      "    - New mask: 32 features, Fitness: -4.1305\n",
      "    - New mask: 31 features, Fitness: -3.7440\n",
      "    - New mask: 35 features, Fitness: -5.7535\n",
      "    - New mask: 34 features, Fitness: -5.6832\n",
      "    - New mask: 33 features, Fitness: -4.9646\n",
      "    - New mask: 32 features, Fitness: -4.8448\n",
      "    - New mask: 34 features, Fitness: -5.5596\n",
      "    - New mask: 33 features, Fitness: -4.9177\n",
      "    - New mask: 30 features, Fitness: -3.7998\n",
      "    - New mask: 33 features, Fitness: -5.8439\n",
      "    - New mask: 33 features, Fitness: -4.5171\n",
      "    - New mask: 32 features, Fitness: -4.2423\n",
      "    - New mask: 36 features, Fitness: -6.4894\n",
      "    - New mask: 33 features, Fitness: -5.3862\n",
      "    - New mask: 30 features, Fitness: -4.4354\n",
      "    - New mask: 31 features, Fitness: -4.0223\n",
      "    - New mask: 33 features, Fitness: -4.3776\n",
      "    - New mask: 32 features, Fitness: -4.6693\n",
      "    - New mask: 35 features, Fitness: -5.9989\n",
      "    - New mask: 30 features, Fitness: -4.4103\n",
      "    - New mask: 34 features, Fitness: -2.6652\n",
      "    - New mask: 34 features, Fitness: -2.2620\n",
      "    - New mask: 37 features, Fitness: -3.9478\n",
      "    - New mask: 33 features, Fitness: -2.6037\n",
      "    - New mask: 35 features, Fitness: -2.6048\n",
      "    - New mask: 36 features, Fitness: -3.2564\n",
      "    - New mask: 32 features, Fitness: -2.0143\n",
      "    - New mask: 36 features, Fitness: -3.3676\n",
      "    - New mask: 35 features, Fitness: -3.2607\n",
      "    - New mask: 34 features, Fitness: -2.5445\n",
      "    - New mask: 34 features, Fitness: -3.0847\n",
      "    - New mask: 39 features, Fitness: -3.9279\n",
      "    - New mask: 37 features, Fitness: -3.4833\n",
      "    - New mask: 37 features, Fitness: -3.6799\n",
      "    - New mask: 35 features, Fitness: -2.9002\n",
      "    - New mask: 34 features, Fitness: -2.8967\n",
      "    - New mask: 35 features, Fitness: -2.7769\n",
      "    - New mask: 37 features, Fitness: -3.4119\n",
      "    - New mask: 36 features, Fitness: -3.0629\n",
      "    - New mask: 37 features, Fitness: -3.9828\n",
      "=== End of Round 7: Vote mask selects 40 features (rho: 0.39)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 8 ================\n",
      "  Adaptive rho for this round: 0.42\n",
      "    - New mask: 32 features, Fitness: -3.5234\n",
      "    - New mask: 35 features, Fitness: -4.2766\n",
      "    - New mask: 32 features, Fitness: -3.5080\n",
      "    - New mask: 32 features, Fitness: -3.5675\n",
      "    - New mask: 33 features, Fitness: -3.5250\n",
      "    - New mask: 32 features, Fitness: -3.7771\n",
      "    - New mask: 29 features, Fitness: -2.2253\n",
      "    - New mask: 33 features, Fitness: -4.3276\n",
      "    - New mask: 29 features, Fitness: -2.9222\n",
      "    - New mask: 31 features, Fitness: -3.5851\n",
      "    - New mask: 31 features, Fitness: -3.1586\n",
      "    - New mask: 32 features, Fitness: -3.3494\n",
      "    - New mask: 35 features, Fitness: -4.6792\n",
      "    - New mask: 31 features, Fitness: -3.3274\n",
      "    - New mask: 33 features, Fitness: -4.0382\n",
      "    - New mask: 33 features, Fitness: -4.1309\n",
      "    - New mask: 34 features, Fitness: -4.6404\n",
      "    - New mask: 33 features, Fitness: -3.9479\n",
      "    - New mask: 32 features, Fitness: -4.2698\n",
      "    - New mask: 34 features, Fitness: -4.6133\n",
      "    - New mask: 32 features, Fitness: -3.4934\n",
      "    - New mask: 36 features, Fitness: -5.0437\n",
      "    - New mask: 28 features, Fitness: -1.8430\n",
      "    - New mask: 30 features, Fitness: -2.8153\n",
      "    - New mask: 34 features, Fitness: -3.7672\n",
      "    - New mask: 32 features, Fitness: -3.0320\n",
      "    - New mask: 29 features, Fitness: -3.0507\n",
      "    - New mask: 30 features, Fitness: -2.7473\n",
      "    - New mask: 30 features, Fitness: -2.9652\n",
      "    - New mask: 34 features, Fitness: -3.8506\n",
      "    - New mask: 37 features, Fitness: -5.2875\n",
      "    - New mask: 33 features, Fitness: -3.5902\n",
      "    - New mask: 29 features, Fitness: -2.7534\n",
      "    - New mask: 35 features, Fitness: -3.8993\n",
      "    - New mask: 32 features, Fitness: -3.5785\n",
      "    - New mask: 36 features, Fitness: -5.2862\n",
      "    - New mask: 33 features, Fitness: -3.8434\n",
      "    - New mask: 34 features, Fitness: -4.6282\n",
      "    - New mask: 32 features, Fitness: -3.9466\n",
      "    - New mask: 29 features, Fitness: -2.6709\n",
      "    - New mask: 32 features, Fitness: -3.6918\n",
      "    - New mask: 37 features, Fitness: -3.8338\n",
      "    - New mask: 34 features, Fitness: -3.3191\n",
      "    - New mask: 35 features, Fitness: -3.9385\n",
      "    - New mask: 36 features, Fitness: -4.6036\n",
      "    - New mask: 38 features, Fitness: -4.8893\n",
      "    - New mask: 36 features, Fitness: -3.7698\n",
      "    - New mask: 35 features, Fitness: -4.2820\n",
      "    - New mask: 36 features, Fitness: -4.3454\n",
      "    - New mask: 37 features, Fitness: -5.0174\n",
      "    - New mask: 34 features, Fitness: -3.1690\n",
      "    - New mask: 39 features, Fitness: -5.1340\n",
      "    - New mask: 31 features, Fitness: -2.2383\n",
      "    - New mask: 37 features, Fitness: -4.0297\n",
      "    - New mask: 36 features, Fitness: -3.6311\n",
      "    - New mask: 35 features, Fitness: -3.5989\n",
      "    - New mask: 32 features, Fitness: -2.4413\n",
      "    - New mask: 37 features, Fitness: -4.5417\n",
      "    - New mask: 36 features, Fitness: -4.5518\n",
      "    - New mask: 35 features, Fitness: -2.9225\n",
      "    - New mask: 38 features, Fitness: -0.7269\n",
      "    - New mask: 38 features, Fitness: -0.7078\n",
      "    - New mask: 38 features, Fitness: -0.8180\n",
      "    - New mask: 34 features, Fitness: 0.5690\n",
      "    - New mask: 35 features, Fitness: 0.4838\n",
      "    - New mask: 37 features, Fitness: -0.6662\n",
      "    - New mask: 32 features, Fitness: 0.7527\n",
      "    - New mask: 34 features, Fitness: -0.1000\n",
      "    - New mask: 32 features, Fitness: 0.4617\n",
      "    - New mask: 35 features, Fitness: 0.2108\n",
      "    - New mask: 34 features, Fitness: 0.2440\n",
      "    - New mask: 39 features, Fitness: -0.7205\n",
      "    - New mask: 37 features, Fitness: -0.2711\n",
      "    - New mask: 35 features, Fitness: 0.0139\n",
      "    - New mask: 36 features, Fitness: 0.0724\n",
      "    - New mask: 33 features, Fitness: 0.7766\n",
      "    - New mask: 32 features, Fitness: 1.0172\n",
      "    - New mask: 33 features, Fitness: 0.9570\n",
      "    - New mask: 35 features, Fitness: -0.3381\n",
      "    - New mask: 34 features, Fitness: 0.6217\n",
      "    - New mask: 33 features, Fitness: -0.3787\n",
      "    - New mask: 36 features, Fitness: -0.7733\n",
      "    - New mask: 31 features, Fitness: 0.5211\n",
      "    - New mask: 38 features, Fitness: -2.2612\n",
      "    - New mask: 31 features, Fitness: -0.6262\n",
      "    - New mask: 40 features, Fitness: -3.3997\n",
      "    - New mask: 38 features, Fitness: -2.0948\n",
      "    - New mask: 39 features, Fitness: -2.2151\n",
      "    - New mask: 37 features, Fitness: -2.0904\n",
      "    - New mask: 37 features, Fitness: -1.6963\n",
      "    - New mask: 32 features, Fitness: -0.4093\n",
      "    - New mask: 32 features, Fitness: -0.0155\n",
      "    - New mask: 38 features, Fitness: -1.9051\n",
      "    - New mask: 34 features, Fitness: -1.2753\n",
      "    - New mask: 35 features, Fitness: -0.8009\n",
      "    - New mask: 37 features, Fitness: -1.0821\n",
      "    - New mask: 38 features, Fitness: -2.3855\n",
      "    - New mask: 35 features, Fitness: -1.3092\n",
      "    - New mask: 37 features, Fitness: -2.0435\n",
      "    - New mask: 35 features, Fitness: -1.6922\n",
      "    - New mask: 36 features, Fitness: -6.4520\n",
      "    - New mask: 35 features, Fitness: -7.4075\n",
      "    - New mask: 34 features, Fitness: -6.4392\n",
      "    - New mask: 38 features, Fitness: -9.1203\n",
      "    - New mask: 33 features, Fitness: -5.6399\n",
      "    - New mask: 34 features, Fitness: -5.9200\n",
      "    - New mask: 34 features, Fitness: -6.1077\n",
      "    - New mask: 37 features, Fitness: -8.7990\n",
      "    - New mask: 31 features, Fitness: -5.8316\n",
      "    - New mask: 37 features, Fitness: -7.7378\n",
      "    - New mask: 34 features, Fitness: -6.8803\n",
      "    - New mask: 36 features, Fitness: -7.4514\n",
      "    - New mask: 34 features, Fitness: -6.0355\n",
      "    - New mask: 36 features, Fitness: -7.5741\n",
      "    - New mask: 31 features, Fitness: -4.9681\n",
      "    - New mask: 33 features, Fitness: -7.8924\n",
      "    - New mask: 33 features, Fitness: -5.4791\n",
      "    - New mask: 36 features, Fitness: -7.8254\n",
      "    - New mask: 33 features, Fitness: -5.9505\n",
      "    - New mask: 38 features, Fitness: -9.5839\n",
      "    - New mask: 33 features, Fitness: -3.4448\n",
      "    - New mask: 35 features, Fitness: -3.6347\n",
      "    - New mask: 34 features, Fitness: -3.1501\n",
      "    - New mask: 36 features, Fitness: -4.6347\n",
      "    - New mask: 31 features, Fitness: -3.1779\n",
      "    - New mask: 34 features, Fitness: -3.7568\n",
      "    - New mask: 29 features, Fitness: -2.2569\n",
      "    - New mask: 31 features, Fitness: -2.7926\n",
      "    - New mask: 30 features, Fitness: -2.4081\n",
      "    - New mask: 28 features, Fitness: -2.8709\n",
      "    - New mask: 32 features, Fitness: -3.3541\n",
      "    - New mask: 32 features, Fitness: -3.7939\n",
      "    - New mask: 36 features, Fitness: -5.3743\n",
      "    - New mask: 33 features, Fitness: -3.6334\n",
      "    - New mask: 32 features, Fitness: -3.1723\n",
      "    - New mask: 32 features, Fitness: -3.3771\n",
      "    - New mask: 31 features, Fitness: -3.4597\n",
      "    - New mask: 34 features, Fitness: -3.4706\n",
      "    - New mask: 31 features, Fitness: -2.6442\n",
      "    - New mask: 33 features, Fitness: -3.3306\n",
      "    - New mask: 32 features, Fitness: -5.4582\n",
      "    - New mask: 31 features, Fitness: -4.6832\n",
      "    - New mask: 31 features, Fitness: -5.8197\n",
      "    - New mask: 33 features, Fitness: -5.6879\n",
      "    - New mask: 30 features, Fitness: -4.9291\n",
      "    - New mask: 31 features, Fitness: -4.6834\n",
      "    - New mask: 34 features, Fitness: -6.3964\n",
      "    - New mask: 36 features, Fitness: -7.9791\n",
      "    - New mask: 38 features, Fitness: -9.1142\n",
      "    - New mask: 34 features, Fitness: -7.1287\n",
      "    - New mask: 37 features, Fitness: -8.2992\n",
      "    - New mask: 32 features, Fitness: -5.4716\n",
      "    - New mask: 34 features, Fitness: -6.3549\n",
      "    - New mask: 38 features, Fitness: -8.8257\n",
      "    - New mask: 30 features, Fitness: -3.9108\n",
      "    - New mask: 35 features, Fitness: -7.8201\n",
      "    - New mask: 33 features, Fitness: -6.6753\n",
      "    - New mask: 33 features, Fitness: -6.6017\n",
      "    - New mask: 36 features, Fitness: -7.6724\n",
      "    - New mask: 33 features, Fitness: -5.4097\n",
      "    - New mask: 33 features, Fitness: -4.5078\n",
      "    - New mask: 32 features, Fitness: -4.1209\n",
      "    - New mask: 34 features, Fitness: -4.6897\n",
      "    - New mask: 32 features, Fitness: -4.5015\n",
      "    - New mask: 37 features, Fitness: -7.3118\n",
      "    - New mask: 35 features, Fitness: -5.2616\n",
      "    - New mask: 36 features, Fitness: -5.7834\n",
      "    - New mask: 32 features, Fitness: -3.9978\n",
      "    - New mask: 33 features, Fitness: -5.2913\n",
      "    - New mask: 34 features, Fitness: -5.5845\n",
      "    - New mask: 32 features, Fitness: -4.5924\n",
      "    - New mask: 32 features, Fitness: -4.1769\n",
      "    - New mask: 34 features, Fitness: -5.1650\n",
      "    - New mask: 34 features, Fitness: -5.2279\n",
      "    - New mask: 32 features, Fitness: -4.5511\n",
      "    - New mask: 34 features, Fitness: -6.0274\n",
      "    - New mask: 32 features, Fitness: -3.8332\n",
      "    - New mask: 35 features, Fitness: -5.8852\n",
      "    - New mask: 37 features, Fitness: -6.4633\n",
      "    - New mask: 33 features, Fitness: -5.2695\n",
      "    - New mask: 36 features, Fitness: -2.6150\n",
      "    - New mask: 35 features, Fitness: -2.6616\n",
      "    - New mask: 35 features, Fitness: -2.6049\n",
      "    - New mask: 32 features, Fitness: -1.9547\n",
      "    - New mask: 34 features, Fitness: -2.9342\n",
      "    - New mask: 37 features, Fitness: -3.8208\n",
      "    - New mask: 33 features, Fitness: -2.5172\n",
      "    - New mask: 35 features, Fitness: -3.4358\n",
      "    - New mask: 33 features, Fitness: -2.7110\n",
      "    - New mask: 36 features, Fitness: -3.0727\n",
      "    - New mask: 37 features, Fitness: -3.8837\n",
      "    - New mask: 37 features, Fitness: -3.4032\n",
      "    - New mask: 38 features, Fitness: -3.6920\n",
      "    - New mask: 34 features, Fitness: -2.0434\n",
      "    - New mask: 37 features, Fitness: -3.4538\n",
      "    - New mask: 32 features, Fitness: -1.8619\n",
      "    - New mask: 37 features, Fitness: -3.7192\n",
      "    - New mask: 37 features, Fitness: -3.1061\n",
      "    - New mask: 39 features, Fitness: -4.2308\n",
      "    - New mask: 34 features, Fitness: -2.8515\n",
      "=== End of Round 8: Vote mask selects 39 features (rho: 0.42)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 9 ================\n",
      "  Adaptive rho for this round: 0.45\n",
      "    - New mask: 36 features, Fitness: -4.8750\n",
      "    - New mask: 34 features, Fitness: -4.8730\n",
      "    - New mask: 34 features, Fitness: -4.0217\n",
      "    - New mask: 33 features, Fitness: -3.6566\n",
      "    - New mask: 32 features, Fitness: -3.0480\n",
      "    - New mask: 33 features, Fitness: -3.3880\n",
      "    - New mask: 32 features, Fitness: -3.3092\n",
      "    - New mask: 31 features, Fitness: -2.9610\n",
      "    - New mask: 28 features, Fitness: -2.5150\n",
      "    - New mask: 33 features, Fitness: -3.9492\n",
      "    - New mask: 34 features, Fitness: -5.3830\n",
      "    - New mask: 30 features, Fitness: -2.6061\n",
      "    - New mask: 31 features, Fitness: -2.9360\n",
      "    - New mask: 32 features, Fitness: -3.5796\n",
      "    - New mask: 32 features, Fitness: -3.7463\n",
      "    - New mask: 32 features, Fitness: -3.1325\n",
      "    - New mask: 34 features, Fitness: -3.9688\n",
      "    - New mask: 31 features, Fitness: -2.7558\n",
      "    - New mask: 33 features, Fitness: -3.8100\n",
      "    - New mask: 34 features, Fitness: -4.1572\n",
      "    - New mask: 33 features, Fitness: -3.2530\n",
      "    - New mask: 36 features, Fitness: -4.4758\n",
      "    - New mask: 30 features, Fitness: -2.4112\n",
      "    - New mask: 29 features, Fitness: -2.0954\n",
      "    - New mask: 33 features, Fitness: -3.4473\n",
      "    - New mask: 32 features, Fitness: -2.8294\n",
      "    - New mask: 31 features, Fitness: -2.6700\n",
      "    - New mask: 34 features, Fitness: -4.0588\n",
      "    - New mask: 36 features, Fitness: -4.2860\n",
      "    - New mask: 33 features, Fitness: -3.2949\n",
      "    - New mask: 36 features, Fitness: -4.4177\n",
      "    - New mask: 32 features, Fitness: -3.8822\n",
      "    - New mask: 31 features, Fitness: -2.9680\n",
      "    - New mask: 35 features, Fitness: -4.0593\n",
      "    - New mask: 33 features, Fitness: -3.7214\n",
      "    - New mask: 35 features, Fitness: -4.7472\n",
      "    - New mask: 32 features, Fitness: -3.2448\n",
      "    - New mask: 36 features, Fitness: -4.9081\n",
      "    - New mask: 32 features, Fitness: -3.1812\n",
      "    - New mask: 34 features, Fitness: -4.0953\n",
      "    - New mask: 34 features, Fitness: -3.4622\n",
      "    - New mask: 35 features, Fitness: -3.1629\n",
      "    - New mask: 34 features, Fitness: -2.9636\n",
      "    - New mask: 36 features, Fitness: -4.1176\n",
      "    - New mask: 33 features, Fitness: -3.6423\n",
      "    - New mask: 37 features, Fitness: -3.8952\n",
      "    - New mask: 34 features, Fitness: -2.7146\n",
      "    - New mask: 37 features, Fitness: -4.3209\n",
      "    - New mask: 36 features, Fitness: -4.5667\n",
      "    - New mask: 34 features, Fitness: -4.0433\n",
      "    - New mask: 36 features, Fitness: -3.9565\n",
      "    - New mask: 37 features, Fitness: -4.2259\n",
      "    - New mask: 36 features, Fitness: -3.9691\n",
      "    - New mask: 35 features, Fitness: -3.1341\n",
      "    - New mask: 33 features, Fitness: -2.5259\n",
      "    - New mask: 32 features, Fitness: -2.7886\n",
      "    - New mask: 34 features, Fitness: -2.9950\n",
      "    - New mask: 33 features, Fitness: -2.9133\n",
      "    - New mask: 34 features, Fitness: -3.2378\n",
      "    - New mask: 37 features, Fitness: -3.7721\n",
      "    - New mask: 32 features, Fitness: 0.3266\n",
      "    - New mask: 31 features, Fitness: 0.8688\n",
      "    - New mask: 35 features, Fitness: 0.2059\n",
      "    - New mask: 34 features, Fitness: 0.4686\n",
      "    - New mask: 35 features, Fitness: 0.4838\n",
      "    - New mask: 37 features, Fitness: -0.2047\n",
      "    - New mask: 33 features, Fitness: 0.7351\n",
      "    - New mask: 34 features, Fitness: 0.7377\n",
      "    - New mask: 31 features, Fitness: 1.2857\n",
      "    - New mask: 34 features, Fitness: 0.6011\n",
      "    - New mask: 32 features, Fitness: 0.5043\n",
      "    - New mask: 37 features, Fitness: -0.4907\n",
      "    - New mask: 35 features, Fitness: 0.3652\n",
      "    - New mask: 35 features, Fitness: 0.3256\n",
      "    - New mask: 36 features, Fitness: -0.1442\n",
      "    - New mask: 32 features, Fitness: 1.2730\n",
      "    - New mask: 34 features, Fitness: 0.4462\n",
      "    - New mask: 32 features, Fitness: 0.5795\n",
      "    - New mask: 35 features, Fitness: 0.4447\n",
      "    - New mask: 33 features, Fitness: 0.8628\n",
      "    - New mask: 35 features, Fitness: -0.7647\n",
      "    - New mask: 31 features, Fitness: 0.4716\n",
      "    - New mask: 36 features, Fitness: -0.9878\n",
      "    - New mask: 37 features, Fitness: -2.2962\n",
      "    - New mask: 31 features, Fitness: 0.1249\n",
      "    - New mask: 37 features, Fitness: -1.9572\n",
      "    - New mask: 32 features, Fitness: -0.0046\n",
      "    - New mask: 38 features, Fitness: -1.9263\n",
      "    - New mask: 33 features, Fitness: -0.9469\n",
      "    - New mask: 35 features, Fitness: -1.6654\n",
      "    - New mask: 35 features, Fitness: -0.4871\n",
      "    - New mask: 35 features, Fitness: -0.4082\n",
      "    - New mask: 36 features, Fitness: -0.7624\n",
      "    - New mask: 36 features, Fitness: -1.3191\n",
      "    - New mask: 34 features, Fitness: -0.7380\n",
      "    - New mask: 35 features, Fitness: -0.8887\n",
      "    - New mask: 33 features, Fitness: -0.9878\n",
      "    - New mask: 31 features, Fitness: 0.6278\n",
      "    - New mask: 37 features, Fitness: -2.3123\n",
      "    - New mask: 35 features, Fitness: -0.8717\n",
      "    - New mask: 37 features, Fitness: -8.5880\n",
      "    - New mask: 34 features, Fitness: -5.9692\n",
      "    - New mask: 33 features, Fitness: -6.6509\n",
      "    - New mask: 33 features, Fitness: -5.6207\n",
      "    - New mask: 35 features, Fitness: -6.9627\n",
      "    - New mask: 36 features, Fitness: -7.8670\n",
      "    - New mask: 34 features, Fitness: -7.2085\n",
      "    - New mask: 36 features, Fitness: -7.9901\n",
      "    - New mask: 35 features, Fitness: -7.8215\n",
      "    - New mask: 30 features, Fitness: -3.7178\n",
      "    - New mask: 37 features, Fitness: -9.3247\n",
      "    - New mask: 33 features, Fitness: -6.5829\n",
      "    - New mask: 37 features, Fitness: -8.3488\n",
      "    - New mask: 34 features, Fitness: -7.7370\n",
      "    - New mask: 34 features, Fitness: -7.2336\n",
      "    - New mask: 33 features, Fitness: -7.4876\n",
      "    - New mask: 36 features, Fitness: -8.3549\n",
      "    - New mask: 32 features, Fitness: -5.0459\n",
      "    - New mask: 36 features, Fitness: -6.8248\n",
      "    - New mask: 35 features, Fitness: -8.0700\n",
      "    - New mask: 34 features, Fitness: -3.4065\n",
      "    - New mask: 32 features, Fitness: -3.0912\n",
      "    - New mask: 35 features, Fitness: -4.0879\n",
      "    - New mask: 33 features, Fitness: -3.6330\n",
      "    - New mask: 29 features, Fitness: -2.4384\n",
      "    - New mask: 34 features, Fitness: -4.2184\n",
      "    - New mask: 30 features, Fitness: -3.2219\n",
      "    - New mask: 34 features, Fitness: -4.2215\n",
      "    - New mask: 32 features, Fitness: -3.3025\n",
      "    - New mask: 31 features, Fitness: -3.8959\n",
      "    - New mask: 34 features, Fitness: -3.5801\n",
      "    - New mask: 31 features, Fitness: -3.0301\n",
      "    - New mask: 34 features, Fitness: -3.5228\n",
      "    - New mask: 33 features, Fitness: -3.6207\n",
      "    - New mask: 31 features, Fitness: -3.0286\n",
      "    - New mask: 32 features, Fitness: -3.3775\n",
      "    - New mask: 33 features, Fitness: -3.7183\n",
      "    - New mask: 33 features, Fitness: -3.7383\n",
      "    - New mask: 32 features, Fitness: -3.1455\n",
      "    - New mask: 33 features, Fitness: -3.8310\n",
      "    - New mask: 33 features, Fitness: -5.3645\n",
      "    - New mask: 32 features, Fitness: -5.8588\n",
      "    - New mask: 33 features, Fitness: -5.9928\n",
      "    - New mask: 32 features, Fitness: -5.3553\n",
      "    - New mask: 35 features, Fitness: -6.7995\n",
      "    - New mask: 31 features, Fitness: -4.3645\n",
      "    - New mask: 33 features, Fitness: -5.8133\n",
      "    - New mask: 34 features, Fitness: -7.1569\n",
      "    - New mask: 33 features, Fitness: -5.0912\n",
      "    - New mask: 36 features, Fitness: -8.2643\n",
      "    - New mask: 37 features, Fitness: -8.0984\n",
      "    - New mask: 34 features, Fitness: -6.6621\n",
      "    - New mask: 31 features, Fitness: -4.8216\n",
      "    - New mask: 32 features, Fitness: -4.9314\n",
      "    - New mask: 31 features, Fitness: -4.5036\n",
      "    - New mask: 37 features, Fitness: -7.9425\n",
      "    - New mask: 32 features, Fitness: -4.6161\n",
      "    - New mask: 36 features, Fitness: -7.3351\n",
      "    - New mask: 35 features, Fitness: -6.9151\n",
      "    - New mask: 32 features, Fitness: -4.9005\n",
      "    - New mask: 35 features, Fitness: -5.5870\n",
      "    - New mask: 34 features, Fitness: -5.1457\n",
      "    - New mask: 38 features, Fitness: -6.6905\n",
      "    - New mask: 33 features, Fitness: -4.2763\n",
      "    - New mask: 35 features, Fitness: -6.4461\n",
      "    - New mask: 35 features, Fitness: -4.8131\n",
      "    - New mask: 35 features, Fitness: -4.7963\n",
      "    - New mask: 33 features, Fitness: -4.7580\n",
      "    - New mask: 35 features, Fitness: -5.8966\n",
      "    - New mask: 30 features, Fitness: -4.0388\n",
      "    - New mask: 33 features, Fitness: -4.6582\n",
      "    - New mask: 34 features, Fitness: -4.3291\n",
      "    - New mask: 34 features, Fitness: -5.2997\n",
      "    - New mask: 34 features, Fitness: -4.6467\n",
      "    - New mask: 33 features, Fitness: -4.3304\n",
      "    - New mask: 33 features, Fitness: -5.2749\n",
      "    - New mask: 34 features, Fitness: -4.6720\n",
      "    - New mask: 36 features, Fitness: -5.9562\n",
      "    - New mask: 38 features, Fitness: -6.6536\n",
      "    - New mask: 33 features, Fitness: -4.7354\n",
      "    - New mask: 35 features, Fitness: -2.5023\n",
      "    - New mask: 33 features, Fitness: -2.1127\n",
      "    - New mask: 36 features, Fitness: -3.4112\n",
      "    - New mask: 35 features, Fitness: -3.0306\n",
      "    - New mask: 36 features, Fitness: -3.2987\n",
      "    - New mask: 32 features, Fitness: -2.5799\n",
      "    - New mask: 33 features, Fitness: -2.4155\n",
      "    - New mask: 32 features, Fitness: -1.6785\n",
      "    - New mask: 34 features, Fitness: -2.6586\n",
      "    - New mask: 37 features, Fitness: -3.0551\n",
      "    - New mask: 37 features, Fitness: -3.4281\n",
      "    - New mask: 38 features, Fitness: -3.5804\n",
      "    - New mask: 35 features, Fitness: -3.5599\n",
      "    - New mask: 30 features, Fitness: -1.4106\n",
      "    - New mask: 34 features, Fitness: -2.6704\n",
      "    - New mask: 35 features, Fitness: -2.7727\n",
      "    - New mask: 37 features, Fitness: -3.2319\n",
      "    - New mask: 37 features, Fitness: -3.6018\n",
      "    - New mask: 38 features, Fitness: -3.9669\n",
      "    - New mask: 32 features, Fitness: -1.8619\n",
      "=== End of Round 9: Vote mask selects 39 features (rho: 0.45)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 10 ================\n",
      "  Adaptive rho for this round: 0.48\n",
      "    - New mask: 34 features, Fitness: -4.4396\n",
      "    - New mask: 35 features, Fitness: -4.4644\n",
      "    - New mask: 35 features, Fitness: -4.5627\n",
      "    - New mask: 34 features, Fitness: -4.0496\n",
      "    - New mask: 35 features, Fitness: -4.7589\n",
      "    - New mask: 36 features, Fitness: -5.4454\n",
      "    - New mask: 31 features, Fitness: -3.0893\n",
      "    - New mask: 25 features, Fitness: -2.4093\n",
      "    - New mask: 29 features, Fitness: -2.2744\n",
      "    - New mask: 32 features, Fitness: -3.7179\n",
      "    - New mask: 32 features, Fitness: -3.7819\n",
      "    - New mask: 34 features, Fitness: -4.2666\n",
      "    - New mask: 32 features, Fitness: -2.7898\n",
      "    - New mask: 35 features, Fitness: -5.0593\n",
      "    - New mask: 30 features, Fitness: -4.0223\n",
      "    - New mask: 34 features, Fitness: -3.8642\n",
      "    - New mask: 32 features, Fitness: -4.0303\n",
      "    - New mask: 37 features, Fitness: -5.8159\n",
      "    - New mask: 32 features, Fitness: -3.7535\n",
      "    - New mask: 36 features, Fitness: -5.2601\n",
      "    - New mask: 33 features, Fitness: -3.0203\n",
      "    - New mask: 34 features, Fitness: -3.7084\n",
      "    - New mask: 32 features, Fitness: -2.7079\n",
      "    - New mask: 33 features, Fitness: -3.2230\n",
      "    - New mask: 34 features, Fitness: -3.9119\n",
      "    - New mask: 34 features, Fitness: -3.3258\n",
      "    - New mask: 31 features, Fitness: -2.5221\n",
      "    - New mask: 36 features, Fitness: -4.1039\n",
      "    - New mask: 34 features, Fitness: -3.6887\n",
      "    - New mask: 34 features, Fitness: -3.6468\n",
      "    - New mask: 35 features, Fitness: -4.0219\n",
      "    - New mask: 35 features, Fitness: -4.6438\n",
      "    - New mask: 32 features, Fitness: -3.0018\n",
      "    - New mask: 32 features, Fitness: -2.9997\n",
      "    - New mask: 30 features, Fitness: -2.2721\n",
      "    - New mask: 33 features, Fitness: -3.3240\n",
      "    - New mask: 37 features, Fitness: -4.9924\n",
      "    - New mask: 32 features, Fitness: -2.8027\n",
      "    - New mask: 32 features, Fitness: -2.8144\n",
      "    - New mask: 35 features, Fitness: -4.0002\n",
      "    - New mask: 36 features, Fitness: -3.6127\n",
      "    - New mask: 33 features, Fitness: -2.7219\n",
      "    - New mask: 35 features, Fitness: -3.1684\n",
      "    - New mask: 36 features, Fitness: -3.9424\n",
      "    - New mask: 34 features, Fitness: -3.7316\n",
      "    - New mask: 37 features, Fitness: -4.1618\n",
      "    - New mask: 36 features, Fitness: -3.9530\n",
      "    - New mask: 33 features, Fitness: -2.8044\n",
      "    - New mask: 36 features, Fitness: -3.8107\n",
      "    - New mask: 35 features, Fitness: -3.9606\n",
      "    - New mask: 36 features, Fitness: -3.9565\n",
      "    - New mask: 35 features, Fitness: -3.5516\n",
      "    - New mask: 35 features, Fitness: -3.5071\n",
      "    - New mask: 38 features, Fitness: -4.5343\n",
      "    - New mask: 33 features, Fitness: -2.5259\n",
      "    - New mask: 33 features, Fitness: -2.6596\n",
      "    - New mask: 37 features, Fitness: -3.9921\n",
      "    - New mask: 34 features, Fitness: -3.0113\n",
      "    - New mask: 34 features, Fitness: -2.7811\n",
      "    - New mask: 37 features, Fitness: -3.8290\n",
      "    - New mask: 33 features, Fitness: 0.8557\n",
      "    - New mask: 34 features, Fitness: 0.6644\n",
      "    - New mask: 36 features, Fitness: -0.1450\n",
      "    - New mask: 35 features, Fitness: 0.4682\n",
      "    - New mask: 33 features, Fitness: 0.7197\n",
      "    - New mask: 33 features, Fitness: 0.7964\n",
      "    - New mask: 33 features, Fitness: 0.0519\n",
      "    - New mask: 31 features, Fitness: 1.0837\n",
      "    - New mask: 32 features, Fitness: 0.9682\n",
      "    - New mask: 35 features, Fitness: 0.3203\n",
      "    - New mask: 33 features, Fitness: -0.0667\n",
      "    - New mask: 34 features, Fitness: 0.0145\n",
      "    - New mask: 32 features, Fitness: 1.0444\n",
      "    - New mask: 32 features, Fitness: 1.0536\n",
      "    - New mask: 36 features, Fitness: -0.0092\n",
      "    - New mask: 33 features, Fitness: 0.8600\n",
      "    - New mask: 35 features, Fitness: 0.1163\n",
      "    - New mask: 34 features, Fitness: 0.8001\n",
      "    - New mask: 38 features, Fitness: -0.4717\n",
      "    - New mask: 35 features, Fitness: 0.4817\n",
      "    - New mask: 34 features, Fitness: -0.1901\n",
      "    - New mask: 31 features, Fitness: 0.4045\n",
      "    - New mask: 35 features, Fitness: -1.0656\n",
      "    - New mask: 36 features, Fitness: -1.4330\n",
      "    - New mask: 31 features, Fitness: 0.6587\n",
      "    - New mask: 33 features, Fitness: -0.1375\n",
      "    - New mask: 30 features, Fitness: 0.7951\n",
      "    - New mask: 36 features, Fitness: -1.0093\n",
      "    - New mask: 36 features, Fitness: -1.8527\n",
      "    - New mask: 35 features, Fitness: -0.6496\n",
      "    - New mask: 33 features, Fitness: 0.4311\n",
      "    - New mask: 34 features, Fitness: -1.3424\n",
      "    - New mask: 34 features, Fitness: -1.0994\n",
      "    - New mask: 36 features, Fitness: -1.2403\n",
      "    - New mask: 34 features, Fitness: -0.6446\n",
      "    - New mask: 33 features, Fitness: -0.0104\n",
      "    - New mask: 34 features, Fitness: -0.7145\n",
      "    - New mask: 35 features, Fitness: -2.1680\n",
      "    - New mask: 34 features, Fitness: -0.5989\n",
      "    - New mask: 34 features, Fitness: 0.1420\n",
      "    - New mask: 36 features, Fitness: -7.1832\n",
      "    - New mask: 35 features, Fitness: -5.8217\n",
      "    - New mask: 30 features, Fitness: -4.5742\n",
      "    - New mask: 34 features, Fitness: -5.4468\n",
      "    - New mask: 35 features, Fitness: -7.0399\n",
      "    - New mask: 33 features, Fitness: -5.2435\n",
      "    - New mask: 34 features, Fitness: -5.9236\n",
      "    - New mask: 32 features, Fitness: -5.4778\n",
      "    - New mask: 37 features, Fitness: -7.8902\n",
      "    - New mask: 31 features, Fitness: -4.8943\n",
      "    - New mask: 33 features, Fitness: -5.9427\n",
      "    - New mask: 34 features, Fitness: -7.7765\n",
      "    - New mask: 34 features, Fitness: -6.0352\n",
      "    - New mask: 31 features, Fitness: -6.0018\n",
      "    - New mask: 33 features, Fitness: -5.7670\n",
      "    - New mask: 34 features, Fitness: -6.6283\n",
      "    - New mask: 34 features, Fitness: -5.8386\n",
      "    - New mask: 27 features, Fitness: -3.4491\n",
      "    - New mask: 34 features, Fitness: -6.0071\n",
      "    - New mask: 37 features, Fitness: -9.1453\n",
      "    - New mask: 34 features, Fitness: -3.3179\n",
      "    - New mask: 30 features, Fitness: -2.8481\n",
      "    - New mask: 36 features, Fitness: -4.8507\n",
      "    - New mask: 36 features, Fitness: -4.3450\n",
      "    - New mask: 31 features, Fitness: -3.2921\n",
      "    - New mask: 33 features, Fitness: -3.6936\n",
      "    - New mask: 30 features, Fitness: -3.1688\n",
      "    - New mask: 36 features, Fitness: -4.9970\n",
      "    - New mask: 34 features, Fitness: -4.2496\n",
      "    - New mask: 32 features, Fitness: -3.0926\n",
      "    - New mask: 34 features, Fitness: -3.5570\n",
      "    - New mask: 35 features, Fitness: -4.3844\n",
      "    - New mask: 34 features, Fitness: -3.7964\n",
      "    - New mask: 33 features, Fitness: -4.3612\n",
      "    - New mask: 33 features, Fitness: -3.4960\n",
      "    - New mask: 31 features, Fitness: -3.0684\n",
      "    - New mask: 33 features, Fitness: -4.5076\n",
      "    - New mask: 35 features, Fitness: -4.4129\n",
      "    - New mask: 30 features, Fitness: -2.3746\n",
      "    - New mask: 32 features, Fitness: -2.8427\n",
      "    - New mask: 35 features, Fitness: -6.3492\n",
      "    - New mask: 34 features, Fitness: -5.9865\n",
      "    - New mask: 35 features, Fitness: -6.2689\n",
      "    - New mask: 33 features, Fitness: -5.7599\n",
      "    - New mask: 34 features, Fitness: -6.3384\n",
      "    - New mask: 33 features, Fitness: -5.1682\n",
      "    - New mask: 34 features, Fitness: -5.7010\n",
      "    - New mask: 37 features, Fitness: -7.7965\n",
      "    - New mask: 32 features, Fitness: -5.2275\n",
      "    - New mask: 31 features, Fitness: -4.5126\n",
      "    - New mask: 35 features, Fitness: -6.8081\n",
      "    - New mask: 32 features, Fitness: -5.4994\n",
      "    - New mask: 34 features, Fitness: -6.6314\n",
      "    - New mask: 35 features, Fitness: -6.1947\n",
      "    - New mask: 31 features, Fitness: -4.9141\n",
      "    - New mask: 38 features, Fitness: -9.0081\n",
      "    - New mask: 29 features, Fitness: -3.6901\n",
      "    - New mask: 32 features, Fitness: -5.1954\n",
      "    - New mask: 36 features, Fitness: -7.2118\n",
      "    - New mask: 33 features, Fitness: -5.9980\n",
      "    - New mask: 34 features, Fitness: -5.7059\n",
      "    - New mask: 34 features, Fitness: -5.3208\n",
      "    - New mask: 35 features, Fitness: -5.6187\n",
      "    - New mask: 34 features, Fitness: -4.8092\n",
      "    - New mask: 35 features, Fitness: -5.2998\n",
      "    - New mask: 31 features, Fitness: -3.8858\n",
      "    - New mask: 36 features, Fitness: -5.5460\n",
      "    - New mask: 35 features, Fitness: -5.5101\n",
      "    - New mask: 32 features, Fitness: -4.8852\n",
      "    - New mask: 32 features, Fitness: -4.6841\n",
      "    - New mask: 33 features, Fitness: -5.0021\n",
      "    - New mask: 35 features, Fitness: -5.0452\n",
      "    - New mask: 34 features, Fitness: -5.8649\n",
      "    - New mask: 34 features, Fitness: -5.7310\n",
      "    - New mask: 35 features, Fitness: -5.3746\n",
      "    - New mask: 33 features, Fitness: -4.5248\n",
      "    - New mask: 33 features, Fitness: -5.1862\n",
      "    - New mask: 33 features, Fitness: -5.3613\n",
      "    - New mask: 32 features, Fitness: -3.9246\n",
      "    - New mask: 31 features, Fitness: -4.5073\n",
      "    - New mask: 34 features, Fitness: -2.2931\n",
      "    - New mask: 35 features, Fitness: -3.2147\n",
      "    - New mask: 34 features, Fitness: -2.3184\n",
      "    - New mask: 33 features, Fitness: -2.6386\n",
      "    - New mask: 34 features, Fitness: -2.4872\n",
      "    - New mask: 32 features, Fitness: -1.5795\n",
      "    - New mask: 35 features, Fitness: -2.4890\n",
      "    - New mask: 33 features, Fitness: -2.2590\n",
      "    - New mask: 33 features, Fitness: -2.0631\n",
      "    - New mask: 33 features, Fitness: -2.2177\n",
      "    - New mask: 35 features, Fitness: -2.8104\n",
      "    - New mask: 34 features, Fitness: -2.3816\n",
      "    - New mask: 36 features, Fitness: -3.4179\n",
      "    - New mask: 32 features, Fitness: -2.0741\n",
      "    - New mask: 33 features, Fitness: -2.0944\n",
      "    - New mask: 35 features, Fitness: -3.0218\n",
      "    - New mask: 37 features, Fitness: -3.2212\n",
      "    - New mask: 37 features, Fitness: -3.9921\n",
      "    - New mask: 37 features, Fitness: -3.2292\n",
      "    - New mask: 36 features, Fitness: -3.4413\n",
      "=== End of Round 10: Vote mask selects 38 features (rho: 0.48)\n",
      "    Indices: [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 11 ================\n",
      "  Adaptive rho for this round: 0.52\n",
      "    - New mask: 30 features, Fitness: -3.2396\n",
      "    - New mask: 34 features, Fitness: -4.0556\n",
      "    - New mask: 31 features, Fitness: -3.7322\n",
      "    - New mask: 34 features, Fitness: -4.2622\n",
      "    - New mask: 37 features, Fitness: -4.9304\n",
      "    - New mask: 30 features, Fitness: -2.5830\n",
      "    - New mask: 33 features, Fitness: -4.6067\n",
      "    - New mask: 30 features, Fitness: -3.3935\n",
      "    - New mask: 29 features, Fitness: -2.6994\n",
      "    - New mask: 31 features, Fitness: -3.0599\n",
      "    - New mask: 33 features, Fitness: -3.5601\n",
      "    - New mask: 32 features, Fitness: -3.5150\n",
      "    - New mask: 33 features, Fitness: -3.3591\n",
      "    - New mask: 33 features, Fitness: -3.3068\n",
      "    - New mask: 30 features, Fitness: -3.6330\n",
      "    - New mask: 33 features, Fitness: -3.4283\n",
      "    - New mask: 36 features, Fitness: -4.5725\n",
      "    - New mask: 37 features, Fitness: -4.7768\n",
      "    - New mask: 29 features, Fitness: -2.5479\n",
      "    - New mask: 36 features, Fitness: -5.3336\n",
      "    - New mask: 32 features, Fitness: -2.9580\n",
      "    - New mask: 34 features, Fitness: -3.4952\n",
      "    - New mask: 30 features, Fitness: -2.5570\n",
      "    - New mask: 33 features, Fitness: -2.9880\n",
      "    - New mask: 32 features, Fitness: -3.4140\n",
      "    - New mask: 31 features, Fitness: -2.9406\n",
      "    - New mask: 36 features, Fitness: -4.2999\n",
      "    - New mask: 31 features, Fitness: -2.3977\n",
      "    - New mask: 33 features, Fitness: -3.2484\n",
      "    - New mask: 33 features, Fitness: -3.5586\n",
      "    - New mask: 37 features, Fitness: -4.6240\n",
      "    - New mask: 34 features, Fitness: -4.1239\n",
      "    - New mask: 33 features, Fitness: -3.2482\n",
      "    - New mask: 33 features, Fitness: -3.3129\n",
      "    - New mask: 31 features, Fitness: -2.6167\n",
      "    - New mask: 31 features, Fitness: -2.7908\n",
      "    - New mask: 35 features, Fitness: -4.6411\n",
      "    - New mask: 33 features, Fitness: -3.0203\n",
      "    - New mask: 34 features, Fitness: -3.5136\n",
      "    - New mask: 33 features, Fitness: -2.8582\n",
      "    - New mask: 35 features, Fitness: -3.7179\n",
      "    - New mask: 38 features, Fitness: -4.3334\n",
      "    - New mask: 36 features, Fitness: -3.7003\n",
      "    - New mask: 34 features, Fitness: -3.0706\n",
      "    - New mask: 34 features, Fitness: -2.9436\n",
      "    - New mask: 35 features, Fitness: -3.6005\n",
      "    - New mask: 37 features, Fitness: -3.8110\n",
      "    - New mask: 34 features, Fitness: -2.9617\n",
      "    - New mask: 33 features, Fitness: -2.7771\n",
      "    - New mask: 37 features, Fitness: -4.4790\n",
      "    - New mask: 36 features, Fitness: -3.8030\n",
      "    - New mask: 35 features, Fitness: -3.5118\n",
      "    - New mask: 33 features, Fitness: -2.6796\n",
      "    - New mask: 34 features, Fitness: -3.0544\n",
      "    - New mask: 34 features, Fitness: -3.4024\n",
      "    - New mask: 36 features, Fitness: -3.8202\n",
      "    - New mask: 37 features, Fitness: -4.2048\n",
      "    - New mask: 33 features, Fitness: -3.0136\n",
      "    - New mask: 34 features, Fitness: -2.7376\n",
      "    - New mask: 36 features, Fitness: -3.8493\n",
      "    - New mask: 33 features, Fitness: 0.6094\n",
      "    - New mask: 37 features, Fitness: -0.5109\n",
      "    - New mask: 34 features, Fitness: 0.3605\n",
      "    - New mask: 32 features, Fitness: 1.0023\n",
      "    - New mask: 32 features, Fitness: 1.1461\n",
      "    - New mask: 32 features, Fitness: 0.7399\n",
      "    - New mask: 30 features, Fitness: 0.9466\n",
      "    - New mask: 34 features, Fitness: 0.3351\n",
      "    - New mask: 33 features, Fitness: 0.5158\n",
      "    - New mask: 34 features, Fitness: 0.6732\n",
      "    - New mask: 30 features, Fitness: 0.7680\n",
      "    - New mask: 34 features, Fitness: 0.3108\n",
      "    - New mask: 33 features, Fitness: 0.6797\n",
      "    - New mask: 35 features, Fitness: 0.0134\n",
      "    - New mask: 33 features, Fitness: 0.5381\n",
      "    - New mask: 33 features, Fitness: 0.4167\n",
      "    - New mask: 35 features, Fitness: 0.1885\n",
      "    - New mask: 33 features, Fitness: 0.7781\n",
      "    - New mask: 35 features, Fitness: -0.2275\n",
      "    - New mask: 34 features, Fitness: 0.7028\n",
      "    - New mask: 31 features, Fitness: 0.7535\n",
      "    - New mask: 32 features, Fitness: -0.1220\n",
      "    - New mask: 34 features, Fitness: -1.2214\n",
      "    - New mask: 32 features, Fitness: 0.2558\n",
      "    - New mask: 28 features, Fitness: 0.8016\n",
      "    - New mask: 33 features, Fitness: 0.7732\n",
      "    - New mask: 33 features, Fitness: -0.3999\n",
      "    - New mask: 35 features, Fitness: -0.6856\n",
      "    - New mask: 36 features, Fitness: -1.3964\n",
      "    - New mask: 32 features, Fitness: 0.4004\n",
      "    - New mask: 29 features, Fitness: 0.6107\n",
      "    - New mask: 32 features, Fitness: -1.6257\n",
      "    - New mask: 33 features, Fitness: -0.5495\n",
      "    - New mask: 34 features, Fitness: -0.4000\n",
      "    - New mask: 35 features, Fitness: -0.6390\n",
      "    - New mask: 33 features, Fitness: -0.7086\n",
      "    - New mask: 34 features, Fitness: -0.8798\n",
      "    - New mask: 32 features, Fitness: -0.2475\n",
      "    - New mask: 36 features, Fitness: -0.8274\n",
      "    - New mask: 33 features, Fitness: -0.9527\n",
      "    - New mask: 35 features, Fitness: -6.8844\n",
      "    - New mask: 32 features, Fitness: -4.5064\n",
      "    - New mask: 31 features, Fitness: -4.7369\n",
      "    - New mask: 32 features, Fitness: -5.3402\n",
      "    - New mask: 33 features, Fitness: -6.7178\n",
      "    - New mask: 32 features, Fitness: -6.1790\n",
      "    - New mask: 33 features, Fitness: -5.9213\n",
      "    - New mask: 31 features, Fitness: -5.3745\n",
      "    - New mask: 33 features, Fitness: -6.3085\n",
      "    - New mask: 34 features, Fitness: -6.9168\n",
      "    - New mask: 34 features, Fitness: -8.4373\n",
      "    - New mask: 33 features, Fitness: -6.0629\n",
      "    - New mask: 35 features, Fitness: -6.7968\n",
      "    - New mask: 31 features, Fitness: -5.4689\n",
      "    - New mask: 31 features, Fitness: -4.9883\n",
      "    - New mask: 33 features, Fitness: -5.5278\n",
      "    - New mask: 36 features, Fitness: -7.3110\n",
      "    - New mask: 33 features, Fitness: -5.6645\n",
      "    - New mask: 33 features, Fitness: -6.2941\n",
      "    - New mask: 36 features, Fitness: -8.4388\n",
      "    - New mask: 30 features, Fitness: -2.2398\n",
      "    - New mask: 33 features, Fitness: -3.1759\n",
      "    - New mask: 32 features, Fitness: -3.5182\n",
      "    - New mask: 35 features, Fitness: -4.2230\n",
      "    - New mask: 33 features, Fitness: -3.8591\n",
      "    - New mask: 32 features, Fitness: -3.1010\n",
      "    - New mask: 32 features, Fitness: -3.4863\n",
      "    - New mask: 32 features, Fitness: -3.7895\n",
      "    - New mask: 34 features, Fitness: -4.0173\n",
      "    - New mask: 32 features, Fitness: -3.2208\n",
      "    - New mask: 37 features, Fitness: -4.9384\n",
      "    - New mask: 34 features, Fitness: -4.1516\n",
      "    - New mask: 33 features, Fitness: -3.1574\n",
      "    - New mask: 35 features, Fitness: -4.9458\n",
      "    - New mask: 34 features, Fitness: -4.1330\n",
      "    - New mask: 31 features, Fitness: -3.2325\n",
      "    - New mask: 31 features, Fitness: -3.4075\n",
      "    - New mask: 32 features, Fitness: -2.8903\n",
      "    - New mask: 33 features, Fitness: -3.1250\n",
      "    - New mask: 32 features, Fitness: -2.7484\n",
      "    - New mask: 36 features, Fitness: -7.9941\n",
      "    - New mask: 32 features, Fitness: -5.0564\n",
      "    - New mask: 33 features, Fitness: -5.0879\n",
      "    - New mask: 32 features, Fitness: -4.5295\n",
      "    - New mask: 31 features, Fitness: -4.7444\n",
      "    - New mask: 34 features, Fitness: -5.4357\n",
      "    - New mask: 32 features, Fitness: -5.4145\n",
      "    - New mask: 33 features, Fitness: -5.8816\n",
      "    - New mask: 30 features, Fitness: -3.8962\n",
      "    - New mask: 31 features, Fitness: -5.0140\n",
      "    - New mask: 31 features, Fitness: -4.3114\n",
      "    - New mask: 35 features, Fitness: -6.8699\n",
      "    - New mask: 33 features, Fitness: -6.0929\n",
      "    - New mask: 31 features, Fitness: -4.2152\n",
      "    - New mask: 30 features, Fitness: -4.3478\n",
      "    - New mask: 35 features, Fitness: -6.6326\n",
      "    - New mask: 34 features, Fitness: -5.9291\n",
      "    - New mask: 31 features, Fitness: -4.7828\n",
      "    - New mask: 32 features, Fitness: -4.9541\n",
      "    - New mask: 33 features, Fitness: -5.4920\n",
      "    - New mask: 35 features, Fitness: -5.3491\n",
      "    - New mask: 32 features, Fitness: -4.5618\n",
      "    - New mask: 32 features, Fitness: -4.5703\n",
      "    - New mask: 33 features, Fitness: -4.5477\n",
      "    - New mask: 35 features, Fitness: -5.9660\n",
      "    - New mask: 33 features, Fitness: -4.5376\n",
      "    - New mask: 36 features, Fitness: -6.3616\n",
      "    - New mask: 33 features, Fitness: -4.4525\n",
      "    - New mask: 31 features, Fitness: -4.5298\n",
      "    - New mask: 35 features, Fitness: -5.7547\n",
      "    - New mask: 33 features, Fitness: -4.6223\n",
      "    - New mask: 32 features, Fitness: -4.2398\n",
      "    - New mask: 34 features, Fitness: -5.0200\n",
      "    - New mask: 35 features, Fitness: -5.7924\n",
      "    - New mask: 32 features, Fitness: -3.8591\n",
      "    - New mask: 35 features, Fitness: -5.5364\n",
      "    - New mask: 35 features, Fitness: -5.1428\n",
      "    - New mask: 33 features, Fitness: -4.4784\n",
      "    - New mask: 35 features, Fitness: -5.2790\n",
      "    - New mask: 33 features, Fitness: -4.3116\n",
      "    - New mask: 35 features, Fitness: -2.7778\n",
      "    - New mask: 37 features, Fitness: -3.8933\n",
      "    - New mask: 37 features, Fitness: -3.0981\n",
      "    - New mask: 33 features, Fitness: -2.5889\n",
      "    - New mask: 34 features, Fitness: -2.2931\n",
      "    - New mask: 36 features, Fitness: -2.9519\n",
      "    - New mask: 33 features, Fitness: -1.9892\n",
      "    - New mask: 33 features, Fitness: -2.3152\n",
      "    - New mask: 31 features, Fitness: -1.4249\n",
      "    - New mask: 33 features, Fitness: -1.9092\n",
      "    - New mask: 35 features, Fitness: -2.7542\n",
      "    - New mask: 33 features, Fitness: -1.9259\n",
      "    - New mask: 34 features, Fitness: -2.6065\n",
      "    - New mask: 30 features, Fitness: -1.3333\n",
      "    - New mask: 33 features, Fitness: -2.3100\n",
      "    - New mask: 36 features, Fitness: -2.9913\n",
      "    - New mask: 34 features, Fitness: -2.6208\n",
      "    - New mask: 36 features, Fitness: -2.8839\n",
      "    - New mask: 34 features, Fitness: -2.3278\n",
      "    - New mask: 34 features, Fitness: -2.3961\n",
      "=== End of Round 11: Vote mask selects 35 features (rho: 0.52)\n",
      "    Indices: [0, 2, 3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 12 ================\n",
      "  Adaptive rho for this round: 0.55\n",
      "    - New mask: 32 features, Fitness: -3.7878\n",
      "    - New mask: 31 features, Fitness: -3.2689\n",
      "    - New mask: 31 features, Fitness: -3.7377\n",
      "    - New mask: 32 features, Fitness: -3.3833\n",
      "    - New mask: 34 features, Fitness: -4.3796\n",
      "    - New mask: 30 features, Fitness: -2.9942\n",
      "    - New mask: 38 features, Fitness: -5.7495\n",
      "    - New mask: 29 features, Fitness: -2.5575\n",
      "    - New mask: 33 features, Fitness: -3.8839\n",
      "    - New mask: 34 features, Fitness: -4.3040\n",
      "    - New mask: 32 features, Fitness: -3.4659\n",
      "    - New mask: 27 features, Fitness: -1.8735\n",
      "    - New mask: 29 features, Fitness: -2.8462\n",
      "    - New mask: 33 features, Fitness: -3.9698\n",
      "    - New mask: 30 features, Fitness: -2.4816\n",
      "    - New mask: 29 features, Fitness: -2.6948\n",
      "    - New mask: 33 features, Fitness: -3.6699\n",
      "    - New mask: 35 features, Fitness: -4.4091\n",
      "    - New mask: 30 features, Fitness: -2.7890\n",
      "    - New mask: 32 features, Fitness: -3.2787\n",
      "    - New mask: 34 features, Fitness: -3.8633\n",
      "    - New mask: 36 features, Fitness: -4.5459\n",
      "    - New mask: 30 features, Fitness: -2.2744\n",
      "    - New mask: 33 features, Fitness: -3.2270\n",
      "    - New mask: 32 features, Fitness: -3.1468\n",
      "    - New mask: 31 features, Fitness: -2.5743\n",
      "    - New mask: 33 features, Fitness: -2.9019\n",
      "    - New mask: 34 features, Fitness: -3.3148\n",
      "    - New mask: 32 features, Fitness: -2.7411\n",
      "    - New mask: 35 features, Fitness: -3.8200\n",
      "    - New mask: 34 features, Fitness: -3.5327\n",
      "    - New mask: 34 features, Fitness: -3.6736\n",
      "    - New mask: 33 features, Fitness: -3.2320\n",
      "    - New mask: 32 features, Fitness: -2.7684\n",
      "    - New mask: 32 features, Fitness: -2.7857\n",
      "    - New mask: 32 features, Fitness: -3.2066\n",
      "    - New mask: 34 features, Fitness: -4.2381\n",
      "    - New mask: 33 features, Fitness: -3.0030\n",
      "    - New mask: 34 features, Fitness: -3.7453\n",
      "    - New mask: 33 features, Fitness: -2.8623\n",
      "    - New mask: 30 features, Fitness: -1.6981\n",
      "    - New mask: 35 features, Fitness: -3.2171\n",
      "    - New mask: 34 features, Fitness: -2.9177\n",
      "    - New mask: 35 features, Fitness: -3.2319\n",
      "    - New mask: 36 features, Fitness: -3.9037\n",
      "    - New mask: 35 features, Fitness: -3.8226\n",
      "    - New mask: 33 features, Fitness: -3.0633\n",
      "    - New mask: 33 features, Fitness: -2.7003\n",
      "    - New mask: 32 features, Fitness: -2.6227\n",
      "    - New mask: 34 features, Fitness: -2.5562\n",
      "    - New mask: 36 features, Fitness: -3.7206\n",
      "    - New mask: 34 features, Fitness: -3.5288\n",
      "    - New mask: 29 features, Fitness: -1.7352\n",
      "    - New mask: 35 features, Fitness: -3.3259\n",
      "    - New mask: 34 features, Fitness: -2.9831\n",
      "    - New mask: 34 features, Fitness: -2.9442\n",
      "    - New mask: 34 features, Fitness: -3.3546\n",
      "    - New mask: 34 features, Fitness: -3.4883\n",
      "    - New mask: 35 features, Fitness: -3.5657\n",
      "    - New mask: 32 features, Fitness: -2.6102\n",
      "    - New mask: 31 features, Fitness: 1.0324\n",
      "    - New mask: 38 features, Fitness: -0.6835\n",
      "    - New mask: 32 features, Fitness: 0.9010\n",
      "    - New mask: 31 features, Fitness: 1.0888\n",
      "    - New mask: 34 features, Fitness: 0.7261\n",
      "    - New mask: 36 features, Fitness: 0.2296\n",
      "    - New mask: 33 features, Fitness: 0.3068\n",
      "    - New mask: 35 features, Fitness: 0.2628\n",
      "    - New mask: 34 features, Fitness: 0.1097\n",
      "    - New mask: 36 features, Fitness: 0.1438\n",
      "    - New mask: 33 features, Fitness: 0.7615\n",
      "    - New mask: 32 features, Fitness: 0.8045\n",
      "    - New mask: 29 features, Fitness: 1.4144\n",
      "    - New mask: 31 features, Fitness: 0.9391\n",
      "    - New mask: 34 features, Fitness: 0.6453\n",
      "    - New mask: 35 features, Fitness: 0.0661\n",
      "    - New mask: 33 features, Fitness: 0.4943\n",
      "    - New mask: 33 features, Fitness: 0.9073\n",
      "    - New mask: 36 features, Fitness: -0.1174\n",
      "    - New mask: 32 features, Fitness: 1.0484\n",
      "    - New mask: 36 features, Fitness: -1.2331\n",
      "    - New mask: 32 features, Fitness: -0.8979\n",
      "    - New mask: 33 features, Fitness: -0.8257\n",
      "    - New mask: 34 features, Fitness: -0.7978\n",
      "    - New mask: 29 features, Fitness: 0.5130\n",
      "    - New mask: 33 features, Fitness: -0.1989\n",
      "    - New mask: 27 features, Fitness: 0.8900\n",
      "    - New mask: 31 features, Fitness: 0.1906\n",
      "    - New mask: 30 features, Fitness: -0.2432\n",
      "    - New mask: 30 features, Fitness: 0.6630\n",
      "    - New mask: 29 features, Fitness: 0.1383\n",
      "    - New mask: 28 features, Fitness: 0.0123\n",
      "    - New mask: 34 features, Fitness: -0.7420\n",
      "    - New mask: 31 features, Fitness: 0.0640\n",
      "    - New mask: 36 features, Fitness: -2.0251\n",
      "    - New mask: 29 features, Fitness: 0.4718\n",
      "    - New mask: 29 features, Fitness: 0.4276\n",
      "    - New mask: 29 features, Fitness: 0.4456\n",
      "    - New mask: 33 features, Fitness: -0.1700\n",
      "    - New mask: 27 features, Fitness: 0.1868\n",
      "    - New mask: 32 features, Fitness: -5.6538\n",
      "    - New mask: 33 features, Fitness: -5.9114\n",
      "    - New mask: 35 features, Fitness: -6.8775\n",
      "    - New mask: 33 features, Fitness: -5.1822\n",
      "    - New mask: 32 features, Fitness: -5.0542\n",
      "    - New mask: 34 features, Fitness: -6.6894\n",
      "    - New mask: 37 features, Fitness: -7.7983\n",
      "    - New mask: 31 features, Fitness: -4.7182\n",
      "    - New mask: 35 features, Fitness: -7.2473\n",
      "    - New mask: 34 features, Fitness: -6.2098\n",
      "    - New mask: 32 features, Fitness: -5.6733\n",
      "    - New mask: 31 features, Fitness: -4.3362\n",
      "    - New mask: 33 features, Fitness: -5.9262\n",
      "    - New mask: 30 features, Fitness: -4.5009\n",
      "    - New mask: 30 features, Fitness: -3.4013\n",
      "    - New mask: 35 features, Fitness: -7.3459\n",
      "    - New mask: 34 features, Fitness: -5.5437\n",
      "    - New mask: 32 features, Fitness: -4.7787\n",
      "    - New mask: 33 features, Fitness: -5.1367\n",
      "    - New mask: 32 features, Fitness: -6.4853\n",
      "    - New mask: 33 features, Fitness: -3.1128\n",
      "    - New mask: 33 features, Fitness: -2.8799\n",
      "    - New mask: 33 features, Fitness: -3.0718\n",
      "    - New mask: 36 features, Fitness: -4.3675\n",
      "    - New mask: 29 features, Fitness: -2.4831\n",
      "    - New mask: 32 features, Fitness: -3.1700\n",
      "    - New mask: 30 features, Fitness: -2.9687\n",
      "    - New mask: 35 features, Fitness: -4.2122\n",
      "    - New mask: 34 features, Fitness: -3.9472\n",
      "    - New mask: 30 features, Fitness: -2.5013\n",
      "    - New mask: 37 features, Fitness: -4.8481\n",
      "    - New mask: 33 features, Fitness: -2.9343\n",
      "    - New mask: 32 features, Fitness: -2.9663\n",
      "    - New mask: 31 features, Fitness: -3.2659\n",
      "    - New mask: 32 features, Fitness: -2.9415\n",
      "    - New mask: 31 features, Fitness: -3.2215\n",
      "    - New mask: 33 features, Fitness: -3.3196\n",
      "    - New mask: 32 features, Fitness: -3.7052\n",
      "    - New mask: 33 features, Fitness: -3.4173\n",
      "    - New mask: 33 features, Fitness: -3.1560\n",
      "    - New mask: 35 features, Fitness: -7.3951\n",
      "    - New mask: 33 features, Fitness: -5.3825\n",
      "    - New mask: 32 features, Fitness: -5.6787\n",
      "    - New mask: 32 features, Fitness: -4.5318\n",
      "    - New mask: 33 features, Fitness: -5.3762\n",
      "    - New mask: 33 features, Fitness: -5.0437\n",
      "    - New mask: 31 features, Fitness: -4.3037\n",
      "    - New mask: 32 features, Fitness: -4.9198\n",
      "    - New mask: 29 features, Fitness: -3.5890\n",
      "    - New mask: 34 features, Fitness: -6.1362\n",
      "    - New mask: 35 features, Fitness: -6.6453\n",
      "    - New mask: 33 features, Fitness: -5.7222\n",
      "    - New mask: 34 features, Fitness: -5.8056\n",
      "    - New mask: 32 features, Fitness: -6.2992\n",
      "    - New mask: 28 features, Fitness: -3.6172\n",
      "    - New mask: 33 features, Fitness: -5.1475\n",
      "    - New mask: 32 features, Fitness: -4.7473\n",
      "    - New mask: 35 features, Fitness: -6.8621\n",
      "    - New mask: 31 features, Fitness: -4.6169\n",
      "    - New mask: 33 features, Fitness: -6.5772\n",
      "    - New mask: 32 features, Fitness: -3.7487\n",
      "    - New mask: 29 features, Fitness: -3.5155\n",
      "    - New mask: 36 features, Fitness: -5.6666\n",
      "    - New mask: 31 features, Fitness: -3.5567\n",
      "    - New mask: 32 features, Fitness: -4.6572\n",
      "    - New mask: 33 features, Fitness: -4.4992\n",
      "    - New mask: 34 features, Fitness: -5.2506\n",
      "    - New mask: 32 features, Fitness: -3.9482\n",
      "    - New mask: 32 features, Fitness: -4.7907\n",
      "    - New mask: 35 features, Fitness: -5.1084\n",
      "    - New mask: 34 features, Fitness: -4.9860\n",
      "    - New mask: 35 features, Fitness: -5.0341\n",
      "    - New mask: 33 features, Fitness: -4.3857\n",
      "    - New mask: 34 features, Fitness: -5.0315\n",
      "    - New mask: 32 features, Fitness: -3.8877\n",
      "    - New mask: 32 features, Fitness: -4.2444\n",
      "    - New mask: 36 features, Fitness: -5.7025\n",
      "    - New mask: 33 features, Fitness: -4.6367\n",
      "    - New mask: 35 features, Fitness: -5.0335\n",
      "    - New mask: 31 features, Fitness: -3.4359\n",
      "    - New mask: 32 features, Fitness: -1.5573\n",
      "    - New mask: 34 features, Fitness: -2.7982\n",
      "    - New mask: 30 features, Fitness: -1.3590\n",
      "    - New mask: 33 features, Fitness: -1.9655\n",
      "    - New mask: 32 features, Fitness: -2.2760\n",
      "    - New mask: 35 features, Fitness: -2.3839\n",
      "    - New mask: 33 features, Fitness: -2.1868\n",
      "    - New mask: 31 features, Fitness: -1.3569\n",
      "    - New mask: 34 features, Fitness: -2.1570\n",
      "    - New mask: 32 features, Fitness: -1.7780\n",
      "    - New mask: 36 features, Fitness: -2.8512\n",
      "    - New mask: 31 features, Fitness: -1.2202\n",
      "    - New mask: 30 features, Fitness: -1.2648\n",
      "    - New mask: 31 features, Fitness: -1.8297\n",
      "    - New mask: 33 features, Fitness: -2.1003\n",
      "    - New mask: 28 features, Fitness: -1.1590\n",
      "    - New mask: 34 features, Fitness: -2.6177\n",
      "    - New mask: 36 features, Fitness: -3.2006\n",
      "    - New mask: 33 features, Fitness: -2.0527\n",
      "    - New mask: 33 features, Fitness: -1.8264\n",
      "=== End of Round 12: Vote mask selects 35 features (rho: 0.55)\n",
      "    Indices: [0, 2, 3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 13 ================\n",
      "  Adaptive rho for this round: 0.58\n",
      "    - New mask: 32 features, Fitness: -4.1186\n",
      "    - New mask: 30 features, Fitness: -2.8959\n",
      "    - New mask: 28 features, Fitness: -2.9232\n",
      "    - New mask: 31 features, Fitness: -3.1910\n",
      "    - New mask: 36 features, Fitness: -5.2359\n",
      "    - New mask: 31 features, Fitness: -3.2979\n",
      "    - New mask: 33 features, Fitness: -3.4845\n",
      "    - New mask: 31 features, Fitness: -3.2590\n",
      "    - New mask: 29 features, Fitness: -3.1586\n",
      "    - New mask: 32 features, Fitness: -3.9522\n",
      "    - New mask: 29 features, Fitness: -2.2336\n",
      "    - New mask: 26 features, Fitness: -1.5538\n",
      "    - New mask: 32 features, Fitness: -3.6899\n",
      "    - New mask: 32 features, Fitness: -3.2420\n",
      "    - New mask: 34 features, Fitness: -3.7809\n",
      "    - New mask: 32 features, Fitness: -3.7733\n",
      "    - New mask: 34 features, Fitness: -4.1769\n",
      "    - New mask: 32 features, Fitness: -2.9204\n",
      "    - New mask: 29 features, Fitness: -2.7729\n",
      "    - New mask: 32 features, Fitness: -3.0322\n",
      "    - New mask: 35 features, Fitness: -4.0914\n",
      "    - New mask: 32 features, Fitness: -3.1977\n",
      "    - New mask: 34 features, Fitness: -3.9446\n",
      "    - New mask: 31 features, Fitness: -2.3964\n",
      "    - New mask: 31 features, Fitness: -2.4646\n",
      "    - New mask: 31 features, Fitness: -2.5743\n",
      "    - New mask: 33 features, Fitness: -2.7930\n",
      "    - New mask: 31 features, Fitness: -2.8850\n",
      "    - New mask: 32 features, Fitness: -2.9791\n",
      "    - New mask: 34 features, Fitness: -3.6871\n",
      "    - New mask: 33 features, Fitness: -3.5512\n",
      "    - New mask: 33 features, Fitness: -3.4559\n",
      "    - New mask: 32 features, Fitness: -2.9533\n",
      "    - New mask: 32 features, Fitness: -3.1707\n",
      "    - New mask: 34 features, Fitness: -3.4120\n",
      "    - New mask: 31 features, Fitness: -3.1344\n",
      "    - New mask: 32 features, Fitness: -2.9938\n",
      "    - New mask: 33 features, Fitness: -3.5109\n",
      "    - New mask: 33 features, Fitness: -3.0359\n",
      "    - New mask: 28 features, Fitness: -1.7524\n",
      "    - New mask: 31 features, Fitness: -2.3944\n",
      "    - New mask: 34 features, Fitness: -2.6539\n",
      "    - New mask: 31 features, Fitness: -1.9355\n",
      "    - New mask: 32 features, Fitness: -2.7937\n",
      "    - New mask: 34 features, Fitness: -2.9203\n",
      "    - New mask: 33 features, Fitness: -2.9318\n",
      "    - New mask: 34 features, Fitness: -3.0334\n",
      "    - New mask: 33 features, Fitness: -2.6470\n",
      "    - New mask: 34 features, Fitness: -3.3797\n",
      "    - New mask: 35 features, Fitness: -2.9936\n",
      "    - New mask: 32 features, Fitness: -2.5007\n",
      "    - New mask: 30 features, Fitness: -2.2585\n",
      "    - New mask: 33 features, Fitness: -2.8441\n",
      "    - New mask: 34 features, Fitness: -2.8091\n",
      "    - New mask: 34 features, Fitness: -2.9578\n",
      "    - New mask: 32 features, Fitness: -2.0438\n",
      "    - New mask: 33 features, Fitness: -2.7614\n",
      "    - New mask: 32 features, Fitness: -2.5508\n",
      "    - New mask: 33 features, Fitness: -3.1105\n",
      "    - New mask: 33 features, Fitness: -2.3346\n",
      "    - New mask: 31 features, Fitness: 1.1950\n",
      "    - New mask: 33 features, Fitness: 0.7412\n",
      "    - New mask: 31 features, Fitness: 0.7716\n",
      "    - New mask: 29 features, Fitness: 1.3324\n",
      "    - New mask: 34 features, Fitness: 0.6290\n",
      "    - New mask: 33 features, Fitness: 0.3417\n",
      "    - New mask: 32 features, Fitness: 0.7183\n",
      "    - New mask: 35 features, Fitness: 0.0844\n",
      "    - New mask: 31 features, Fitness: 0.4999\n",
      "    - New mask: 31 features, Fitness: 0.4774\n",
      "    - New mask: 29 features, Fitness: 1.3064\n",
      "    - New mask: 32 features, Fitness: 0.6542\n",
      "    - New mask: 30 features, Fitness: 0.7753\n",
      "    - New mask: 33 features, Fitness: 0.2875\n",
      "    - New mask: 33 features, Fitness: 0.0359\n",
      "    - New mask: 33 features, Fitness: 0.4876\n",
      "    - New mask: 31 features, Fitness: 0.7592\n",
      "    - New mask: 29 features, Fitness: 1.1011\n",
      "    - New mask: 34 features, Fitness: 0.1955\n",
      "    - New mask: 32 features, Fitness: 0.8571\n",
      "    - New mask: 30 features, Fitness: -0.1396\n",
      "    - New mask: 31 features, Fitness: 0.0188\n",
      "    - New mask: 32 features, Fitness: -0.4675\n",
      "    - New mask: 31 features, Fitness: -0.1225\n",
      "    - New mask: 26 features, Fitness: 0.8145\n",
      "    - New mask: 30 features, Fitness: -0.1111\n",
      "    - New mask: 26 features, Fitness: 0.3610\n",
      "    - New mask: 31 features, Fitness: 0.0821\n",
      "    - New mask: 31 features, Fitness: -0.4319\n",
      "    - New mask: 29 features, Fitness: 0.7280\n",
      "    - New mask: 27 features, Fitness: 0.4219\n",
      "    - New mask: 26 features, Fitness: 0.8987\n",
      "    - New mask: 32 features, Fitness: -0.2821\n",
      "    - New mask: 35 features, Fitness: -1.5323\n",
      "    - New mask: 33 features, Fitness: -1.9702\n",
      "    - New mask: 26 features, Fitness: 0.7434\n",
      "    - New mask: 31 features, Fitness: -0.4780\n",
      "    - New mask: 31 features, Fitness: 0.1750\n",
      "    - New mask: 33 features, Fitness: -0.8448\n",
      "    - New mask: 29 features, Fitness: 0.1618\n",
      "    - New mask: 29 features, Fitness: -2.9551\n",
      "    - New mask: 34 features, Fitness: -5.4629\n",
      "    - New mask: 34 features, Fitness: -6.5917\n",
      "    - New mask: 34 features, Fitness: -6.2892\n",
      "    - New mask: 32 features, Fitness: -4.4949\n",
      "    - New mask: 33 features, Fitness: -6.1959\n",
      "    - New mask: 32 features, Fitness: -4.3868\n",
      "    - New mask: 33 features, Fitness: -5.5787\n",
      "    - New mask: 35 features, Fitness: -6.3742\n",
      "    - New mask: 35 features, Fitness: -6.8639\n",
      "    - New mask: 30 features, Fitness: -4.9018\n",
      "    - New mask: 34 features, Fitness: -6.6502\n",
      "    - New mask: 33 features, Fitness: -5.5377\n",
      "    - New mask: 31 features, Fitness: -4.8610\n",
      "    - New mask: 31 features, Fitness: -3.9913\n",
      "    - New mask: 32 features, Fitness: -5.4304\n",
      "    - New mask: 31 features, Fitness: -3.9913\n",
      "    - New mask: 31 features, Fitness: -3.8170\n",
      "    - New mask: 30 features, Fitness: -4.1873\n",
      "    - New mask: 34 features, Fitness: -6.2484\n",
      "    - New mask: 32 features, Fitness: -2.9901\n",
      "    - New mask: 32 features, Fitness: -2.9551\n",
      "    - New mask: 32 features, Fitness: -2.9028\n",
      "    - New mask: 34 features, Fitness: -3.9779\n",
      "    - New mask: 29 features, Fitness: -2.5803\n",
      "    - New mask: 31 features, Fitness: -2.6499\n",
      "    - New mask: 30 features, Fitness: -2.8407\n",
      "    - New mask: 32 features, Fitness: -2.5792\n",
      "    - New mask: 31 features, Fitness: -2.6067\n",
      "    - New mask: 33 features, Fitness: -3.0516\n",
      "    - New mask: 30 features, Fitness: -3.3507\n",
      "    - New mask: 33 features, Fitness: -3.4751\n",
      "    - New mask: 31 features, Fitness: -2.8667\n",
      "    - New mask: 29 features, Fitness: -2.4969\n",
      "    - New mask: 30 features, Fitness: -2.6138\n",
      "    - New mask: 30 features, Fitness: -3.1907\n",
      "    - New mask: 30 features, Fitness: -2.8349\n",
      "    - New mask: 31 features, Fitness: -2.9107\n",
      "    - New mask: 31 features, Fitness: -3.0661\n",
      "    - New mask: 27 features, Fitness: -2.0093\n",
      "    - New mask: 32 features, Fitness: -4.5835\n",
      "    - New mask: 33 features, Fitness: -5.7823\n",
      "    - New mask: 29 features, Fitness: -3.6410\n",
      "    - New mask: 32 features, Fitness: -4.2790\n",
      "    - New mask: 33 features, Fitness: -5.0722\n",
      "    - New mask: 32 features, Fitness: -4.7418\n",
      "    - New mask: 29 features, Fitness: -3.9775\n",
      "    - New mask: 33 features, Fitness: -5.2117\n",
      "    - New mask: 29 features, Fitness: -3.1490\n",
      "    - New mask: 33 features, Fitness: -5.1646\n",
      "    - New mask: 31 features, Fitness: -4.2243\n",
      "    - New mask: 37 features, Fitness: -8.0774\n",
      "    - New mask: 30 features, Fitness: -4.0923\n",
      "    - New mask: 34 features, Fitness: -6.1683\n",
      "    - New mask: 30 features, Fitness: -3.8882\n",
      "    - New mask: 29 features, Fitness: -3.5245\n",
      "    - New mask: 33 features, Fitness: -4.9490\n",
      "    - New mask: 34 features, Fitness: -6.3614\n",
      "    - New mask: 29 features, Fitness: -4.1172\n",
      "    - New mask: 31 features, Fitness: -4.4720\n",
      "    - New mask: 33 features, Fitness: -4.4644\n",
      "    - New mask: 34 features, Fitness: -5.3004\n",
      "    - New mask: 36 features, Fitness: -5.6260\n",
      "    - New mask: 32 features, Fitness: -3.9216\n",
      "    - New mask: 33 features, Fitness: -4.2251\n",
      "    - New mask: 35 features, Fitness: -5.0549\n",
      "    - New mask: 32 features, Fitness: -3.8375\n",
      "    - New mask: 31 features, Fitness: -3.4417\n",
      "    - New mask: 32 features, Fitness: -4.4890\n",
      "    - New mask: 32 features, Fitness: -4.0196\n",
      "    - New mask: 31 features, Fitness: -3.9043\n",
      "    - New mask: 34 features, Fitness: -4.7590\n",
      "    - New mask: 33 features, Fitness: -4.1464\n",
      "    - New mask: 33 features, Fitness: -4.7100\n",
      "    - New mask: 31 features, Fitness: -3.5830\n",
      "    - New mask: 33 features, Fitness: -4.5324\n",
      "    - New mask: 32 features, Fitness: -3.8535\n",
      "    - New mask: 31 features, Fitness: -3.5174\n",
      "    - New mask: 32 features, Fitness: -3.7635\n",
      "    - New mask: 32 features, Fitness: -3.8175\n",
      "    - New mask: 30 features, Fitness: -1.4451\n",
      "    - New mask: 31 features, Fitness: -1.9122\n",
      "    - New mask: 30 features, Fitness: -1.3537\n",
      "    - New mask: 32 features, Fitness: -1.8439\n",
      "    - New mask: 32 features, Fitness: -2.1225\n",
      "    - New mask: 30 features, Fitness: -1.5849\n",
      "    - New mask: 33 features, Fitness: -2.3438\n",
      "    - New mask: 29 features, Fitness: -1.1482\n",
      "    - New mask: 34 features, Fitness: -2.3270\n",
      "    - New mask: 35 features, Fitness: -2.4819\n",
      "    - New mask: 31 features, Fitness: -1.8338\n",
      "    - New mask: 31 features, Fitness: -1.7788\n",
      "    - New mask: 28 features, Fitness: -0.9797\n",
      "    - New mask: 29 features, Fitness: -1.4915\n",
      "    - New mask: 30 features, Fitness: -1.6428\n",
      "    - New mask: 28 features, Fitness: -1.2577\n",
      "    - New mask: 31 features, Fitness: -1.6704\n",
      "    - New mask: 31 features, Fitness: -1.8444\n",
      "    - New mask: 32 features, Fitness: -1.9980\n",
      "    - New mask: 32 features, Fitness: -1.9607\n",
      "=== End of Round 13: Vote mask selects 30 features (rho: 0.58)\n",
      "    Indices: [0, 2, 3, 7, 8, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 14 ================\n",
      "  Adaptive rho for this round: 0.61\n",
      "    - New mask: 30 features, Fitness: -2.9138\n",
      "    - New mask: 29 features, Fitness: -2.5641\n",
      "    - New mask: 30 features, Fitness: -2.7685\n",
      "    - New mask: 30 features, Fitness: -2.4740\n",
      "    - New mask: 29 features, Fitness: -2.1223\n",
      "    - New mask: 30 features, Fitness: -2.3637\n",
      "    - New mask: 29 features, Fitness: -2.3202\n",
      "    - New mask: 29 features, Fitness: -2.0850\n",
      "    - New mask: 25 features, Fitness: -1.3071\n",
      "    - New mask: 27 features, Fitness: -2.1515\n",
      "    - New mask: 28 features, Fitness: -2.2021\n",
      "    - New mask: 26 features, Fitness: -1.7227\n",
      "    - New mask: 29 features, Fitness: -2.2824\n",
      "    - New mask: 27 features, Fitness: -1.9001\n",
      "    - New mask: 28 features, Fitness: -2.0642\n",
      "    - New mask: 29 features, Fitness: -2.5243\n",
      "    - New mask: 29 features, Fitness: -2.4191\n",
      "    - New mask: 29 features, Fitness: -2.5275\n",
      "    - New mask: 29 features, Fitness: -2.4401\n",
      "    - New mask: 31 features, Fitness: -2.5675\n",
      "    - New mask: 32 features, Fitness: -2.9871\n",
      "    - New mask: 30 features, Fitness: -2.3299\n",
      "    - New mask: 29 features, Fitness: -2.2817\n",
      "    - New mask: 28 features, Fitness: -1.4513\n",
      "    - New mask: 29 features, Fitness: -2.1212\n",
      "    - New mask: 29 features, Fitness: -2.2271\n",
      "    - New mask: 30 features, Fitness: -2.2640\n",
      "    - New mask: 26 features, Fitness: -1.5672\n",
      "    - New mask: 28 features, Fitness: -1.8793\n",
      "    - New mask: 30 features, Fitness: -2.1207\n",
      "    - New mask: 29 features, Fitness: -2.1011\n",
      "    - New mask: 28 features, Fitness: -1.9835\n",
      "    - New mask: 29 features, Fitness: -1.9205\n",
      "    - New mask: 31 features, Fitness: -3.3252\n",
      "    - New mask: 28 features, Fitness: -1.4492\n",
      "    - New mask: 33 features, Fitness: -3.4123\n",
      "    - New mask: 30 features, Fitness: -2.5761\n",
      "    - New mask: 28 features, Fitness: -2.0081\n",
      "    - New mask: 30 features, Fitness: -2.6189\n",
      "    - New mask: 30 features, Fitness: -1.9537\n",
      "    - New mask: 34 features, Fitness: -2.9827\n",
      "    - New mask: 34 features, Fitness: -2.7406\n",
      "    - New mask: 31 features, Fitness: -1.9149\n",
      "    - New mask: 30 features, Fitness: -1.3991\n",
      "    - New mask: 32 features, Fitness: -2.4521\n",
      "    - New mask: 30 features, Fitness: -1.9990\n",
      "    - New mask: 29 features, Fitness: -1.2780\n",
      "    - New mask: 31 features, Fitness: -2.1166\n",
      "    - New mask: 32 features, Fitness: -2.0158\n",
      "    - New mask: 28 features, Fitness: -1.4837\n",
      "    - New mask: 30 features, Fitness: -1.8518\n",
      "    - New mask: 27 features, Fitness: -1.1138\n",
      "    - New mask: 31 features, Fitness: -1.8874\n",
      "    - New mask: 33 features, Fitness: -2.4066\n",
      "    - New mask: 31 features, Fitness: -2.2059\n",
      "    - New mask: 31 features, Fitness: -2.2894\n",
      "    - New mask: 31 features, Fitness: -2.8055\n",
      "    - New mask: 32 features, Fitness: -2.1952\n",
      "    - New mask: 32 features, Fitness: -3.1624\n",
      "    - New mask: 24 features, Fitness: -1.2639\n",
      "    - New mask: 30 features, Fitness: 1.4739\n",
      "    - New mask: 29 features, Fitness: 0.6011\n",
      "    - New mask: 32 features, Fitness: 0.5911\n",
      "    - New mask: 28 features, Fitness: 1.3785\n",
      "    - New mask: 30 features, Fitness: 1.2243\n",
      "    - New mask: 28 features, Fitness: 0.5147\n",
      "    - New mask: 30 features, Fitness: 0.3642\n",
      "    - New mask: 33 features, Fitness: 0.5301\n",
      "    - New mask: 26 features, Fitness: 1.0678\n",
      "    - New mask: 31 features, Fitness: 0.6283\n",
      "    - New mask: 30 features, Fitness: 1.0885\n",
      "    - New mask: 34 features, Fitness: 0.4015\n",
      "    - New mask: 31 features, Fitness: 0.5032\n",
      "    - New mask: 29 features, Fitness: 0.6052\n",
      "    - New mask: 29 features, Fitness: 0.7378\n",
      "    - New mask: 32 features, Fitness: 0.2729\n",
      "    - New mask: 32 features, Fitness: 0.4143\n",
      "    - New mask: 22 features, Fitness: 1.6427\n",
      "    - New mask: 30 features, Fitness: 0.7580\n",
      "    - New mask: 31 features, Fitness: 1.2550\n",
      "    - New mask: 26 features, Fitness: 0.9156\n",
      "    - New mask: 29 features, Fitness: 0.3739\n",
      "    - New mask: 26 features, Fitness: 0.8348\n",
      "    - New mask: 28 features, Fitness: 0.6306\n",
      "    - New mask: 25 features, Fitness: 0.8656\n",
      "    - New mask: 25 features, Fitness: 0.8174\n",
      "    - New mask: 27 features, Fitness: 0.5182\n",
      "    - New mask: 29 features, Fitness: 0.6220\n",
      "    - New mask: 28 features, Fitness: 0.4047\n",
      "    - New mask: 26 features, Fitness: 1.2393\n",
      "    - New mask: 32 features, Fitness: -0.4429\n",
      "    - New mask: 27 features, Fitness: -0.0468\n",
      "    - New mask: 33 features, Fitness: -0.3702\n",
      "    - New mask: 30 features, Fitness: 0.2748\n",
      "    - New mask: 34 features, Fitness: -0.9849\n",
      "    - New mask: 31 features, Fitness: -0.1059\n",
      "    - New mask: 25 features, Fitness: 0.4740\n",
      "    - New mask: 27 features, Fitness: 0.8859\n",
      "    - New mask: 28 features, Fitness: 0.4473\n",
      "    - New mask: 23 features, Fitness: 1.5252\n",
      "    - New mask: 29 features, Fitness: -2.9291\n",
      "    - New mask: 28 features, Fitness: -2.6054\n",
      "    - New mask: 29 features, Fitness: -2.8019\n",
      "    - New mask: 33 features, Fitness: -5.8367\n",
      "    - New mask: 31 features, Fitness: -3.9761\n",
      "    - New mask: 30 features, Fitness: -3.8818\n",
      "    - New mask: 29 features, Fitness: -2.9872\n",
      "    - New mask: 32 features, Fitness: -5.2500\n",
      "    - New mask: 30 features, Fitness: -3.5837\n",
      "    - New mask: 32 features, Fitness: -4.6709\n",
      "    - New mask: 29 features, Fitness: -3.2975\n",
      "    - New mask: 32 features, Fitness: -4.7480\n",
      "    - New mask: 30 features, Fitness: -3.1690\n",
      "    - New mask: 28 features, Fitness: -3.0217\n",
      "    - New mask: 28 features, Fitness: -3.7136\n",
      "    - New mask: 30 features, Fitness: -3.5521\n",
      "    - New mask: 26 features, Fitness: -1.4646\n",
      "    - New mask: 29 features, Fitness: -2.9560\n",
      "    - New mask: 30 features, Fitness: -4.3619\n",
      "    - New mask: 33 features, Fitness: -5.3824\n",
      "    - New mask: 30 features, Fitness: -2.3262\n",
      "    - New mask: 32 features, Fitness: -3.0729\n",
      "    - New mask: 30 features, Fitness: -2.0489\n",
      "    - New mask: 30 features, Fitness: -2.6653\n",
      "    - New mask: 26 features, Fitness: -1.7221\n",
      "    - New mask: 29 features, Fitness: -2.1191\n",
      "    - New mask: 30 features, Fitness: -2.5943\n",
      "    - New mask: 27 features, Fitness: -1.4301\n",
      "    - New mask: 30 features, Fitness: -2.2586\n",
      "    - New mask: 32 features, Fitness: -2.7941\n",
      "    - New mask: 27 features, Fitness: -2.3582\n",
      "    - New mask: 30 features, Fitness: -2.4512\n",
      "    - New mask: 26 features, Fitness: -1.9082\n",
      "    - New mask: 29 features, Fitness: -2.2312\n",
      "    - New mask: 29 features, Fitness: -2.0450\n",
      "    - New mask: 30 features, Fitness: -2.3069\n",
      "    - New mask: 26 features, Fitness: -1.6962\n",
      "    - New mask: 30 features, Fitness: -2.5302\n",
      "    - New mask: 29 features, Fitness: -2.0632\n",
      "    - New mask: 25 features, Fitness: -1.3573\n",
      "    - New mask: 28 features, Fitness: -3.9575\n",
      "    - New mask: 29 features, Fitness: -3.1819\n",
      "    - New mask: 28 features, Fitness: -2.8360\n",
      "    - New mask: 29 features, Fitness: -3.6858\n",
      "    - New mask: 28 features, Fitness: -2.7950\n",
      "    - New mask: 28 features, Fitness: -2.8794\n",
      "    - New mask: 27 features, Fitness: -2.5636\n",
      "    - New mask: 32 features, Fitness: -5.1709\n",
      "    - New mask: 30 features, Fitness: -3.4555\n",
      "    - New mask: 29 features, Fitness: -3.0299\n",
      "    - New mask: 31 features, Fitness: -4.0770\n",
      "    - New mask: 34 features, Fitness: -6.8403\n",
      "    - New mask: 29 features, Fitness: -3.6413\n",
      "    - New mask: 27 features, Fitness: -3.2996\n",
      "    - New mask: 27 features, Fitness: -2.2737\n",
      "    - New mask: 29 features, Fitness: -3.3612\n",
      "    - New mask: 30 features, Fitness: -3.6828\n",
      "    - New mask: 35 features, Fitness: -6.7790\n",
      "    - New mask: 28 features, Fitness: -3.3484\n",
      "    - New mask: 26 features, Fitness: -2.2845\n",
      "    - New mask: 33 features, Fitness: -4.2251\n",
      "    - New mask: 31 features, Fitness: -3.8620\n",
      "    - New mask: 31 features, Fitness: -3.8341\n",
      "    - New mask: 34 features, Fitness: -4.6535\n",
      "    - New mask: 31 features, Fitness: -3.6038\n",
      "    - New mask: 34 features, Fitness: -4.7763\n",
      "    - New mask: 30 features, Fitness: -2.8972\n",
      "    - New mask: 30 features, Fitness: -3.7466\n",
      "    - New mask: 31 features, Fitness: -3.6506\n",
      "    - New mask: 32 features, Fitness: -3.9832\n",
      "    - New mask: 30 features, Fitness: -3.2603\n",
      "    - New mask: 34 features, Fitness: -4.6296\n",
      "    - New mask: 31 features, Fitness: -3.4916\n",
      "    - New mask: 27 features, Fitness: -2.2822\n",
      "    - New mask: 27 features, Fitness: -1.9192\n",
      "    - New mask: 31 features, Fitness: -3.5791\n",
      "    - New mask: 30 features, Fitness: -3.2190\n",
      "    - New mask: 30 features, Fitness: -3.0390\n",
      "    - New mask: 33 features, Fitness: -4.0752\n",
      "    - New mask: 29 features, Fitness: -2.8542\n",
      "    - New mask: 32 features, Fitness: -1.8415\n",
      "    - New mask: 28 features, Fitness: -1.1193\n",
      "    - New mask: 32 features, Fitness: -2.1574\n",
      "    - New mask: 28 features, Fitness: -0.9775\n",
      "    - New mask: 31 features, Fitness: -1.7774\n",
      "    - New mask: 31 features, Fitness: -1.4872\n",
      "    - New mask: 31 features, Fitness: -1.7778\n",
      "    - New mask: 27 features, Fitness: -0.8320\n",
      "    - New mask: 29 features, Fitness: -1.0985\n",
      "    - New mask: 32 features, Fitness: -2.0758\n",
      "    - New mask: 29 features, Fitness: -1.2713\n",
      "    - New mask: 27 features, Fitness: -0.7739\n",
      "    - New mask: 28 features, Fitness: -0.9678\n",
      "    - New mask: 28 features, Fitness: -1.0350\n",
      "    - New mask: 29 features, Fitness: -1.1671\n",
      "    - New mask: 30 features, Fitness: -1.3746\n",
      "    - New mask: 28 features, Fitness: -0.8151\n",
      "    - New mask: 29 features, Fitness: -0.8197\n",
      "    - New mask: 29 features, Fitness: -1.1541\n",
      "    - New mask: 31 features, Fitness: -1.5000\n",
      "=== End of Round 14: Vote mask selects 28 features (rho: 0.61)\n",
      "    Indices: [0, 2, 3, 7, 8, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 15 ================\n",
      "  Adaptive rho for this round: 0.64\n",
      "    - New mask: 27 features, Fitness: -1.4623\n",
      "    - New mask: 27 features, Fitness: -1.7262\n",
      "    - New mask: 28 features, Fitness: -2.1856\n",
      "    - New mask: 31 features, Fitness: -2.7541\n",
      "    - New mask: 27 features, Fitness: -1.6837\n",
      "    - New mask: 29 features, Fitness: -2.1416\n",
      "    - New mask: 27 features, Fitness: -1.8348\n",
      "    - New mask: 27 features, Fitness: -1.5697\n",
      "    - New mask: 26 features, Fitness: -1.2589\n",
      "    - New mask: 28 features, Fitness: -2.0596\n",
      "    - New mask: 23 features, Fitness: -1.1538\n",
      "    - New mask: 27 features, Fitness: -1.9452\n",
      "    - New mask: 28 features, Fitness: -2.3456\n",
      "    - New mask: 26 features, Fitness: -1.4426\n",
      "    - New mask: 25 features, Fitness: -1.3078\n",
      "    - New mask: 30 features, Fitness: -2.4612\n",
      "    - New mask: 29 features, Fitness: -2.3175\n",
      "    - New mask: 26 features, Fitness: -1.5383\n",
      "    - New mask: 28 features, Fitness: -2.2121\n",
      "    - New mask: 29 features, Fitness: -2.5042\n",
      "    - New mask: 27 features, Fitness: -1.3837\n",
      "    - New mask: 28 features, Fitness: -1.6473\n",
      "    - New mask: 25 features, Fitness: -0.9910\n",
      "    - New mask: 29 features, Fitness: -1.8036\n",
      "    - New mask: 26 features, Fitness: -1.0280\n",
      "    - New mask: 26 features, Fitness: -1.4893\n",
      "    - New mask: 29 features, Fitness: -2.3451\n",
      "    - New mask: 26 features, Fitness: -1.1231\n",
      "    - New mask: 26 features, Fitness: -0.9686\n",
      "    - New mask: 26 features, Fitness: -1.2379\n",
      "    - New mask: 29 features, Fitness: -1.7972\n",
      "    - New mask: 28 features, Fitness: -1.6809\n",
      "    - New mask: 26 features, Fitness: -1.3623\n",
      "    - New mask: 31 features, Fitness: -2.6054\n",
      "    - New mask: 29 features, Fitness: -1.7985\n",
      "    - New mask: 27 features, Fitness: -1.5341\n",
      "    - New mask: 29 features, Fitness: -2.1145\n",
      "    - New mask: 28 features, Fitness: -1.6710\n",
      "    - New mask: 30 features, Fitness: -2.5434\n",
      "    - New mask: 29 features, Fitness: -1.7916\n",
      "    - New mask: 30 features, Fitness: -1.9201\n",
      "    - New mask: 30 features, Fitness: -1.9126\n",
      "    - New mask: 31 features, Fitness: -2.1331\n",
      "    - New mask: 28 features, Fitness: -1.5218\n",
      "    - New mask: 28 features, Fitness: -1.8385\n",
      "    - New mask: 27 features, Fitness: -1.1545\n",
      "    - New mask: 31 features, Fitness: -2.0804\n",
      "    - New mask: 29 features, Fitness: -1.8368\n",
      "    - New mask: 32 features, Fitness: -2.2236\n",
      "    - New mask: 27 features, Fitness: -1.2472\n",
      "    - New mask: 31 features, Fitness: -2.3183\n",
      "    - New mask: 29 features, Fitness: -1.4395\n",
      "    - New mask: 26 features, Fitness: -1.0035\n",
      "    - New mask: 29 features, Fitness: -1.4586\n",
      "    - New mask: 32 features, Fitness: -2.3707\n",
      "    - New mask: 29 features, Fitness: -1.3375\n",
      "    - New mask: 28 features, Fitness: -1.6991\n",
      "    - New mask: 29 features, Fitness: -1.7088\n",
      "    - New mask: 29 features, Fitness: -2.0080\n",
      "    - New mask: 25 features, Fitness: -0.8035\n",
      "    - New mask: 27 features, Fitness: 1.2485\n",
      "    - New mask: 23 features, Fitness: 0.9517\n",
      "    - New mask: 26 features, Fitness: 1.0804\n",
      "    - New mask: 26 features, Fitness: 1.7203\n",
      "    - New mask: 28 features, Fitness: 0.9476\n",
      "    - New mask: 28 features, Fitness: 0.5704\n",
      "    - New mask: 28 features, Fitness: 0.8888\n",
      "    - New mask: 32 features, Fitness: 1.1809\n",
      "    - New mask: 25 features, Fitness: 1.0711\n",
      "    - New mask: 27 features, Fitness: 1.0768\n",
      "    - New mask: 25 features, Fitness: 1.5757\n",
      "    - New mask: 29 features, Fitness: 0.8123\n",
      "    - New mask: 31 features, Fitness: 0.7771\n",
      "    - New mask: 26 features, Fitness: 1.2965\n",
      "    - New mask: 24 features, Fitness: 0.7008\n",
      "    - New mask: 28 features, Fitness: 1.2160\n",
      "    - New mask: 26 features, Fitness: 1.1927\n",
      "    - New mask: 23 features, Fitness: 1.5838\n",
      "    - New mask: 25 features, Fitness: 1.3394\n",
      "    - New mask: 29 features, Fitness: 0.7828\n",
      "    - New mask: 27 features, Fitness: 1.1047\n",
      "    - New mask: 27 features, Fitness: -0.0064\n",
      "    - New mask: 24 features, Fitness: 1.4937\n",
      "    - New mask: 29 features, Fitness: 0.7638\n",
      "    - New mask: 26 features, Fitness: 0.4841\n",
      "    - New mask: 26 features, Fitness: 0.4825\n",
      "    - New mask: 27 features, Fitness: 0.1934\n",
      "    - New mask: 27 features, Fitness: 0.8490\n",
      "    - New mask: 28 features, Fitness: 0.2916\n",
      "    - New mask: 23 features, Fitness: 1.4403\n",
      "    - New mask: 28 features, Fitness: 0.3857\n",
      "    - New mask: 29 features, Fitness: 0.3916\n",
      "    - New mask: 27 features, Fitness: 1.0065\n",
      "    - New mask: 25 features, Fitness: 1.0107\n",
      "    - New mask: 26 features, Fitness: 0.0594\n",
      "    - New mask: 29 features, Fitness: 0.6096\n",
      "    - New mask: 26 features, Fitness: 0.3811\n",
      "    - New mask: 26 features, Fitness: 1.0108\n",
      "    - New mask: 22 features, Fitness: 1.3297\n",
      "    - New mask: 24 features, Fitness: 1.2082\n",
      "    - New mask: 28 features, Fitness: -2.1712\n",
      "    - New mask: 26 features, Fitness: -1.6763\n",
      "    - New mask: 27 features, Fitness: -1.8134\n",
      "    - New mask: 31 features, Fitness: -4.5849\n",
      "    - New mask: 29 features, Fitness: -3.2184\n",
      "    - New mask: 28 features, Fitness: -2.5191\n",
      "    - New mask: 26 features, Fitness: -1.6488\n",
      "    - New mask: 31 features, Fitness: -4.2869\n",
      "    - New mask: 27 features, Fitness: -1.9656\n",
      "    - New mask: 31 features, Fitness: -3.8283\n",
      "    - New mask: 29 features, Fitness: -3.0642\n",
      "    - New mask: 28 features, Fitness: -2.6995\n",
      "    - New mask: 28 features, Fitness: -2.6741\n",
      "    - New mask: 28 features, Fitness: -2.7222\n",
      "    - New mask: 26 features, Fitness: -1.4280\n",
      "    - New mask: 30 features, Fitness: -3.5182\n",
      "    - New mask: 24 features, Fitness: -1.1819\n",
      "    - New mask: 28 features, Fitness: -2.4984\n",
      "    - New mask: 27 features, Fitness: -1.9311\n",
      "    - New mask: 28 features, Fitness: -2.3926\n",
      "    - New mask: 27 features, Fitness: -1.7311\n",
      "    - New mask: 27 features, Fitness: -1.7439\n",
      "    - New mask: 29 features, Fitness: -2.2156\n",
      "    - New mask: 28 features, Fitness: -1.8072\n",
      "    - New mask: 24 features, Fitness: -1.1228\n",
      "    - New mask: 26 features, Fitness: -1.5703\n",
      "    - New mask: 29 features, Fitness: -2.2975\n",
      "    - New mask: 27 features, Fitness: -1.6971\n",
      "    - New mask: 27 features, Fitness: -1.5493\n",
      "    - New mask: 29 features, Fitness: -1.9373\n",
      "    - New mask: 25 features, Fitness: -1.5270\n",
      "    - New mask: 28 features, Fitness: -1.8023\n",
      "    - New mask: 30 features, Fitness: -2.2501\n",
      "    - New mask: 27 features, Fitness: -1.2131\n",
      "    - New mask: 24 features, Fitness: -1.0843\n",
      "    - New mask: 29 features, Fitness: -2.0587\n",
      "    - New mask: 27 features, Fitness: -1.6705\n",
      "    - New mask: 26 features, Fitness: -1.3438\n",
      "    - New mask: 29 features, Fitness: -2.2659\n",
      "    - New mask: 25 features, Fitness: -1.3573\n",
      "    - New mask: 27 features, Fitness: -2.8218\n",
      "    - New mask: 27 features, Fitness: -2.4750\n",
      "    - New mask: 24 features, Fitness: -1.2935\n",
      "    - New mask: 26 features, Fitness: -2.6070\n",
      "    - New mask: 27 features, Fitness: -2.8552\n",
      "    - New mask: 29 features, Fitness: -3.6522\n",
      "    - New mask: 29 features, Fitness: -3.2447\n",
      "    - New mask: 30 features, Fitness: -3.6516\n",
      "    - New mask: 26 features, Fitness: -2.1813\n",
      "    - New mask: 29 features, Fitness: -3.1806\n",
      "    - New mask: 31 features, Fitness: -4.1883\n",
      "    - New mask: 29 features, Fitness: -3.2954\n",
      "    - New mask: 29 features, Fitness: -3.4875\n",
      "    - New mask: 31 features, Fitness: -5.2349\n",
      "    - New mask: 25 features, Fitness: -1.6193\n",
      "    - New mask: 25 features, Fitness: -1.6669\n",
      "    - New mask: 26 features, Fitness: -2.7458\n",
      "    - New mask: 32 features, Fitness: -4.5367\n",
      "    - New mask: 26 features, Fitness: -2.0605\n",
      "    - New mask: 27 features, Fitness: -2.4716\n",
      "    - New mask: 30 features, Fitness: -3.0493\n",
      "    - New mask: 28 features, Fitness: -2.6072\n",
      "    - New mask: 29 features, Fitness: -2.7305\n",
      "    - New mask: 30 features, Fitness: -3.4043\n",
      "    - New mask: 28 features, Fitness: -2.5143\n",
      "    - New mask: 29 features, Fitness: -2.7955\n",
      "    - New mask: 28 features, Fitness: -2.3743\n",
      "    - New mask: 29 features, Fitness: -2.7183\n",
      "    - New mask: 28 features, Fitness: -3.1920\n",
      "    - New mask: 28 features, Fitness: -2.2873\n",
      "    - New mask: 27 features, Fitness: -2.4152\n",
      "    - New mask: 31 features, Fitness: -3.4261\n",
      "    - New mask: 26 features, Fitness: -1.8910\n",
      "    - New mask: 25 features, Fitness: -1.4220\n",
      "    - New mask: 27 features, Fitness: -1.9978\n",
      "    - New mask: 29 features, Fitness: -2.9847\n",
      "    - New mask: 27 features, Fitness: -2.1710\n",
      "    - New mask: 28 features, Fitness: -2.6195\n",
      "    - New mask: 29 features, Fitness: -2.8625\n",
      "    - New mask: 28 features, Fitness: -2.4830\n",
      "    - New mask: 26 features, Fitness: -0.4103\n",
      "    - New mask: 27 features, Fitness: -0.6833\n",
      "    - New mask: 28 features, Fitness: -0.8299\n",
      "    - New mask: 28 features, Fitness: -1.0062\n",
      "    - New mask: 27 features, Fitness: -0.9083\n",
      "    - New mask: 29 features, Fitness: -1.1904\n",
      "    - New mask: 24 features, Fitness: -0.3887\n",
      "    - New mask: 30 features, Fitness: -1.2400\n",
      "    - New mask: 31 features, Fitness: -1.4597\n",
      "    - New mask: 29 features, Fitness: -1.3018\n",
      "    - New mask: 29 features, Fitness: -1.1347\n",
      "    - New mask: 26 features, Fitness: -0.6781\n",
      "    - New mask: 31 features, Fitness: -1.5397\n",
      "    - New mask: 31 features, Fitness: -1.4303\n",
      "    - New mask: 28 features, Fitness: -1.0002\n",
      "    - New mask: 26 features, Fitness: -0.4339\n",
      "    - New mask: 26 features, Fitness: -0.4936\n",
      "    - New mask: 30 features, Fitness: -1.3558\n",
      "    - New mask: 27 features, Fitness: -0.9197\n",
      "    - New mask: 27 features, Fitness: -0.6798\n",
      "=== End of Round 15: Vote mask selects 26 features (rho: 0.64)\n",
      "    Indices: [0, 2, 3, 7, 8, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 29, 31, 32, 33, 37, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 16 ================\n",
      "  Adaptive rho for this round: 0.67\n",
      "    - New mask: 26 features, Fitness: -1.3440\n",
      "    - New mask: 26 features, Fitness: -1.6237\n",
      "    - New mask: 27 features, Fitness: -1.6843\n",
      "    - New mask: 26 features, Fitness: -1.6000\n",
      "    - New mask: 24 features, Fitness: -1.3216\n",
      "    - New mask: 26 features, Fitness: -1.7929\n",
      "    - New mask: 28 features, Fitness: -1.8793\n",
      "    - New mask: 28 features, Fitness: -1.7761\n",
      "    - New mask: 24 features, Fitness: -1.1506\n",
      "    - New mask: 24 features, Fitness: -0.8421\n",
      "    - New mask: 25 features, Fitness: -1.2504\n",
      "    - New mask: 24 features, Fitness: -1.6066\n",
      "    - New mask: 24 features, Fitness: -1.3424\n",
      "    - New mask: 26 features, Fitness: -1.5950\n",
      "    - New mask: 25 features, Fitness: -1.0130\n",
      "    - New mask: 25 features, Fitness: -1.3990\n",
      "    - New mask: 27 features, Fitness: -2.0282\n",
      "    - New mask: 24 features, Fitness: -1.1445\n",
      "    - New mask: 27 features, Fitness: -1.7383\n",
      "    - New mask: 25 features, Fitness: -1.3921\n",
      "    - New mask: 27 features, Fitness: -1.5892\n",
      "    - New mask: 27 features, Fitness: -1.3374\n",
      "    - New mask: 25 features, Fitness: -1.0755\n",
      "    - New mask: 27 features, Fitness: -1.5241\n",
      "    - New mask: 28 features, Fitness: -1.5282\n",
      "    - New mask: 24 features, Fitness: -0.7985\n",
      "    - New mask: 26 features, Fitness: -1.1531\n",
      "    - New mask: 30 features, Fitness: -2.4124\n",
      "    - New mask: 24 features, Fitness: -0.7071\n",
      "    - New mask: 27 features, Fitness: -1.3945\n",
      "    - New mask: 26 features, Fitness: -1.1307\n",
      "    - New mask: 23 features, Fitness: -0.6187\n",
      "    - New mask: 26 features, Fitness: -1.1673\n",
      "    - New mask: 27 features, Fitness: -1.4767\n",
      "    - New mask: 27 features, Fitness: -1.4075\n",
      "    - New mask: 28 features, Fitness: -1.3881\n",
      "    - New mask: 22 features, Fitness: -0.5302\n",
      "    - New mask: 26 features, Fitness: -1.1594\n",
      "    - New mask: 29 features, Fitness: -2.0363\n",
      "    - New mask: 28 features, Fitness: -1.7776\n",
      "    - New mask: 29 features, Fitness: -1.6434\n",
      "    - New mask: 26 features, Fitness: -0.9055\n",
      "    - New mask: 26 features, Fitness: -0.7959\n",
      "    - New mask: 29 features, Fitness: -1.3496\n",
      "    - New mask: 28 features, Fitness: -1.4162\n",
      "    - New mask: 27 features, Fitness: -0.9823\n",
      "    - New mask: 30 features, Fitness: -1.7255\n",
      "    - New mask: 26 features, Fitness: -1.0218\n",
      "    - New mask: 25 features, Fitness: -0.8185\n",
      "    - New mask: 27 features, Fitness: -1.1988\n",
      "    - New mask: 28 features, Fitness: -1.2674\n",
      "    - New mask: 24 features, Fitness: -0.7837\n",
      "    - New mask: 25 features, Fitness: -0.7994\n",
      "    - New mask: 27 features, Fitness: -1.1223\n",
      "    - New mask: 31 features, Fitness: -2.1688\n",
      "    - New mask: 28 features, Fitness: -1.3878\n",
      "    - New mask: 24 features, Fitness: -0.5502\n",
      "    - New mask: 25 features, Fitness: -0.9626\n",
      "    - New mask: 26 features, Fitness: -1.2061\n",
      "    - New mask: 26 features, Fitness: -1.0009\n",
      "    - New mask: 30 features, Fitness: 1.0041\n",
      "    - New mask: 24 features, Fitness: 1.5432\n",
      "    - New mask: 23 features, Fitness: 1.0404\n",
      "    - New mask: 26 features, Fitness: 1.2228\n",
      "    - New mask: 29 features, Fitness: 1.0264\n",
      "    - New mask: 25 features, Fitness: 0.6867\n",
      "    - New mask: 26 features, Fitness: 1.1553\n",
      "    - New mask: 30 features, Fitness: 1.2969\n",
      "    - New mask: 25 features, Fitness: 1.5164\n",
      "    - New mask: 27 features, Fitness: 1.3726\n",
      "    - New mask: 24 features, Fitness: 2.0042\n",
      "    - New mask: 28 features, Fitness: 1.2858\n",
      "    - New mask: 30 features, Fitness: 0.8900\n",
      "    - New mask: 24 features, Fitness: 1.5885\n",
      "    - New mask: 26 features, Fitness: 0.3859\n",
      "    - New mask: 24 features, Fitness: 1.4082\n",
      "    - New mask: 22 features, Fitness: 1.9007\n",
      "    - New mask: 23 features, Fitness: 1.6760\n",
      "    - New mask: 26 features, Fitness: 1.5479\n",
      "    - New mask: 27 features, Fitness: 1.2631\n",
      "    - New mask: 26 features, Fitness: 0.6517\n",
      "    - New mask: 24 features, Fitness: 1.2288\n",
      "    - New mask: 22 features, Fitness: 1.3843\n",
      "    - New mask: 23 features, Fitness: 1.4645\n",
      "    - New mask: 23 features, Fitness: 1.7732\n",
      "    - New mask: 24 features, Fitness: 1.4459\n",
      "    - New mask: 22 features, Fitness: 0.8060\n",
      "    - New mask: 24 features, Fitness: 0.9756\n",
      "    - New mask: 24 features, Fitness: 0.8038\n",
      "    - New mask: 23 features, Fitness: 1.6774\n",
      "    - New mask: 25 features, Fitness: 1.3394\n",
      "    - New mask: 28 features, Fitness: 0.6017\n",
      "    - New mask: 23 features, Fitness: 1.3254\n",
      "    - New mask: 22 features, Fitness: 0.7242\n",
      "    - New mask: 22 features, Fitness: 1.1139\n",
      "    - New mask: 27 features, Fitness: 0.7126\n",
      "    - New mask: 23 features, Fitness: 1.0640\n",
      "    - New mask: 25 features, Fitness: 0.9507\n",
      "    - New mask: 26 features, Fitness: 0.7208\n",
      "    - New mask: 24 features, Fitness: 1.4772\n",
      "    - New mask: 28 features, Fitness: -2.7076\n",
      "    - New mask: 25 features, Fitness: -1.3775\n",
      "    - New mask: 24 features, Fitness: -1.2605\n",
      "    - New mask: 24 features, Fitness: -1.1161\n",
      "    - New mask: 27 features, Fitness: -2.0428\n",
      "    - New mask: 26 features, Fitness: -1.9033\n",
      "    - New mask: 27 features, Fitness: -2.2296\n",
      "    - New mask: 25 features, Fitness: -1.4487\n",
      "    - New mask: 24 features, Fitness: -1.1254\n",
      "    - New mask: 28 features, Fitness: -2.4912\n",
      "    - New mask: 26 features, Fitness: -1.8126\n",
      "    - New mask: 25 features, Fitness: -1.9081\n",
      "    - New mask: 26 features, Fitness: -2.2243\n",
      "    - New mask: 27 features, Fitness: -2.4618\n",
      "    - New mask: 26 features, Fitness: -1.4285\n",
      "    - New mask: 25 features, Fitness: -1.7450\n",
      "    - New mask: 22 features, Fitness: -0.7083\n",
      "    - New mask: 25 features, Fitness: -1.3823\n",
      "    - New mask: 26 features, Fitness: -1.4662\n",
      "    - New mask: 26 features, Fitness: -1.7116\n",
      "    - New mask: 26 features, Fitness: -1.5735\n",
      "    - New mask: 23 features, Fitness: -0.7955\n",
      "    - New mask: 24 features, Fitness: -0.8468\n",
      "    - New mask: 26 features, Fitness: -1.1774\n",
      "    - New mask: 22 features, Fitness: -0.6936\n",
      "    - New mask: 27 features, Fitness: -2.3310\n",
      "    - New mask: 26 features, Fitness: -1.4005\n",
      "    - New mask: 26 features, Fitness: -1.2913\n",
      "    - New mask: 27 features, Fitness: -1.3500\n",
      "    - New mask: 26 features, Fitness: -1.6485\n",
      "    - New mask: 25 features, Fitness: -1.2143\n",
      "    - New mask: 23 features, Fitness: -0.8108\n",
      "    - New mask: 28 features, Fitness: -1.7017\n",
      "    - New mask: 27 features, Fitness: -1.6825\n",
      "    - New mask: 24 features, Fitness: -1.0859\n",
      "    - New mask: 28 features, Fitness: -1.6974\n",
      "    - New mask: 25 features, Fitness: -1.0361\n",
      "    - New mask: 26 features, Fitness: -1.4093\n",
      "    - New mask: 28 features, Fitness: -2.0714\n",
      "    - New mask: 22 features, Fitness: -0.6833\n",
      "    - New mask: 26 features, Fitness: -2.1670\n",
      "    - New mask: 26 features, Fitness: -2.1313\n",
      "    - New mask: 26 features, Fitness: -1.9690\n",
      "    - New mask: 21 features, Fitness: -1.3373\n",
      "    - New mask: 22 features, Fitness: -0.8372\n",
      "    - New mask: 27 features, Fitness: -2.4523\n",
      "    - New mask: 23 features, Fitness: -1.2337\n",
      "    - New mask: 26 features, Fitness: -1.9235\n",
      "    - New mask: 27 features, Fitness: -2.3730\n",
      "    - New mask: 25 features, Fitness: -1.7973\n",
      "    - New mask: 28 features, Fitness: -2.6786\n",
      "    - New mask: 25 features, Fitness: -1.9251\n",
      "    - New mask: 24 features, Fitness: -1.4052\n",
      "    - New mask: 25 features, Fitness: -1.7793\n",
      "    - New mask: 25 features, Fitness: -1.6193\n",
      "    - New mask: 22 features, Fitness: -1.0898\n",
      "    - New mask: 23 features, Fitness: -1.1524\n",
      "    - New mask: 26 features, Fitness: -2.4827\n",
      "    - New mask: 24 features, Fitness: -1.4641\n",
      "    - New mask: 24 features, Fitness: -1.2768\n",
      "    - New mask: 25 features, Fitness: -2.2275\n",
      "    - New mask: 25 features, Fitness: -1.7306\n",
      "    - New mask: 26 features, Fitness: -1.8739\n",
      "    - New mask: 29 features, Fitness: -2.7412\n",
      "    - New mask: 28 features, Fitness: -2.5102\n",
      "    - New mask: 26 features, Fitness: -2.0955\n",
      "    - New mask: 26 features, Fitness: -1.5978\n",
      "    - New mask: 30 features, Fitness: -3.2201\n",
      "    - New mask: 26 features, Fitness: -2.4501\n",
      "    - New mask: 28 features, Fitness: -2.2751\n",
      "    - New mask: 27 features, Fitness: -1.9260\n",
      "    - New mask: 32 features, Fitness: -3.7543\n",
      "    - New mask: 24 features, Fitness: -1.2789\n",
      "    - New mask: 24 features, Fitness: -1.2029\n",
      "    - New mask: 26 features, Fitness: -1.9809\n",
      "    - New mask: 25 features, Fitness: -1.4709\n",
      "    - New mask: 27 features, Fitness: -2.1184\n",
      "    - New mask: 26 features, Fitness: -2.3160\n",
      "    - New mask: 24 features, Fitness: -1.7783\n",
      "    - New mask: 25 features, Fitness: -1.5713\n",
      "    - New mask: 26 features, Fitness: -0.6570\n",
      "    - New mask: 28 features, Fitness: -1.1168\n",
      "    - New mask: 30 features, Fitness: -1.4072\n",
      "    - New mask: 27 features, Fitness: -0.8644\n",
      "    - New mask: 27 features, Fitness: -1.2285\n",
      "    - New mask: 25 features, Fitness: -0.6004\n",
      "    - New mask: 25 features, Fitness: -0.4495\n",
      "    - New mask: 28 features, Fitness: -0.9454\n",
      "    - New mask: 28 features, Fitness: -1.1037\n",
      "    - New mask: 28 features, Fitness: -0.9950\n",
      "    - New mask: 27 features, Fitness: -0.7698\n",
      "    - New mask: 28 features, Fitness: -1.1719\n",
      "    - New mask: 24 features, Fitness: -0.2725\n",
      "    - New mask: 28 features, Fitness: -0.9516\n",
      "    - New mask: 24 features, Fitness: -0.3290\n",
      "    - New mask: 23 features, Fitness: -0.2014\n",
      "    - New mask: 26 features, Fitness: -0.6909\n",
      "    - New mask: 26 features, Fitness: -0.6642\n",
      "    - New mask: 26 features, Fitness: -0.9354\n",
      "    - New mask: 28 features, Fitness: -1.0463\n",
      "=== End of Round 16: Vote mask selects 25 features (rho: 0.67)\n",
      "    Indices: [0, 2, 3, 7, 8, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 29, 31, 32, 33, 37, 39, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 17 ================\n",
      "  Adaptive rho for this round: 0.71\n",
      "    - New mask: 25 features, Fitness: -1.0427\n",
      "    - New mask: 26 features, Fitness: -1.3959\n",
      "    - New mask: 28 features, Fitness: -1.6950\n",
      "    - New mask: 25 features, Fitness: -1.4294\n",
      "    - New mask: 26 features, Fitness: -1.3738\n",
      "    - New mask: 22 features, Fitness: -0.7347\n",
      "    - New mask: 25 features, Fitness: -1.2412\n",
      "    - New mask: 25 features, Fitness: -1.1537\n",
      "    - New mask: 23 features, Fitness: -0.7581\n",
      "    - New mask: 23 features, Fitness: -0.7649\n",
      "    - New mask: 22 features, Fitness: -0.8472\n",
      "    - New mask: 22 features, Fitness: -0.7668\n",
      "    - New mask: 24 features, Fitness: -1.2742\n",
      "    - New mask: 23 features, Fitness: -0.9649\n",
      "    - New mask: 23 features, Fitness: -0.5804\n",
      "    - New mask: 23 features, Fitness: -0.4724\n",
      "    - New mask: 26 features, Fitness: -1.2793\n",
      "    - New mask: 26 features, Fitness: -1.4732\n",
      "    - New mask: 29 features, Fitness: -2.6322\n",
      "    - New mask: 24 features, Fitness: -0.7331\n",
      "    - New mask: 24 features, Fitness: -1.0155\n",
      "    - New mask: 24 features, Fitness: -0.6151\n",
      "    - New mask: 26 features, Fitness: -1.1599\n",
      "    - New mask: 24 features, Fitness: -1.0250\n",
      "    - New mask: 25 features, Fitness: -1.3739\n",
      "    - New mask: 24 features, Fitness: -0.6895\n",
      "    - New mask: 21 features, Fitness: -0.3828\n",
      "    - New mask: 24 features, Fitness: -1.0469\n",
      "    - New mask: 24 features, Fitness: -0.9574\n",
      "    - New mask: 21 features, Fitness: -0.3032\n",
      "    - New mask: 23 features, Fitness: -0.7220\n",
      "    - New mask: 23 features, Fitness: -0.5996\n",
      "    - New mask: 23 features, Fitness: -1.4490\n",
      "    - New mask: 26 features, Fitness: -0.9470\n",
      "    - New mask: 23 features, Fitness: -0.7383\n",
      "    - New mask: 22 features, Fitness: -0.6925\n",
      "    - New mask: 23 features, Fitness: -0.6620\n",
      "    - New mask: 25 features, Fitness: -1.0608\n",
      "    - New mask: 24 features, Fitness: -0.8419\n",
      "    - New mask: 25 features, Fitness: -1.0194\n",
      "    - New mask: 26 features, Fitness: -0.9164\n",
      "    - New mask: 24 features, Fitness: -0.6844\n",
      "    - New mask: 25 features, Fitness: -0.6461\n",
      "    - New mask: 26 features, Fitness: -0.6343\n",
      "    - New mask: 28 features, Fitness: -1.2977\n",
      "    - New mask: 24 features, Fitness: -0.5826\n",
      "    - New mask: 26 features, Fitness: -0.9426\n",
      "    - New mask: 26 features, Fitness: -0.7593\n",
      "    - New mask: 22 features, Fitness: -0.3091\n",
      "    - New mask: 27 features, Fitness: -1.0751\n",
      "    - New mask: 24 features, Fitness: -0.6537\n",
      "    - New mask: 26 features, Fitness: -0.9707\n",
      "    - New mask: 26 features, Fitness: -0.9585\n",
      "    - New mask: 28 features, Fitness: -1.2599\n",
      "    - New mask: 25 features, Fitness: -1.4122\n",
      "    - New mask: 24 features, Fitness: -0.4787\n",
      "    - New mask: 24 features, Fitness: -0.5502\n",
      "    - New mask: 27 features, Fitness: -1.3921\n",
      "    - New mask: 22 features, Fitness: -0.5399\n",
      "    - New mask: 21 features, Fitness: -0.5490\n",
      "    - New mask: 24 features, Fitness: 0.9608\n",
      "    - New mask: 24 features, Fitness: 1.3306\n",
      "    - New mask: 28 features, Fitness: 1.0856\n",
      "    - New mask: 23 features, Fitness: 1.4235\n",
      "    - New mask: 24 features, Fitness: 1.2277\n",
      "    - New mask: 24 features, Fitness: 0.9799\n",
      "    - New mask: 23 features, Fitness: 1.1708\n",
      "    - New mask: 26 features, Fitness: 1.8299\n",
      "    - New mask: 27 features, Fitness: 0.7924\n",
      "    - New mask: 22 features, Fitness: 1.8342\n",
      "    - New mask: 23 features, Fitness: 1.8529\n",
      "    - New mask: 26 features, Fitness: 1.1271\n",
      "    - New mask: 27 features, Fitness: 1.6388\n",
      "    - New mask: 22 features, Fitness: 1.8980\n",
      "    - New mask: 23 features, Fitness: 1.2197\n",
      "    - New mask: 24 features, Fitness: 1.2338\n",
      "    - New mask: 23 features, Fitness: 1.6466\n",
      "    - New mask: 24 features, Fitness: 1.4036\n",
      "    - New mask: 28 features, Fitness: 0.7615\n",
      "    - New mask: 27 features, Fitness: 0.9689\n",
      "    - New mask: 26 features, Fitness: 0.5690\n",
      "    - New mask: 26 features, Fitness: 1.5090\n",
      "    - New mask: 25 features, Fitness: 1.2608\n",
      "    - New mask: 25 features, Fitness: 1.1508\n",
      "    - New mask: 23 features, Fitness: 1.8693\n",
      "    - New mask: 23 features, Fitness: 1.2897\n",
      "    - New mask: 23 features, Fitness: 1.5287\n",
      "    - New mask: 24 features, Fitness: 1.8395\n",
      "    - New mask: 25 features, Fitness: 0.2150\n",
      "    - New mask: 24 features, Fitness: 1.2136\n",
      "    - New mask: 21 features, Fitness: 1.5492\n",
      "    - New mask: 28 features, Fitness: 0.4147\n",
      "    - New mask: 27 features, Fitness: 1.6300\n",
      "    - New mask: 23 features, Fitness: 1.5492\n",
      "    - New mask: 23 features, Fitness: 0.9736\n",
      "    - New mask: 23 features, Fitness: 1.1763\n",
      "    - New mask: 25 features, Fitness: 0.7618\n",
      "    - New mask: 25 features, Fitness: 1.2556\n",
      "    - New mask: 26 features, Fitness: 1.2650\n",
      "    - New mask: 21 features, Fitness: 1.1860\n",
      "    - New mask: 24 features, Fitness: -2.5350\n",
      "    - New mask: 24 features, Fitness: -2.0624\n",
      "    - New mask: 25 features, Fitness: -1.6868\n",
      "    - New mask: 24 features, Fitness: -1.2620\n",
      "    - New mask: 25 features, Fitness: -1.7335\n",
      "    - New mask: 25 features, Fitness: -2.3792\n",
      "    - New mask: 26 features, Fitness: -2.5529\n",
      "    - New mask: 23 features, Fitness: -1.8241\n",
      "    - New mask: 25 features, Fitness: -1.3877\n",
      "    - New mask: 25 features, Fitness: -1.6761\n",
      "    - New mask: 23 features, Fitness: -1.7256\n",
      "    - New mask: 24 features, Fitness: -1.0047\n",
      "    - New mask: 23 features, Fitness: -1.1468\n",
      "    - New mask: 26 features, Fitness: -2.0084\n",
      "    - New mask: 24 features, Fitness: -1.0823\n",
      "    - New mask: 25 features, Fitness: -1.5136\n",
      "    - New mask: 21 features, Fitness: -1.4823\n",
      "    - New mask: 25 features, Fitness: -1.1714\n",
      "    - New mask: 23 features, Fitness: -1.1073\n",
      "    - New mask: 25 features, Fitness: -1.2232\n",
      "    - New mask: 22 features, Fitness: -0.7283\n",
      "    - New mask: 24 features, Fitness: -0.9646\n",
      "    - New mask: 24 features, Fitness: -0.8460\n",
      "    - New mask: 26 features, Fitness: -1.3800\n",
      "    - New mask: 24 features, Fitness: -1.7797\n",
      "    - New mask: 22 features, Fitness: -0.6743\n",
      "    - New mask: 24 features, Fitness: -0.9333\n",
      "    - New mask: 22 features, Fitness: -0.8051\n",
      "    - New mask: 23 features, Fitness: -1.2378\n",
      "    - New mask: 22 features, Fitness: -0.5638\n",
      "    - New mask: 21 features, Fitness: -0.1370\n",
      "    - New mask: 23 features, Fitness: -0.5756\n",
      "    - New mask: 23 features, Fitness: -0.5327\n",
      "    - New mask: 27 features, Fitness: -1.4549\n",
      "    - New mask: 25 features, Fitness: -1.1368\n",
      "    - New mask: 24 features, Fitness: -0.9037\n",
      "    - New mask: 19 features, Fitness: -0.0612\n",
      "    - New mask: 28 features, Fitness: -1.8308\n",
      "    - New mask: 25 features, Fitness: -1.3802\n",
      "    - New mask: 20 features, Fitness: -0.1441\n",
      "    - New mask: 26 features, Fitness: -1.9705\n",
      "    - New mask: 26 features, Fitness: -2.1428\n",
      "    - New mask: 23 features, Fitness: -1.1699\n",
      "    - New mask: 24 features, Fitness: -1.3699\n",
      "    - New mask: 23 features, Fitness: -1.0734\n",
      "    - New mask: 25 features, Fitness: -1.7368\n",
      "    - New mask: 21 features, Fitness: -0.6346\n",
      "    - New mask: 23 features, Fitness: -1.0749\n",
      "    - New mask: 24 features, Fitness: -1.4058\n",
      "    - New mask: 22 features, Fitness: -0.7139\n",
      "    - New mask: 27 features, Fitness: -2.3092\n",
      "    - New mask: 24 features, Fitness: -1.2744\n",
      "    - New mask: 23 features, Fitness: -1.0493\n",
      "    - New mask: 26 features, Fitness: -2.0768\n",
      "    - New mask: 25 features, Fitness: -1.5966\n",
      "    - New mask: 19 features, Fitness: -0.4470\n",
      "    - New mask: 24 features, Fitness: -1.3893\n",
      "    - New mask: 23 features, Fitness: -1.3885\n",
      "    - New mask: 26 features, Fitness: -2.0300\n",
      "    - New mask: 20 features, Fitness: -1.5787\n",
      "    - New mask: 24 features, Fitness: -2.0713\n",
      "    - New mask: 27 features, Fitness: -2.1422\n",
      "    - New mask: 25 features, Fitness: -1.5201\n",
      "    - New mask: 22 features, Fitness: -0.8863\n",
      "    - New mask: 26 features, Fitness: -1.7337\n",
      "    - New mask: 22 features, Fitness: -0.9595\n",
      "    - New mask: 25 features, Fitness: -1.4534\n",
      "    - New mask: 24 features, Fitness: -1.2942\n",
      "    - New mask: 26 features, Fitness: -1.8739\n",
      "    - New mask: 27 features, Fitness: -2.2435\n",
      "    - New mask: 25 features, Fitness: -1.3958\n",
      "    - New mask: 28 features, Fitness: -2.4175\n",
      "    - New mask: 26 features, Fitness: -1.8923\n",
      "    - New mask: 24 features, Fitness: -1.2974\n",
      "    - New mask: 26 features, Fitness: -2.1098\n",
      "    - New mask: 24 features, Fitness: -1.4936\n",
      "    - New mask: 25 features, Fitness: -1.5512\n",
      "    - New mask: 27 features, Fitness: -2.1476\n",
      "    - New mask: 23 features, Fitness: -1.0957\n",
      "    - New mask: 22 features, Fitness: -0.8055\n",
      "    - New mask: 24 features, Fitness: -0.2100\n",
      "    - New mask: 25 features, Fitness: -0.5035\n",
      "    - New mask: 26 features, Fitness: -0.7082\n",
      "    - New mask: 24 features, Fitness: -0.9600\n",
      "    - New mask: 24 features, Fitness: -0.3415\n",
      "    - New mask: 23 features, Fitness: -0.1706\n",
      "    - New mask: 26 features, Fitness: -0.6124\n",
      "    - New mask: 26 features, Fitness: -0.7023\n",
      "    - New mask: 24 features, Fitness: -0.3525\n",
      "    - New mask: 27 features, Fitness: -0.7808\n",
      "    - New mask: 25 features, Fitness: -0.4666\n",
      "    - New mask: 25 features, Fitness: -0.5021\n",
      "    - New mask: 25 features, Fitness: -0.3349\n",
      "    - New mask: 29 features, Fitness: -1.1092\n",
      "    - New mask: 23 features, Fitness: -0.2711\n",
      "    - New mask: 24 features, Fitness: -0.2511\n",
      "    - New mask: 24 features, Fitness: -0.2490\n",
      "    - New mask: 27 features, Fitness: -0.8032\n",
      "    - New mask: 28 features, Fitness: -1.0655\n",
      "    - New mask: 26 features, Fitness: -0.5336\n",
      "=== End of Round 17: Vote mask selects 18 features (rho: 0.71)\n",
      "    Indices: [2, 3, 10, 14, 15, 19, 20, 21, 22, 23, 25, 29, 31, 33, 37, 39, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 18 ================\n",
      "  Adaptive rho for this round: 0.74\n",
      "    - New mask: 23 features, Fitness: -0.8347\n",
      "    - New mask: 24 features, Fitness: -0.9238\n",
      "    - New mask: 23 features, Fitness: -0.5624\n",
      "    - New mask: 24 features, Fitness: -0.8382\n",
      "    - New mask: 23 features, Fitness: -0.8897\n",
      "    - New mask: 22 features, Fitness: -0.2317\n",
      "    - New mask: 22 features, Fitness: -0.7228\n",
      "    - New mask: 20 features, Fitness: -0.4381\n",
      "    - New mask: 20 features, Fitness: -0.3981\n",
      "    - New mask: 20 features, Fitness: -0.2007\n",
      "    - New mask: 23 features, Fitness: -1.5929\n",
      "    - New mask: 17 features, Fitness: -0.0190\n",
      "    - New mask: 21 features, Fitness: -0.3948\n",
      "    - New mask: 22 features, Fitness: -0.6568\n",
      "    - New mask: 21 features, Fitness: -0.4571\n",
      "    - New mask: 23 features, Fitness: -0.4401\n",
      "    - New mask: 24 features, Fitness: -1.0601\n",
      "    - New mask: 21 features, Fitness: -0.2298\n",
      "    - New mask: 22 features, Fitness: -0.5102\n",
      "    - New mask: 17 features, Fitness: -0.0010\n",
      "    - New mask: 21 features, Fitness: -0.4167\n",
      "    - New mask: 21 features, Fitness: -0.2115\n",
      "    - New mask: 23 features, Fitness: -0.5773\n",
      "    - New mask: 24 features, Fitness: -0.7269\n",
      "    - New mask: 19 features, Fitness: 0.0693\n",
      "    - New mask: 22 features, Fitness: -0.4183\n",
      "    - New mask: 15 features, Fitness: 0.4796\n",
      "    - New mask: 18 features, Fitness: 0.0179\n",
      "    - New mask: 22 features, Fitness: -0.5589\n",
      "    - New mask: 22 features, Fitness: -0.3866\n",
      "    - New mask: 19 features, Fitness: -0.1758\n",
      "    - New mask: 20 features, Fitness: -0.2944\n",
      "    - New mask: 23 features, Fitness: -1.6206\n",
      "    - New mask: 22 features, Fitness: -0.4544\n",
      "    - New mask: 21 features, Fitness: -0.4039\n",
      "    - New mask: 21 features, Fitness: -0.5502\n",
      "    - New mask: 23 features, Fitness: -0.5693\n",
      "    - New mask: 20 features, Fitness: -0.2367\n",
      "    - New mask: 25 features, Fitness: -0.8856\n",
      "    - New mask: 23 features, Fitness: -0.6713\n",
      "    - New mask: 23 features, Fitness: -0.2905\n",
      "    - New mask: 20 features, Fitness: -0.1135\n",
      "    - New mask: 22 features, Fitness: -0.3532\n",
      "    - New mask: 20 features, Fitness: 0.0904\n",
      "    - New mask: 26 features, Fitness: -1.3439\n",
      "    - New mask: 19 features, Fitness: 0.0221\n",
      "    - New mask: 23 features, Fitness: -0.4404\n",
      "    - New mask: 20 features, Fitness: 0.2056\n",
      "    - New mask: 19 features, Fitness: 0.2291\n",
      "    - New mask: 24 features, Fitness: -1.2931\n",
      "    - New mask: 21 features, Fitness: -0.2644\n",
      "    - New mask: 23 features, Fitness: -0.5134\n",
      "    - New mask: 22 features, Fitness: -0.4524\n",
      "    - New mask: 24 features, Fitness: -0.5161\n",
      "    - New mask: 23 features, Fitness: -1.0431\n",
      "    - New mask: 17 features, Fitness: 0.3277\n",
      "    - New mask: 20 features, Fitness: -0.0525\n",
      "    - New mask: 23 features, Fitness: -0.3955\n",
      "    - New mask: 25 features, Fitness: -0.8254\n",
      "    - New mask: 24 features, Fitness: -0.7369\n",
      "    - New mask: 24 features, Fitness: 1.3746\n",
      "    - New mask: 23 features, Fitness: 1.9815\n",
      "    - New mask: 20 features, Fitness: 1.4807\n",
      "    - New mask: 22 features, Fitness: 1.4731\n",
      "    - New mask: 22 features, Fitness: 1.7969\n",
      "    - New mask: 24 features, Fitness: 1.5958\n",
      "    - New mask: 18 features, Fitness: 2.2031\n",
      "    - New mask: 21 features, Fitness: 1.5261\n",
      "    - New mask: 22 features, Fitness: 1.1653\n",
      "    - New mask: 21 features, Fitness: 1.9174\n",
      "    - New mask: 19 features, Fitness: 1.5434\n",
      "    - New mask: 19 features, Fitness: 1.6917\n",
      "    - New mask: 21 features, Fitness: 1.5363\n",
      "    - New mask: 21 features, Fitness: 1.5060\n",
      "    - New mask: 24 features, Fitness: 1.5087\n",
      "    - New mask: 21 features, Fitness: 1.1907\n",
      "    - New mask: 20 features, Fitness: 1.6387\n",
      "    - New mask: 20 features, Fitness: 1.3974\n",
      "    - New mask: 25 features, Fitness: 0.7691\n",
      "    - New mask: 20 features, Fitness: 1.3252\n",
      "    - New mask: 22 features, Fitness: 1.4759\n",
      "    - New mask: 22 features, Fitness: 1.9683\n",
      "    - New mask: 23 features, Fitness: 2.3348\n",
      "    - New mask: 22 features, Fitness: 0.9704\n",
      "    - New mask: 20 features, Fitness: 1.3900\n",
      "    - New mask: 23 features, Fitness: 1.7559\n",
      "    - New mask: 22 features, Fitness: 1.6603\n",
      "    - New mask: 22 features, Fitness: 1.6580\n",
      "    - New mask: 21 features, Fitness: 1.7918\n",
      "    - New mask: 24 features, Fitness: 0.6924\n",
      "    - New mask: 22 features, Fitness: 0.6943\n",
      "    - New mask: 21 features, Fitness: 1.2509\n",
      "    - New mask: 25 features, Fitness: 1.5814\n",
      "    - New mask: 18 features, Fitness: 1.5133\n",
      "    - New mask: 22 features, Fitness: 0.9783\n",
      "    - New mask: 19 features, Fitness: 1.3523\n",
      "    - New mask: 24 features, Fitness: 1.5261\n",
      "    - New mask: 21 features, Fitness: 1.1998\n",
      "    - New mask: 21 features, Fitness: 1.6734\n",
      "    - New mask: 22 features, Fitness: 1.9996\n",
      "    - New mask: 23 features, Fitness: -1.7844\n",
      "    - New mask: 25 features, Fitness: -2.5725\n",
      "    - New mask: 24 features, Fitness: -1.2785\n",
      "    - New mask: 20 features, Fitness: -1.2338\n",
      "    - New mask: 23 features, Fitness: -1.5993\n",
      "    - New mask: 22 features, Fitness: -1.8016\n",
      "    - New mask: 25 features, Fitness: -2.1848\n",
      "    - New mask: 21 features, Fitness: -0.5953\n",
      "    - New mask: 23 features, Fitness: -2.1110\n",
      "    - New mask: 24 features, Fitness: -1.1655\n",
      "    - New mask: 26 features, Fitness: -2.6609\n",
      "    - New mask: 23 features, Fitness: -1.1888\n",
      "    - New mask: 21 features, Fitness: -0.7064\n",
      "    - New mask: 22 features, Fitness: -1.0593\n",
      "    - New mask: 23 features, Fitness: -0.8015\n",
      "    - New mask: 24 features, Fitness: -1.1998\n",
      "    - New mask: 25 features, Fitness: -2.7012\n",
      "    - New mask: 23 features, Fitness: -1.9420\n",
      "    - New mask: 25 features, Fitness: -1.7133\n",
      "    - New mask: 22 features, Fitness: -0.7355\n",
      "    - New mask: 19 features, Fitness: 0.0670\n",
      "    - New mask: 22 features, Fitness: -0.3967\n",
      "    - New mask: 19 features, Fitness: -0.2074\n",
      "    - New mask: 23 features, Fitness: -0.8557\n",
      "    - New mask: 21 features, Fitness: -1.0427\n",
      "    - New mask: 17 features, Fitness: 0.1670\n",
      "    - New mask: 23 features, Fitness: -0.7293\n",
      "    - New mask: 20 features, Fitness: -0.3059\n",
      "    - New mask: 19 features, Fitness: -0.0713\n",
      "    - New mask: 21 features, Fitness: -0.1478\n",
      "    - New mask: 21 features, Fitness: -0.2331\n",
      "    - New mask: 22 features, Fitness: -0.4680\n",
      "    - New mask: 22 features, Fitness: -0.5900\n",
      "    - New mask: 21 features, Fitness: -1.1262\n",
      "    - New mask: 20 features, Fitness: -0.3455\n",
      "    - New mask: 21 features, Fitness: -0.6304\n",
      "    - New mask: 18 features, Fitness: 0.0476\n",
      "    - New mask: 19 features, Fitness: 0.0390\n",
      "    - New mask: 22 features, Fitness: -0.8397\n",
      "    - New mask: 20 features, Fitness: -0.2678\n",
      "    - New mask: 23 features, Fitness: -1.3442\n",
      "    - New mask: 21 features, Fitness: -0.7144\n",
      "    - New mask: 22 features, Fitness: -1.3028\n",
      "    - New mask: 21 features, Fitness: -0.8104\n",
      "    - New mask: 19 features, Fitness: -0.3642\n",
      "    - New mask: 21 features, Fitness: -0.6169\n",
      "    - New mask: 20 features, Fitness: -0.5601\n",
      "    - New mask: 22 features, Fitness: -1.0776\n",
      "    - New mask: 18 features, Fitness: -0.3363\n",
      "    - New mask: 21 features, Fitness: -0.8503\n",
      "    - New mask: 19 features, Fitness: -0.4116\n",
      "    - New mask: 22 features, Fitness: -1.0765\n",
      "    - New mask: 20 features, Fitness: -0.4423\n",
      "    - New mask: 21 features, Fitness: -1.0451\n",
      "    - New mask: 20 features, Fitness: -0.6549\n",
      "    - New mask: 17 features, Fitness: 0.0843\n",
      "    - New mask: 20 features, Fitness: -0.2594\n",
      "    - New mask: 19 features, Fitness: -0.1984\n",
      "    - New mask: 24 features, Fitness: -1.6170\n",
      "    - New mask: 20 features, Fitness: -0.4865\n",
      "    - New mask: 22 features, Fitness: -1.5786\n",
      "    - New mask: 27 features, Fitness: -2.3885\n",
      "    - New mask: 26 features, Fitness: -1.9092\n",
      "    - New mask: 20 features, Fitness: -0.5550\n",
      "    - New mask: 20 features, Fitness: -0.7480\n",
      "    - New mask: 19 features, Fitness: -0.1863\n",
      "    - New mask: 25 features, Fitness: -1.2723\n",
      "    - New mask: 20 features, Fitness: -0.2784\n",
      "    - New mask: 24 features, Fitness: -1.2369\n",
      "    - New mask: 21 features, Fitness: -0.5434\n",
      "    - New mask: 24 features, Fitness: -1.1031\n",
      "    - New mask: 23 features, Fitness: -1.0931\n",
      "    - New mask: 23 features, Fitness: -0.8433\n",
      "    - New mask: 20 features, Fitness: -0.2991\n",
      "    - New mask: 26 features, Fitness: -1.9779\n",
      "    - New mask: 20 features, Fitness: -0.5453\n",
      "    - New mask: 21 features, Fitness: -0.5329\n",
      "    - New mask: 20 features, Fitness: -0.3864\n",
      "    - New mask: 24 features, Fitness: -1.2914\n",
      "    - New mask: 18 features, Fitness: 0.0643\n",
      "    - New mask: 23 features, Fitness: -0.2627\n",
      "    - New mask: 24 features, Fitness: -0.5450\n",
      "    - New mask: 23 features, Fitness: -0.1889\n",
      "    - New mask: 23 features, Fitness: -0.0739\n",
      "    - New mask: 22 features, Fitness: -0.3250\n",
      "    - New mask: 22 features, Fitness: -0.0972\n",
      "    - New mask: 26 features, Fitness: -0.8211\n",
      "    - New mask: 21 features, Fitness: -0.0445\n",
      "    - New mask: 24 features, Fitness: -0.4913\n",
      "    - New mask: 23 features, Fitness: -0.3508\n",
      "    - New mask: 22 features, Fitness: -0.0915\n",
      "    - New mask: 24 features, Fitness: -0.3278\n",
      "    - New mask: 22 features, Fitness: 0.0721\n",
      "    - New mask: 22 features, Fitness: -0.0855\n",
      "    - New mask: 21 features, Fitness: -0.0526\n",
      "    - New mask: 22 features, Fitness: -0.0410\n",
      "    - New mask: 19 features, Fitness: 0.3195\n",
      "    - New mask: 23 features, Fitness: -0.0251\n",
      "    - New mask: 20 features, Fitness: -0.7435\n",
      "    - New mask: 22 features, Fitness: -0.1897\n",
      "=== End of Round 18: Vote mask selects 13 features (rho: 0.74)\n",
      "    Indices: [2, 3, 10, 14, 15, 21, 23, 29, 31, 33, 39, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 19 ================\n",
      "  Adaptive rho for this round: 0.77\n",
      "    - New mask: 15 features, Fitness: 0.4448\n",
      "    - New mask: 20 features, Fitness: -0.2050\n",
      "    - New mask: 19 features, Fitness: -0.7574\n",
      "    - New mask: 17 features, Fitness: -0.0749\n",
      "    - New mask: 20 features, Fitness: -0.1779\n",
      "    - New mask: 19 features, Fitness: -0.0305\n",
      "    - New mask: 13 features, Fitness: 0.4790\n",
      "    - New mask: 19 features, Fitness: -0.2068\n",
      "    - New mask: 16 features, Fitness: 0.2352\n",
      "    - New mask: 17 features, Fitness: 0.1630\n",
      "    - New mask: 20 features, Fitness: -0.5998\n",
      "    - New mask: 15 features, Fitness: 0.1076\n",
      "    - New mask: 17 features, Fitness: 0.1266\n",
      "    - New mask: 19 features, Fitness: -0.3156\n",
      "    - New mask: 19 features, Fitness: -0.0305\n",
      "    - New mask: 18 features, Fitness: 0.1762\n",
      "    - New mask: 20 features, Fitness: -0.3650\n",
      "    - New mask: 20 features, Fitness: -0.2283\n",
      "    - New mask: 20 features, Fitness: -0.2289\n",
      "    - New mask: 18 features, Fitness: -0.1121\n",
      "    - New mask: 15 features, Fitness: 0.3930\n",
      "    - New mask: 16 features, Fitness: 0.2383\n",
      "    - New mask: 14 features, Fitness: 0.5106\n",
      "    - New mask: 21 features, Fitness: -0.3094\n",
      "    - New mask: 17 features, Fitness: 0.2895\n",
      "    - New mask: 18 features, Fitness: 0.2171\n",
      "    - New mask: 14 features, Fitness: 0.5605\n",
      "    - New mask: 13 features, Fitness: 0.7292\n",
      "    - New mask: 16 features, Fitness: 0.3087\n",
      "    - New mask: 18 features, Fitness: 0.0559\n",
      "    - New mask: 17 features, Fitness: 0.1846\n",
      "    - New mask: 16 features, Fitness: 0.2775\n",
      "    - New mask: 17 features, Fitness: -0.0949\n",
      "    - New mask: 18 features, Fitness: 0.0463\n",
      "    - New mask: 19 features, Fitness: -0.0808\n",
      "    - New mask: 20 features, Fitness: -0.3553\n",
      "    - New mask: 16 features, Fitness: 0.3546\n",
      "    - New mask: 17 features, Fitness: 0.2135\n",
      "    - New mask: 21 features, Fitness: -0.4013\n",
      "    - New mask: 19 features, Fitness: -0.1200\n",
      "    - New mask: 16 features, Fitness: 0.4756\n",
      "    - New mask: 18 features, Fitness: 0.3738\n",
      "    - New mask: 20 features, Fitness: 0.0267\n",
      "    - New mask: 13 features, Fitness: 0.6891\n",
      "    - New mask: 17 features, Fitness: 0.2581\n",
      "    - New mask: 17 features, Fitness: 0.3192\n",
      "    - New mask: 19 features, Fitness: 0.1179\n",
      "    - New mask: 18 features, Fitness: 0.3552\n",
      "    - New mask: 13 features, Fitness: 0.6317\n",
      "    - New mask: 22 features, Fitness: -0.4409\n",
      "    - New mask: 18 features, Fitness: 0.1780\n",
      "    - New mask: 19 features, Fitness: 0.0770\n",
      "    - New mask: 19 features, Fitness: 0.0813\n",
      "    - New mask: 21 features, Fitness: -0.1398\n",
      "    - New mask: 18 features, Fitness: -0.5493\n",
      "    - New mask: 15 features, Fitness: 0.4711\n",
      "    - New mask: 15 features, Fitness: 0.5150\n",
      "    - New mask: 22 features, Fitness: -0.2990\n",
      "    - New mask: 21 features, Fitness: -0.1371\n",
      "    - New mask: 19 features, Fitness: -0.0503\n",
      "    - New mask: 22 features, Fitness: 1.7760\n",
      "    - New mask: 18 features, Fitness: 2.4617\n",
      "    - New mask: 17 features, Fitness: 1.5746\n",
      "    - New mask: 20 features, Fitness: 2.1098\n",
      "    - New mask: 19 features, Fitness: 1.9184\n",
      "    - New mask: 18 features, Fitness: 1.5549\n",
      "    - New mask: 15 features, Fitness: 1.7352\n",
      "    - New mask: 15 features, Fitness: 1.8169\n",
      "    - New mask: 18 features, Fitness: 1.7576\n",
      "    - New mask: 19 features, Fitness: 1.4702\n",
      "    - New mask: 17 features, Fitness: 1.6920\n",
      "    - New mask: 15 features, Fitness: 1.7281\n",
      "    - New mask: 18 features, Fitness: 2.4067\n",
      "    - New mask: 16 features, Fitness: 1.8242\n",
      "    - New mask: 16 features, Fitness: 1.9773\n",
      "    - New mask: 16 features, Fitness: 0.9485\n",
      "    - New mask: 18 features, Fitness: 2.2164\n",
      "    - New mask: 19 features, Fitness: 1.7381\n",
      "    - New mask: 21 features, Fitness: 1.8215\n",
      "    - New mask: 18 features, Fitness: 2.1501\n",
      "    - New mask: 18 features, Fitness: 1.6363\n",
      "    - New mask: 22 features, Fitness: 1.5007\n",
      "    - New mask: 19 features, Fitness: 2.2642\n",
      "    - New mask: 22 features, Fitness: 1.5703\n",
      "    - New mask: 21 features, Fitness: 1.5809\n",
      "    - New mask: 20 features, Fitness: 2.1018\n",
      "    - New mask: 19 features, Fitness: 2.0295\n",
      "    - New mask: 21 features, Fitness: 1.7752\n",
      "    - New mask: 20 features, Fitness: 1.9551\n",
      "    - New mask: 20 features, Fitness: 1.5261\n",
      "    - New mask: 17 features, Fitness: 0.8733\n",
      "    - New mask: 18 features, Fitness: 1.7061\n",
      "    - New mask: 20 features, Fitness: 2.3070\n",
      "    - New mask: 18 features, Fitness: 2.5115\n",
      "    - New mask: 16 features, Fitness: 2.3246\n",
      "    - New mask: 15 features, Fitness: 2.3888\n",
      "    - New mask: 20 features, Fitness: 2.1636\n",
      "    - New mask: 20 features, Fitness: 1.6015\n",
      "    - New mask: 21 features, Fitness: 1.9923\n",
      "    - New mask: 18 features, Fitness: 1.6609\n",
      "    - New mask: 22 features, Fitness: -1.0714\n",
      "    - New mask: 23 features, Fitness: -1.3964\n",
      "    - New mask: 20 features, Fitness: -1.5390\n",
      "    - New mask: 19 features, Fitness: -1.1800\n",
      "    - New mask: 18 features, Fitness: -0.2347\n",
      "    - New mask: 16 features, Fitness: -1.0058\n",
      "    - New mask: 19 features, Fitness: -1.1885\n",
      "    - New mask: 20 features, Fitness: -0.6213\n",
      "    - New mask: 21 features, Fitness: -1.6056\n",
      "    - New mask: 20 features, Fitness: -0.5708\n",
      "    - New mask: 16 features, Fitness: -0.9256\n",
      "    - New mask: 19 features, Fitness: -0.3918\n",
      "    - New mask: 17 features, Fitness: -0.7847\n",
      "    - New mask: 17 features, Fitness: -0.1115\n",
      "    - New mask: 18 features, Fitness: -1.3267\n",
      "    - New mask: 24 features, Fitness: -1.3587\n",
      "    - New mask: 19 features, Fitness: -0.2150\n",
      "    - New mask: 20 features, Fitness: -0.4785\n",
      "    - New mask: 18 features, Fitness: -0.9217\n",
      "    - New mask: 18 features, Fitness: -0.3986\n",
      "    - New mask: 16 features, Fitness: 0.3498\n",
      "    - New mask: 19 features, Fitness: -0.0453\n",
      "    - New mask: 17 features, Fitness: 0.2749\n",
      "    - New mask: 19 features, Fitness: -0.1200\n",
      "    - New mask: 22 features, Fitness: -0.6374\n",
      "    - New mask: 15 features, Fitness: 0.2709\n",
      "    - New mask: 20 features, Fitness: -0.3573\n",
      "    - New mask: 16 features, Fitness: 0.4132\n",
      "    - New mask: 17 features, Fitness: 0.1262\n",
      "    - New mask: 16 features, Fitness: 0.4451\n",
      "    - New mask: 21 features, Fitness: -0.4697\n",
      "    - New mask: 16 features, Fitness: 0.2802\n",
      "    - New mask: 16 features, Fitness: 0.2061\n",
      "    - New mask: 18 features, Fitness: -0.0628\n",
      "    - New mask: 16 features, Fitness: 0.1966\n",
      "    - New mask: 20 features, Fitness: -0.5449\n",
      "    - New mask: 17 features, Fitness: 0.1071\n",
      "    - New mask: 15 features, Fitness: -0.2729\n",
      "    - New mask: 18 features, Fitness: 0.1382\n",
      "    - New mask: 19 features, Fitness: 0.0570\n",
      "    - New mask: 18 features, Fitness: -0.1594\n",
      "    - New mask: 17 features, Fitness: -0.1089\n",
      "    - New mask: 17 features, Fitness: 0.1210\n",
      "    - New mask: 15 features, Fitness: 0.0953\n",
      "    - New mask: 17 features, Fitness: -0.0417\n",
      "    - New mask: 18 features, Fitness: -0.0438\n",
      "    - New mask: 16 features, Fitness: 0.0600\n",
      "    - New mask: 16 features, Fitness: 0.0147\n",
      "    - New mask: 18 features, Fitness: -0.0392\n",
      "    - New mask: 13 features, Fitness: 0.4727\n",
      "    - New mask: 19 features, Fitness: -0.4329\n",
      "    - New mask: 20 features, Fitness: -0.4516\n",
      "    - New mask: 16 features, Fitness: 0.2143\n",
      "    - New mask: 18 features, Fitness: -0.2904\n",
      "    - New mask: 18 features, Fitness: -0.4275\n",
      "    - New mask: 17 features, Fitness: 0.0624\n",
      "    - New mask: 17 features, Fitness: 0.1466\n",
      "    - New mask: 16 features, Fitness: 0.2025\n",
      "    - New mask: 20 features, Fitness: -0.4655\n",
      "    - New mask: 16 features, Fitness: 0.2737\n",
      "    - New mask: 17 features, Fitness: -0.6202\n",
      "    - New mask: 20 features, Fitness: -0.2659\n",
      "    - New mask: 19 features, Fitness: -0.2741\n",
      "    - New mask: 20 features, Fitness: -0.4888\n",
      "    - New mask: 15 features, Fitness: 0.3827\n",
      "    - New mask: 17 features, Fitness: 0.1153\n",
      "    - New mask: 19 features, Fitness: -0.3722\n",
      "    - New mask: 19 features, Fitness: -0.2389\n",
      "    - New mask: 16 features, Fitness: 0.2688\n",
      "    - New mask: 18 features, Fitness: -0.1504\n",
      "    - New mask: 18 features, Fitness: 0.0750\n",
      "    - New mask: 18 features, Fitness: -0.1901\n",
      "    - New mask: 18 features, Fitness: 0.1553\n",
      "    - New mask: 20 features, Fitness: -0.5334\n",
      "    - New mask: 23 features, Fitness: -1.4763\n",
      "    - New mask: 19 features, Fitness: -0.3262\n",
      "    - New mask: 17 features, Fitness: 0.0913\n",
      "    - New mask: 17 features, Fitness: 0.0810\n",
      "    - New mask: 19 features, Fitness: -0.0861\n",
      "    - New mask: 15 features, Fitness: 0.3827\n",
      "    - New mask: 21 features, Fitness: 0.1630\n",
      "    - New mask: 21 features, Fitness: -0.0723\n",
      "    - New mask: 17 features, Fitness: 0.4813\n",
      "    - New mask: 19 features, Fitness: 0.4869\n",
      "    - New mask: 18 features, Fitness: 0.5220\n",
      "    - New mask: 18 features, Fitness: 0.4882\n",
      "    - New mask: 20 features, Fitness: 0.3343\n",
      "    - New mask: 17 features, Fitness: 0.5511\n",
      "    - New mask: 20 features, Fitness: 0.2207\n",
      "    - New mask: 21 features, Fitness: -0.0758\n",
      "    - New mask: 19 features, Fitness: 0.2717\n",
      "    - New mask: 16 features, Fitness: 0.7198\n",
      "    - New mask: 20 features, Fitness: 0.3040\n",
      "    - New mask: 16 features, Fitness: 0.7481\n",
      "    - New mask: 18 features, Fitness: 0.3865\n",
      "    - New mask: 19 features, Fitness: 0.0265\n",
      "    - New mask: 18 features, Fitness: 0.4371\n",
      "    - New mask: 18 features, Fitness: 0.5179\n",
      "    - New mask: 18 features, Fitness: -0.4076\n",
      "    - New mask: 20 features, Fitness: 0.0351\n",
      "=== End of Round 19: Vote mask selects 11 features (rho: 0.77)\n",
      "    Indices: [2, 3, 10, 14, 15, 21, 23, 29, 31, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 20 ================\n",
      "  Adaptive rho for this round: 0.80\n",
      "    - New mask: 15 features, Fitness: 0.4497\n",
      "    - New mask: 13 features, Fitness: 0.5487\n",
      "    - New mask: 16 features, Fitness: -0.5620\n",
      "    - New mask: 12 features, Fitness: 0.5808\n",
      "    - New mask: 14 features, Fitness: 0.5127\n",
      "    - New mask: 15 features, Fitness: 0.2214\n",
      "    - New mask: 10 features, Fitness: 0.6874\n",
      "    - New mask: 17 features, Fitness: -0.0066\n",
      "    - New mask: 12 features, Fitness: 0.5402\n",
      "    - New mask: 14 features, Fitness: 0.3536\n",
      "    - New mask: 19 features, Fitness: -0.2638\n",
      "    - New mask: 11 features, Fitness: 0.4434\n",
      "    - New mask: 15 features, Fitness: 0.1504\n",
      "    - New mask: 14 features, Fitness: 0.3513\n",
      "    - New mask: 15 features, Fitness: 0.3488\n",
      "    - New mask: 16 features, Fitness: 0.3839\n",
      "    - New mask: 16 features, Fitness: 0.2578\n",
      "    - New mask: 17 features, Fitness: 0.2346\n",
      "    - New mask: 15 features, Fitness: 0.2523\n",
      "    - New mask: 16 features, Fitness: 0.1815\n",
      "    - New mask: 12 features, Fitness: 0.7253\n",
      "    - New mask: 15 features, Fitness: 0.3937\n",
      "    - New mask: 8 features, Fitness: 0.8236\n",
      "    - New mask: 17 features, Fitness: 0.2335\n",
      "    - New mask: 14 features, Fitness: 0.6076\n",
      "    - New mask: 18 features, Fitness: 0.0094\n",
      "    - New mask: 11 features, Fitness: 0.8093\n",
      "    - New mask: 13 features, Fitness: 0.7038\n",
      "    - New mask: 12 features, Fitness: 0.8000\n",
      "    - New mask: 14 features, Fitness: 0.5849\n",
      "    - New mask: 13 features, Fitness: 0.6257\n",
      "    - New mask: 14 features, Fitness: 0.5745\n",
      "    - New mask: 12 features, Fitness: 0.7352\n",
      "    - New mask: 12 features, Fitness: 0.6664\n",
      "    - New mask: 14 features, Fitness: 0.4940\n",
      "    - New mask: 13 features, Fitness: 0.6860\n",
      "    - New mask: 11 features, Fitness: 0.6417\n",
      "    - New mask: 14 features, Fitness: 0.5590\n",
      "    - New mask: 18 features, Fitness: -0.1199\n",
      "    - New mask: 14 features, Fitness: 0.5324\n",
      "    - New mask: 14 features, Fitness: 0.6950\n",
      "    - New mask: 17 features, Fitness: 0.3195\n",
      "    - New mask: 15 features, Fitness: 0.6092\n",
      "    - New mask: 13 features, Fitness: 0.6206\n",
      "    - New mask: 14 features, Fitness: 0.6089\n",
      "    - New mask: 12 features, Fitness: 0.7476\n",
      "    - New mask: 15 features, Fitness: 0.4758\n",
      "    - New mask: 13 features, Fitness: 0.6541\n",
      "    - New mask: 13 features, Fitness: 0.6905\n",
      "    - New mask: 17 features, Fitness: 0.3418\n",
      "    - New mask: 15 features, Fitness: 0.5870\n",
      "    - New mask: 16 features, Fitness: 0.3400\n",
      "    - New mask: 12 features, Fitness: 0.5882\n",
      "    - New mask: 16 features, Fitness: 0.5551\n",
      "    - New mask: 13 features, Fitness: -0.0596\n",
      "    - New mask: 12 features, Fitness: 0.7013\n",
      "    - New mask: 11 features, Fitness: 0.7842\n",
      "    - New mask: 17 features, Fitness: 0.2670\n",
      "    - New mask: 18 features, Fitness: 0.1434\n",
      "    - New mask: 14 features, Fitness: 0.6075\n",
      "    - New mask: 13 features, Fitness: 2.8288\n",
      "    - New mask: 16 features, Fitness: 1.5704\n",
      "    - New mask: 16 features, Fitness: 1.9884\n",
      "    - New mask: 21 features, Fitness: 1.9523\n",
      "    - New mask: 12 features, Fitness: 1.4105\n",
      "    - New mask: 14 features, Fitness: 1.8943\n",
      "    - New mask: 14 features, Fitness: 2.3804\n",
      "    - New mask: 15 features, Fitness: 1.8869\n",
      "    - New mask: 17 features, Fitness: 2.4615\n",
      "    - New mask: 16 features, Fitness: 1.2423\n",
      "    - New mask: 14 features, Fitness: 0.7773\n",
      "    - New mask: 14 features, Fitness: 1.6510\n",
      "    - New mask: 13 features, Fitness: 1.9551\n",
      "    - New mask: 18 features, Fitness: 1.7573\n",
      "    - New mask: 17 features, Fitness: 1.6367\n",
      "    - New mask: 15 features, Fitness: 1.3401\n",
      "    - New mask: 18 features, Fitness: 2.4487\n",
      "    - New mask: 12 features, Fitness: 1.8116\n",
      "    - New mask: 15 features, Fitness: 1.6405\n",
      "    - New mask: 15 features, Fitness: 2.1955\n",
      "    - New mask: 13 features, Fitness: 1.3989\n",
      "    - New mask: 17 features, Fitness: 1.2422\n",
      "    - New mask: 15 features, Fitness: 1.7163\n",
      "    - New mask: 17 features, Fitness: 1.4652\n",
      "    - New mask: 15 features, Fitness: 2.1520\n",
      "    - New mask: 17 features, Fitness: 2.0847\n",
      "    - New mask: 17 features, Fitness: 1.9597\n",
      "    - New mask: 15 features, Fitness: 1.3439\n",
      "    - New mask: 17 features, Fitness: 1.6099\n",
      "    - New mask: 16 features, Fitness: 1.8933\n",
      "    - New mask: 17 features, Fitness: 1.3507\n",
      "    - New mask: 15 features, Fitness: 2.3336\n",
      "    - New mask: 19 features, Fitness: 2.1127\n",
      "    - New mask: 17 features, Fitness: 2.0070\n",
      "    - New mask: 18 features, Fitness: 1.8728\n",
      "    - New mask: 14 features, Fitness: 2.3545\n",
      "    - New mask: 18 features, Fitness: 2.1750\n",
      "    - New mask: 16 features, Fitness: 2.0569\n",
      "    - New mask: 16 features, Fitness: 2.0371\n",
      "    - New mask: 17 features, Fitness: 2.3767\n",
      "    - New mask: 19 features, Fitness: -1.6121\n",
      "    - New mask: 17 features, Fitness: -0.0051\n",
      "    - New mask: 12 features, Fitness: -0.3602\n",
      "    - New mask: 13 features, Fitness: 0.4209\n",
      "    - New mask: 14 features, Fitness: -0.6519\n",
      "    - New mask: 20 features, Fitness: -0.6594\n",
      "    - New mask: 16 features, Fitness: -0.1305\n",
      "    - New mask: 17 features, Fitness: -0.0960\n",
      "    - New mask: 17 features, Fitness: -1.3879\n",
      "    - New mask: 16 features, Fitness: -0.0236\n",
      "    - New mask: 17 features, Fitness: -1.5531\n",
      "    - New mask: 13 features, Fitness: 0.4751\n",
      "    - New mask: 17 features, Fitness: -1.2133\n",
      "    - New mask: 12 features, Fitness: -0.4494\n",
      "    - New mask: 15 features, Fitness: -0.7464\n",
      "    - New mask: 15 features, Fitness: -0.8975\n",
      "    - New mask: 17 features, Fitness: -0.1677\n",
      "    - New mask: 15 features, Fitness: 0.1378\n",
      "    - New mask: 16 features, Fitness: -0.9893\n",
      "    - New mask: 12 features, Fitness: -0.3274\n",
      "    - New mask: 14 features, Fitness: 0.4540\n",
      "    - New mask: 17 features, Fitness: 0.2693\n",
      "    - New mask: 14 features, Fitness: 0.5000\n",
      "    - New mask: 13 features, Fitness: 0.4936\n",
      "    - New mask: 13 features, Fitness: 0.5909\n",
      "    - New mask: 13 features, Fitness: 0.5582\n",
      "    - New mask: 17 features, Fitness: -0.0220\n",
      "    - New mask: 13 features, Fitness: 0.6523\n",
      "    - New mask: 16 features, Fitness: 0.3591\n",
      "    - New mask: 15 features, Fitness: 0.4418\n",
      "    - New mask: 20 features, Fitness: -0.2886\n",
      "    - New mask: 16 features, Fitness: 0.0535\n",
      "    - New mask: 16 features, Fitness: 0.0831\n",
      "    - New mask: 16 features, Fitness: 0.4066\n",
      "    - New mask: 16 features, Fitness: 0.4288\n",
      "    - New mask: 15 features, Fitness: 0.0834\n",
      "    - New mask: 12 features, Fitness: 0.5853\n",
      "    - New mask: 13 features, Fitness: -0.1481\n",
      "    - New mask: 18 features, Fitness: 0.3135\n",
      "    - New mask: 14 features, Fitness: 0.5420\n",
      "    - New mask: 16 features, Fitness: 0.0164\n",
      "    - New mask: 10 features, Fitness: 0.6780\n",
      "    - New mask: 15 features, Fitness: 0.3003\n",
      "    - New mask: 13 features, Fitness: 0.3406\n",
      "    - New mask: 12 features, Fitness: 0.5967\n",
      "    - New mask: 14 features, Fitness: 0.3375\n",
      "    - New mask: 16 features, Fitness: -0.1033\n",
      "    - New mask: 14 features, Fitness: 0.2697\n",
      "    - New mask: 12 features, Fitness: 0.5112\n",
      "    - New mask: 12 features, Fitness: 0.5752\n",
      "    - New mask: 17 features, Fitness: -0.1913\n",
      "    - New mask: 17 features, Fitness: 0.0246\n",
      "    - New mask: 16 features, Fitness: 0.0244\n",
      "    - New mask: 16 features, Fitness: 0.0911\n",
      "    - New mask: 19 features, Fitness: -0.4977\n",
      "    - New mask: 15 features, Fitness: 0.3874\n",
      "    - New mask: 11 features, Fitness: 0.6471\n",
      "    - New mask: 13 features, Fitness: 0.4564\n",
      "    - New mask: 13 features, Fitness: 0.4225\n",
      "    - New mask: 13 features, Fitness: 0.3448\n",
      "    - New mask: 13 features, Fitness: -0.3284\n",
      "    - New mask: 18 features, Fitness: -0.1422\n",
      "    - New mask: 15 features, Fitness: 0.2055\n",
      "    - New mask: 18 features, Fitness: -0.1411\n",
      "    - New mask: 12 features, Fitness: 0.6615\n",
      "    - New mask: 15 features, Fitness: 0.3542\n",
      "    - New mask: 16 features, Fitness: 0.2314\n",
      "    - New mask: 17 features, Fitness: -0.0087\n",
      "    - New mask: 14 features, Fitness: 0.4747\n",
      "    - New mask: 15 features, Fitness: 0.2903\n",
      "    - New mask: 14 features, Fitness: 0.2812\n",
      "    - New mask: 13 features, Fitness: 0.4138\n",
      "    - New mask: 15 features, Fitness: 0.3202\n",
      "    - New mask: 19 features, Fitness: -0.7211\n",
      "    - New mask: 21 features, Fitness: -0.7916\n",
      "    - New mask: 17 features, Fitness: -0.0866\n",
      "    - New mask: 18 features, Fitness: -0.0451\n",
      "    - New mask: 17 features, Fitness: -0.1567\n",
      "    - New mask: 17 features, Fitness: 0.1686\n",
      "    - New mask: 13 features, Fitness: 0.4933\n",
      "    - New mask: 17 features, Fitness: 0.4940\n",
      "    - New mask: 15 features, Fitness: 0.8298\n",
      "    - New mask: 16 features, Fitness: 0.6346\n",
      "    - New mask: 11 features, Fitness: 0.9583\n",
      "    - New mask: 14 features, Fitness: 0.7652\n",
      "    - New mask: 15 features, Fitness: 0.6836\n",
      "    - New mask: 13 features, Fitness: 0.6344\n",
      "    - New mask: 16 features, Fitness: 0.4822\n",
      "    - New mask: 19 features, Fitness: 0.1822\n",
      "    - New mask: 15 features, Fitness: 0.8276\n",
      "    - New mask: 17 features, Fitness: 0.4556\n",
      "    - New mask: 12 features, Fitness: 0.9781\n",
      "    - New mask: 14 features, Fitness: 0.8068\n",
      "    - New mask: 14 features, Fitness: 0.7803\n",
      "    - New mask: 14 features, Fitness: 0.7911\n",
      "    - New mask: 15 features, Fitness: 0.4122\n",
      "    - New mask: 17 features, Fitness: 0.5425\n",
      "    - New mask: 15 features, Fitness: 0.7086\n",
      "    - New mask: 16 features, Fitness: -0.0820\n",
      "    - New mask: 14 features, Fitness: 0.8400\n",
      "=== End of Round 20: Vote mask selects 7 features (rho: 0.80)\n",
      "    Indices: [2, 14, 21, 23, 29, 31, 42]\n",
      "\n",
      "Final federated feature count: 7\n",
      "Selected feature names: ['Dport', 'Rate', 'SIntPkt', 'Proto', 'sDSb', 'dTtl', 'IdleTime']\n"
     ]
    }
   ],
   "source": [
    "n_feat_select_rounds = 20\n",
    "n_fireflies = 20           # Number of fireflies per client\n",
    "n_features = X.shape[1]\n",
    "num_clients = len(client_data_np)\n",
    "rho_start, rho_end = 0.2, 0.8\n",
    "penalty_lambda = 0.9\n",
    "\n",
    "# Precompute Fisher scores and correlation matrix for each client\n",
    "client_fisher_scores = []\n",
    "client_corr_matrix = []\n",
    "for Xc, yc in client_data_np:\n",
    "    fisher_scores = compute_fisher_scores(Xc, yc)\n",
    "    corr_matrix = compute_corr_matrix(Xc)\n",
    "    client_fisher_scores.append(fisher_scores)\n",
    "    client_corr_matrix.append(corr_matrix)\n",
    "\n",
    "# Initialize fireflies for each client at round 1\n",
    "client_fireflies = []\n",
    "client_local_bests = []\n",
    "for cid in range(num_clients):\n",
    "    fireflies = []\n",
    "    for _ in range(n_fireflies):\n",
    "        mask = np.random.choice([0, 1], size=n_features)\n",
    "        if np.sum(mask) == 0:\n",
    "            mask[np.random.randint(n_features)] = 1  # Ensure at least one feature is selected\n",
    "        fireflies.append(mask)\n",
    "    # Evaluate and store best\n",
    "    best_fitness = -np.inf\n",
    "    best_mask = None\n",
    "    for mask in fireflies:\n",
    "        sel = np.where(mask)[0]\n",
    "        fit = evaluate_feature_subset(sel, client_fisher_scores[cid], client_corr_matrix[cid], penalty_lambda)\n",
    "        if fit > best_fitness or best_mask is None:\n",
    "            best_fitness = fit\n",
    "            best_mask = mask.copy()\n",
    "    # Fallback: all features if somehow none was found\n",
    "    if best_mask is None:\n",
    "        best_mask = np.ones(n_features, dtype=int)\n",
    "    client_fireflies.append(fireflies)\n",
    "    client_local_bests.append(best_mask.copy())\n",
    "\n",
    "# Start with all features selected in global mask\n",
    "global_mask = np.ones(n_features, dtype=int)\n",
    "\n",
    "for round_fs in range(n_feat_select_rounds):\n",
    "    print(f\"\\n================ Federated BFA Round {round_fs+1} ================\")\n",
    "    # Linear schedule for rho\n",
    "    rho = rho_start + (rho_end - rho_start) * (round_fs / (n_feat_select_rounds - 1))\n",
    "    print(f\"  Adaptive rho for this round: {rho:.2f}\")\n",
    "\n",
    "    client_best_masks = []\n",
    "    # For each client, update fireflies and find new local best\n",
    "    for cid in range(num_clients):\n",
    "        fireflies = client_fireflies[cid]\n",
    "        fisher_scores = client_fisher_scores[cid]\n",
    "        corr_matrix = client_corr_matrix[cid]\n",
    "        local_best = client_local_bests[cid]\n",
    "        new_fireflies = []\n",
    "        best_fitness = -np.inf\n",
    "        best_mask = None\n",
    "        for f in range(n_fireflies):\n",
    "            new_mask = one_step_binary_firefly(\n",
    "                fireflies[f],\n",
    "                global_mask,\n",
    "                local_best,\n",
    "                fisher_scores,\n",
    "                corr_matrix,\n",
    "                penalty_lambda=penalty_lambda,\n",
    "                verbose=True\n",
    "            )\n",
    "            # Ensure at least one feature\n",
    "            if np.sum(new_mask) == 0:\n",
    "                new_mask[np.random.randint(n_features)] = 1\n",
    "            new_fireflies.append(new_mask)\n",
    "            sel = np.where(new_mask)[0]\n",
    "            fit = evaluate_feature_subset(sel, fisher_scores, corr_matrix, penalty_lambda)\n",
    "            if fit > best_fitness or best_mask is None:\n",
    "                best_fitness = fit\n",
    "                best_mask = new_mask.copy()\n",
    "        # Fallback: all features if somehow none was found\n",
    "        if best_mask is None:\n",
    "            best_mask = np.ones(n_features, dtype=int)\n",
    "        # Update client's fireflies and local best\n",
    "        client_fireflies[cid] = new_fireflies\n",
    "        client_local_bests[cid] = best_mask.copy()\n",
    "        client_best_masks.append(best_mask.copy())\n",
    "    client_best_masks = np.array(client_best_masks)\n",
    "    vote_counts = np.sum(client_best_masks, axis=0)\n",
    "    vote_mask = (vote_counts >= (rho * num_clients)).astype(int)\n",
    "    print(f\"=== End of Round {round_fs+1}: Vote mask selects {vote_mask.sum()} features (rho: {rho:.2f})\\n\"\n",
    "          f\"    Indices: {np.where(vote_mask)[0].tolist()}\")\n",
    "    global_mask = vote_mask.copy()\n",
    "\n",
    "selected_indices = np.where(global_mask == 1)[0]\n",
    "print(f\"\\nFinal federated feature count: {len(selected_indices)}\")\n",
    "selected_feature_names = [feature_cols[i] for i in selected_indices]\n",
    "print(\"Selected feature names:\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final federated feature count: 7\n",
      "Selected feature names: ['Dport', 'Rate', 'SIntPkt', 'Proto', 'sDSb', 'dTtl', 'IdleTime']\n"
     ]
    }
   ],
   "source": [
    "selected_indices = np.where(global_mask == 1)[0]\n",
    "print(f\"\\nFinal federated feature count: {len(selected_indices)}\")\n",
    "selected_feature_names = [feature_cols[i] for i in selected_indices]\n",
    "print(\"Selected feature names:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel = X[:, selected_indices]\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        features = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(features)\n",
    "        out = self.fc3(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 77.56% | Acc After: 99.03%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 81.78% | Acc After: 98.93%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 90.74% | Acc After: 98.84%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.27% | Acc After: 99.54%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.19% | Acc After: 99.24%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 80.80% | Acc After: 98.93%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 89.76% | Acc After: 98.81%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 57.60% | Acc After: 99.06%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 95.06% | Acc After: 98.98%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 98.76%\n",
      "Client Acc BEFORE (mean Â± std): 87.17% Â± 12.54%\n",
      "Client Acc AFTER  (mean Â± std): 99.13% Â± 0.35%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 97.78% | Acc After: 99.12%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.09% | Acc After: 98.92%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 98.67% | Acc After: 99.13%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.21% | Acc After: 99.55%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.20% | Acc After: 99.35%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.15% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 97.95% | Acc After: 99.14%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 98.61% | Acc After: 98.91%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 96.47% | Acc After: 99.06%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 98.97% | Acc After: 99.26%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 99.29%\n",
      "Client Acc BEFORE (mean Â± std): 98.41% Â± 0.82%\n",
      "Client Acc AFTER  (mean Â± std): 99.24% Â± 0.31%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.08% | Acc After: 99.23%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.09% | Acc After: 99.14%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.23% | Acc After: 99.13%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.39% | Acc After: 99.51%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.40% | Acc After: 99.43%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.37% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.11% | Acc After: 99.24%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.33% | Acc After: 98.94%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.74% | Acc After: 99.09%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.38% | Acc After: 99.25%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 99.27%\n",
      "Client Acc BEFORE (mean Â± std): 99.21% Â± 0.20%\n",
      "Client Acc AFTER  (mean Â± std): 99.29% Â± 0.28%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.12% | Acc After: 99.28%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.10% | Acc After: 99.17%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.27% | Acc After: 99.37%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.37% | Acc After: 99.52%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.39% | Acc After: 99.43%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.30% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.14% | Acc After: 99.27%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.24% | Acc After: 99.09%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.80% | Acc After: 99.08%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.36% | Acc After: 99.44%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 99.21%\n",
      "Client Acc BEFORE (mean Â± std): 99.21% Â± 0.17%\n",
      "Client Acc AFTER  (mean Â± std): 99.36% Â± 0.25%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.29% | Acc After: 99.18%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.54% | Acc After: 99.16%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.11% | Acc After: 99.49%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.67% | Acc After: 99.48%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.70% | Acc After: 99.44%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.63% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.46% | Acc After: 99.27%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.07% | Acc After: 99.41%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 97.09% | Acc After: 99.17%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.43% | Acc After: 99.45%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 99.21%\n",
      "Client Acc BEFORE (mean Â± std): 98.90% Â± 0.78%\n",
      "Client Acc AFTER  (mean Â± std): 99.40% Â± 0.23%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.04% | Acc After: 99.36%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.29% | Acc After: 99.39%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.07% | Acc After: 99.27%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.79% | Acc After: 99.55%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.77% | Acc After: 99.47%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.25% | Acc After: 99.34%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.02% | Acc After: 99.67%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 96.28% | Acc After: 99.20%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.42% | Acc After: 99.33%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 98.99%\n",
      "Client Acc BEFORE (mean Â± std): 98.78% Â± 1.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.46% Â± 0.22%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 97.48% | Acc After: 99.37%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 97.77% | Acc After: 99.45%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 98.80% | Acc After: 99.52%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.78% | Acc After: 99.66%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.73% | Acc After: 99.47%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 97.75% | Acc After: 99.42%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 98.72% | Acc After: 99.65%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 95.18% | Acc After: 99.24%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.30% | Acc After: 99.33%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 98.94%\n",
      "Client Acc BEFORE (mean Â± std): 98.44% Â± 1.37%\n",
      "Client Acc AFTER  (mean Â± std): 99.51% Â± 0.20%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 97.21% | Acc After: 99.39%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 97.61% | Acc After: 99.33%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 98.74% | Acc After: 99.48%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.77% | Acc After: 99.67%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.75% | Acc After: 99.64%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 97.61% | Acc After: 99.49%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 98.72% | Acc After: 99.59%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 94.82% | Acc After: 99.23%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.26% | Acc After: 99.58%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 97.98%\n",
      "Client Acc BEFORE (mean Â± std): 98.34% Â± 1.49%\n",
      "Client Acc AFTER  (mean Â± std): 99.54% Â± 0.20%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 94.33% | Acc After: 99.27%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 95.13% | Acc After: 99.48%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 97.54% | Acc After: 99.61%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.67% | Acc After: 99.69%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.64% | Acc After: 99.62%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 95.01% | Acc After: 99.43%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 97.40% | Acc After: 99.48%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 89.55% | Acc After: 99.11%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 98.69% | Acc After: 99.66%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 97.75%\n",
      "Client Acc BEFORE (mean Â± std): 96.68% Â± 3.08%\n",
      "Client Acc AFTER  (mean Â± std): 99.53% Â± 0.23%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 93.64% | Acc After: 99.30%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 94.56% | Acc After: 99.45%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 97.28% | Acc After: 99.39%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.65% | Acc After: 99.78%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.61% | Acc After: 99.61%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 94.43% | Acc After: 99.46%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 97.09% | Acc After: 99.63%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 88.19% | Acc After: 99.21%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 98.54% | Acc After: 99.21%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 99.55%\n",
      "Client Acc BEFORE (mean Â± std): 96.29% Â± 3.48%\n",
      "Client Acc AFTER  (mean Â± std): 99.50% Â± 0.24%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.02% | Acc After: 99.55%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.09% | Acc After: 99.40%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.47% | Acc After: 99.57%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.82% | Acc After: 99.71%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.82% | Acc After: 99.63%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.17% | Acc After: 99.45%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.61% | Acc After: 99.54%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.22% | Acc After: 99.29%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.65% | Acc After: 99.47%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 99.26%\n",
      "Client Acc BEFORE (mean Â± std): 99.37% Â± 0.49%\n",
      "Client Acc AFTER  (mean Â± std): 99.56% Â± 0.18%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.17% | Acc After: 99.42%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.34% | Acc After: 99.39%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.14% | Acc After: 99.30%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.79% | Acc After: 99.71%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.79% | Acc After: 99.83%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.49% | Acc After: 99.44%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.11% | Acc After: 99.65%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 96.65% | Acc After: 99.29%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.47% | Acc After: 99.70%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 99.53%\n",
      "Client Acc BEFORE (mean Â± std): 98.88% Â± 0.95%\n",
      "Client Acc AFTER  (mean Â± std): 99.57% Â± 0.23%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.96% | Acc After: 99.44%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.03% | Acc After: 99.42%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.44% | Acc After: 99.34%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.82% | Acc After: 99.41%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.81% | Acc After: 99.83%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.13% | Acc After: 99.46%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.52% | Acc After: 99.67%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.03% | Acc After: 99.22%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.63% | Acc After: 99.68%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 99.43%\n",
      "Client Acc BEFORE (mean Â± std): 99.32% Â± 0.54%\n",
      "Client Acc AFTER  (mean Â± std): 99.55% Â± 0.22%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.63% | Acc After: 99.46%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.71% | Acc After: 99.44%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.30% | Acc After: 99.63%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.81% | Acc After: 99.53%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.81% | Acc After: 99.73%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.97%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.87% | Acc After: 99.46%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.41% | Acc After: 99.74%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 97.47% | Acc After: 99.23%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.57% | Acc After: 99.64%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 99.36%\n",
      "Client Acc BEFORE (mean Â± std): 99.14% Â± 0.71%\n",
      "Client Acc AFTER  (mean Â± std): 99.58% Â± 0.19%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.51% | Acc After: 99.40%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.66% | Acc After: 99.40%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.27% | Acc After: 99.63%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.80% | Acc After: 99.84%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.79% | Acc After: 99.85%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.75% | Acc After: 99.39%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.28% | Acc After: 99.76%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 97.14% | Acc After: 99.33%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.53% | Acc After: 99.56%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 99.44%\n",
      "Client Acc BEFORE (mean Â± std): 99.06% Â± 0.79%\n",
      "Client Acc AFTER  (mean Â± std): 99.61% Â± 0.22%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.65% | Acc After: 99.44%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.74% | Acc After: 99.45%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.33% | Acc After: 99.62%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.80% | Acc After: 99.52%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.80% | Acc After: 99.81%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.95%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.89% | Acc After: 99.49%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.46% | Acc After: 99.48%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 97.53% | Acc After: 99.30%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.57% | Acc After: 99.77%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 99.45%\n",
      "Client Acc BEFORE (mean Â± std): 99.16% Â± 0.69%\n",
      "Client Acc AFTER  (mean Â± std): 99.58% Â± 0.19%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.73% | Acc After: 99.49%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 98.83% | Acc After: 99.45%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.35% | Acc After: 99.49%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.81% | Acc After: 99.41%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.81% | Acc After: 99.83%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.95%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 98.94% | Acc After: 99.48%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.48% | Acc After: 99.74%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 97.60% | Acc After: 99.21%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.59% | Acc After: 99.68%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 99.55%\n",
      "Client Acc BEFORE (mean Â± std): 99.20% Â± 0.67%\n",
      "Client Acc AFTER  (mean Â± std): 99.57% Â± 0.21%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.03% | Acc After: 99.29%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.11% | Acc After: 99.47%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.51% | Acc After: 99.72%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.82% | Acc After: 99.72%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.81% | Acc After: 99.71%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.95%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.19% | Acc After: 99.40%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.57% | Acc After: 99.72%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.20% | Acc After: 99.22%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.65% | Acc After: 99.56%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 99.57%\n",
      "Client Acc BEFORE (mean Â± std): 99.38% Â± 0.49%\n",
      "Client Acc AFTER  (mean Â± std): 99.58% Â± 0.22%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.09% | Acc After: 99.41%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.21% | Acc After: 99.56%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.55% | Acc After: 99.60%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.82% | Acc After: 99.53%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.82% | Acc After: 99.81%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.87% | Acc After: 99.87%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.25% | Acc After: 99.40%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.54% | Acc After: 99.74%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.33% | Acc After: 99.29%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.68% | Acc After: 99.56%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 99.60%\n",
      "Client Acc BEFORE (mean Â± std): 99.42% Â± 0.45%\n",
      "Client Acc AFTER  (mean Â± std): 99.58% Â± 0.18%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.35% | Acc After: 99.42%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.41% | Acc After: 99.53%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.59% | Acc After: 99.41%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.74% | Acc After: 99.69%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.78% | Acc After: 99.72%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.68% | Acc After: 99.90%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.42% | Acc After: 99.43%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.72% | Acc After: 99.72%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.94% | Acc After: 99.20%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.69% | Acc After: 99.64%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 99.66%\n",
      "Client Acc BEFORE (mean Â± std): 99.53% Â± 0.25%\n",
      "Client Acc AFTER  (mean Â± std): 99.57% Â± 0.19%\n",
      "Client sample count (min, max): 4650, 561481\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.66%\n",
      "Confusion Matrix:\n",
      " [[221114    376]\n",
      " [   441  16962]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_modelv2(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "    acc = 100. * correct / total\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    return acc, cm\n",
    "\n",
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def frhc_local_feature_selection(X, max_clusters=None, comp_feat=1):\n",
    "    \"\"\"\n",
    "    Local representative feature selection by hierarchical clustering of features.\n",
    "    \n",
    "    Parameters:\n",
    "        X: [n_samples, n_features] numpy array (client's local data)\n",
    "        max_clusters: int or None, maximum clusters to try for optimal selection\n",
    "        comp_feat: int, number of compensation features to add\n",
    "\n",
    "    Returns:\n",
    "        selected_feature_indices: list of selected feature indices\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    # Step 1: Compute absolute correlation distance between features\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    dist_matrix = 1 - np.abs(corr_matrix)\n",
    "    # Ensure distance matrix is valid\n",
    "    np.fill_diagonal(dist_matrix, 0)\n",
    "    # Convert to condensed form for linkage\n",
    "    condensed = squareform(dist_matrix, checks=False)\n",
    "    # Step 2: Hierarchical clustering\n",
    "    Z = linkage(condensed, method='average')\n",
    "    # Step 3: Optimal number of clusters (can be determined by a method, here use max_clusters or sqrt rule)\n",
    "    if max_clusters is None:\n",
    "        K = int(np.sqrt(n_features))\n",
    "    else:\n",
    "        K = min(max_clusters, n_features)\n",
    "    clusters = fcluster(Z, K, criterion='maxclust')\n",
    "    # Step 4: Find the two largest clusters\n",
    "    cluster_sizes = [(c, np.sum(clusters == c)) for c in np.unique(clusters)]\n",
    "    cluster_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_features = []\n",
    "    for i in range(min(2, len(cluster_sizes))):\n",
    "        c = cluster_sizes[i][0]\n",
    "        selected_features.extend(np.where(clusters == c)[0].tolist())\n",
    "    # Step 5: Optionally add compensation feature(s)\n",
    "    if comp_feat > 0:\n",
    "        feature_counts = [(c, np.sum(clusters == c)) for c in np.unique(clusters)]\n",
    "        cluster_sorted = sorted(feature_counts, key=lambda x: x[1], reverse=True)\n",
    "        # Add features from next largest clusters if needed\n",
    "        for i in range(2, min(2 + comp_feat, len(cluster_sorted))):\n",
    "            c = cluster_sorted[i][0]\n",
    "            selected_features.append(np.where(clusters == c)[0][0])\n",
    "    # Remove duplicates\n",
    "    selected_features = list(sorted(set(selected_features)))\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frhc_global_intersection(selected_lists):\n",
    "    \"\"\"\n",
    "    Compute global overlapping federated features as intersection of local sets.\n",
    "    Parameters:\n",
    "        selected_lists: list of list of feature indices (from each client)\n",
    "    Returns:\n",
    "        final_indices: list of feature indices present in all clients\n",
    "    \"\"\"\n",
    "    # Convert all to set for intersection\n",
    "    final_indices = set(selected_lists[0])\n",
    "    for feat_set in selected_lists[1:]:\n",
    "        final_indices &= set(feat_set)\n",
    "    return sorted(list(final_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 7\n",
      "Global federated feature indices (FRHC): [0, 1, 3, 18, 21, 30, 40]\n",
      "Selected feature names: ['Mean', 'Sport', 'SrcPkts', 'pLoss', 'SIntPkt', 'sTtl', 'SrcJitAct']\n"
     ]
    }
   ],
   "source": [
    "# Suppose client_data_np is a list of (X_local, y_local) for all clients\n",
    "selected_lists = []\n",
    "for Xc, yc in client_data_np:\n",
    "    feats = frhc_local_feature_selection(Xc,max_clusters=9,comp_feat=1)\n",
    "    selected_lists.append(feats)\n",
    "\n",
    "# Global intersection at the server\n",
    "global_frhc_indices = frhc_global_intersection(selected_lists)\n",
    "print(\"Count:\",len(global_frhc_indices))\n",
    "print(\"Global federated feature indices (FRHC):\", global_frhc_indices)\n",
    "print(\"Selected feature names:\", [feature_cols[i] for i in global_frhc_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices=global_frhc_indices\n",
    "X_sel = X[:, selected_indices]\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        features = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(features)\n",
    "        out = self.fc3(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 97.43% | Acc After: 99.91%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 97.68% | Acc After: 99.89%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 98.01% | Acc After: 99.56%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 98.47% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 98.57% | Acc After: 99.90%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 98.25% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 97.53% | Acc After: 99.88%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 98.39% | Acc After: 99.65%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 96.43% | Acc After: 99.79%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 98.22% | Acc After: 99.91%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 99.74%\n",
      "Client Acc BEFORE (mean Â± std): 97.90% Â± 0.62%\n",
      "Client Acc AFTER  (mean Â± std): 99.85% Â± 0.13%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.30% | Acc After: 99.93%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.45% | Acc After: 99.91%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.68% | Acc After: 97.76%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.95% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.95% | Acc After: 99.98%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 99.97% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.35% | Acc After: 99.94%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.70% | Acc After: 99.91%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.71% | Acc After: 99.84%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.82% | Acc After: 99.86%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 99.67%\n",
      "Client Acc BEFORE (mean Â± std): 99.59% Â± 0.38%\n",
      "Client Acc AFTER  (mean Â± std): 99.71% Â± 0.65%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 98.97% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.28% | Acc After: 99.95%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.55% | Acc After: 99.89%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.96% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.12% | Acc After: 99.81%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.50% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 98.14% | Acc After: 99.91%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.77% | Acc After: 99.97%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 99.84%\n",
      "Client Acc BEFORE (mean Â± std): 99.43% Â± 0.55%\n",
      "Client Acc AFTER  (mean Â± std): 99.94% Â± 0.05%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.52% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.69% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.79% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.98% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.56% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.78% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.10% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.89% | Acc After: 99.97%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 99.95%\n",
      "Client Acc BEFORE (mean Â± std): 99.73% Â± 0.27%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.86% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.93% | Acc After: 99.77%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.90% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.78% | Acc After: 99.91%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 99.90%\n",
      "Client Acc BEFORE (mean Â± std): 99.93% Â± 0.07%\n",
      "Client Acc AFTER  (mean Â± std): 99.95% Â± 0.07%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.72% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.83% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.88% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.76% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.85% | Acc After: 99.96%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.52% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.93% | Acc After: 99.99%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.85% Â± 0.14%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.89% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.94% | Acc After: 99.94%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.83% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 99.96%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.88% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.91% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.79% | Acc After: 99.89%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.94% Â± 0.06%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.91% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.85% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.86% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.90% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.83% | Acc After: 99.91%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.95% | Acc After: 99.94%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.85% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.92% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.95% | Acc After: 99.97%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.85% | Acc After: 99.91%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.91% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.95% | Acc After: 99.10%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.96%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.85% | Acc After: 99.90%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 99.81%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.88% Â± 0.26%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.45% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.58% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.77% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.97% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.53% | Acc After: 99.96%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.72% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.02% | Acc After: 99.91%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.87% | Acc After: 99.98%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.69% Â± 0.29%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.90% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.95% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.83% | Acc After: 99.89%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.98%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.86% | Acc After: 99.91%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.98%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.85% | Acc After: 99.89%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.94% | Acc After: 99.96%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.86% | Acc After: 99.88%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.84% | Acc After: 99.88%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.97%\n",
      "Confusion Matrix:\n",
      " [[221487      3]\n",
      " [    67  17336]]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_sel = X\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        features = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(features)\n",
    "        out = self.fc3(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 22.51% | Acc After: 99.88%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 18.27% | Acc After: 99.95%\n",
      "  Client  3 | Samples: 47228 | Acc Before:  9.36% | Acc After: 99.92%\n",
      "  Client  4 | Samples: 561481 | Acc Before:  0.91% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before:  0.97% | Acc After: 99.93%\n",
      "  Client  6 | Samples: 6137 | Acc Before:  0.17% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 19.26% | Acc After: 99.94%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 10.31% | Acc After: 99.83%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 42.25% | Acc After: 99.87%\n",
      "  Client 10 | Samples: 70089 | Acc Before:  5.09% | Acc After: 99.95%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 99.88%\n",
      "Client Acc BEFORE (mean Â± std): 12.91% Â± 12.46%\n",
      "Client Acc AFTER  (mean Â± std): 99.93% Â± 0.05%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.68% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.77% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.83% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.98% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.71% | Acc After: 99.96%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.93% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.38% | Acc After: 99.92%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.92% | Acc After: 99.98%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.82% Â± 0.18%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.91% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.95% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.84% | Acc After: 99.94%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.93% | Acc After: 99.92%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.95% | Acc After: 99.93%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.98% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.88% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 99.96%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.03%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.03%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.91% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.94% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.92% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.84% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.92% | Acc After: 99.96%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.97% Â± 0.03%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.92% | Acc After: 99.96%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.97% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.97% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.94%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.95%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.99% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.96% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.94% | Acc After: 99.96%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.02%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.01%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.01%\n",
      "Client Acc AFTER  (mean Â± std): 99.99% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.94%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.01%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.02%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.01%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.96%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client 10 | Samples: 70089 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.98% Â± 0.01%\n",
      "Client Acc AFTER  (mean Â± std): 99.98% Â± 0.01%\n",
      "Client sample count (min, max): 4650, 561481\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 83796 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 42092 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 47228 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  4 | Samples: 561481 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 15006 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  6 | Samples: 6137 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 96532 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  8 | Samples: 4650 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 28560 | Acc Before: 99.95% | Acc After: 99.95%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1303049,
     "sourceId": 2260912,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
