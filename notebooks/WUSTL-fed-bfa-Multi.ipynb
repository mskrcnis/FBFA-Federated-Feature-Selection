{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For IoT IDS\n",
    "csv_path = 'wustl_corrected.csv'\n",
    "df = pd.read_csv(csv_path,low_memory=False)\n",
    "#print(df.columns)\n",
    "#print(df.shape)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartTime', 'LastTime', 'SrcAddr', 'DstAddr', 'Mean', 'Sport', 'Dport',\n",
       "       'SrcPkts', 'DstPkts', 'TotPkts', 'DstBytes', 'SrcBytes', 'TotBytes',\n",
       "       'SrcLoad', 'DstLoad', 'Load', 'SrcRate', 'DstRate', 'Rate', 'SrcLoss',\n",
       "       'DstLoss', 'Loss', 'pLoss', 'SrcJitter', 'DstJitter', 'SIntPkt',\n",
       "       'DIntPkt', 'Proto', 'Dur', 'TcpRtt', 'Sum', 'Min', 'Max', 'sDSb',\n",
       "       'sTtl', 'dTtl', 'sIpId', 'dIpId', 'SAppBytes', 'DAppBytes',\n",
       "       'TotAppByte', 'SynAck', 'RunTime', 'sTos', 'SrcJitAct', 'DstJitAct',\n",
       "       'Traffic', 'Target', 'IdleTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LastTime</th>\n",
       "      <th>SrcAddr</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dport</th>\n",
       "      <th>SrcPkts</th>\n",
       "      <th>DstPkts</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>...</th>\n",
       "      <th>DAppBytes</th>\n",
       "      <th>TotAppByte</th>\n",
       "      <th>SynAck</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>sTos</th>\n",
       "      <th>SrcJitAct</th>\n",
       "      <th>DstJitAct</th>\n",
       "      <th>Traffic</th>\n",
       "      <th>Target</th>\n",
       "      <th>IdleTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-19 09:46:08</td>\n",
       "      <td>2019-08-19 14:14:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-19 13:24:34</td>\n",
       "      <td>2019-08-19 14:14:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-19 11:05:18</td>\n",
       "      <td>2019-08-19 11:04:18</td>\n",
       "      <td>0</td>\n",
       "      <td>14740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>90864</td>\n",
       "      <td>11501</td>\n",
       "      <td>90864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019535332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-19 12:30:18</td>\n",
       "      <td>2019-08-19 12:29:18</td>\n",
       "      <td>0</td>\n",
       "      <td>15046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11560267</td>\n",
       "      <td>154248</td>\n",
       "      <td>11560267</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3488030376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-19 11:10:18</td>\n",
       "      <td>2019-08-19 11:09:18</td>\n",
       "      <td>0</td>\n",
       "      <td>16274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93115</td>\n",
       "      <td>14011</td>\n",
       "      <td>93115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2138927796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartTime             LastTime SrcAddr DstAddr  Mean  Sport  \\\n",
       "0  2019-08-19 09:46:08  2019-08-19 14:14:18       0       0     0      0   \n",
       "1  2019-08-19 13:24:34  2019-08-19 14:14:18       0       0     0      0   \n",
       "2  2019-08-19 11:05:18  2019-08-19 11:04:18       0   14740     0      0   \n",
       "3  2019-08-19 12:30:18  2019-08-19 12:29:18       0   15046     0      0   \n",
       "4  2019-08-19 11:10:18  2019-08-19 11:09:18       0   16274     0      0   \n",
       "\n",
       "   Dport   SrcPkts  DstPkts   TotPkts  ...  DAppBytes  TotAppByte  SynAck  \\\n",
       "0      0         0        0         0  ...          0           0     0.0   \n",
       "1      0         0        0         0  ...          0           0     0.0   \n",
       "2      2     90864    11501     90864  ...          0  2019535332     0.0   \n",
       "3      2  11560267   154248  11560267  ...          0  3488030376     0.0   \n",
       "4      2     93115    14011     93115  ...          0  2138927796     0.0   \n",
       "\n",
       "   RunTime  sTos  SrcJitAct  DstJitAct  Traffic  Target  IdleTime  \n",
       "0      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "1      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "2      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "3      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "4      0.0     0        0.0        0.0   normal       0       0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic\n",
      "normal      1107448\n",
      "DoS           78305\n",
      "Reconn         8240\n",
      "CommInj         259\n",
      "Backdoor        212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Traffic'].value_counts())\n",
    "# Now, remap your classes as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['StartTime', 'LastTime', 'SrcAddr', 'DstAddr','Traffic','Target']\n",
    "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "label_col = 'Traffic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "X = df[feature_cols].values\n",
    "y = df[label_col].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features removed: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.0)\n",
    "X_var = var_thresh.fit_transform(X)\n",
    "print(f\"Constant features removed: {X.shape[1] - X_var.shape[1]}\")\n",
    "X = X_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 class distribution: [     4     32    711   4566 169522]\n",
      "Client 2 class distribution: [    9     1  2326   515 91731]\n",
      "Client 3 class distribution: [   42     3    28   640 24081]\n",
      "Client 4 class distribution: [     0     97   1440     24 117109]\n",
      "Client 5 class distribution: [   64     9  7958   219 40444]\n",
      "Client 6 class distribution: [     1      0   3634     52 213912]\n",
      "Client 7 class distribution: [     5     10   2724    117 128339]\n",
      "Client 8 class distribution: [    0     3 30297   314 73005]\n",
      "Client 9 class distribution: [   44    47 12706    81  3065]\n",
      "Client 10 class distribution: [    1     5   820    64 24750]\n"
     ]
    }
   ],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "full_dataset = TabularDataset(X, y)\n",
    "train_idx, test_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, stratify=y, random_state=6)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "def partition_tabular_dataset(dataset, labels, train_idx, num_clients=10, alpha=0.5):\n",
    "    np.random.seed(6)\n",
    "    targets = np.array(labels)[train_idx]\n",
    "    num_classes = np.max(targets) + 1\n",
    "    idxs = np.arange(len(targets))\n",
    "    client_idx = [[] for _ in range(num_clients)]\n",
    "    for c in range(num_classes):\n",
    "        idx_c = idxs[targets == c]\n",
    "        np.random.shuffle(idx_c)\n",
    "        proportions = np.random.dirichlet([alpha]*num_clients)\n",
    "        proportions = (np.cumsum(proportions) * len(idx_c)).astype(int)[:-1]\n",
    "        split_idxs = np.split(idx_c, proportions)\n",
    "        for i, idx in enumerate(split_idxs):\n",
    "            client_idx[i].extend(idx)\n",
    "    return client_idx\n",
    "\n",
    "num_clients = 10\n",
    "alpha = 0.5\n",
    "client_indices = partition_tabular_dataset(train_dataset, y, train_idx, num_clients, alpha)\n",
    "\n",
    "client_data_np = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    X_client = X[train_idx][idxs]\n",
    "    y_client = y[train_idx][idxs]\n",
    "    client_data_np.append((X_client, y_client))\n",
    "\n",
    "for i, (Xc, yc) in enumerate(client_data_np):\n",
    "    print(f\"Client {i+1} class distribution:\", np.bincount(yc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_scores(X, y):\n",
    "    scores, _ = f_classif(X, y)\n",
    "    # Normalize scores to [0,1]\n",
    "    min_val = np.min(scores)\n",
    "    max_val = np.max(scores)\n",
    "    if max_val > min_val:\n",
    "        normalized_scores = (scores - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_scores = np.zeros_like(scores)\n",
    "    return normalized_scores\n",
    "\n",
    "def compute_corr_matrix(X):\n",
    "    corr = np.corrcoef(X, rowvar=False)\n",
    "    return np.abs(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_feature_subset(subset, fisher_scores, corr_matrix, penalty_lambda=0.7):\n",
    "    if len(subset) == 0:\n",
    "        return 0\n",
    "    fisher_sum = np.sum(fisher_scores[subset])\n",
    "    if len(subset) > 1:\n",
    "        corr_penalty = np.sum(corr_matrix[np.ix_(subset, subset)]) - np.sum(np.diag(corr_matrix[subset][:, subset]))\n",
    "        corr_penalty /= 2\n",
    "    else:\n",
    "        corr_penalty = 0.0\n",
    "    return penalty_lambda * fisher_sum - (1 - penalty_lambda) * corr_penalty\n",
    "\n",
    "def one_step_binary_firefly(\n",
    "    firefly_mask_prev, global_mask_prev, local_best_mask_prev,\n",
    "    fisher_scores, corr_matrix, penalty_lambda=0.7, p_global=0.3, p_local=0.3, mutation_rate=0.05, verbose=False\n",
    "):\n",
    "    n_features = len(firefly_mask_prev)\n",
    "    new_mask = firefly_mask_prev.copy()\n",
    "    for i in range(n_features):\n",
    "        r = np.random.rand()\n",
    "        if r < p_global:\n",
    "            new_mask[i] = global_mask_prev[i]\n",
    "        elif r < p_global + p_local:\n",
    "            new_mask[i] = local_best_mask_prev[i]\n",
    "        elif np.random.rand() < mutation_rate:\n",
    "            new_mask[i] = 1 - new_mask[i]  # mutate\n",
    "\n",
    "    # Optional: flip one bit with small probability for extra exploration\n",
    "    if np.random.rand() < 0.2:\n",
    "        idx = np.random.randint(n_features)\n",
    "        new_mask[idx] = 1 - new_mask[idx]\n",
    "\n",
    "    if verbose:\n",
    "        sel = np.where(new_mask)[0]\n",
    "        fit = evaluate_feature_subset(sel, fisher_scores, corr_matrix, penalty_lambda)\n",
    "        print(f\"    - New mask: {np.sum(new_mask)} features, Fitness: {fit:.4f}\")\n",
    "\n",
    "    return new_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Federated BFA Round 1 ================\n",
      "  Adaptive rho for this round: 0.20\n",
      "    - New mask: 32 features, Fitness: -1.9649\n",
      "    - New mask: 30 features, Fitness: -2.5025\n",
      "    - New mask: 26 features, Fitness: -1.2879\n",
      "    - New mask: 29 features, Fitness: -0.9003\n",
      "    - New mask: 22 features, Fitness: 0.7260\n",
      "    - New mask: 32 features, Fitness: -1.6593\n",
      "    - New mask: 29 features, Fitness: -0.9314\n",
      "    - New mask: 28 features, Fitness: -1.1427\n",
      "    - New mask: 26 features, Fitness: -0.2693\n",
      "    - New mask: 24 features, Fitness: -0.4621\n",
      "    - New mask: 28 features, Fitness: -0.3458\n",
      "    - New mask: 32 features, Fitness: -1.6361\n",
      "    - New mask: 31 features, Fitness: -1.7771\n",
      "    - New mask: 29 features, Fitness: -1.4027\n",
      "    - New mask: 31 features, Fitness: -2.4309\n",
      "    - New mask: 29 features, Fitness: -1.3634\n",
      "    - New mask: 32 features, Fitness: -3.7715\n",
      "    - New mask: 29 features, Fitness: -2.3686\n",
      "    - New mask: 24 features, Fitness: -0.3966\n",
      "    - New mask: 30 features, Fitness: -0.7125\n",
      "    - New mask: 27 features, Fitness: -2.6818\n",
      "    - New mask: 25 features, Fitness: -1.8548\n",
      "    - New mask: 28 features, Fitness: -2.4333\n",
      "    - New mask: 21 features, Fitness: -2.1386\n",
      "    - New mask: 27 features, Fitness: -2.2833\n",
      "    - New mask: 27 features, Fitness: -3.5135\n",
      "    - New mask: 26 features, Fitness: -2.2707\n",
      "    - New mask: 28 features, Fitness: -3.0273\n",
      "    - New mask: 28 features, Fitness: -3.7522\n",
      "    - New mask: 25 features, Fitness: -1.7997\n",
      "    - New mask: 26 features, Fitness: -2.5178\n",
      "    - New mask: 25 features, Fitness: -1.7762\n",
      "    - New mask: 25 features, Fitness: -3.3327\n",
      "    - New mask: 24 features, Fitness: -2.5516\n",
      "    - New mask: 26 features, Fitness: -2.2236\n",
      "    - New mask: 26 features, Fitness: -2.4971\n",
      "    - New mask: 29 features, Fitness: -4.6128\n",
      "    - New mask: 29 features, Fitness: -3.1370\n",
      "    - New mask: 27 features, Fitness: -2.9954\n",
      "    - New mask: 28 features, Fitness: -5.2665\n",
      "    - New mask: 28 features, Fitness: -1.3333\n",
      "    - New mask: 26 features, Fitness: -0.6925\n",
      "    - New mask: 24 features, Fitness: -0.6537\n",
      "    - New mask: 28 features, Fitness: -1.8308\n",
      "    - New mask: 31 features, Fitness: -1.5210\n",
      "    - New mask: 26 features, Fitness: -1.9201\n",
      "    - New mask: 21 features, Fitness: 0.6356\n",
      "    - New mask: 31 features, Fitness: -3.6139\n",
      "    - New mask: 27 features, Fitness: -0.6322\n",
      "    - New mask: 31 features, Fitness: -2.6863\n",
      "    - New mask: 28 features, Fitness: -1.3335\n",
      "    - New mask: 28 features, Fitness: -1.0862\n",
      "    - New mask: 25 features, Fitness: 0.0299\n",
      "    - New mask: 26 features, Fitness: -1.7391\n",
      "    - New mask: 27 features, Fitness: 0.4006\n",
      "    - New mask: 26 features, Fitness: -1.7525\n",
      "    - New mask: 29 features, Fitness: -1.5890\n",
      "    - New mask: 29 features, Fitness: -2.1126\n",
      "    - New mask: 26 features, Fitness: -0.8278\n",
      "    - New mask: 32 features, Fitness: -3.5448\n",
      "    - New mask: 23 features, Fitness: 0.7804\n",
      "    - New mask: 24 features, Fitness: -0.5219\n",
      "    - New mask: 24 features, Fitness: -0.6758\n",
      "    - New mask: 30 features, Fitness: -1.4730\n",
      "    - New mask: 26 features, Fitness: -2.7529\n",
      "    - New mask: 30 features, Fitness: -1.2747\n",
      "    - New mask: 24 features, Fitness: 0.3316\n",
      "    - New mask: 33 features, Fitness: -2.3049\n",
      "    - New mask: 28 features, Fitness: -0.5630\n",
      "    - New mask: 25 features, Fitness: -0.3525\n",
      "    - New mask: 27 features, Fitness: -0.7162\n",
      "    - New mask: 30 features, Fitness: -1.2612\n",
      "    - New mask: 23 features, Fitness: 0.3904\n",
      "    - New mask: 23 features, Fitness: 0.0028\n",
      "    - New mask: 28 features, Fitness: -0.9188\n",
      "    - New mask: 29 features, Fitness: -0.7147\n",
      "    - New mask: 32 features, Fitness: -1.8814\n",
      "    - New mask: 26 features, Fitness: -1.5701\n",
      "    - New mask: 27 features, Fitness: -0.5992\n",
      "    - New mask: 25 features, Fitness: -0.6344\n",
      "    - New mask: 25 features, Fitness: -1.7590\n",
      "    - New mask: 21 features, Fitness: -0.9532\n",
      "    - New mask: 23 features, Fitness: -1.7604\n",
      "    - New mask: 37 features, Fitness: -6.7199\n",
      "    - New mask: 28 features, Fitness: -3.8581\n",
      "    - New mask: 21 features, Fitness: -1.0986\n",
      "    - New mask: 30 features, Fitness: -3.7259\n",
      "    - New mask: 19 features, Fitness: -1.4487\n",
      "    - New mask: 25 features, Fitness: -3.0394\n",
      "    - New mask: 29 features, Fitness: -3.5465\n",
      "    - New mask: 29 features, Fitness: -3.5319\n",
      "    - New mask: 24 features, Fitness: -2.7511\n",
      "    - New mask: 23 features, Fitness: -2.7855\n",
      "    - New mask: 23 features, Fitness: -1.3549\n",
      "    - New mask: 28 features, Fitness: -4.1150\n",
      "    - New mask: 26 features, Fitness: -2.3443\n",
      "    - New mask: 31 features, Fitness: -4.4928\n",
      "    - New mask: 30 features, Fitness: -2.7062\n",
      "    - New mask: 28 features, Fitness: -2.8561\n",
      "    - New mask: 25 features, Fitness: -2.8916\n",
      "    - New mask: 25 features, Fitness: 0.9119\n",
      "    - New mask: 26 features, Fitness: -1.0603\n",
      "    - New mask: 30 features, Fitness: -0.9449\n",
      "    - New mask: 29 features, Fitness: -1.5437\n",
      "    - New mask: 31 features, Fitness: -2.2563\n",
      "    - New mask: 24 features, Fitness: -0.2526\n",
      "    - New mask: 25 features, Fitness: -1.3158\n",
      "    - New mask: 26 features, Fitness: -1.7633\n",
      "    - New mask: 26 features, Fitness: -0.4081\n",
      "    - New mask: 25 features, Fitness: -0.1455\n",
      "    - New mask: 25 features, Fitness: -0.8734\n",
      "    - New mask: 27 features, Fitness: -2.1040\n",
      "    - New mask: 21 features, Fitness: 0.0985\n",
      "    - New mask: 28 features, Fitness: -0.5290\n",
      "    - New mask: 21 features, Fitness: 0.6500\n",
      "    - New mask: 24 features, Fitness: -1.1364\n",
      "    - New mask: 27 features, Fitness: -1.2604\n",
      "    - New mask: 29 features, Fitness: -1.0148\n",
      "    - New mask: 22 features, Fitness: 0.4047\n",
      "    - New mask: 27 features, Fitness: -0.4479\n",
      "    - New mask: 28 features, Fitness: 0.3375\n",
      "    - New mask: 22 features, Fitness: 0.3665\n",
      "    - New mask: 28 features, Fitness: -0.7480\n",
      "    - New mask: 24 features, Fitness: -1.1461\n",
      "    - New mask: 26 features, Fitness: 0.2811\n",
      "    - New mask: 33 features, Fitness: -1.7174\n",
      "    - New mask: 30 features, Fitness: -0.3167\n",
      "    - New mask: 22 features, Fitness: -0.6630\n",
      "    - New mask: 30 features, Fitness: -1.1845\n",
      "    - New mask: 21 features, Fitness: 0.5990\n",
      "    - New mask: 27 features, Fitness: -0.6021\n",
      "    - New mask: 26 features, Fitness: -0.4708\n",
      "    - New mask: 23 features, Fitness: -0.6474\n",
      "    - New mask: 19 features, Fitness: -0.2134\n",
      "    - New mask: 30 features, Fitness: -0.4179\n",
      "    - New mask: 22 features, Fitness: 0.4691\n",
      "    - New mask: 26 features, Fitness: 0.1621\n",
      "    - New mask: 29 features, Fitness: -0.5679\n",
      "    - New mask: 29 features, Fitness: -0.9762\n",
      "    - New mask: 33 features, Fitness: -1.4592\n",
      "    - New mask: 31 features, Fitness: -5.5839\n",
      "    - New mask: 29 features, Fitness: -4.5002\n",
      "    - New mask: 28 features, Fitness: -3.2395\n",
      "    - New mask: 25 features, Fitness: -2.1833\n",
      "    - New mask: 20 features, Fitness: -1.2505\n",
      "    - New mask: 27 features, Fitness: -3.6536\n",
      "    - New mask: 27 features, Fitness: -3.1379\n",
      "    - New mask: 26 features, Fitness: -2.8987\n",
      "    - New mask: 24 features, Fitness: -2.0492\n",
      "    - New mask: 33 features, Fitness: -5.5392\n",
      "    - New mask: 29 features, Fitness: -3.9978\n",
      "    - New mask: 31 features, Fitness: -3.9612\n",
      "    - New mask: 28 features, Fitness: -4.0367\n",
      "    - New mask: 29 features, Fitness: -3.1172\n",
      "    - New mask: 28 features, Fitness: -3.0062\n",
      "    - New mask: 23 features, Fitness: -1.6953\n",
      "    - New mask: 21 features, Fitness: -1.3889\n",
      "    - New mask: 27 features, Fitness: -2.7619\n",
      "    - New mask: 34 features, Fitness: -5.9006\n",
      "    - New mask: 25 features, Fitness: -2.5921\n",
      "    - New mask: 27 features, Fitness: -5.2367\n",
      "    - New mask: 26 features, Fitness: -3.1815\n",
      "    - New mask: 26 features, Fitness: -3.8938\n",
      "    - New mask: 29 features, Fitness: -4.8224\n",
      "    - New mask: 26 features, Fitness: -4.3466\n",
      "    - New mask: 28 features, Fitness: -3.4897\n",
      "    - New mask: 22 features, Fitness: -1.3017\n",
      "    - New mask: 27 features, Fitness: -4.3003\n",
      "    - New mask: 24 features, Fitness: -1.9956\n",
      "    - New mask: 26 features, Fitness: -2.8179\n",
      "    - New mask: 30 features, Fitness: -7.7136\n",
      "    - New mask: 24 features, Fitness: -3.6182\n",
      "    - New mask: 27 features, Fitness: -3.5501\n",
      "    - New mask: 31 features, Fitness: -5.1382\n",
      "    - New mask: 29 features, Fitness: -4.8928\n",
      "    - New mask: 31 features, Fitness: -5.8144\n",
      "    - New mask: 25 features, Fitness: -3.0933\n",
      "    - New mask: 29 features, Fitness: -4.3913\n",
      "    - New mask: 24 features, Fitness: -3.5499\n",
      "    - New mask: 30 features, Fitness: -7.3805\n",
      "    - New mask: 24 features, Fitness: -1.0026\n",
      "    - New mask: 25 features, Fitness: -1.1041\n",
      "    - New mask: 21 features, Fitness: 0.5769\n",
      "    - New mask: 23 features, Fitness: -1.6155\n",
      "    - New mask: 24 features, Fitness: -3.3903\n",
      "    - New mask: 26 features, Fitness: -0.9479\n",
      "    - New mask: 23 features, Fitness: -0.6281\n",
      "    - New mask: 24 features, Fitness: -1.1238\n",
      "    - New mask: 32 features, Fitness: -3.7345\n",
      "    - New mask: 20 features, Fitness: -0.2100\n",
      "    - New mask: 24 features, Fitness: -1.1890\n",
      "    - New mask: 20 features, Fitness: -0.5106\n",
      "    - New mask: 23 features, Fitness: 0.1509\n",
      "    - New mask: 30 features, Fitness: -3.1433\n",
      "    - New mask: 32 features, Fitness: -1.9254\n",
      "    - New mask: 28 features, Fitness: -1.7577\n",
      "    - New mask: 24 features, Fitness: 0.3499\n",
      "    - New mask: 24 features, Fitness: -0.5834\n",
      "    - New mask: 30 features, Fitness: -0.8091\n",
      "    - New mask: 29 features, Fitness: -2.7623\n",
      "=== End of Round 1: Vote mask selects 43 features (rho: 0.20)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 2 ================\n",
      "  Adaptive rho for this round: 0.23\n",
      "    - New mask: 37 features, Fitness: -3.8970\n",
      "    - New mask: 29 features, Fitness: -2.7776\n",
      "    - New mask: 28 features, Fitness: -1.4550\n",
      "    - New mask: 32 features, Fitness: -2.4144\n",
      "    - New mask: 26 features, Fitness: -0.3465\n",
      "    - New mask: 31 features, Fitness: -1.6366\n",
      "    - New mask: 30 features, Fitness: -0.7838\n",
      "    - New mask: 27 features, Fitness: -0.8422\n",
      "    - New mask: 29 features, Fitness: -0.6328\n",
      "    - New mask: 31 features, Fitness: -1.6240\n",
      "    - New mask: 32 features, Fitness: -1.7653\n",
      "    - New mask: 33 features, Fitness: -2.1819\n",
      "    - New mask: 30 features, Fitness: -1.7694\n",
      "    - New mask: 28 features, Fitness: -0.5082\n",
      "    - New mask: 29 features, Fitness: -2.4725\n",
      "    - New mask: 30 features, Fitness: -1.1630\n",
      "    - New mask: 29 features, Fitness: -1.6098\n",
      "    - New mask: 28 features, Fitness: -0.9014\n",
      "    - New mask: 28 features, Fitness: -1.2187\n",
      "    - New mask: 31 features, Fitness: -1.5229\n",
      "    - New mask: 32 features, Fitness: -4.1826\n",
      "    - New mask: 33 features, Fitness: -3.8035\n",
      "    - New mask: 30 features, Fitness: -2.8116\n",
      "    - New mask: 29 features, Fitness: -2.6433\n",
      "    - New mask: 30 features, Fitness: -3.0110\n",
      "    - New mask: 36 features, Fitness: -5.9318\n",
      "    - New mask: 24 features, Fitness: -2.3578\n",
      "    - New mask: 32 features, Fitness: -4.5584\n",
      "    - New mask: 28 features, Fitness: -2.7639\n",
      "    - New mask: 33 features, Fitness: -3.9551\n",
      "    - New mask: 26 features, Fitness: -2.5079\n",
      "    - New mask: 30 features, Fitness: -3.2000\n",
      "    - New mask: 30 features, Fitness: -3.2523\n",
      "    - New mask: 28 features, Fitness: -3.3863\n",
      "    - New mask: 30 features, Fitness: -3.2909\n",
      "    - New mask: 29 features, Fitness: -2.9738\n",
      "    - New mask: 31 features, Fitness: -4.6502\n",
      "    - New mask: 36 features, Fitness: -5.3477\n",
      "    - New mask: 31 features, Fitness: -3.6052\n",
      "    - New mask: 30 features, Fitness: -4.5016\n",
      "    - New mask: 29 features, Fitness: -1.2756\n",
      "    - New mask: 25 features, Fitness: 0.4454\n",
      "    - New mask: 32 features, Fitness: -3.3937\n",
      "    - New mask: 29 features, Fitness: -0.9191\n",
      "    - New mask: 33 features, Fitness: -2.5106\n",
      "    - New mask: 30 features, Fitness: -2.3150\n",
      "    - New mask: 28 features, Fitness: -0.5933\n",
      "    - New mask: 32 features, Fitness: -2.5291\n",
      "    - New mask: 32 features, Fitness: -1.8872\n",
      "    - New mask: 32 features, Fitness: -3.0778\n",
      "    - New mask: 35 features, Fitness: -3.1982\n",
      "    - New mask: 30 features, Fitness: -1.5773\n",
      "    - New mask: 31 features, Fitness: -1.3940\n",
      "    - New mask: 32 features, Fitness: -3.4880\n",
      "    - New mask: 24 features, Fitness: 0.8704\n",
      "    - New mask: 27 features, Fitness: -1.1636\n",
      "    - New mask: 33 features, Fitness: -3.2248\n",
      "    - New mask: 26 features, Fitness: -0.8306\n",
      "    - New mask: 34 features, Fitness: -2.2380\n",
      "    - New mask: 33 features, Fitness: -1.9888\n",
      "    - New mask: 32 features, Fitness: -1.4215\n",
      "    - New mask: 23 features, Fitness: 0.6272\n",
      "    - New mask: 30 features, Fitness: -1.7368\n",
      "    - New mask: 32 features, Fitness: -2.2538\n",
      "    - New mask: 25 features, Fitness: -0.9529\n",
      "    - New mask: 30 features, Fitness: -1.0300\n",
      "    - New mask: 30 features, Fitness: -0.4817\n",
      "    - New mask: 30 features, Fitness: -1.0219\n",
      "    - New mask: 34 features, Fitness: -3.3693\n",
      "    - New mask: 29 features, Fitness: -0.6137\n",
      "    - New mask: 32 features, Fitness: -2.9986\n",
      "    - New mask: 32 features, Fitness: -1.9142\n",
      "    - New mask: 29 features, Fitness: -0.5320\n",
      "    - New mask: 31 features, Fitness: -1.5126\n",
      "    - New mask: 30 features, Fitness: -1.3408\n",
      "    - New mask: 34 features, Fitness: -2.9219\n",
      "    - New mask: 30 features, Fitness: -2.1923\n",
      "    - New mask: 32 features, Fitness: -2.4755\n",
      "    - New mask: 31 features, Fitness: -3.2776\n",
      "    - New mask: 30 features, Fitness: -1.0229\n",
      "    - New mask: 29 features, Fitness: -3.5448\n",
      "    - New mask: 24 features, Fitness: -1.7337\n",
      "    - New mask: 26 features, Fitness: -2.7151\n",
      "    - New mask: 36 features, Fitness: -5.5778\n",
      "    - New mask: 30 features, Fitness: -3.4937\n",
      "    - New mask: 28 features, Fitness: -2.9192\n",
      "    - New mask: 32 features, Fitness: -4.0892\n",
      "    - New mask: 23 features, Fitness: -2.6996\n",
      "    - New mask: 27 features, Fitness: -3.8835\n",
      "    - New mask: 31 features, Fitness: -5.3779\n",
      "    - New mask: 33 features, Fitness: -5.5614\n",
      "    - New mask: 25 features, Fitness: -1.7873\n",
      "    - New mask: 29 features, Fitness: -4.4306\n",
      "    - New mask: 32 features, Fitness: -4.4937\n",
      "    - New mask: 29 features, Fitness: -4.4221\n",
      "    - New mask: 27 features, Fitness: -2.8092\n",
      "    - New mask: 30 features, Fitness: -3.6433\n",
      "    - New mask: 35 features, Fitness: -4.7611\n",
      "    - New mask: 27 features, Fitness: -2.2628\n",
      "    - New mask: 30 features, Fitness: -3.9502\n",
      "    - New mask: 30 features, Fitness: -0.4504\n",
      "    - New mask: 32 features, Fitness: -2.1787\n",
      "    - New mask: 33 features, Fitness: -1.7240\n",
      "    - New mask: 32 features, Fitness: -2.1654\n",
      "    - New mask: 35 features, Fitness: -3.7182\n",
      "    - New mask: 28 features, Fitness: -1.0527\n",
      "    - New mask: 33 features, Fitness: -2.4810\n",
      "    - New mask: 29 features, Fitness: -0.7171\n",
      "    - New mask: 31 features, Fitness: -1.1862\n",
      "    - New mask: 27 features, Fitness: 0.3735\n",
      "    - New mask: 32 features, Fitness: -1.8067\n",
      "    - New mask: 32 features, Fitness: -2.2053\n",
      "    - New mask: 24 features, Fitness: 0.4919\n",
      "    - New mask: 29 features, Fitness: 0.0181\n",
      "    - New mask: 33 features, Fitness: -2.0443\n",
      "    - New mask: 27 features, Fitness: -0.4468\n",
      "    - New mask: 31 features, Fitness: -2.3063\n",
      "    - New mask: 32 features, Fitness: -1.3012\n",
      "    - New mask: 32 features, Fitness: -2.0611\n",
      "    - New mask: 30 features, Fitness: -1.1670\n",
      "    - New mask: 32 features, Fitness: -0.5932\n",
      "    - New mask: 32 features, Fitness: -0.9445\n",
      "    - New mask: 28 features, Fitness: -1.8666\n",
      "    - New mask: 28 features, Fitness: -1.8572\n",
      "    - New mask: 28 features, Fitness: -1.3349\n",
      "    - New mask: 34 features, Fitness: -2.4970\n",
      "    - New mask: 31 features, Fitness: -1.2209\n",
      "    - New mask: 29 features, Fitness: -0.6798\n",
      "    - New mask: 30 features, Fitness: -0.8951\n",
      "    - New mask: 25 features, Fitness: 0.3681\n",
      "    - New mask: 25 features, Fitness: 0.3725\n",
      "    - New mask: 27 features, Fitness: 0.3198\n",
      "    - New mask: 29 features, Fitness: -2.3854\n",
      "    - New mask: 29 features, Fitness: -0.3298\n",
      "    - New mask: 31 features, Fitness: -0.8373\n",
      "    - New mask: 32 features, Fitness: -1.4475\n",
      "    - New mask: 28 features, Fitness: -0.2045\n",
      "    - New mask: 33 features, Fitness: -1.0696\n",
      "    - New mask: 28 features, Fitness: -0.1314\n",
      "    - New mask: 27 features, Fitness: 0.1299\n",
      "    - New mask: 28 features, Fitness: -3.5220\n",
      "    - New mask: 33 features, Fitness: -4.4732\n",
      "    - New mask: 31 features, Fitness: -3.2588\n",
      "    - New mask: 28 features, Fitness: -2.5337\n",
      "    - New mask: 28 features, Fitness: -2.7971\n",
      "    - New mask: 27 features, Fitness: -4.0242\n",
      "    - New mask: 29 features, Fitness: -3.2729\n",
      "    - New mask: 31 features, Fitness: -4.3277\n",
      "    - New mask: 27 features, Fitness: -2.2550\n",
      "    - New mask: 32 features, Fitness: -4.2140\n",
      "    - New mask: 33 features, Fitness: -4.3429\n",
      "    - New mask: 31 features, Fitness: -3.7383\n",
      "    - New mask: 34 features, Fitness: -6.2905\n",
      "    - New mask: 31 features, Fitness: -4.0597\n",
      "    - New mask: 29 features, Fitness: -3.3238\n",
      "    - New mask: 22 features, Fitness: -1.6755\n",
      "    - New mask: 28 features, Fitness: -3.2534\n",
      "    - New mask: 22 features, Fitness: -2.1878\n",
      "    - New mask: 27 features, Fitness: -3.3335\n",
      "    - New mask: 29 features, Fitness: -3.1105\n",
      "    - New mask: 35 features, Fitness: -8.7781\n",
      "    - New mask: 28 features, Fitness: -3.7338\n",
      "    - New mask: 30 features, Fitness: -4.7385\n",
      "    - New mask: 32 features, Fitness: -5.6458\n",
      "    - New mask: 27 features, Fitness: -4.4826\n",
      "    - New mask: 32 features, Fitness: -4.6913\n",
      "    - New mask: 30 features, Fitness: -4.6628\n",
      "    - New mask: 31 features, Fitness: -6.2856\n",
      "    - New mask: 26 features, Fitness: -3.3117\n",
      "    - New mask: 33 features, Fitness: -6.5817\n",
      "    - New mask: 27 features, Fitness: -5.4393\n",
      "    - New mask: 26 features, Fitness: -4.0463\n",
      "    - New mask: 32 features, Fitness: -4.4571\n",
      "    - New mask: 28 features, Fitness: -3.4736\n",
      "    - New mask: 27 features, Fitness: -4.2795\n",
      "    - New mask: 32 features, Fitness: -5.0864\n",
      "    - New mask: 28 features, Fitness: -4.6779\n",
      "    - New mask: 33 features, Fitness: -5.4149\n",
      "    - New mask: 30 features, Fitness: -4.6188\n",
      "    - New mask: 34 features, Fitness: -8.8417\n",
      "    - New mask: 32 features, Fitness: -1.8854\n",
      "    - New mask: 29 features, Fitness: -1.1911\n",
      "    - New mask: 28 features, Fitness: -1.7321\n",
      "    - New mask: 28 features, Fitness: -1.2973\n",
      "    - New mask: 28 features, Fitness: -1.8226\n",
      "    - New mask: 28 features, Fitness: -1.0966\n",
      "    - New mask: 29 features, Fitness: -0.3676\n",
      "    - New mask: 31 features, Fitness: -1.3950\n",
      "    - New mask: 31 features, Fitness: -3.3273\n",
      "    - New mask: 32 features, Fitness: -2.8446\n",
      "    - New mask: 31 features, Fitness: -3.3073\n",
      "    - New mask: 29 features, Fitness: -0.6492\n",
      "    - New mask: 24 features, Fitness: 0.5509\n",
      "    - New mask: 29 features, Fitness: -2.9681\n",
      "    - New mask: 33 features, Fitness: -2.8374\n",
      "    - New mask: 33 features, Fitness: -4.1117\n",
      "    - New mask: 31 features, Fitness: -1.4687\n",
      "    - New mask: 35 features, Fitness: -2.5688\n",
      "    - New mask: 34 features, Fitness: -3.9986\n",
      "    - New mask: 26 features, Fitness: -1.2655\n",
      "=== End of Round 2: Vote mask selects 42 features (rho: 0.23)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 3 ================\n",
      "  Adaptive rho for this round: 0.26\n",
      "    - New mask: 34 features, Fitness: -2.8228\n",
      "    - New mask: 33 features, Fitness: -2.5591\n",
      "    - New mask: 31 features, Fitness: -1.2901\n",
      "    - New mask: 32 features, Fitness: -1.4577\n",
      "    - New mask: 27 features, Fitness: -0.4049\n",
      "    - New mask: 33 features, Fitness: -2.1671\n",
      "    - New mask: 30 features, Fitness: -1.9543\n",
      "    - New mask: 29 features, Fitness: -1.2943\n",
      "    - New mask: 35 features, Fitness: -2.2878\n",
      "    - New mask: 33 features, Fitness: -2.4845\n",
      "    - New mask: 34 features, Fitness: -2.8799\n",
      "    - New mask: 31 features, Fitness: -1.4701\n",
      "    - New mask: 35 features, Fitness: -3.6959\n",
      "    - New mask: 30 features, Fitness: -1.3719\n",
      "    - New mask: 32 features, Fitness: -2.6762\n",
      "    - New mask: 30 features, Fitness: -1.2959\n",
      "    - New mask: 34 features, Fitness: -1.9725\n",
      "    - New mask: 27 features, Fitness: -0.7018\n",
      "    - New mask: 26 features, Fitness: -0.1775\n",
      "    - New mask: 33 features, Fitness: -1.4282\n",
      "    - New mask: 35 features, Fitness: -5.0055\n",
      "    - New mask: 33 features, Fitness: -4.1948\n",
      "    - New mask: 29 features, Fitness: -4.2899\n",
      "    - New mask: 33 features, Fitness: -5.1694\n",
      "    - New mask: 31 features, Fitness: -3.2046\n",
      "    - New mask: 31 features, Fitness: -4.8177\n",
      "    - New mask: 28 features, Fitness: -3.6218\n",
      "    - New mask: 33 features, Fitness: -5.7815\n",
      "    - New mask: 31 features, Fitness: -3.7338\n",
      "    - New mask: 29 features, Fitness: -4.3928\n",
      "    - New mask: 29 features, Fitness: -2.5137\n",
      "    - New mask: 33 features, Fitness: -5.6852\n",
      "    - New mask: 23 features, Fitness: -1.2808\n",
      "    - New mask: 30 features, Fitness: -3.2488\n",
      "    - New mask: 32 features, Fitness: -3.4504\n",
      "    - New mask: 29 features, Fitness: -3.7564\n",
      "    - New mask: 29 features, Fitness: -4.2813\n",
      "    - New mask: 33 features, Fitness: -3.5549\n",
      "    - New mask: 34 features, Fitness: -4.3167\n",
      "    - New mask: 35 features, Fitness: -5.1195\n",
      "    - New mask: 34 features, Fitness: -3.1077\n",
      "    - New mask: 26 features, Fitness: -0.0295\n",
      "    - New mask: 29 features, Fitness: -0.3944\n",
      "    - New mask: 33 features, Fitness: -2.3074\n",
      "    - New mask: 30 features, Fitness: -1.7833\n",
      "    - New mask: 31 features, Fitness: -1.6059\n",
      "    - New mask: 25 features, Fitness: 0.9435\n",
      "    - New mask: 35 features, Fitness: -3.2222\n",
      "    - New mask: 31 features, Fitness: -1.1305\n",
      "    - New mask: 31 features, Fitness: -1.2407\n",
      "    - New mask: 35 features, Fitness: -2.5532\n",
      "    - New mask: 32 features, Fitness: -2.0955\n",
      "    - New mask: 29 features, Fitness: -0.3432\n",
      "    - New mask: 34 features, Fitness: -3.0247\n",
      "    - New mask: 26 features, Fitness: 0.0882\n",
      "    - New mask: 30 features, Fitness: -1.0250\n",
      "    - New mask: 33 features, Fitness: -3.1007\n",
      "    - New mask: 29 features, Fitness: -1.5610\n",
      "    - New mask: 33 features, Fitness: -2.3140\n",
      "    - New mask: 31 features, Fitness: -1.1702\n",
      "    - New mask: 31 features, Fitness: -0.5577\n",
      "    - New mask: 30 features, Fitness: -1.2862\n",
      "    - New mask: 34 features, Fitness: -2.0662\n",
      "    - New mask: 31 features, Fitness: -1.7175\n",
      "    - New mask: 30 features, Fitness: -1.7464\n",
      "    - New mask: 26 features, Fitness: -0.8808\n",
      "    - New mask: 30 features, Fitness: -0.5508\n",
      "    - New mask: 32 features, Fitness: -1.2396\n",
      "    - New mask: 31 features, Fitness: -1.6971\n",
      "    - New mask: 36 features, Fitness: -3.1848\n",
      "    - New mask: 31 features, Fitness: -1.8307\n",
      "    - New mask: 28 features, Fitness: -0.2808\n",
      "    - New mask: 31 features, Fitness: -1.4986\n",
      "    - New mask: 31 features, Fitness: -0.8627\n",
      "    - New mask: 31 features, Fitness: -1.3290\n",
      "    - New mask: 32 features, Fitness: -2.6402\n",
      "    - New mask: 28 features, Fitness: -1.9725\n",
      "    - New mask: 30 features, Fitness: -1.8816\n",
      "    - New mask: 29 features, Fitness: -1.5010\n",
      "    - New mask: 34 features, Fitness: -2.4812\n",
      "    - New mask: 29 features, Fitness: -2.7472\n",
      "    - New mask: 30 features, Fitness: -3.0739\n",
      "    - New mask: 28 features, Fitness: -3.4839\n",
      "    - New mask: 40 features, Fitness: -7.3223\n",
      "    - New mask: 30 features, Fitness: -3.2970\n",
      "    - New mask: 34 features, Fitness: -5.6954\n",
      "    - New mask: 33 features, Fitness: -4.9188\n",
      "    - New mask: 30 features, Fitness: -3.2083\n",
      "    - New mask: 30 features, Fitness: -4.0498\n",
      "    - New mask: 34 features, Fitness: -5.4931\n",
      "    - New mask: 33 features, Fitness: -4.8123\n",
      "    - New mask: 30 features, Fitness: -3.9313\n",
      "    - New mask: 32 features, Fitness: -5.2325\n",
      "    - New mask: 34 features, Fitness: -4.2313\n",
      "    - New mask: 34 features, Fitness: -5.5020\n",
      "    - New mask: 30 features, Fitness: -3.6343\n",
      "    - New mask: 36 features, Fitness: -6.0592\n",
      "    - New mask: 35 features, Fitness: -4.3383\n",
      "    - New mask: 32 features, Fitness: -4.3098\n",
      "    - New mask: 31 features, Fitness: -4.0902\n",
      "    - New mask: 32 features, Fitness: -2.0574\n",
      "    - New mask: 31 features, Fitness: -1.0463\n",
      "    - New mask: 28 features, Fitness: -1.1361\n",
      "    - New mask: 35 features, Fitness: -3.0816\n",
      "    - New mask: 31 features, Fitness: -0.3118\n",
      "    - New mask: 32 features, Fitness: -1.2160\n",
      "    - New mask: 31 features, Fitness: -1.7296\n",
      "    - New mask: 27 features, Fitness: -0.6989\n",
      "    - New mask: 28 features, Fitness: 0.4850\n",
      "    - New mask: 30 features, Fitness: -1.7388\n",
      "    - New mask: 35 features, Fitness: -2.6795\n",
      "    - New mask: 32 features, Fitness: -1.9862\n",
      "    - New mask: 29 features, Fitness: -0.4294\n",
      "    - New mask: 34 features, Fitness: -1.3582\n",
      "    - New mask: 28 features, Fitness: -0.2220\n",
      "    - New mask: 29 features, Fitness: -0.3487\n",
      "    - New mask: 31 features, Fitness: -1.8044\n",
      "    - New mask: 30 features, Fitness: -1.1832\n",
      "    - New mask: 27 features, Fitness: 0.1039\n",
      "    - New mask: 29 features, Fitness: -1.1962\n",
      "    - New mask: 29 features, Fitness: -0.1890\n",
      "    - New mask: 33 features, Fitness: -1.1650\n",
      "    - New mask: 34 features, Fitness: -2.0715\n",
      "    - New mask: 30 features, Fitness: -0.6471\n",
      "    - New mask: 36 features, Fitness: -2.8492\n",
      "    - New mask: 34 features, Fitness: -1.6672\n",
      "    - New mask: 33 features, Fitness: -2.6131\n",
      "    - New mask: 30 features, Fitness: -0.8836\n",
      "    - New mask: 30 features, Fitness: -0.8926\n",
      "    - New mask: 27 features, Fitness: 0.2755\n",
      "    - New mask: 27 features, Fitness: 0.0810\n",
      "    - New mask: 28 features, Fitness: -0.3877\n",
      "    - New mask: 33 features, Fitness: -1.9657\n",
      "    - New mask: 28 features, Fitness: -0.3703\n",
      "    - New mask: 35 features, Fitness: -1.8212\n",
      "    - New mask: 35 features, Fitness: -2.2791\n",
      "    - New mask: 30 features, Fitness: -0.1737\n",
      "    - New mask: 34 features, Fitness: -1.3974\n",
      "    - New mask: 33 features, Fitness: -0.9310\n",
      "    - New mask: 32 features, Fitness: -1.0002\n",
      "    - New mask: 33 features, Fitness: -5.0868\n",
      "    - New mask: 28 features, Fitness: -2.2923\n",
      "    - New mask: 30 features, Fitness: -3.4539\n",
      "    - New mask: 31 features, Fitness: -3.3312\n",
      "    - New mask: 31 features, Fitness: -3.7973\n",
      "    - New mask: 28 features, Fitness: -3.3030\n",
      "    - New mask: 28 features, Fitness: -3.0742\n",
      "    - New mask: 25 features, Fitness: -1.8527\n",
      "    - New mask: 29 features, Fitness: -3.3184\n",
      "    - New mask: 28 features, Fitness: -3.1062\n",
      "    - New mask: 32 features, Fitness: -4.0899\n",
      "    - New mask: 32 features, Fitness: -4.5837\n",
      "    - New mask: 34 features, Fitness: -5.6761\n",
      "    - New mask: 29 features, Fitness: -3.6961\n",
      "    - New mask: 26 features, Fitness: -2.7187\n",
      "    - New mask: 23 features, Fitness: -1.6416\n",
      "    - New mask: 26 features, Fitness: -3.3830\n",
      "    - New mask: 26 features, Fitness: -2.5339\n",
      "    - New mask: 31 features, Fitness: -3.8441\n",
      "    - New mask: 25 features, Fitness: -2.1580\n",
      "    - New mask: 33 features, Fitness: -7.3958\n",
      "    - New mask: 29 features, Fitness: -4.6877\n",
      "    - New mask: 30 features, Fitness: -5.0625\n",
      "    - New mask: 35 features, Fitness: -6.5383\n",
      "    - New mask: 31 features, Fitness: -5.5945\n",
      "    - New mask: 31 features, Fitness: -5.4213\n",
      "    - New mask: 31 features, Fitness: -5.8030\n",
      "    - New mask: 32 features, Fitness: -5.8008\n",
      "    - New mask: 31 features, Fitness: -6.0274\n",
      "    - New mask: 36 features, Fitness: -7.4387\n",
      "    - New mask: 37 features, Fitness: -10.0586\n",
      "    - New mask: 32 features, Fitness: -5.2420\n",
      "    - New mask: 33 features, Fitness: -7.7722\n",
      "    - New mask: 30 features, Fitness: -6.1077\n",
      "    - New mask: 34 features, Fitness: -6.2409\n",
      "    - New mask: 34 features, Fitness: -5.8786\n",
      "    - New mask: 29 features, Fitness: -4.3391\n",
      "    - New mask: 32 features, Fitness: -5.7173\n",
      "    - New mask: 30 features, Fitness: -4.4114\n",
      "    - New mask: 33 features, Fitness: -7.2047\n",
      "    - New mask: 33 features, Fitness: -1.9646\n",
      "    - New mask: 33 features, Fitness: -1.8535\n",
      "    - New mask: 30 features, Fitness: -1.7448\n",
      "    - New mask: 28 features, Fitness: -1.0246\n",
      "    - New mask: 29 features, Fitness: -2.0533\n",
      "    - New mask: 27 features, Fitness: -1.3956\n",
      "    - New mask: 31 features, Fitness: -1.0555\n",
      "    - New mask: 31 features, Fitness: -1.3739\n",
      "    - New mask: 32 features, Fitness: -3.5956\n",
      "    - New mask: 29 features, Fitness: -0.7815\n",
      "    - New mask: 31 features, Fitness: -1.6197\n",
      "    - New mask: 32 features, Fitness: -0.9044\n",
      "    - New mask: 30 features, Fitness: -0.3457\n",
      "    - New mask: 30 features, Fitness: -1.8372\n",
      "    - New mask: 32 features, Fitness: -1.9994\n",
      "    - New mask: 32 features, Fitness: -1.3612\n",
      "    - New mask: 34 features, Fitness: -3.4810\n",
      "    - New mask: 36 features, Fitness: -2.3890\n",
      "    - New mask: 38 features, Fitness: -3.5623\n",
      "    - New mask: 27 features, Fitness: 0.0394\n",
      "=== End of Round 3: Vote mask selects 41 features (rho: 0.26)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 4 ================\n",
      "  Adaptive rho for this round: 0.29\n",
      "    - New mask: 33 features, Fitness: -1.8793\n",
      "    - New mask: 33 features, Fitness: -3.0562\n",
      "    - New mask: 32 features, Fitness: -1.8590\n",
      "    - New mask: 31 features, Fitness: -0.9032\n",
      "    - New mask: 29 features, Fitness: -0.9982\n",
      "    - New mask: 34 features, Fitness: -1.7282\n",
      "    - New mask: 34 features, Fitness: -3.3312\n",
      "    - New mask: 28 features, Fitness: -0.6051\n",
      "    - New mask: 33 features, Fitness: -1.3949\n",
      "    - New mask: 30 features, Fitness: -1.5516\n",
      "    - New mask: 32 features, Fitness: -2.2538\n",
      "    - New mask: 31 features, Fitness: -0.9095\n",
      "    - New mask: 34 features, Fitness: -2.5783\n",
      "    - New mask: 35 features, Fitness: -2.5180\n",
      "    - New mask: 33 features, Fitness: -2.6446\n",
      "    - New mask: 32 features, Fitness: -1.7615\n",
      "    - New mask: 30 features, Fitness: -0.8881\n",
      "    - New mask: 33 features, Fitness: -2.6251\n",
      "    - New mask: 31 features, Fitness: -1.4171\n",
      "    - New mask: 33 features, Fitness: -1.5273\n",
      "    - New mask: 31 features, Fitness: -2.5923\n",
      "    - New mask: 35 features, Fitness: -5.1576\n",
      "    - New mask: 31 features, Fitness: -4.4947\n",
      "    - New mask: 30 features, Fitness: -3.0442\n",
      "    - New mask: 32 features, Fitness: -3.1621\n",
      "    - New mask: 34 features, Fitness: -4.4203\n",
      "    - New mask: 29 features, Fitness: -3.7859\n",
      "    - New mask: 30 features, Fitness: -3.5417\n",
      "    - New mask: 32 features, Fitness: -3.1884\n",
      "    - New mask: 32 features, Fitness: -5.2133\n",
      "    - New mask: 30 features, Fitness: -3.7410\n",
      "    - New mask: 30 features, Fitness: -4.5366\n",
      "    - New mask: 33 features, Fitness: -5.2532\n",
      "    - New mask: 29 features, Fitness: -2.9729\n",
      "    - New mask: 27 features, Fitness: -2.2641\n",
      "    - New mask: 28 features, Fitness: -2.7781\n",
      "    - New mask: 35 features, Fitness: -4.6696\n",
      "    - New mask: 30 features, Fitness: -3.5445\n",
      "    - New mask: 32 features, Fitness: -4.0779\n",
      "    - New mask: 30 features, Fitness: -2.7820\n",
      "    - New mask: 38 features, Fitness: -3.8774\n",
      "    - New mask: 29 features, Fitness: -0.3656\n",
      "    - New mask: 29 features, Fitness: -0.2629\n",
      "    - New mask: 32 features, Fitness: -1.6095\n",
      "    - New mask: 30 features, Fitness: -2.2878\n",
      "    - New mask: 35 features, Fitness: -2.1377\n",
      "    - New mask: 28 features, Fitness: -0.1673\n",
      "    - New mask: 31 features, Fitness: -1.6686\n",
      "    - New mask: 31 features, Fitness: -1.1976\n",
      "    - New mask: 33 features, Fitness: -2.1413\n",
      "    - New mask: 32 features, Fitness: -1.1875\n",
      "    - New mask: 32 features, Fitness: -1.7190\n",
      "    - New mask: 28 features, Fitness: 0.3111\n",
      "    - New mask: 33 features, Fitness: -1.7651\n",
      "    - New mask: 27 features, Fitness: 0.2927\n",
      "    - New mask: 29 features, Fitness: -1.3007\n",
      "    - New mask: 37 features, Fitness: -3.3827\n",
      "    - New mask: 30 features, Fitness: -1.2376\n",
      "    - New mask: 33 features, Fitness: -1.3370\n",
      "    - New mask: 33 features, Fitness: -1.8030\n",
      "    - New mask: 31 features, Fitness: -2.2515\n",
      "    - New mask: 31 features, Fitness: -1.8046\n",
      "    - New mask: 36 features, Fitness: -2.4784\n",
      "    - New mask: 33 features, Fitness: -2.3175\n",
      "    - New mask: 34 features, Fitness: -1.6715\n",
      "    - New mask: 33 features, Fitness: -1.8307\n",
      "    - New mask: 34 features, Fitness: -2.0016\n",
      "    - New mask: 34 features, Fitness: -2.5577\n",
      "    - New mask: 33 features, Fitness: -2.7786\n",
      "    - New mask: 36 features, Fitness: -3.2899\n",
      "    - New mask: 33 features, Fitness: -2.0231\n",
      "    - New mask: 30 features, Fitness: -0.7443\n",
      "    - New mask: 33 features, Fitness: -1.6151\n",
      "    - New mask: 32 features, Fitness: -1.3226\n",
      "    - New mask: 30 features, Fitness: -0.6278\n",
      "    - New mask: 33 features, Fitness: -2.2206\n",
      "    - New mask: 34 features, Fitness: -3.2308\n",
      "    - New mask: 33 features, Fitness: -3.2451\n",
      "    - New mask: 32 features, Fitness: -2.0744\n",
      "    - New mask: 33 features, Fitness: -1.9724\n",
      "    - New mask: 33 features, Fitness: -4.4864\n",
      "    - New mask: 31 features, Fitness: -3.2317\n",
      "    - New mask: 32 features, Fitness: -3.6531\n",
      "    - New mask: 35 features, Fitness: -4.8550\n",
      "    - New mask: 35 features, Fitness: -5.1854\n",
      "    - New mask: 34 features, Fitness: -5.5834\n",
      "    - New mask: 35 features, Fitness: -5.5013\n",
      "    - New mask: 32 features, Fitness: -4.1942\n",
      "    - New mask: 33 features, Fitness: -4.5333\n",
      "    - New mask: 31 features, Fitness: -3.7993\n",
      "    - New mask: 36 features, Fitness: -5.8993\n",
      "    - New mask: 35 features, Fitness: -6.0625\n",
      "    - New mask: 28 features, Fitness: -3.9079\n",
      "    - New mask: 34 features, Fitness: -4.4968\n",
      "    - New mask: 35 features, Fitness: -6.0395\n",
      "    - New mask: 30 features, Fitness: -2.8844\n",
      "    - New mask: 34 features, Fitness: -4.6200\n",
      "    - New mask: 35 features, Fitness: -5.3887\n",
      "    - New mask: 32 features, Fitness: -4.3624\n",
      "    - New mask: 32 features, Fitness: -3.8161\n",
      "    - New mask: 31 features, Fitness: -0.5139\n",
      "    - New mask: 33 features, Fitness: -3.1827\n",
      "    - New mask: 32 features, Fitness: -2.3296\n",
      "    - New mask: 35 features, Fitness: -2.7072\n",
      "    - New mask: 33 features, Fitness: -1.1586\n",
      "    - New mask: 35 features, Fitness: -3.2846\n",
      "    - New mask: 30 features, Fitness: -1.3566\n",
      "    - New mask: 31 features, Fitness: -0.9937\n",
      "    - New mask: 29 features, Fitness: -0.5524\n",
      "    - New mask: 34 features, Fitness: -2.6592\n",
      "    - New mask: 36 features, Fitness: -3.0287\n",
      "    - New mask: 34 features, Fitness: -1.9678\n",
      "    - New mask: 31 features, Fitness: -0.3635\n",
      "    - New mask: 33 features, Fitness: -1.9249\n",
      "    - New mask: 31 features, Fitness: -1.0305\n",
      "    - New mask: 36 features, Fitness: -1.9266\n",
      "    - New mask: 35 features, Fitness: -2.4898\n",
      "    - New mask: 31 features, Fitness: -1.8287\n",
      "    - New mask: 26 features, Fitness: 0.5398\n",
      "    - New mask: 36 features, Fitness: -3.3975\n",
      "    - New mask: 28 features, Fitness: -0.0803\n",
      "    - New mask: 33 features, Fitness: -0.9199\n",
      "    - New mask: 32 features, Fitness: -1.1143\n",
      "    - New mask: 32 features, Fitness: -0.8601\n",
      "    - New mask: 38 features, Fitness: -3.0505\n",
      "    - New mask: 30 features, Fitness: -0.6840\n",
      "    - New mask: 33 features, Fitness: -0.6202\n",
      "    - New mask: 30 features, Fitness: -1.1715\n",
      "    - New mask: 35 features, Fitness: -1.8348\n",
      "    - New mask: 33 features, Fitness: -0.7736\n",
      "    - New mask: 32 features, Fitness: -0.5611\n",
      "    - New mask: 35 features, Fitness: -1.1901\n",
      "    - New mask: 38 features, Fitness: -2.8753\n",
      "    - New mask: 32 features, Fitness: -0.8871\n",
      "    - New mask: 35 features, Fitness: -1.6536\n",
      "    - New mask: 36 features, Fitness: -2.1440\n",
      "    - New mask: 30 features, Fitness: -0.1961\n",
      "    - New mask: 30 features, Fitness: -0.1431\n",
      "    - New mask: 31 features, Fitness: -0.6555\n",
      "    - New mask: 27 features, Fitness: 0.4064\n",
      "    - New mask: 34 features, Fitness: -5.2462\n",
      "    - New mask: 26 features, Fitness: -1.6480\n",
      "    - New mask: 30 features, Fitness: -3.8111\n",
      "    - New mask: 30 features, Fitness: -3.4602\n",
      "    - New mask: 33 features, Fitness: -4.4554\n",
      "    - New mask: 27 features, Fitness: -2.8553\n",
      "    - New mask: 28 features, Fitness: -3.0482\n",
      "    - New mask: 32 features, Fitness: -4.3281\n",
      "    - New mask: 30 features, Fitness: -3.8088\n",
      "    - New mask: 33 features, Fitness: -4.8101\n",
      "    - New mask: 34 features, Fitness: -4.9014\n",
      "    - New mask: 34 features, Fitness: -5.5792\n",
      "    - New mask: 32 features, Fitness: -5.0411\n",
      "    - New mask: 27 features, Fitness: -3.2419\n",
      "    - New mask: 33 features, Fitness: -4.3610\n",
      "    - New mask: 27 features, Fitness: -2.9044\n",
      "    - New mask: 29 features, Fitness: -3.9062\n",
      "    - New mask: 29 features, Fitness: -3.4824\n",
      "    - New mask: 35 features, Fitness: -5.1645\n",
      "    - New mask: 29 features, Fitness: -3.2762\n",
      "    - New mask: 35 features, Fitness: -7.6818\n",
      "    - New mask: 31 features, Fitness: -6.1492\n",
      "    - New mask: 33 features, Fitness: -5.9408\n",
      "    - New mask: 34 features, Fitness: -7.3899\n",
      "    - New mask: 34 features, Fitness: -6.4949\n",
      "    - New mask: 34 features, Fitness: -7.0931\n",
      "    - New mask: 31 features, Fitness: -5.2081\n",
      "    - New mask: 35 features, Fitness: -8.3094\n",
      "    - New mask: 31 features, Fitness: -6.5588\n",
      "    - New mask: 40 features, Fitness: -10.3863\n",
      "    - New mask: 33 features, Fitness: -7.2012\n",
      "    - New mask: 29 features, Fitness: -4.2713\n",
      "    - New mask: 33 features, Fitness: -6.0999\n",
      "    - New mask: 34 features, Fitness: -7.4108\n",
      "    - New mask: 35 features, Fitness: -7.1177\n",
      "    - New mask: 33 features, Fitness: -6.5898\n",
      "    - New mask: 32 features, Fitness: -5.9177\n",
      "    - New mask: 33 features, Fitness: -7.0228\n",
      "    - New mask: 31 features, Fitness: -3.8873\n",
      "    - New mask: 31 features, Fitness: -6.0336\n",
      "    - New mask: 34 features, Fitness: -2.8344\n",
      "    - New mask: 32 features, Fitness: -1.2920\n",
      "    - New mask: 28 features, Fitness: -2.1111\n",
      "    - New mask: 25 features, Fitness: 0.0328\n",
      "    - New mask: 33 features, Fitness: -3.4428\n",
      "    - New mask: 28 features, Fitness: -0.8887\n",
      "    - New mask: 32 features, Fitness: -1.3265\n",
      "    - New mask: 34 features, Fitness: -2.8141\n",
      "    - New mask: 30 features, Fitness: -2.2903\n",
      "    - New mask: 33 features, Fitness: -1.6660\n",
      "    - New mask: 30 features, Fitness: -1.4517\n",
      "    - New mask: 31 features, Fitness: -1.9250\n",
      "    - New mask: 35 features, Fitness: -2.4137\n",
      "    - New mask: 36 features, Fitness: -3.3330\n",
      "    - New mask: 32 features, Fitness: -1.7892\n",
      "    - New mask: 32 features, Fitness: -1.5474\n",
      "    - New mask: 34 features, Fitness: -2.1961\n",
      "    - New mask: 32 features, Fitness: -1.2687\n",
      "    - New mask: 35 features, Fitness: -2.8389\n",
      "    - New mask: 31 features, Fitness: -1.4017\n",
      "=== End of Round 4: Vote mask selects 42 features (rho: 0.29)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 5 ================\n",
      "  Adaptive rho for this round: 0.33\n",
      "    - New mask: 35 features, Fitness: -2.4895\n",
      "    - New mask: 33 features, Fitness: -2.1579\n",
      "    - New mask: 38 features, Fitness: -3.4800\n",
      "    - New mask: 31 features, Fitness: -1.1591\n",
      "    - New mask: 30 features, Fitness: -0.9881\n",
      "    - New mask: 36 features, Fitness: -2.3817\n",
      "    - New mask: 35 features, Fitness: -2.6367\n",
      "    - New mask: 30 features, Fitness: -0.9818\n",
      "    - New mask: 32 features, Fitness: -1.8376\n",
      "    - New mask: 33 features, Fitness: -1.9628\n",
      "    - New mask: 32 features, Fitness: -3.1567\n",
      "    - New mask: 32 features, Fitness: -1.6802\n",
      "    - New mask: 32 features, Fitness: -1.5079\n",
      "    - New mask: 33 features, Fitness: -1.6107\n",
      "    - New mask: 35 features, Fitness: -2.5835\n",
      "    - New mask: 35 features, Fitness: -2.1392\n",
      "    - New mask: 32 features, Fitness: -1.3383\n",
      "    - New mask: 32 features, Fitness: -2.3313\n",
      "    - New mask: 32 features, Fitness: -1.5575\n",
      "    - New mask: 32 features, Fitness: -1.5778\n",
      "    - New mask: 32 features, Fitness: -3.0592\n",
      "    - New mask: 36 features, Fitness: -5.1960\n",
      "    - New mask: 32 features, Fitness: -3.7746\n",
      "    - New mask: 31 features, Fitness: -3.6206\n",
      "    - New mask: 34 features, Fitness: -4.1070\n",
      "    - New mask: 34 features, Fitness: -4.6663\n",
      "    - New mask: 31 features, Fitness: -3.9466\n",
      "    - New mask: 29 features, Fitness: -3.1147\n",
      "    - New mask: 33 features, Fitness: -4.2768\n",
      "    - New mask: 32 features, Fitness: -3.8563\n",
      "    - New mask: 29 features, Fitness: -2.9232\n",
      "    - New mask: 32 features, Fitness: -3.9436\n",
      "    - New mask: 32 features, Fitness: -4.1818\n",
      "    - New mask: 34 features, Fitness: -5.0723\n",
      "    - New mask: 30 features, Fitness: -3.1456\n",
      "    - New mask: 34 features, Fitness: -4.6338\n",
      "    - New mask: 34 features, Fitness: -3.9464\n",
      "    - New mask: 34 features, Fitness: -4.4699\n",
      "    - New mask: 32 features, Fitness: -3.8603\n",
      "    - New mask: 31 features, Fitness: -3.8180\n",
      "    - New mask: 37 features, Fitness: -3.2301\n",
      "    - New mask: 32 features, Fitness: -2.4656\n",
      "    - New mask: 30 features, Fitness: -0.4196\n",
      "    - New mask: 36 features, Fitness: -2.7511\n",
      "    - New mask: 33 features, Fitness: -2.7280\n",
      "    - New mask: 37 features, Fitness: -3.0446\n",
      "    - New mask: 35 features, Fitness: -2.7590\n",
      "    - New mask: 31 features, Fitness: -1.8630\n",
      "    - New mask: 36 features, Fitness: -2.4300\n",
      "    - New mask: 32 features, Fitness: -1.0948\n",
      "    - New mask: 33 features, Fitness: -1.4826\n",
      "    - New mask: 35 features, Fitness: -2.5839\n",
      "    - New mask: 32 features, Fitness: -1.4626\n",
      "    - New mask: 33 features, Fitness: -1.8706\n",
      "    - New mask: 32 features, Fitness: -1.8638\n",
      "    - New mask: 32 features, Fitness: -2.3168\n",
      "    - New mask: 33 features, Fitness: -1.5360\n",
      "    - New mask: 33 features, Fitness: -1.9749\n",
      "    - New mask: 34 features, Fitness: -1.5045\n",
      "    - New mask: 29 features, Fitness: -0.5138\n",
      "    - New mask: 33 features, Fitness: -3.4275\n",
      "    - New mask: 33 features, Fitness: -2.6751\n",
      "    - New mask: 33 features, Fitness: -1.4165\n",
      "    - New mask: 37 features, Fitness: -3.3376\n",
      "    - New mask: 35 features, Fitness: -2.3388\n",
      "    - New mask: 37 features, Fitness: -3.4175\n",
      "    - New mask: 38 features, Fitness: -3.3941\n",
      "    - New mask: 35 features, Fitness: -2.1245\n",
      "    - New mask: 34 features, Fitness: -2.5597\n",
      "    - New mask: 33 features, Fitness: -3.0587\n",
      "    - New mask: 40 features, Fitness: -4.9409\n",
      "    - New mask: 34 features, Fitness: -2.6102\n",
      "    - New mask: 35 features, Fitness: -2.3426\n",
      "    - New mask: 32 features, Fitness: -1.9375\n",
      "    - New mask: 33 features, Fitness: -2.2684\n",
      "    - New mask: 33 features, Fitness: -1.6584\n",
      "    - New mask: 35 features, Fitness: -2.3888\n",
      "    - New mask: 32 features, Fitness: -1.9285\n",
      "    - New mask: 39 features, Fitness: -4.3871\n",
      "    - New mask: 32 features, Fitness: -2.2004\n",
      "    - New mask: 37 features, Fitness: -5.7424\n",
      "    - New mask: 35 features, Fitness: -5.2007\n",
      "    - New mask: 35 features, Fitness: -4.6333\n",
      "    - New mask: 35 features, Fitness: -5.5063\n",
      "    - New mask: 36 features, Fitness: -5.9759\n",
      "    - New mask: 37 features, Fitness: -5.8727\n",
      "    - New mask: 33 features, Fitness: -4.0371\n",
      "    - New mask: 35 features, Fitness: -5.0310\n",
      "    - New mask: 31 features, Fitness: -3.7908\n",
      "    - New mask: 32 features, Fitness: -3.7665\n",
      "    - New mask: 36 features, Fitness: -5.5160\n",
      "    - New mask: 36 features, Fitness: -5.7117\n",
      "    - New mask: 29 features, Fitness: -3.3888\n",
      "    - New mask: 38 features, Fitness: -6.0067\n",
      "    - New mask: 38 features, Fitness: -6.6835\n",
      "    - New mask: 31 features, Fitness: -3.1466\n",
      "    - New mask: 35 features, Fitness: -5.3332\n",
      "    - New mask: 34 features, Fitness: -5.7940\n",
      "    - New mask: 30 features, Fitness: -3.3182\n",
      "    - New mask: 30 features, Fitness: -3.6991\n",
      "    - New mask: 32 features, Fitness: -1.9136\n",
      "    - New mask: 30 features, Fitness: -1.2565\n",
      "    - New mask: 32 features, Fitness: -1.5264\n",
      "    - New mask: 31 features, Fitness: -1.3899\n",
      "    - New mask: 34 features, Fitness: -2.0580\n",
      "    - New mask: 36 features, Fitness: -3.2399\n",
      "    - New mask: 33 features, Fitness: -0.7784\n",
      "    - New mask: 36 features, Fitness: -2.3954\n",
      "    - New mask: 31 features, Fitness: -0.3870\n",
      "    - New mask: 28 features, Fitness: -0.2431\n",
      "    - New mask: 31 features, Fitness: -1.2525\n",
      "    - New mask: 34 features, Fitness: -1.5689\n",
      "    - New mask: 32 features, Fitness: -0.8887\n",
      "    - New mask: 32 features, Fitness: -0.9883\n",
      "    - New mask: 31 features, Fitness: -1.0612\n",
      "    - New mask: 34 features, Fitness: -1.6228\n",
      "    - New mask: 33 features, Fitness: -2.8293\n",
      "    - New mask: 30 features, Fitness: -0.9974\n",
      "    - New mask: 30 features, Fitness: -0.7887\n",
      "    - New mask: 32 features, Fitness: -1.3401\n",
      "    - New mask: 35 features, Fitness: -0.9570\n",
      "    - New mask: 40 features, Fitness: -2.8752\n",
      "    - New mask: 35 features, Fitness: -1.2305\n",
      "    - New mask: 33 features, Fitness: -1.1861\n",
      "    - New mask: 33 features, Fitness: -1.6036\n",
      "    - New mask: 35 features, Fitness: -1.5564\n",
      "    - New mask: 35 features, Fitness: -1.1924\n",
      "    - New mask: 34 features, Fitness: -1.1982\n",
      "    - New mask: 34 features, Fitness: -0.5193\n",
      "    - New mask: 34 features, Fitness: -1.1796\n",
      "    - New mask: 33 features, Fitness: -0.9155\n",
      "    - New mask: 36 features, Fitness: -1.5574\n",
      "    - New mask: 31 features, Fitness: -0.9523\n",
      "    - New mask: 32 features, Fitness: -1.0274\n",
      "    - New mask: 33 features, Fitness: -0.6172\n",
      "    - New mask: 38 features, Fitness: -2.5566\n",
      "    - New mask: 34 features, Fitness: -1.1605\n",
      "    - New mask: 32 features, Fitness: -0.5061\n",
      "    - New mask: 37 features, Fitness: -2.0215\n",
      "    - New mask: 29 features, Fitness: -0.3702\n",
      "    - New mask: 32 features, Fitness: -4.4445\n",
      "    - New mask: 29 features, Fitness: -3.1638\n",
      "    - New mask: 35 features, Fitness: -4.8742\n",
      "    - New mask: 30 features, Fitness: -4.3123\n",
      "    - New mask: 30 features, Fitness: -2.9559\n",
      "    - New mask: 33 features, Fitness: -4.2716\n",
      "    - New mask: 31 features, Fitness: -3.2503\n",
      "    - New mask: 31 features, Fitness: -3.7125\n",
      "    - New mask: 32 features, Fitness: -3.9579\n",
      "    - New mask: 34 features, Fitness: -4.6291\n",
      "    - New mask: 33 features, Fitness: -4.7390\n",
      "    - New mask: 37 features, Fitness: -6.2535\n",
      "    - New mask: 36 features, Fitness: -5.4628\n",
      "    - New mask: 33 features, Fitness: -4.6670\n",
      "    - New mask: 33 features, Fitness: -4.2938\n",
      "    - New mask: 30 features, Fitness: -3.5484\n",
      "    - New mask: 34 features, Fitness: -4.5355\n",
      "    - New mask: 33 features, Fitness: -3.9939\n",
      "    - New mask: 30 features, Fitness: -2.6610\n",
      "    - New mask: 32 features, Fitness: -4.4134\n",
      "    - New mask: 34 features, Fitness: -6.4714\n",
      "    - New mask: 35 features, Fitness: -8.9595\n",
      "    - New mask: 32 features, Fitness: -5.1413\n",
      "    - New mask: 34 features, Fitness: -5.9004\n",
      "    - New mask: 33 features, Fitness: -5.4392\n",
      "    - New mask: 34 features, Fitness: -6.1374\n",
      "    - New mask: 33 features, Fitness: -6.5858\n",
      "    - New mask: 36 features, Fitness: -8.1183\n",
      "    - New mask: 31 features, Fitness: -5.5484\n",
      "    - New mask: 37 features, Fitness: -7.6519\n",
      "    - New mask: 36 features, Fitness: -9.5628\n",
      "    - New mask: 33 features, Fitness: -5.7187\n",
      "    - New mask: 33 features, Fitness: -4.8844\n",
      "    - New mask: 31 features, Fitness: -6.5614\n",
      "    - New mask: 36 features, Fitness: -7.7669\n",
      "    - New mask: 38 features, Fitness: -8.2600\n",
      "    - New mask: 37 features, Fitness: -8.6901\n",
      "    - New mask: 37 features, Fitness: -8.3635\n",
      "    - New mask: 34 features, Fitness: -5.8330\n",
      "    - New mask: 33 features, Fitness: -5.4542\n",
      "    - New mask: 35 features, Fitness: -2.5159\n",
      "    - New mask: 30 features, Fitness: -1.6920\n",
      "    - New mask: 32 features, Fitness: -3.8464\n",
      "    - New mask: 32 features, Fitness: -1.1469\n",
      "    - New mask: 31 features, Fitness: -2.1137\n",
      "    - New mask: 30 features, Fitness: -1.7124\n",
      "    - New mask: 34 features, Fitness: -2.9751\n",
      "    - New mask: 36 features, Fitness: -2.8855\n",
      "    - New mask: 31 features, Fitness: -2.0957\n",
      "    - New mask: 35 features, Fitness: -2.3976\n",
      "    - New mask: 33 features, Fitness: -2.4031\n",
      "    - New mask: 31 features, Fitness: -2.3423\n",
      "    - New mask: 34 features, Fitness: -2.0180\n",
      "    - New mask: 37 features, Fitness: -3.8178\n",
      "    - New mask: 36 features, Fitness: -2.9656\n",
      "    - New mask: 32 features, Fitness: -1.9790\n",
      "    - New mask: 33 features, Fitness: -1.9159\n",
      "    - New mask: 35 features, Fitness: -2.5618\n",
      "    - New mask: 32 features, Fitness: -1.9509\n",
      "    - New mask: 35 features, Fitness: -2.3551\n",
      "=== End of Round 5: Vote mask selects 41 features (rho: 0.33)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 6 ================\n",
      "  Adaptive rho for this round: 0.36\n",
      "    - New mask: 35 features, Fitness: -2.4280\n",
      "    - New mask: 34 features, Fitness: -2.4748\n",
      "    - New mask: 35 features, Fitness: -3.0270\n",
      "    - New mask: 30 features, Fitness: -0.6771\n",
      "    - New mask: 32 features, Fitness: -2.1453\n",
      "    - New mask: 34 features, Fitness: -2.0662\n",
      "    - New mask: 34 features, Fitness: -2.6240\n",
      "    - New mask: 32 features, Fitness: -1.6019\n",
      "    - New mask: 34 features, Fitness: -2.9872\n",
      "    - New mask: 31 features, Fitness: -1.7999\n",
      "    - New mask: 32 features, Fitness: -2.2456\n",
      "    - New mask: 32 features, Fitness: -1.9577\n",
      "    - New mask: 34 features, Fitness: -2.1020\n",
      "    - New mask: 32 features, Fitness: -1.7021\n",
      "    - New mask: 34 features, Fitness: -1.9697\n",
      "    - New mask: 37 features, Fitness: -2.9827\n",
      "    - New mask: 35 features, Fitness: -2.8718\n",
      "    - New mask: 39 features, Fitness: -4.6381\n",
      "    - New mask: 35 features, Fitness: -2.3656\n",
      "    - New mask: 33 features, Fitness: -1.6608\n",
      "    - New mask: 28 features, Fitness: -3.7054\n",
      "    - New mask: 36 features, Fitness: -5.5355\n",
      "    - New mask: 36 features, Fitness: -5.1145\n",
      "    - New mask: 32 features, Fitness: -4.7182\n",
      "    - New mask: 35 features, Fitness: -4.6637\n",
      "    - New mask: 35 features, Fitness: -5.1097\n",
      "    - New mask: 30 features, Fitness: -3.8502\n",
      "    - New mask: 30 features, Fitness: -3.2715\n",
      "    - New mask: 31 features, Fitness: -3.4211\n",
      "    - New mask: 35 features, Fitness: -5.0211\n",
      "    - New mask: 33 features, Fitness: -4.5940\n",
      "    - New mask: 35 features, Fitness: -5.3406\n",
      "    - New mask: 31 features, Fitness: -3.7881\n",
      "    - New mask: 35 features, Fitness: -4.6711\n",
      "    - New mask: 34 features, Fitness: -4.8222\n",
      "    - New mask: 36 features, Fitness: -5.1867\n",
      "    - New mask: 33 features, Fitness: -3.5929\n",
      "    - New mask: 33 features, Fitness: -3.7483\n",
      "    - New mask: 32 features, Fitness: -3.5968\n",
      "    - New mask: 36 features, Fitness: -4.8177\n",
      "    - New mask: 38 features, Fitness: -3.1959\n",
      "    - New mask: 32 features, Fitness: -2.4103\n",
      "    - New mask: 33 features, Fitness: -1.8313\n",
      "    - New mask: 31 features, Fitness: -0.7602\n",
      "    - New mask: 33 features, Fitness: -1.8813\n",
      "    - New mask: 34 features, Fitness: -1.3698\n",
      "    - New mask: 33 features, Fitness: -2.2874\n",
      "    - New mask: 31 features, Fitness: -1.6918\n",
      "    - New mask: 38 features, Fitness: -3.1276\n",
      "    - New mask: 35 features, Fitness: -2.0826\n",
      "    - New mask: 37 features, Fitness: -3.8717\n",
      "    - New mask: 36 features, Fitness: -3.2594\n",
      "    - New mask: 32 features, Fitness: -0.6889\n",
      "    - New mask: 34 features, Fitness: -2.3286\n",
      "    - New mask: 31 features, Fitness: -1.3348\n",
      "    - New mask: 35 features, Fitness: -2.6424\n",
      "    - New mask: 35 features, Fitness: -2.5726\n",
      "    - New mask: 35 features, Fitness: -2.9216\n",
      "    - New mask: 35 features, Fitness: -2.0726\n",
      "    - New mask: 31 features, Fitness: -1.0220\n",
      "    - New mask: 32 features, Fitness: -2.3927\n",
      "    - New mask: 35 features, Fitness: -2.8172\n",
      "    - New mask: 35 features, Fitness: -2.1262\n",
      "    - New mask: 37 features, Fitness: -2.9590\n",
      "    - New mask: 36 features, Fitness: -3.0737\n",
      "    - New mask: 37 features, Fitness: -3.3032\n",
      "    - New mask: 37 features, Fitness: -3.2892\n",
      "    - New mask: 36 features, Fitness: -2.4204\n",
      "    - New mask: 34 features, Fitness: -2.8336\n",
      "    - New mask: 32 features, Fitness: -2.3888\n",
      "    - New mask: 39 features, Fitness: -4.2211\n",
      "    - New mask: 30 features, Fitness: -1.8021\n",
      "    - New mask: 35 features, Fitness: -1.5395\n",
      "    - New mask: 33 features, Fitness: -1.9458\n",
      "    - New mask: 36 features, Fitness: -2.7841\n",
      "    - New mask: 37 features, Fitness: -3.3185\n",
      "    - New mask: 33 features, Fitness: -2.4102\n",
      "    - New mask: 37 features, Fitness: -3.6384\n",
      "    - New mask: 37 features, Fitness: -3.8340\n",
      "    - New mask: 32 features, Fitness: -2.3249\n",
      "    - New mask: 33 features, Fitness: -4.3898\n",
      "    - New mask: 34 features, Fitness: -5.0076\n",
      "    - New mask: 32 features, Fitness: -3.6491\n",
      "    - New mask: 35 features, Fitness: -5.1722\n",
      "    - New mask: 37 features, Fitness: -6.0486\n",
      "    - New mask: 34 features, Fitness: -4.5437\n",
      "    - New mask: 37 features, Fitness: -5.5026\n",
      "    - New mask: 38 features, Fitness: -6.1126\n",
      "    - New mask: 32 features, Fitness: -3.7554\n",
      "    - New mask: 33 features, Fitness: -4.1280\n",
      "    - New mask: 33 features, Fitness: -3.7034\n",
      "    - New mask: 36 features, Fitness: -5.4104\n",
      "    - New mask: 33 features, Fitness: -5.2206\n",
      "    - New mask: 34 features, Fitness: -4.5333\n",
      "    - New mask: 38 features, Fitness: -6.3718\n",
      "    - New mask: 35 features, Fitness: -4.6503\n",
      "    - New mask: 35 features, Fitness: -4.8895\n",
      "    - New mask: 34 features, Fitness: -5.5502\n",
      "    - New mask: 32 features, Fitness: -4.2295\n",
      "    - New mask: 29 features, Fitness: -2.8085\n",
      "    - New mask: 38 features, Fitness: -4.7864\n",
      "    - New mask: 31 features, Fitness: -1.8162\n",
      "    - New mask: 32 features, Fitness: -1.6808\n",
      "    - New mask: 34 features, Fitness: -2.1281\n",
      "    - New mask: 37 features, Fitness: -2.9690\n",
      "    - New mask: 35 features, Fitness: -2.7221\n",
      "    - New mask: 31 features, Fitness: -0.7538\n",
      "    - New mask: 35 features, Fitness: -2.8456\n",
      "    - New mask: 32 features, Fitness: -1.3803\n",
      "    - New mask: 33 features, Fitness: -1.4751\n",
      "    - New mask: 34 features, Fitness: -3.4209\n",
      "    - New mask: 34 features, Fitness: -2.5448\n",
      "    - New mask: 37 features, Fitness: -3.6750\n",
      "    - New mask: 35 features, Fitness: -2.2282\n",
      "    - New mask: 30 features, Fitness: -3.0870\n",
      "    - New mask: 36 features, Fitness: -2.6597\n",
      "    - New mask: 36 features, Fitness: -4.0571\n",
      "    - New mask: 33 features, Fitness: -2.1379\n",
      "    - New mask: 30 features, Fitness: -1.4731\n",
      "    - New mask: 32 features, Fitness: -0.4590\n",
      "    - New mask: 29 features, Fitness: 0.2082\n",
      "    - New mask: 36 features, Fitness: -1.7872\n",
      "    - New mask: 39 features, Fitness: -2.4472\n",
      "    - New mask: 33 features, Fitness: -1.1441\n",
      "    - New mask: 31 features, Fitness: -2.3143\n",
      "    - New mask: 34 features, Fitness: -1.5030\n",
      "    - New mask: 33 features, Fitness: -1.0543\n",
      "    - New mask: 36 features, Fitness: -1.8600\n",
      "    - New mask: 34 features, Fitness: -1.2637\n",
      "    - New mask: 32 features, Fitness: -1.0101\n",
      "    - New mask: 35 features, Fitness: -1.6664\n",
      "    - New mask: 37 features, Fitness: -2.0770\n",
      "    - New mask: 33 features, Fitness: -1.1448\n",
      "    - New mask: 32 features, Fitness: -1.1459\n",
      "    - New mask: 34 features, Fitness: -1.9036\n",
      "    - New mask: 35 features, Fitness: -2.1644\n",
      "    - New mask: 36 features, Fitness: -1.1835\n",
      "    - New mask: 33 features, Fitness: -0.8933\n",
      "    - New mask: 37 features, Fitness: -2.2662\n",
      "    - New mask: 34 features, Fitness: -1.7262\n",
      "    - New mask: 31 features, Fitness: -3.1128\n",
      "    - New mask: 29 features, Fitness: -3.5475\n",
      "    - New mask: 33 features, Fitness: -4.1197\n",
      "    - New mask: 32 features, Fitness: -3.8812\n",
      "    - New mask: 33 features, Fitness: -4.2899\n",
      "    - New mask: 34 features, Fitness: -4.1384\n",
      "    - New mask: 31 features, Fitness: -3.6804\n",
      "    - New mask: 36 features, Fitness: -4.6593\n",
      "    - New mask: 37 features, Fitness: -5.9133\n",
      "    - New mask: 35 features, Fitness: -5.0536\n",
      "    - New mask: 34 features, Fitness: -5.0443\n",
      "    - New mask: 35 features, Fitness: -4.7624\n",
      "    - New mask: 33 features, Fitness: -4.1236\n",
      "    - New mask: 33 features, Fitness: -3.7180\n",
      "    - New mask: 36 features, Fitness: -5.8761\n",
      "    - New mask: 32 features, Fitness: -3.2946\n",
      "    - New mask: 32 features, Fitness: -4.5801\n",
      "    - New mask: 30 features, Fitness: -2.9413\n",
      "    - New mask: 34 features, Fitness: -4.6625\n",
      "    - New mask: 34 features, Fitness: -4.0771\n",
      "    - New mask: 32 features, Fitness: -5.1719\n",
      "    - New mask: 35 features, Fitness: -7.8397\n",
      "    - New mask: 36 features, Fitness: -7.5950\n",
      "    - New mask: 36 features, Fitness: -7.5529\n",
      "    - New mask: 33 features, Fitness: -5.9942\n",
      "    - New mask: 36 features, Fitness: -8.1848\n",
      "    - New mask: 35 features, Fitness: -6.0228\n",
      "    - New mask: 35 features, Fitness: -6.5881\n",
      "    - New mask: 32 features, Fitness: -6.1377\n",
      "    - New mask: 35 features, Fitness: -6.7700\n",
      "    - New mask: 35 features, Fitness: -7.2397\n",
      "    - New mask: 36 features, Fitness: -8.0687\n",
      "    - New mask: 37 features, Fitness: -7.8893\n",
      "    - New mask: 35 features, Fitness: -6.4832\n",
      "    - New mask: 36 features, Fitness: -7.0148\n",
      "    - New mask: 38 features, Fitness: -8.3920\n",
      "    - New mask: 35 features, Fitness: -6.0605\n",
      "    - New mask: 36 features, Fitness: -7.5299\n",
      "    - New mask: 35 features, Fitness: -6.0643\n",
      "    - New mask: 33 features, Fitness: -5.2525\n",
      "    - New mask: 36 features, Fitness: -3.2431\n",
      "    - New mask: 31 features, Fitness: -1.9173\n",
      "    - New mask: 30 features, Fitness: -2.7495\n",
      "    - New mask: 34 features, Fitness: -2.1494\n",
      "    - New mask: 31 features, Fitness: -1.2371\n",
      "    - New mask: 30 features, Fitness: -1.4382\n",
      "    - New mask: 36 features, Fitness: -2.7022\n",
      "    - New mask: 39 features, Fitness: -3.7079\n",
      "    - New mask: 33 features, Fitness: -1.7256\n",
      "    - New mask: 36 features, Fitness: -2.7688\n",
      "    - New mask: 35 features, Fitness: -2.0505\n",
      "    - New mask: 37 features, Fitness: -3.6097\n",
      "    - New mask: 36 features, Fitness: -2.6395\n",
      "    - New mask: 38 features, Fitness: -3.7329\n",
      "    - New mask: 37 features, Fitness: -2.9087\n",
      "    - New mask: 34 features, Fitness: -2.5011\n",
      "    - New mask: 37 features, Fitness: -3.0379\n",
      "    - New mask: 36 features, Fitness: -2.5165\n",
      "    - New mask: 34 features, Fitness: -2.4308\n",
      "    - New mask: 34 features, Fitness: -2.6143\n",
      "=== End of Round 6: Vote mask selects 41 features (rho: 0.36)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 7 ================\n",
      "  Adaptive rho for this round: 0.39\n",
      "    - New mask: 36 features, Fitness: -2.4595\n",
      "    - New mask: 36 features, Fitness: -2.5766\n",
      "    - New mask: 34 features, Fitness: -2.2516\n",
      "    - New mask: 34 features, Fitness: -1.7767\n",
      "    - New mask: 37 features, Fitness: -2.5106\n",
      "    - New mask: 35 features, Fitness: -2.1881\n",
      "    - New mask: 37 features, Fitness: -3.5334\n",
      "    - New mask: 30 features, Fitness: -0.6993\n",
      "    - New mask: 34 features, Fitness: -2.8410\n",
      "    - New mask: 33 features, Fitness: -1.4118\n",
      "    - New mask: 32 features, Fitness: -1.0753\n",
      "    - New mask: 33 features, Fitness: -2.0685\n",
      "    - New mask: 37 features, Fitness: -3.3844\n",
      "    - New mask: 32 features, Fitness: -1.2293\n",
      "    - New mask: 34 features, Fitness: -2.0042\n",
      "    - New mask: 36 features, Fitness: -2.7147\n",
      "    - New mask: 35 features, Fitness: -2.9382\n",
      "    - New mask: 34 features, Fitness: -2.1532\n",
      "    - New mask: 35 features, Fitness: -2.0912\n",
      "    - New mask: 34 features, Fitness: -1.4181\n",
      "    - New mask: 33 features, Fitness: -5.4798\n",
      "    - New mask: 33 features, Fitness: -4.4451\n",
      "    - New mask: 34 features, Fitness: -5.6554\n",
      "    - New mask: 33 features, Fitness: -5.8530\n",
      "    - New mask: 32 features, Fitness: -3.2715\n",
      "    - New mask: 34 features, Fitness: -4.9115\n",
      "    - New mask: 35 features, Fitness: -5.1572\n",
      "    - New mask: 33 features, Fitness: -4.4044\n",
      "    - New mask: 35 features, Fitness: -4.9729\n",
      "    - New mask: 34 features, Fitness: -4.7636\n",
      "    - New mask: 31 features, Fitness: -3.8520\n",
      "    - New mask: 37 features, Fitness: -5.4852\n",
      "    - New mask: 37 features, Fitness: -5.4466\n",
      "    - New mask: 34 features, Fitness: -4.8390\n",
      "    - New mask: 32 features, Fitness: -4.1477\n",
      "    - New mask: 29 features, Fitness: -2.8326\n",
      "    - New mask: 35 features, Fitness: -4.2448\n",
      "    - New mask: 31 features, Fitness: -4.5662\n",
      "    - New mask: 35 features, Fitness: -4.3721\n",
      "    - New mask: 34 features, Fitness: -4.2798\n",
      "    - New mask: 37 features, Fitness: -3.2714\n",
      "    - New mask: 36 features, Fitness: -4.1572\n",
      "    - New mask: 36 features, Fitness: -2.7945\n",
      "    - New mask: 32 features, Fitness: -1.1812\n",
      "    - New mask: 34 features, Fitness: -1.9986\n",
      "    - New mask: 37 features, Fitness: -3.4648\n",
      "    - New mask: 38 features, Fitness: -3.6210\n",
      "    - New mask: 35 features, Fitness: -2.9630\n",
      "    - New mask: 35 features, Fitness: -1.9070\n",
      "    - New mask: 32 features, Fitness: -0.9745\n",
      "    - New mask: 35 features, Fitness: -2.6482\n",
      "    - New mask: 34 features, Fitness: -2.6772\n",
      "    - New mask: 34 features, Fitness: -2.0975\n",
      "    - New mask: 34 features, Fitness: -2.9968\n",
      "    - New mask: 33 features, Fitness: -1.6922\n",
      "    - New mask: 33 features, Fitness: -1.3655\n",
      "    - New mask: 37 features, Fitness: -2.7677\n",
      "    - New mask: 36 features, Fitness: -2.4904\n",
      "    - New mask: 38 features, Fitness: -3.9286\n",
      "    - New mask: 33 features, Fitness: -1.0863\n",
      "    - New mask: 31 features, Fitness: -2.0766\n",
      "    - New mask: 39 features, Fitness: -4.1559\n",
      "    - New mask: 34 features, Fitness: -1.8600\n",
      "    - New mask: 38 features, Fitness: -2.9344\n",
      "    - New mask: 37 features, Fitness: -3.0801\n",
      "    - New mask: 36 features, Fitness: -3.1502\n",
      "    - New mask: 34 features, Fitness: -2.0816\n",
      "    - New mask: 35 features, Fitness: -1.5999\n",
      "    - New mask: 36 features, Fitness: -2.3310\n",
      "    - New mask: 37 features, Fitness: -2.7612\n",
      "    - New mask: 39 features, Fitness: -3.6595\n",
      "    - New mask: 36 features, Fitness: -2.3310\n",
      "    - New mask: 36 features, Fitness: -2.4913\n",
      "    - New mask: 33 features, Fitness: -2.1510\n",
      "    - New mask: 35 features, Fitness: -1.7866\n",
      "    - New mask: 38 features, Fitness: -3.0617\n",
      "    - New mask: 36 features, Fitness: -3.9175\n",
      "    - New mask: 36 features, Fitness: -2.6794\n",
      "    - New mask: 33 features, Fitness: -1.3146\n",
      "    - New mask: 36 features, Fitness: -4.1017\n",
      "    - New mask: 31 features, Fitness: -3.4938\n",
      "    - New mask: 34 features, Fitness: -4.3194\n",
      "    - New mask: 35 features, Fitness: -4.8549\n",
      "    - New mask: 37 features, Fitness: -5.7401\n",
      "    - New mask: 33 features, Fitness: -4.2389\n",
      "    - New mask: 34 features, Fitness: -5.3586\n",
      "    - New mask: 35 features, Fitness: -5.2092\n",
      "    - New mask: 36 features, Fitness: -5.4679\n",
      "    - New mask: 31 features, Fitness: -4.0822\n",
      "    - New mask: 34 features, Fitness: -4.7333\n",
      "    - New mask: 34 features, Fitness: -4.3049\n",
      "    - New mask: 31 features, Fitness: -3.4704\n",
      "    - New mask: 32 features, Fitness: -4.6499\n",
      "    - New mask: 32 features, Fitness: -3.6501\n",
      "    - New mask: 37 features, Fitness: -5.4598\n",
      "    - New mask: 33 features, Fitness: -4.0837\n",
      "    - New mask: 33 features, Fitness: -4.3593\n",
      "    - New mask: 36 features, Fitness: -6.2246\n",
      "    - New mask: 33 features, Fitness: -4.7890\n",
      "    - New mask: 36 features, Fitness: -5.8008\n",
      "    - New mask: 40 features, Fitness: -4.3768\n",
      "    - New mask: 31 features, Fitness: -0.7112\n",
      "    - New mask: 38 features, Fitness: -4.1184\n",
      "    - New mask: 36 features, Fitness: -3.0351\n",
      "    - New mask: 38 features, Fitness: -3.7367\n",
      "    - New mask: 33 features, Fitness: -1.1648\n",
      "    - New mask: 32 features, Fitness: -1.4030\n",
      "    - New mask: 35 features, Fitness: -2.9723\n",
      "    - New mask: 33 features, Fitness: -1.6923\n",
      "    - New mask: 38 features, Fitness: -3.1925\n",
      "    - New mask: 37 features, Fitness: -3.2128\n",
      "    - New mask: 33 features, Fitness: -1.5812\n",
      "    - New mask: 36 features, Fitness: -3.2619\n",
      "    - New mask: 38 features, Fitness: -3.6982\n",
      "    - New mask: 34 features, Fitness: -2.7601\n",
      "    - New mask: 38 features, Fitness: -4.1203\n",
      "    - New mask: 33 features, Fitness: -1.2955\n",
      "    - New mask: 35 features, Fitness: -2.2674\n",
      "    - New mask: 35 features, Fitness: -2.6592\n",
      "    - New mask: 34 features, Fitness: -1.6857\n",
      "    - New mask: 31 features, Fitness: -0.0201\n",
      "    - New mask: 31 features, Fitness: -0.3632\n",
      "    - New mask: 37 features, Fitness: -2.3841\n",
      "    - New mask: 33 features, Fitness: -0.9206\n",
      "    - New mask: 34 features, Fitness: -1.9394\n",
      "    - New mask: 34 features, Fitness: -0.8409\n",
      "    - New mask: 30 features, Fitness: -0.4939\n",
      "    - New mask: 32 features, Fitness: -0.6583\n",
      "    - New mask: 32 features, Fitness: -1.5338\n",
      "    - New mask: 33 features, Fitness: -1.6963\n",
      "    - New mask: 35 features, Fitness: -0.9828\n",
      "    - New mask: 35 features, Fitness: -1.4296\n",
      "    - New mask: 32 features, Fitness: -0.5896\n",
      "    - New mask: 34 features, Fitness: -1.0871\n",
      "    - New mask: 34 features, Fitness: -0.4677\n",
      "    - New mask: 33 features, Fitness: -1.6331\n",
      "    - New mask: 34 features, Fitness: -1.0782\n",
      "    - New mask: 32 features, Fitness: -0.4706\n",
      "    - New mask: 33 features, Fitness: -1.0569\n",
      "    - New mask: 34 features, Fitness: -1.2280\n",
      "    - New mask: 32 features, Fitness: -3.8313\n",
      "    - New mask: 37 features, Fitness: -7.1026\n",
      "    - New mask: 33 features, Fitness: -4.3115\n",
      "    - New mask: 32 features, Fitness: -3.9472\n",
      "    - New mask: 36 features, Fitness: -5.7058\n",
      "    - New mask: 35 features, Fitness: -4.8028\n",
      "    - New mask: 34 features, Fitness: -4.6826\n",
      "    - New mask: 35 features, Fitness: -5.4989\n",
      "    - New mask: 34 features, Fitness: -4.7007\n",
      "    - New mask: 33 features, Fitness: -3.6967\n",
      "    - New mask: 36 features, Fitness: -5.2068\n",
      "    - New mask: 35 features, Fitness: -4.5616\n",
      "    - New mask: 33 features, Fitness: -4.0448\n",
      "    - New mask: 33 features, Fitness: -4.6128\n",
      "    - New mask: 34 features, Fitness: -4.2164\n",
      "    - New mask: 36 features, Fitness: -5.0840\n",
      "    - New mask: 34 features, Fitness: -4.8665\n",
      "    - New mask: 34 features, Fitness: -4.0785\n",
      "    - New mask: 36 features, Fitness: -5.7487\n",
      "    - New mask: 36 features, Fitness: -4.9483\n",
      "    - New mask: 34 features, Fitness: -6.5802\n",
      "    - New mask: 34 features, Fitness: -6.2630\n",
      "    - New mask: 37 features, Fitness: -7.8427\n",
      "    - New mask: 37 features, Fitness: -8.5700\n",
      "    - New mask: 34 features, Fitness: -6.7083\n",
      "    - New mask: 36 features, Fitness: -8.0469\n",
      "    - New mask: 32 features, Fitness: -6.7512\n",
      "    - New mask: 36 features, Fitness: -7.8525\n",
      "    - New mask: 34 features, Fitness: -6.6980\n",
      "    - New mask: 35 features, Fitness: -6.8051\n",
      "    - New mask: 39 features, Fitness: -9.0197\n",
      "    - New mask: 35 features, Fitness: -8.3081\n",
      "    - New mask: 36 features, Fitness: -7.9855\n",
      "    - New mask: 37 features, Fitness: -8.6819\n",
      "    - New mask: 34 features, Fitness: -5.5211\n",
      "    - New mask: 36 features, Fitness: -7.6895\n",
      "    - New mask: 35 features, Fitness: -6.3226\n",
      "    - New mask: 36 features, Fitness: -7.4107\n",
      "    - New mask: 38 features, Fitness: -8.8077\n",
      "    - New mask: 32 features, Fitness: -5.6816\n",
      "    - New mask: 34 features, Fitness: -2.9130\n",
      "    - New mask: 37 features, Fitness: -3.4313\n",
      "    - New mask: 35 features, Fitness: -4.7509\n",
      "    - New mask: 36 features, Fitness: -2.6564\n",
      "    - New mask: 34 features, Fitness: -2.5445\n",
      "    - New mask: 35 features, Fitness: -2.6481\n",
      "    - New mask: 34 features, Fitness: -1.9708\n",
      "    - New mask: 35 features, Fitness: -2.6070\n",
      "    - New mask: 34 features, Fitness: -2.1237\n",
      "    - New mask: 36 features, Fitness: -2.9712\n",
      "    - New mask: 34 features, Fitness: -2.3569\n",
      "    - New mask: 37 features, Fitness: -3.4892\n",
      "    - New mask: 34 features, Fitness: -2.2264\n",
      "    - New mask: 37 features, Fitness: -3.5089\n",
      "    - New mask: 35 features, Fitness: -2.4741\n",
      "    - New mask: 34 features, Fitness: -2.0260\n",
      "    - New mask: 36 features, Fitness: -2.9653\n",
      "    - New mask: 36 features, Fitness: -2.6748\n",
      "    - New mask: 35 features, Fitness: -2.6175\n",
      "    - New mask: 34 features, Fitness: -2.1500\n",
      "=== End of Round 7: Vote mask selects 41 features (rho: 0.39)\n",
      "    Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 8 ================\n",
      "  Adaptive rho for this round: 0.42\n",
      "    - New mask: 30 features, Fitness: -0.5729\n",
      "    - New mask: 35 features, Fitness: -2.8086\n",
      "    - New mask: 35 features, Fitness: -2.8688\n",
      "    - New mask: 31 features, Fitness: -1.1870\n",
      "    - New mask: 36 features, Fitness: -2.8509\n",
      "    - New mask: 38 features, Fitness: -3.0985\n",
      "    - New mask: 33 features, Fitness: -1.9665\n",
      "    - New mask: 31 features, Fitness: -1.2108\n",
      "    - New mask: 37 features, Fitness: -2.7375\n",
      "    - New mask: 36 features, Fitness: -2.7015\n",
      "    - New mask: 31 features, Fitness: -1.2046\n",
      "    - New mask: 33 features, Fitness: -1.7210\n",
      "    - New mask: 35 features, Fitness: -2.4201\n",
      "    - New mask: 34 features, Fitness: -2.9064\n",
      "    - New mask: 34 features, Fitness: -1.7753\n",
      "    - New mask: 38 features, Fitness: -3.2090\n",
      "    - New mask: 36 features, Fitness: -2.9044\n",
      "    - New mask: 33 features, Fitness: -1.4537\n",
      "    - New mask: 35 features, Fitness: -2.2769\n",
      "    - New mask: 31 features, Fitness: -0.6066\n",
      "    - New mask: 36 features, Fitness: -5.4637\n",
      "    - New mask: 33 features, Fitness: -4.4078\n",
      "    - New mask: 30 features, Fitness: -4.1833\n",
      "    - New mask: 36 features, Fitness: -5.5536\n",
      "    - New mask: 28 features, Fitness: -2.2734\n",
      "    - New mask: 29 features, Fitness: -3.9134\n",
      "    - New mask: 35 features, Fitness: -4.9946\n",
      "    - New mask: 32 features, Fitness: -4.0338\n",
      "    - New mask: 35 features, Fitness: -4.6043\n",
      "    - New mask: 33 features, Fitness: -3.8421\n",
      "    - New mask: 35 features, Fitness: -4.7245\n",
      "    - New mask: 35 features, Fitness: -4.8835\n",
      "    - New mask: 34 features, Fitness: -4.5551\n",
      "    - New mask: 35 features, Fitness: -4.3607\n",
      "    - New mask: 35 features, Fitness: -4.9474\n",
      "    - New mask: 32 features, Fitness: -3.5964\n",
      "    - New mask: 33 features, Fitness: -4.3395\n",
      "    - New mask: 32 features, Fitness: -4.9699\n",
      "    - New mask: 33 features, Fitness: -4.6912\n",
      "    - New mask: 34 features, Fitness: -4.2640\n",
      "    - New mask: 36 features, Fitness: -2.8778\n",
      "    - New mask: 37 features, Fitness: -3.6032\n",
      "    - New mask: 36 features, Fitness: -2.4362\n",
      "    - New mask: 38 features, Fitness: -4.2290\n",
      "    - New mask: 31 features, Fitness: -1.2929\n",
      "    - New mask: 38 features, Fitness: -3.4917\n",
      "    - New mask: 36 features, Fitness: -3.6212\n",
      "    - New mask: 35 features, Fitness: -3.5405\n",
      "    - New mask: 38 features, Fitness: -3.8061\n",
      "    - New mask: 36 features, Fitness: -3.2554\n",
      "    - New mask: 37 features, Fitness: -3.4556\n",
      "    - New mask: 37 features, Fitness: -3.5417\n",
      "    - New mask: 37 features, Fitness: -3.9351\n",
      "    - New mask: 37 features, Fitness: -3.8735\n",
      "    - New mask: 34 features, Fitness: -2.7436\n",
      "    - New mask: 34 features, Fitness: -2.3346\n",
      "    - New mask: 38 features, Fitness: -3.7934\n",
      "    - New mask: 34 features, Fitness: -1.6031\n",
      "    - New mask: 39 features, Fitness: -4.5277\n",
      "    - New mask: 38 features, Fitness: -3.8365\n",
      "    - New mask: 33 features, Fitness: -1.2269\n",
      "    - New mask: 35 features, Fitness: -2.2827\n",
      "    - New mask: 36 features, Fitness: -2.6210\n",
      "    - New mask: 37 features, Fitness: -2.4126\n",
      "    - New mask: 36 features, Fitness: -2.7127\n",
      "    - New mask: 35 features, Fitness: -2.9497\n",
      "    - New mask: 34 features, Fitness: -2.0253\n",
      "    - New mask: 35 features, Fitness: -1.2985\n",
      "    - New mask: 38 features, Fitness: -3.4858\n",
      "    - New mask: 38 features, Fitness: -3.3014\n",
      "    - New mask: 38 features, Fitness: -2.9903\n",
      "    - New mask: 37 features, Fitness: -3.3518\n",
      "    - New mask: 34 features, Fitness: -1.4131\n",
      "    - New mask: 33 features, Fitness: -2.7367\n",
      "    - New mask: 31 features, Fitness: -0.3333\n",
      "    - New mask: 38 features, Fitness: -3.0617\n",
      "    - New mask: 32 features, Fitness: -1.8420\n",
      "    - New mask: 39 features, Fitness: -4.3089\n",
      "    - New mask: 35 features, Fitness: -1.7100\n",
      "    - New mask: 32 features, Fitness: -1.1742\n",
      "    - New mask: 32 features, Fitness: -4.5875\n",
      "    - New mask: 33 features, Fitness: -4.3228\n",
      "    - New mask: 35 features, Fitness: -4.4091\n",
      "    - New mask: 37 features, Fitness: -6.0138\n",
      "    - New mask: 37 features, Fitness: -6.0519\n",
      "    - New mask: 34 features, Fitness: -5.1912\n",
      "    - New mask: 33 features, Fitness: -4.4186\n",
      "    - New mask: 35 features, Fitness: -5.1708\n",
      "    - New mask: 30 features, Fitness: -4.2105\n",
      "    - New mask: 36 features, Fitness: -5.2341\n",
      "    - New mask: 35 features, Fitness: -4.4245\n",
      "    - New mask: 37 features, Fitness: -5.7051\n",
      "    - New mask: 36 features, Fitness: -5.5227\n",
      "    - New mask: 35 features, Fitness: -4.6198\n",
      "    - New mask: 34 features, Fitness: -4.9328\n",
      "    - New mask: 37 features, Fitness: -6.5802\n",
      "    - New mask: 33 features, Fitness: -4.3326\n",
      "    - New mask: 38 features, Fitness: -6.2251\n",
      "    - New mask: 37 features, Fitness: -5.5378\n",
      "    - New mask: 37 features, Fitness: -5.5726\n",
      "    - New mask: 38 features, Fitness: -4.3930\n",
      "    - New mask: 34 features, Fitness: -1.8156\n",
      "    - New mask: 37 features, Fitness: -3.6024\n",
      "    - New mask: 35 features, Fitness: -1.7382\n",
      "    - New mask: 37 features, Fitness: -3.1635\n",
      "    - New mask: 34 features, Fitness: -1.9393\n",
      "    - New mask: 34 features, Fitness: -2.6086\n",
      "    - New mask: 33 features, Fitness: -1.8367\n",
      "    - New mask: 38 features, Fitness: -3.9472\n",
      "    - New mask: 36 features, Fitness: -2.8072\n",
      "    - New mask: 33 features, Fitness: -1.5364\n",
      "    - New mask: 32 features, Fitness: -1.3023\n",
      "    - New mask: 31 features, Fitness: -1.6961\n",
      "    - New mask: 35 features, Fitness: -1.9081\n",
      "    - New mask: 32 features, Fitness: -1.3581\n",
      "    - New mask: 36 features, Fitness: -3.4251\n",
      "    - New mask: 36 features, Fitness: -3.0351\n",
      "    - New mask: 34 features, Fitness: -1.8644\n",
      "    - New mask: 35 features, Fitness: -2.7891\n",
      "    - New mask: 35 features, Fitness: -2.6919\n",
      "    - New mask: 33 features, Fitness: -0.4584\n",
      "    - New mask: 33 features, Fitness: -1.1930\n",
      "    - New mask: 34 features, Fitness: -0.8543\n",
      "    - New mask: 32 features, Fitness: -0.5210\n",
      "    - New mask: 31 features, Fitness: -0.6785\n",
      "    - New mask: 33 features, Fitness: -0.4231\n",
      "    - New mask: 35 features, Fitness: -2.0195\n",
      "    - New mask: 35 features, Fitness: -1.4015\n",
      "    - New mask: 32 features, Fitness: -1.2747\n",
      "    - New mask: 31 features, Fitness: -0.3945\n",
      "    - New mask: 33 features, Fitness: -0.9877\n",
      "    - New mask: 38 features, Fitness: -2.0099\n",
      "    - New mask: 30 features, Fitness: 0.3712\n",
      "    - New mask: 38 features, Fitness: -2.7999\n",
      "    - New mask: 36 features, Fitness: -0.9827\n",
      "    - New mask: 32 features, Fitness: -1.1339\n",
      "    - New mask: 37 features, Fitness: -2.0034\n",
      "    - New mask: 34 features, Fitness: -0.5712\n",
      "    - New mask: 35 features, Fitness: -1.0905\n",
      "    - New mask: 35 features, Fitness: -1.0191\n",
      "    - New mask: 34 features, Fitness: -4.1488\n",
      "    - New mask: 37 features, Fitness: -6.3627\n",
      "    - New mask: 37 features, Fitness: -5.5695\n",
      "    - New mask: 33 features, Fitness: -4.4488\n",
      "    - New mask: 35 features, Fitness: -4.7063\n",
      "    - New mask: 39 features, Fitness: -6.4075\n",
      "    - New mask: 35 features, Fitness: -5.0297\n",
      "    - New mask: 36 features, Fitness: -5.9505\n",
      "    - New mask: 37 features, Fitness: -5.8502\n",
      "    - New mask: 35 features, Fitness: -4.4627\n",
      "    - New mask: 35 features, Fitness: -4.4687\n",
      "    - New mask: 37 features, Fitness: -5.6448\n",
      "    - New mask: 37 features, Fitness: -5.8848\n",
      "    - New mask: 32 features, Fitness: -4.1967\n",
      "    - New mask: 32 features, Fitness: -3.8127\n",
      "    - New mask: 40 features, Fitness: -6.8767\n",
      "    - New mask: 37 features, Fitness: -5.9219\n",
      "    - New mask: 34 features, Fitness: -4.2070\n",
      "    - New mask: 35 features, Fitness: -4.4826\n",
      "    - New mask: 38 features, Fitness: -6.7387\n",
      "    - New mask: 33 features, Fitness: -6.0215\n",
      "    - New mask: 36 features, Fitness: -7.1703\n",
      "    - New mask: 36 features, Fitness: -6.8948\n",
      "    - New mask: 35 features, Fitness: -7.0562\n",
      "    - New mask: 33 features, Fitness: -6.1141\n",
      "    - New mask: 37 features, Fitness: -8.2971\n",
      "    - New mask: 34 features, Fitness: -5.9367\n",
      "    - New mask: 40 features, Fitness: -9.9579\n",
      "    - New mask: 37 features, Fitness: -7.8909\n",
      "    - New mask: 36 features, Fitness: -6.6804\n",
      "    - New mask: 40 features, Fitness: -10.3374\n",
      "    - New mask: 34 features, Fitness: -6.7148\n",
      "    - New mask: 35 features, Fitness: -7.6693\n",
      "    - New mask: 38 features, Fitness: -8.4090\n",
      "    - New mask: 35 features, Fitness: -6.0301\n",
      "    - New mask: 39 features, Fitness: -9.9136\n",
      "    - New mask: 36 features, Fitness: -7.5076\n",
      "    - New mask: 36 features, Fitness: -7.3772\n",
      "    - New mask: 35 features, Fitness: -7.0806\n",
      "    - New mask: 36 features, Fitness: -8.1816\n",
      "    - New mask: 32 features, Fitness: -1.5764\n",
      "    - New mask: 37 features, Fitness: -3.3921\n",
      "    - New mask: 33 features, Fitness: -3.7025\n",
      "    - New mask: 36 features, Fitness: -3.7277\n",
      "    - New mask: 34 features, Fitness: -2.1543\n",
      "    - New mask: 35 features, Fitness: -2.2965\n",
      "    - New mask: 34 features, Fitness: -2.1543\n",
      "    - New mask: 38 features, Fitness: -2.8492\n",
      "    - New mask: 38 features, Fitness: -3.9205\n",
      "    - New mask: 38 features, Fitness: -3.6151\n",
      "    - New mask: 34 features, Fitness: -1.8541\n",
      "    - New mask: 37 features, Fitness: -3.1531\n",
      "    - New mask: 36 features, Fitness: -2.3082\n",
      "    - New mask: 38 features, Fitness: -3.6885\n",
      "    - New mask: 36 features, Fitness: -2.0959\n",
      "    - New mask: 37 features, Fitness: -3.6999\n",
      "    - New mask: 37 features, Fitness: -2.8273\n",
      "    - New mask: 37 features, Fitness: -3.5192\n",
      "    - New mask: 35 features, Fitness: -2.5409\n",
      "    - New mask: 34 features, Fitness: -2.3297\n",
      "=== End of Round 8: Vote mask selects 40 features (rho: 0.42)\n",
      "    Indices: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 9 ================\n",
      "  Adaptive rho for this round: 0.45\n",
      "    - New mask: 35 features, Fitness: -2.1133\n",
      "    - New mask: 39 features, Fitness: -3.3044\n",
      "    - New mask: 36 features, Fitness: -2.1981\n",
      "    - New mask: 33 features, Fitness: -1.5953\n",
      "    - New mask: 36 features, Fitness: -2.9097\n",
      "    - New mask: 35 features, Fitness: -2.2668\n",
      "    - New mask: 29 features, Fitness: -0.2737\n",
      "    - New mask: 33 features, Fitness: -1.8898\n",
      "    - New mask: 35 features, Fitness: -1.9434\n",
      "    - New mask: 35 features, Fitness: -3.0682\n",
      "    - New mask: 32 features, Fitness: -1.8310\n",
      "    - New mask: 35 features, Fitness: -2.5383\n",
      "    - New mask: 34 features, Fitness: -1.4821\n",
      "    - New mask: 35 features, Fitness: -2.4863\n",
      "    - New mask: 35 features, Fitness: -2.3075\n",
      "    - New mask: 36 features, Fitness: -2.6225\n",
      "    - New mask: 36 features, Fitness: -2.4173\n",
      "    - New mask: 33 features, Fitness: -1.6254\n",
      "    - New mask: 33 features, Fitness: -1.4157\n",
      "    - New mask: 34 features, Fitness: -1.5355\n",
      "    - New mask: 33 features, Fitness: -4.3032\n",
      "    - New mask: 33 features, Fitness: -3.9714\n",
      "    - New mask: 34 features, Fitness: -5.2531\n",
      "    - New mask: 35 features, Fitness: -5.4525\n",
      "    - New mask: 33 features, Fitness: -3.6660\n",
      "    - New mask: 33 features, Fitness: -3.5984\n",
      "    - New mask: 33 features, Fitness: -4.6133\n",
      "    - New mask: 30 features, Fitness: -2.7922\n",
      "    - New mask: 33 features, Fitness: -3.8863\n",
      "    - New mask: 34 features, Fitness: -4.0986\n",
      "    - New mask: 36 features, Fitness: -4.7827\n",
      "    - New mask: 33 features, Fitness: -3.9258\n",
      "    - New mask: 34 features, Fitness: -4.0635\n",
      "    - New mask: 36 features, Fitness: -5.4283\n",
      "    - New mask: 35 features, Fitness: -4.5305\n",
      "    - New mask: 31 features, Fitness: -3.2053\n",
      "    - New mask: 35 features, Fitness: -4.4392\n",
      "    - New mask: 35 features, Fitness: -4.6900\n",
      "    - New mask: 38 features, Fitness: -5.9610\n",
      "    - New mask: 31 features, Fitness: -2.8108\n",
      "    - New mask: 34 features, Fitness: -2.1690\n",
      "    - New mask: 33 features, Fitness: -1.6660\n",
      "    - New mask: 37 features, Fitness: -3.1992\n",
      "    - New mask: 35 features, Fitness: -3.2618\n",
      "    - New mask: 35 features, Fitness: -2.2845\n",
      "    - New mask: 32 features, Fitness: -1.2370\n",
      "    - New mask: 33 features, Fitness: -2.0622\n",
      "    - New mask: 36 features, Fitness: -3.6198\n",
      "    - New mask: 34 features, Fitness: -1.6929\n",
      "    - New mask: 35 features, Fitness: -2.4263\n",
      "    - New mask: 35 features, Fitness: -2.7253\n",
      "    - New mask: 35 features, Fitness: -2.5685\n",
      "    - New mask: 38 features, Fitness: -4.2216\n",
      "    - New mask: 38 features, Fitness: -3.7039\n",
      "    - New mask: 32 features, Fitness: -1.7543\n",
      "    - New mask: 36 features, Fitness: -3.1355\n",
      "    - New mask: 35 features, Fitness: -2.4564\n",
      "    - New mask: 35 features, Fitness: -2.5576\n",
      "    - New mask: 35 features, Fitness: -3.2912\n",
      "    - New mask: 38 features, Fitness: -3.9421\n",
      "    - New mask: 32 features, Fitness: -0.9615\n",
      "    - New mask: 37 features, Fitness: -2.7377\n",
      "    - New mask: 39 features, Fitness: -3.5920\n",
      "    - New mask: 32 features, Fitness: -1.4858\n",
      "    - New mask: 37 features, Fitness: -3.2865\n",
      "    - New mask: 33 features, Fitness: -2.1041\n",
      "    - New mask: 34 features, Fitness: -1.4550\n",
      "    - New mask: 32 features, Fitness: -0.3257\n",
      "    - New mask: 35 features, Fitness: -2.2014\n",
      "    - New mask: 36 features, Fitness: -2.1085\n",
      "    - New mask: 35 features, Fitness: -1.7889\n",
      "    - New mask: 36 features, Fitness: -2.1037\n",
      "    - New mask: 36 features, Fitness: -2.3954\n",
      "    - New mask: 34 features, Fitness: -2.7653\n",
      "    - New mask: 34 features, Fitness: -1.9877\n",
      "    - New mask: 36 features, Fitness: -1.9835\n",
      "    - New mask: 33 features, Fitness: -1.4115\n",
      "    - New mask: 34 features, Fitness: -1.7111\n",
      "    - New mask: 33 features, Fitness: -1.1404\n",
      "    - New mask: 36 features, Fitness: -3.0524\n",
      "    - New mask: 34 features, Fitness: -4.3122\n",
      "    - New mask: 35 features, Fitness: -5.0076\n",
      "    - New mask: 31 features, Fitness: -3.9607\n",
      "    - New mask: 34 features, Fitness: -5.1894\n",
      "    - New mask: 34 features, Fitness: -5.1789\n",
      "    - New mask: 33 features, Fitness: -5.0486\n",
      "    - New mask: 37 features, Fitness: -5.8245\n",
      "    - New mask: 36 features, Fitness: -5.9013\n",
      "    - New mask: 33 features, Fitness: -5.2420\n",
      "    - New mask: 37 features, Fitness: -5.8478\n",
      "    - New mask: 40 features, Fitness: -6.9869\n",
      "    - New mask: 35 features, Fitness: -5.4166\n",
      "    - New mask: 34 features, Fitness: -4.7212\n",
      "    - New mask: 36 features, Fitness: -5.5316\n",
      "    - New mask: 33 features, Fitness: -4.2715\n",
      "    - New mask: 38 features, Fitness: -6.7421\n",
      "    - New mask: 37 features, Fitness: -6.1461\n",
      "    - New mask: 34 features, Fitness: -4.3657\n",
      "    - New mask: 37 features, Fitness: -6.1427\n",
      "    - New mask: 36 features, Fitness: -5.4470\n",
      "    - New mask: 35 features, Fitness: -2.8534\n",
      "    - New mask: 33 features, Fitness: -1.3852\n",
      "    - New mask: 35 features, Fitness: -2.8192\n",
      "    - New mask: 35 features, Fitness: -3.1429\n",
      "    - New mask: 35 features, Fitness: -2.8031\n",
      "    - New mask: 37 features, Fitness: -3.0395\n",
      "    - New mask: 35 features, Fitness: -2.2215\n",
      "    - New mask: 35 features, Fitness: -2.1768\n",
      "    - New mask: 37 features, Fitness: -3.7355\n",
      "    - New mask: 35 features, Fitness: -2.6107\n",
      "    - New mask: 35 features, Fitness: -2.6915\n",
      "    - New mask: 34 features, Fitness: -2.3446\n",
      "    - New mask: 32 features, Fitness: -2.0015\n",
      "    - New mask: 33 features, Fitness: -2.4691\n",
      "    - New mask: 31 features, Fitness: -1.3813\n",
      "    - New mask: 39 features, Fitness: -4.7624\n",
      "    - New mask: 33 features, Fitness: -2.1584\n",
      "    - New mask: 36 features, Fitness: -2.7396\n",
      "    - New mask: 34 features, Fitness: -1.9315\n",
      "    - New mask: 37 features, Fitness: -3.0874\n",
      "    - New mask: 29 features, Fitness: 0.3645\n",
      "    - New mask: 35 features, Fitness: -1.4289\n",
      "    - New mask: 33 features, Fitness: -0.7486\n",
      "    - New mask: 33 features, Fitness: -0.4961\n",
      "    - New mask: 34 features, Fitness: -1.0038\n",
      "    - New mask: 31 features, Fitness: -1.2394\n",
      "    - New mask: 35 features, Fitness: -0.8295\n",
      "    - New mask: 34 features, Fitness: -1.0350\n",
      "    - New mask: 35 features, Fitness: -1.1047\n",
      "    - New mask: 34 features, Fitness: -0.8917\n",
      "    - New mask: 34 features, Fitness: -0.7336\n",
      "    - New mask: 34 features, Fitness: -1.1178\n",
      "    - New mask: 30 features, Fitness: 0.2370\n",
      "    - New mask: 37 features, Fitness: -1.8816\n",
      "    - New mask: 36 features, Fitness: -1.1977\n",
      "    - New mask: 33 features, Fitness: -1.4569\n",
      "    - New mask: 34 features, Fitness: -1.5916\n",
      "    - New mask: 35 features, Fitness: -0.8331\n",
      "    - New mask: 32 features, Fitness: -0.1304\n",
      "    - New mask: 36 features, Fitness: -1.4623\n",
      "    - New mask: 37 features, Fitness: -5.7284\n",
      "    - New mask: 35 features, Fitness: -4.6023\n",
      "    - New mask: 35 features, Fitness: -4.9375\n",
      "    - New mask: 31 features, Fitness: -3.7974\n",
      "    - New mask: 35 features, Fitness: -5.2704\n",
      "    - New mask: 36 features, Fitness: -5.4043\n",
      "    - New mask: 34 features, Fitness: -4.5709\n",
      "    - New mask: 38 features, Fitness: -6.0082\n",
      "    - New mask: 35 features, Fitness: -4.9245\n",
      "    - New mask: 35 features, Fitness: -4.6943\n",
      "    - New mask: 35 features, Fitness: -4.9267\n",
      "    - New mask: 37 features, Fitness: -5.5553\n",
      "    - New mask: 35 features, Fitness: -5.2150\n",
      "    - New mask: 36 features, Fitness: -4.8503\n",
      "    - New mask: 35 features, Fitness: -4.9318\n",
      "    - New mask: 37 features, Fitness: -5.9060\n",
      "    - New mask: 33 features, Fitness: -4.3056\n",
      "    - New mask: 34 features, Fitness: -4.7869\n",
      "    - New mask: 35 features, Fitness: -4.5670\n",
      "    - New mask: 38 features, Fitness: -6.0976\n",
      "    - New mask: 35 features, Fitness: -6.9024\n",
      "    - New mask: 35 features, Fitness: -6.2291\n",
      "    - New mask: 37 features, Fitness: -7.7988\n",
      "    - New mask: 37 features, Fitness: -7.6061\n",
      "    - New mask: 37 features, Fitness: -8.6982\n",
      "    - New mask: 38 features, Fitness: -8.8888\n",
      "    - New mask: 36 features, Fitness: -8.6074\n",
      "    - New mask: 37 features, Fitness: -8.1599\n",
      "    - New mask: 34 features, Fitness: -5.8779\n",
      "    - New mask: 33 features, Fitness: -5.6532\n",
      "    - New mask: 37 features, Fitness: -8.5270\n",
      "    - New mask: 37 features, Fitness: -8.5193\n",
      "    - New mask: 33 features, Fitness: -6.7121\n",
      "    - New mask: 40 features, Fitness: -9.9579\n",
      "    - New mask: 36 features, Fitness: -6.7104\n",
      "    - New mask: 36 features, Fitness: -7.5042\n",
      "    - New mask: 37 features, Fitness: -8.5444\n",
      "    - New mask: 35 features, Fitness: -6.5365\n",
      "    - New mask: 34 features, Fitness: -7.1477\n",
      "    - New mask: 33 features, Fitness: -7.0328\n",
      "    - New mask: 37 features, Fitness: -3.7970\n",
      "    - New mask: 38 features, Fitness: -3.4087\n",
      "    - New mask: 33 features, Fitness: -2.8451\n",
      "    - New mask: 37 features, Fitness: -3.3854\n",
      "    - New mask: 35 features, Fitness: -2.0919\n",
      "    - New mask: 37 features, Fitness: -2.7673\n",
      "    - New mask: 39 features, Fitness: -3.7652\n",
      "    - New mask: 39 features, Fitness: -3.6562\n",
      "    - New mask: 41 features, Fitness: -4.8344\n",
      "    - New mask: 37 features, Fitness: -3.4742\n",
      "    - New mask: 33 features, Fitness: -2.4055\n",
      "    - New mask: 35 features, Fitness: -2.3503\n",
      "    - New mask: 37 features, Fitness: -3.4189\n",
      "    - New mask: 37 features, Fitness: -2.6737\n",
      "    - New mask: 36 features, Fitness: -2.7692\n",
      "    - New mask: 36 features, Fitness: -2.7025\n",
      "    - New mask: 34 features, Fitness: -1.8958\n",
      "    - New mask: 34 features, Fitness: -1.7533\n",
      "    - New mask: 34 features, Fitness: -2.3397\n",
      "    - New mask: 34 features, Fitness: -2.2891\n",
      "=== End of Round 9: Vote mask selects 39 features (rho: 0.45)\n",
      "    Indices: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 10 ================\n",
      "  Adaptive rho for this round: 0.48\n",
      "    - New mask: 33 features, Fitness: -1.5465\n",
      "    - New mask: 38 features, Fitness: -2.8555\n",
      "    - New mask: 31 features, Fitness: -0.7924\n",
      "    - New mask: 33 features, Fitness: -1.4189\n",
      "    - New mask: 34 features, Fitness: -3.5401\n",
      "    - New mask: 35 features, Fitness: -2.4953\n",
      "    - New mask: 31 features, Fitness: -0.8717\n",
      "    - New mask: 30 features, Fitness: -0.7399\n",
      "    - New mask: 33 features, Fitness: -1.3797\n",
      "    - New mask: 38 features, Fitness: -3.6137\n",
      "    - New mask: 38 features, Fitness: -3.2276\n",
      "    - New mask: 32 features, Fitness: -1.0563\n",
      "    - New mask: 34 features, Fitness: -2.0978\n",
      "    - New mask: 37 features, Fitness: -3.0707\n",
      "    - New mask: 33 features, Fitness: -1.3239\n",
      "    - New mask: 34 features, Fitness: -1.7902\n",
      "    - New mask: 35 features, Fitness: -2.0519\n",
      "    - New mask: 33 features, Fitness: -1.6751\n",
      "    - New mask: 31 features, Fitness: -1.1440\n",
      "    - New mask: 33 features, Fitness: -1.7048\n",
      "    - New mask: 34 features, Fitness: -3.7974\n",
      "    - New mask: 33 features, Fitness: -3.8484\n",
      "    - New mask: 34 features, Fitness: -5.3686\n",
      "    - New mask: 36 features, Fitness: -5.3201\n",
      "    - New mask: 33 features, Fitness: -3.7033\n",
      "    - New mask: 31 features, Fitness: -3.6545\n",
      "    - New mask: 34 features, Fitness: -4.1542\n",
      "    - New mask: 34 features, Fitness: -3.9774\n",
      "    - New mask: 36 features, Fitness: -4.7430\n",
      "    - New mask: 33 features, Fitness: -4.0729\n",
      "    - New mask: 33 features, Fitness: -3.8153\n",
      "    - New mask: 33 features, Fitness: -4.4743\n",
      "    - New mask: 35 features, Fitness: -3.7928\n",
      "    - New mask: 37 features, Fitness: -4.8070\n",
      "    - New mask: 35 features, Fitness: -4.3589\n",
      "    - New mask: 30 features, Fitness: -2.6572\n",
      "    - New mask: 35 features, Fitness: -4.5789\n",
      "    - New mask: 37 features, Fitness: -5.3913\n",
      "    - New mask: 33 features, Fitness: -3.6537\n",
      "    - New mask: 33 features, Fitness: -3.8010\n",
      "    - New mask: 33 features, Fitness: -1.9504\n",
      "    - New mask: 32 features, Fitness: -1.4163\n",
      "    - New mask: 34 features, Fitness: -1.7389\n",
      "    - New mask: 33 features, Fitness: -2.2204\n",
      "    - New mask: 32 features, Fitness: -1.5287\n",
      "    - New mask: 35 features, Fitness: -2.7331\n",
      "    - New mask: 34 features, Fitness: -2.4676\n",
      "    - New mask: 35 features, Fitness: -2.3854\n",
      "    - New mask: 35 features, Fitness: -2.1939\n",
      "    - New mask: 32 features, Fitness: -1.6457\n",
      "    - New mask: 31 features, Fitness: -1.3824\n",
      "    - New mask: 37 features, Fitness: -2.8668\n",
      "    - New mask: 37 features, Fitness: -3.1667\n",
      "    - New mask: 35 features, Fitness: -2.4558\n",
      "    - New mask: 31 features, Fitness: -2.1648\n",
      "    - New mask: 36 features, Fitness: -2.7089\n",
      "    - New mask: 35 features, Fitness: -2.4241\n",
      "    - New mask: 33 features, Fitness: -1.7693\n",
      "    - New mask: 34 features, Fitness: -2.9455\n",
      "    - New mask: 36 features, Fitness: -2.7120\n",
      "    - New mask: 34 features, Fitness: -1.1603\n",
      "    - New mask: 32 features, Fitness: -1.2323\n",
      "    - New mask: 36 features, Fitness: -2.7663\n",
      "    - New mask: 32 features, Fitness: -1.3559\n",
      "    - New mask: 35 features, Fitness: -2.0932\n",
      "    - New mask: 35 features, Fitness: -1.8743\n",
      "    - New mask: 34 features, Fitness: -0.9515\n",
      "    - New mask: 34 features, Fitness: -2.2878\n",
      "    - New mask: 32 features, Fitness: -0.8480\n",
      "    - New mask: 36 features, Fitness: -3.1829\n",
      "    - New mask: 34 features, Fitness: -1.4030\n",
      "    - New mask: 36 features, Fitness: -1.7650\n",
      "    - New mask: 32 features, Fitness: -0.4367\n",
      "    - New mask: 36 features, Fitness: -2.8854\n",
      "    - New mask: 35 features, Fitness: -1.6476\n",
      "    - New mask: 35 features, Fitness: -1.9682\n",
      "    - New mask: 35 features, Fitness: -1.8203\n",
      "    - New mask: 34 features, Fitness: -1.1701\n",
      "    - New mask: 35 features, Fitness: -2.5426\n",
      "    - New mask: 36 features, Fitness: -3.5835\n",
      "    - New mask: 31 features, Fitness: -3.3477\n",
      "    - New mask: 31 features, Fitness: -3.3113\n",
      "    - New mask: 33 features, Fitness: -4.6689\n",
      "    - New mask: 35 features, Fitness: -5.3842\n",
      "    - New mask: 33 features, Fitness: -4.8105\n",
      "    - New mask: 32 features, Fitness: -4.1849\n",
      "    - New mask: 32 features, Fitness: -3.6871\n",
      "    - New mask: 35 features, Fitness: -4.8250\n",
      "    - New mask: 33 features, Fitness: -4.8704\n",
      "    - New mask: 36 features, Fitness: -5.5141\n",
      "    - New mask: 39 features, Fitness: -6.4993\n",
      "    - New mask: 32 features, Fitness: -3.9947\n",
      "    - New mask: 35 features, Fitness: -4.6649\n",
      "    - New mask: 35 features, Fitness: -4.8937\n",
      "    - New mask: 33 features, Fitness: -4.3612\n",
      "    - New mask: 34 features, Fitness: -5.3717\n",
      "    - New mask: 34 features, Fitness: -4.9820\n",
      "    - New mask: 32 features, Fitness: -3.8736\n",
      "    - New mask: 36 features, Fitness: -6.0991\n",
      "    - New mask: 33 features, Fitness: -4.8979\n",
      "    - New mask: 35 features, Fitness: -2.6430\n",
      "    - New mask: 37 features, Fitness: -3.2404\n",
      "    - New mask: 30 features, Fitness: -0.8139\n",
      "    - New mask: 34 features, Fitness: -2.1103\n",
      "    - New mask: 33 features, Fitness: -1.4296\n",
      "    - New mask: 38 features, Fitness: -3.6407\n",
      "    - New mask: 31 features, Fitness: -1.4418\n",
      "    - New mask: 31 features, Fitness: -0.3081\n",
      "    - New mask: 35 features, Fitness: -3.0557\n",
      "    - New mask: 32 features, Fitness: -2.0263\n",
      "    - New mask: 36 features, Fitness: -3.7093\n",
      "    - New mask: 32 features, Fitness: -1.3023\n",
      "    - New mask: 34 features, Fitness: -2.2446\n",
      "    - New mask: 33 features, Fitness: -1.3297\n",
      "    - New mask: 27 features, Fitness: -0.3245\n",
      "    - New mask: 33 features, Fitness: -1.9528\n",
      "    - New mask: 35 features, Fitness: -2.5201\n",
      "    - New mask: 37 features, Fitness: -3.1138\n",
      "    - New mask: 33 features, Fitness: -1.8955\n",
      "    - New mask: 39 features, Fitness: -4.3180\n",
      "    - New mask: 34 features, Fitness: -0.8123\n",
      "    - New mask: 33 features, Fitness: -1.1896\n",
      "    - New mask: 32 features, Fitness: -0.4191\n",
      "    - New mask: 32 features, Fitness: -0.6451\n",
      "    - New mask: 40 features, Fitness: -2.6262\n",
      "    - New mask: 35 features, Fitness: -0.8100\n",
      "    - New mask: 30 features, Fitness: 0.2364\n",
      "    - New mask: 35 features, Fitness: -1.2508\n",
      "    - New mask: 38 features, Fitness: -1.8994\n",
      "    - New mask: 33 features, Fitness: -0.5738\n",
      "    - New mask: 33 features, Fitness: -1.2227\n",
      "    - New mask: 31 features, Fitness: -0.5735\n",
      "    - New mask: 34 features, Fitness: -0.7128\n",
      "    - New mask: 32 features, Fitness: -0.5986\n",
      "    - New mask: 35 features, Fitness: -1.2579\n",
      "    - New mask: 33 features, Fitness: -1.5300\n",
      "    - New mask: 32 features, Fitness: -0.5866\n",
      "    - New mask: 34 features, Fitness: -0.5263\n",
      "    - New mask: 31 features, Fitness: -0.0276\n",
      "    - New mask: 34 features, Fitness: -0.7427\n",
      "    - New mask: 36 features, Fitness: -5.7002\n",
      "    - New mask: 34 features, Fitness: -4.9088\n",
      "    - New mask: 34 features, Fitness: -3.9741\n",
      "    - New mask: 33 features, Fitness: -4.1019\n",
      "    - New mask: 36 features, Fitness: -5.0456\n",
      "    - New mask: 34 features, Fitness: -4.5085\n",
      "    - New mask: 33 features, Fitness: -4.2906\n",
      "    - New mask: 36 features, Fitness: -4.9948\n",
      "    - New mask: 36 features, Fitness: -5.6292\n",
      "    - New mask: 38 features, Fitness: -5.9537\n",
      "    - New mask: 36 features, Fitness: -4.7359\n",
      "    - New mask: 33 features, Fitness: -3.8910\n",
      "    - New mask: 35 features, Fitness: -5.0232\n",
      "    - New mask: 34 features, Fitness: -4.0159\n",
      "    - New mask: 34 features, Fitness: -5.4025\n",
      "    - New mask: 36 features, Fitness: -5.4612\n",
      "    - New mask: 38 features, Fitness: -6.3156\n",
      "    - New mask: 33 features, Fitness: -4.8081\n",
      "    - New mask: 36 features, Fitness: -4.6525\n",
      "    - New mask: 34 features, Fitness: -4.8885\n",
      "    - New mask: 35 features, Fitness: -7.4257\n",
      "    - New mask: 34 features, Fitness: -5.8240\n",
      "    - New mask: 33 features, Fitness: -5.9147\n",
      "    - New mask: 37 features, Fitness: -7.8143\n",
      "    - New mask: 35 features, Fitness: -6.6048\n",
      "    - New mask: 32 features, Fitness: -4.8256\n",
      "    - New mask: 35 features, Fitness: -7.1515\n",
      "    - New mask: 37 features, Fitness: -8.8620\n",
      "    - New mask: 34 features, Fitness: -5.8741\n",
      "    - New mask: 34 features, Fitness: -6.5043\n",
      "    - New mask: 36 features, Fitness: -7.9822\n",
      "    - New mask: 34 features, Fitness: -6.2459\n",
      "    - New mask: 33 features, Fitness: -5.9286\n",
      "    - New mask: 37 features, Fitness: -7.9710\n",
      "    - New mask: 35 features, Fitness: -7.1608\n",
      "    - New mask: 35 features, Fitness: -7.6345\n",
      "    - New mask: 35 features, Fitness: -6.9223\n",
      "    - New mask: 34 features, Fitness: -6.0155\n",
      "    - New mask: 32 features, Fitness: -6.3004\n",
      "    - New mask: 34 features, Fitness: -7.1978\n",
      "    - New mask: 36 features, Fitness: -2.8731\n",
      "    - New mask: 34 features, Fitness: -2.0053\n",
      "    - New mask: 35 features, Fitness: -2.9672\n",
      "    - New mask: 35 features, Fitness: -2.2890\n",
      "    - New mask: 38 features, Fitness: -3.4608\n",
      "    - New mask: 36 features, Fitness: -2.2248\n",
      "    - New mask: 36 features, Fitness: -2.3480\n",
      "    - New mask: 34 features, Fitness: -1.5972\n",
      "    - New mask: 37 features, Fitness: -3.7246\n",
      "    - New mask: 36 features, Fitness: -3.0523\n",
      "    - New mask: 36 features, Fitness: -3.6806\n",
      "    - New mask: 37 features, Fitness: -3.0057\n",
      "    - New mask: 36 features, Fitness: -2.5838\n",
      "    - New mask: 38 features, Fitness: -2.9335\n",
      "    - New mask: 37 features, Fitness: -2.7242\n",
      "    - New mask: 38 features, Fitness: -3.4581\n",
      "    - New mask: 34 features, Fitness: -1.9503\n",
      "    - New mask: 34 features, Fitness: -1.7533\n",
      "    - New mask: 38 features, Fitness: -2.9360\n",
      "    - New mask: 34 features, Fitness: -1.7917\n",
      "=== End of Round 10: Vote mask selects 38 features (rho: 0.48)\n",
      "    Indices: [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 11 ================\n",
      "  Adaptive rho for this round: 0.52\n",
      "    - New mask: 36 features, Fitness: -2.7376\n",
      "    - New mask: 34 features, Fitness: -1.8558\n",
      "    - New mask: 32 features, Fitness: -1.1722\n",
      "    - New mask: 32 features, Fitness: -1.7577\n",
      "    - New mask: 36 features, Fitness: -4.0531\n",
      "    - New mask: 35 features, Fitness: -3.1648\n",
      "    - New mask: 32 features, Fitness: -1.3709\n",
      "    - New mask: 32 features, Fitness: -1.3508\n",
      "    - New mask: 36 features, Fitness: -3.5265\n",
      "    - New mask: 34 features, Fitness: -2.2584\n",
      "    - New mask: 36 features, Fitness: -2.8337\n",
      "    - New mask: 32 features, Fitness: -1.5735\n",
      "    - New mask: 33 features, Fitness: -1.8302\n",
      "    - New mask: 33 features, Fitness: -1.2659\n",
      "    - New mask: 35 features, Fitness: -1.8438\n",
      "    - New mask: 38 features, Fitness: -3.2110\n",
      "    - New mask: 32 features, Fitness: -1.1324\n",
      "    - New mask: 35 features, Fitness: -2.4509\n",
      "    - New mask: 32 features, Fitness: -1.5432\n",
      "    - New mask: 29 features, Fitness: -0.7539\n",
      "    - New mask: 36 features, Fitness: -4.5536\n",
      "    - New mask: 27 features, Fitness: -2.2551\n",
      "    - New mask: 34 features, Fitness: -4.3939\n",
      "    - New mask: 35 features, Fitness: -4.5427\n",
      "    - New mask: 31 features, Fitness: -3.3076\n",
      "    - New mask: 34 features, Fitness: -4.2546\n",
      "    - New mask: 34 features, Fitness: -4.4415\n",
      "    - New mask: 34 features, Fitness: -3.9361\n",
      "    - New mask: 32 features, Fitness: -3.4842\n",
      "    - New mask: 30 features, Fitness: -2.8635\n",
      "    - New mask: 33 features, Fitness: -3.8327\n",
      "    - New mask: 35 features, Fitness: -4.4751\n",
      "    - New mask: 31 features, Fitness: -2.8208\n",
      "    - New mask: 34 features, Fitness: -3.5061\n",
      "    - New mask: 33 features, Fitness: -3.3184\n",
      "    - New mask: 31 features, Fitness: -2.8954\n",
      "    - New mask: 35 features, Fitness: -4.4503\n",
      "    - New mask: 36 features, Fitness: -5.1131\n",
      "    - New mask: 33 features, Fitness: -3.8452\n",
      "    - New mask: 34 features, Fitness: -4.1708\n",
      "    - New mask: 33 features, Fitness: -2.1071\n",
      "    - New mask: 32 features, Fitness: -1.5713\n",
      "    - New mask: 34 features, Fitness: -2.7250\n",
      "    - New mask: 36 features, Fitness: -3.5375\n",
      "    - New mask: 33 features, Fitness: -1.5791\n",
      "    - New mask: 33 features, Fitness: -2.5448\n",
      "    - New mask: 34 features, Fitness: -2.0576\n",
      "    - New mask: 35 features, Fitness: -2.5056\n",
      "    - New mask: 33 features, Fitness: -1.5615\n",
      "    - New mask: 31 features, Fitness: -1.6939\n",
      "    - New mask: 32 features, Fitness: -1.0541\n",
      "    - New mask: 35 features, Fitness: -2.9831\n",
      "    - New mask: 33 features, Fitness: -2.0947\n",
      "    - New mask: 33 features, Fitness: -2.0941\n",
      "    - New mask: 34 features, Fitness: -2.3494\n",
      "    - New mask: 37 features, Fitness: -3.6800\n",
      "    - New mask: 34 features, Fitness: -2.4033\n",
      "    - New mask: 34 features, Fitness: -1.9232\n",
      "    - New mask: 34 features, Fitness: -1.8177\n",
      "    - New mask: 34 features, Fitness: -2.4374\n",
      "    - New mask: 33 features, Fitness: -0.9748\n",
      "    - New mask: 35 features, Fitness: -2.7962\n",
      "    - New mask: 36 features, Fitness: -2.9565\n",
      "    - New mask: 34 features, Fitness: -1.5763\n",
      "    - New mask: 37 features, Fitness: -2.4172\n",
      "    - New mask: 37 features, Fitness: -3.0867\n",
      "    - New mask: 33 features, Fitness: -1.7892\n",
      "    - New mask: 31 features, Fitness: -1.2490\n",
      "    - New mask: 29 features, Fitness: 0.1287\n",
      "    - New mask: 36 features, Fitness: -2.1842\n",
      "    - New mask: 34 features, Fitness: -1.4027\n",
      "    - New mask: 36 features, Fitness: -2.3674\n",
      "    - New mask: 34 features, Fitness: -1.5721\n",
      "    - New mask: 35 features, Fitness: -1.4805\n",
      "    - New mask: 34 features, Fitness: -1.3602\n",
      "    - New mask: 34 features, Fitness: -1.3154\n",
      "    - New mask: 34 features, Fitness: -1.3211\n",
      "    - New mask: 34 features, Fitness: -1.2879\n",
      "    - New mask: 32 features, Fitness: -2.0350\n",
      "    - New mask: 37 features, Fitness: -4.0897\n",
      "    - New mask: 35 features, Fitness: -4.7667\n",
      "    - New mask: 30 features, Fitness: -3.2315\n",
      "    - New mask: 32 features, Fitness: -4.0730\n",
      "    - New mask: 37 features, Fitness: -6.0082\n",
      "    - New mask: 31 features, Fitness: -3.9549\n",
      "    - New mask: 37 features, Fitness: -5.5844\n",
      "    - New mask: 38 features, Fitness: -6.1173\n",
      "    - New mask: 33 features, Fitness: -3.8554\n",
      "    - New mask: 33 features, Fitness: -4.5641\n",
      "    - New mask: 36 features, Fitness: -4.9982\n",
      "    - New mask: 36 features, Fitness: -4.9841\n",
      "    - New mask: 33 features, Fitness: -3.9635\n",
      "    - New mask: 32 features, Fitness: -3.7711\n",
      "    - New mask: 33 features, Fitness: -4.3629\n",
      "    - New mask: 35 features, Fitness: -5.4560\n",
      "    - New mask: 35 features, Fitness: -5.1034\n",
      "    - New mask: 33 features, Fitness: -4.6175\n",
      "    - New mask: 35 features, Fitness: -4.9072\n",
      "    - New mask: 33 features, Fitness: -4.2959\n",
      "    - New mask: 32 features, Fitness: -4.3670\n",
      "    - New mask: 33 features, Fitness: -0.8728\n",
      "    - New mask: 36 features, Fitness: -2.7245\n",
      "    - New mask: 30 features, Fitness: -0.4533\n",
      "    - New mask: 33 features, Fitness: -1.1893\n",
      "    - New mask: 30 features, Fitness: -0.6026\n",
      "    - New mask: 36 features, Fitness: -2.4730\n",
      "    - New mask: 31 features, Fitness: -1.0527\n",
      "    - New mask: 33 features, Fitness: -1.3996\n",
      "    - New mask: 37 features, Fitness: -3.3121\n",
      "    - New mask: 33 features, Fitness: -1.9336\n",
      "    - New mask: 34 features, Fitness: -1.9946\n",
      "    - New mask: 31 features, Fitness: -0.4177\n",
      "    - New mask: 33 features, Fitness: -1.8550\n",
      "    - New mask: 37 features, Fitness: -2.9552\n",
      "    - New mask: 34 features, Fitness: -0.7500\n",
      "    - New mask: 35 features, Fitness: -2.4979\n",
      "    - New mask: 38 features, Fitness: -3.2286\n",
      "    - New mask: 35 features, Fitness: -2.4944\n",
      "    - New mask: 36 features, Fitness: -2.9868\n",
      "    - New mask: 37 features, Fitness: -2.3927\n",
      "    - New mask: 33 features, Fitness: -0.6411\n",
      "    - New mask: 32 features, Fitness: -0.6373\n",
      "    - New mask: 34 features, Fitness: -1.1758\n",
      "    - New mask: 33 features, Fitness: -0.4996\n",
      "    - New mask: 33 features, Fitness: -0.1774\n",
      "    - New mask: 35 features, Fitness: -0.9600\n",
      "    - New mask: 32 features, Fitness: -0.3903\n",
      "    - New mask: 35 features, Fitness: -1.3230\n",
      "    - New mask: 36 features, Fitness: -1.1005\n",
      "    - New mask: 34 features, Fitness: -0.8294\n",
      "    - New mask: 35 features, Fitness: -1.5183\n",
      "    - New mask: 32 features, Fitness: -0.3036\n",
      "    - New mask: 35 features, Fitness: -1.2105\n",
      "    - New mask: 33 features, Fitness: -0.7180\n",
      "    - New mask: 35 features, Fitness: -1.2623\n",
      "    - New mask: 31 features, Fitness: -0.1675\n",
      "    - New mask: 30 features, Fitness: 0.0486\n",
      "    - New mask: 34 features, Fitness: -0.6447\n",
      "    - New mask: 31 features, Fitness: -0.0678\n",
      "    - New mask: 30 features, Fitness: 0.0235\n",
      "    - New mask: 36 features, Fitness: -5.3491\n",
      "    - New mask: 31 features, Fitness: -3.7337\n",
      "    - New mask: 35 features, Fitness: -4.2874\n",
      "    - New mask: 32 features, Fitness: -3.5317\n",
      "    - New mask: 33 features, Fitness: -3.6882\n",
      "    - New mask: 33 features, Fitness: -4.1964\n",
      "    - New mask: 33 features, Fitness: -3.6879\n",
      "    - New mask: 36 features, Fitness: -4.6795\n",
      "    - New mask: 38 features, Fitness: -5.7481\n",
      "    - New mask: 35 features, Fitness: -4.5347\n",
      "    - New mask: 34 features, Fitness: -4.2267\n",
      "    - New mask: 33 features, Fitness: -3.8478\n",
      "    - New mask: 36 features, Fitness: -6.1361\n",
      "    - New mask: 34 features, Fitness: -3.9125\n",
      "    - New mask: 32 features, Fitness: -3.6235\n",
      "    - New mask: 35 features, Fitness: -4.6434\n",
      "    - New mask: 38 features, Fitness: -5.7458\n",
      "    - New mask: 35 features, Fitness: -4.5005\n",
      "    - New mask: 34 features, Fitness: -4.4599\n",
      "    - New mask: 33 features, Fitness: -4.5615\n",
      "    - New mask: 35 features, Fitness: -6.5943\n",
      "    - New mask: 33 features, Fitness: -5.8671\n",
      "    - New mask: 31 features, Fitness: -5.7669\n",
      "    - New mask: 31 features, Fitness: -4.1268\n",
      "    - New mask: 34 features, Fitness: -6.3123\n",
      "    - New mask: 35 features, Fitness: -7.1327\n",
      "    - New mask: 31 features, Fitness: -4.9287\n",
      "    - New mask: 35 features, Fitness: -6.6203\n",
      "    - New mask: 32 features, Fitness: -5.4128\n",
      "    - New mask: 35 features, Fitness: -6.7278\n",
      "    - New mask: 34 features, Fitness: -5.6232\n",
      "    - New mask: 37 features, Fitness: -7.7940\n",
      "    - New mask: 34 features, Fitness: -6.1643\n",
      "    - New mask: 34 features, Fitness: -5.7433\n",
      "    - New mask: 34 features, Fitness: -6.2554\n",
      "    - New mask: 35 features, Fitness: -6.7563\n",
      "    - New mask: 36 features, Fitness: -7.3592\n",
      "    - New mask: 31 features, Fitness: -4.5596\n",
      "    - New mask: 29 features, Fitness: -4.1065\n",
      "    - New mask: 34 features, Fitness: -6.0522\n",
      "    - New mask: 39 features, Fitness: -3.9388\n",
      "    - New mask: 34 features, Fitness: -1.9036\n",
      "    - New mask: 38 features, Fitness: -3.2212\n",
      "    - New mask: 34 features, Fitness: -2.4010\n",
      "    - New mask: 35 features, Fitness: -2.4476\n",
      "    - New mask: 36 features, Fitness: -3.0347\n",
      "    - New mask: 34 features, Fitness: -2.1172\n",
      "    - New mask: 35 features, Fitness: -2.0858\n",
      "    - New mask: 33 features, Fitness: -2.3729\n",
      "    - New mask: 37 features, Fitness: -2.6844\n",
      "    - New mask: 34 features, Fitness: -1.8309\n",
      "    - New mask: 35 features, Fitness: -2.2730\n",
      "    - New mask: 37 features, Fitness: -2.8023\n",
      "    - New mask: 35 features, Fitness: -2.3234\n",
      "    - New mask: 38 features, Fitness: -3.1692\n",
      "    - New mask: 38 features, Fitness: -3.7997\n",
      "    - New mask: 35 features, Fitness: -2.2541\n",
      "    - New mask: 35 features, Fitness: -2.1961\n",
      "    - New mask: 34 features, Fitness: -1.5592\n",
      "    - New mask: 35 features, Fitness: -1.9730\n",
      "=== End of Round 11: Vote mask selects 35 features (rho: 0.52)\n",
      "    Indices: [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 12 ================\n",
      "  Adaptive rho for this round: 0.55\n",
      "    - New mask: 33 features, Fitness: -2.0760\n",
      "    - New mask: 31 features, Fitness: -1.1396\n",
      "    - New mask: 28 features, Fitness: -0.5790\n",
      "    - New mask: 33 features, Fitness: -1.7136\n",
      "    - New mask: 35 features, Fitness: -2.6583\n",
      "    - New mask: 34 features, Fitness: -1.9348\n",
      "    - New mask: 33 features, Fitness: -1.4938\n",
      "    - New mask: 29 features, Fitness: -1.0211\n",
      "    - New mask: 33 features, Fitness: -1.8340\n",
      "    - New mask: 31 features, Fitness: -1.7722\n",
      "    - New mask: 31 features, Fitness: -0.9342\n",
      "    - New mask: 35 features, Fitness: -2.1164\n",
      "    - New mask: 33 features, Fitness: -1.7674\n",
      "    - New mask: 32 features, Fitness: -1.0929\n",
      "    - New mask: 32 features, Fitness: -1.1703\n",
      "    - New mask: 34 features, Fitness: -2.5700\n",
      "    - New mask: 28 features, Fitness: -0.4835\n",
      "    - New mask: 31 features, Fitness: -1.1609\n",
      "    - New mask: 30 features, Fitness: -0.9345\n",
      "    - New mask: 30 features, Fitness: -0.9606\n",
      "    - New mask: 31 features, Fitness: -2.8926\n",
      "    - New mask: 30 features, Fitness: -3.1817\n",
      "    - New mask: 33 features, Fitness: -3.8073\n",
      "    - New mask: 34 features, Fitness: -4.3115\n",
      "    - New mask: 34 features, Fitness: -4.4684\n",
      "    - New mask: 35 features, Fitness: -4.4831\n",
      "    - New mask: 34 features, Fitness: -3.8373\n",
      "    - New mask: 31 features, Fitness: -2.8666\n",
      "    - New mask: 29 features, Fitness: -2.5949\n",
      "    - New mask: 28 features, Fitness: -2.5243\n",
      "    - New mask: 34 features, Fitness: -4.3312\n",
      "    - New mask: 30 features, Fitness: -3.3223\n",
      "    - New mask: 31 features, Fitness: -3.4527\n",
      "    - New mask: 33 features, Fitness: -3.2342\n",
      "    - New mask: 34 features, Fitness: -4.0615\n",
      "    - New mask: 30 features, Fitness: -2.7481\n",
      "    - New mask: 35 features, Fitness: -4.1630\n",
      "    - New mask: 32 features, Fitness: -3.3298\n",
      "    - New mask: 31 features, Fitness: -3.1888\n",
      "    - New mask: 30 features, Fitness: -2.4375\n",
      "    - New mask: 34 features, Fitness: -1.5436\n",
      "    - New mask: 34 features, Fitness: -1.5831\n",
      "    - New mask: 33 features, Fitness: -2.2454\n",
      "    - New mask: 34 features, Fitness: -2.0106\n",
      "    - New mask: 32 features, Fitness: -1.2393\n",
      "    - New mask: 30 features, Fitness: -1.8838\n",
      "    - New mask: 35 features, Fitness: -2.1093\n",
      "    - New mask: 34 features, Fitness: -1.8974\n",
      "    - New mask: 32 features, Fitness: -0.8276\n",
      "    - New mask: 33 features, Fitness: -2.1320\n",
      "    - New mask: 32 features, Fitness: -1.3533\n",
      "    - New mask: 35 features, Fitness: -2.0589\n",
      "    - New mask: 32 features, Fitness: -1.3605\n",
      "    - New mask: 35 features, Fitness: -2.7925\n",
      "    - New mask: 32 features, Fitness: -1.1617\n",
      "    - New mask: 33 features, Fitness: -1.7844\n",
      "    - New mask: 31 features, Fitness: -1.4401\n",
      "    - New mask: 36 features, Fitness: -2.3457\n",
      "    - New mask: 33 features, Fitness: -1.4472\n",
      "    - New mask: 33 features, Fitness: -1.6472\n",
      "    - New mask: 37 features, Fitness: -2.8391\n",
      "    - New mask: 35 features, Fitness: -1.8717\n",
      "    - New mask: 33 features, Fitness: -1.1150\n",
      "    - New mask: 30 features, Fitness: -0.1949\n",
      "    - New mask: 37 features, Fitness: -3.4529\n",
      "    - New mask: 32 features, Fitness: -1.1875\n",
      "    - New mask: 33 features, Fitness: -1.5475\n",
      "    - New mask: 31 features, Fitness: -0.8179\n",
      "    - New mask: 33 features, Fitness: -1.7989\n",
      "    - New mask: 30 features, Fitness: -0.8671\n",
      "    - New mask: 30 features, Fitness: -0.2141\n",
      "    - New mask: 36 features, Fitness: -2.6710\n",
      "    - New mask: 32 features, Fitness: -0.7231\n",
      "    - New mask: 33 features, Fitness: -1.2821\n",
      "    - New mask: 31 features, Fitness: -0.7452\n",
      "    - New mask: 36 features, Fitness: -2.9690\n",
      "    - New mask: 32 features, Fitness: -0.6015\n",
      "    - New mask: 35 features, Fitness: -1.5977\n",
      "    - New mask: 33 features, Fitness: -1.8832\n",
      "    - New mask: 33 features, Fitness: -2.3235\n",
      "    - New mask: 33 features, Fitness: -3.6570\n",
      "    - New mask: 29 features, Fitness: -2.7119\n",
      "    - New mask: 33 features, Fitness: -3.9635\n",
      "    - New mask: 33 features, Fitness: -4.1868\n",
      "    - New mask: 30 features, Fitness: -3.6383\n",
      "    - New mask: 31 features, Fitness: -2.9776\n",
      "    - New mask: 32 features, Fitness: -3.3551\n",
      "    - New mask: 30 features, Fitness: -3.0628\n",
      "    - New mask: 28 features, Fitness: -2.9106\n",
      "    - New mask: 32 features, Fitness: -3.6544\n",
      "    - New mask: 31 features, Fitness: -3.5651\n",
      "    - New mask: 32 features, Fitness: -3.1727\n",
      "    - New mask: 31 features, Fitness: -3.9217\n",
      "    - New mask: 31 features, Fitness: -3.4850\n",
      "    - New mask: 35 features, Fitness: -5.8588\n",
      "    - New mask: 34 features, Fitness: -4.1454\n",
      "    - New mask: 30 features, Fitness: -3.6010\n",
      "    - New mask: 30 features, Fitness: -3.3344\n",
      "    - New mask: 31 features, Fitness: -3.6132\n",
      "    - New mask: 34 features, Fitness: -5.3437\n",
      "    - New mask: 37 features, Fitness: -2.2795\n",
      "    - New mask: 37 features, Fitness: -2.8760\n",
      "    - New mask: 31 features, Fitness: -1.1324\n",
      "    - New mask: 35 features, Fitness: -2.1679\n",
      "    - New mask: 36 features, Fitness: -2.4252\n",
      "    - New mask: 35 features, Fitness: -2.2958\n",
      "    - New mask: 33 features, Fitness: -1.6520\n",
      "    - New mask: 34 features, Fitness: -2.1951\n",
      "    - New mask: 33 features, Fitness: -1.6640\n",
      "    - New mask: 34 features, Fitness: -2.0825\n",
      "    - New mask: 33 features, Fitness: -2.2319\n",
      "    - New mask: 32 features, Fitness: -1.1676\n",
      "    - New mask: 33 features, Fitness: -1.6274\n",
      "    - New mask: 34 features, Fitness: -1.3919\n",
      "    - New mask: 33 features, Fitness: -0.9797\n",
      "    - New mask: 33 features, Fitness: -1.3856\n",
      "    - New mask: 33 features, Fitness: -1.8268\n",
      "    - New mask: 36 features, Fitness: -2.1978\n",
      "    - New mask: 35 features, Fitness: -2.5704\n",
      "    - New mask: 33 features, Fitness: -1.3676\n",
      "    - New mask: 32 features, Fitness: -0.2687\n",
      "    - New mask: 27 features, Fitness: 0.4622\n",
      "    - New mask: 34 features, Fitness: -0.7111\n",
      "    - New mask: 32 features, Fitness: -0.3144\n",
      "    - New mask: 33 features, Fitness: -0.7491\n",
      "    - New mask: 32 features, Fitness: -0.3323\n",
      "    - New mask: 29 features, Fitness: -0.3755\n",
      "    - New mask: 33 features, Fitness: -0.6574\n",
      "    - New mask: 32 features, Fitness: -0.6495\n",
      "    - New mask: 31 features, Fitness: -0.1375\n",
      "    - New mask: 34 features, Fitness: -1.3420\n",
      "    - New mask: 32 features, Fitness: -0.2415\n",
      "    - New mask: 29 features, Fitness: 0.4847\n",
      "    - New mask: 32 features, Fitness: -0.2736\n",
      "    - New mask: 31 features, Fitness: -1.0717\n",
      "    - New mask: 34 features, Fitness: -0.8886\n",
      "    - New mask: 32 features, Fitness: -0.1623\n",
      "    - New mask: 35 features, Fitness: -0.8809\n",
      "    - New mask: 31 features, Fitness: -0.1344\n",
      "    - New mask: 28 features, Fitness: 0.1687\n",
      "    - New mask: 35 features, Fitness: -5.2083\n",
      "    - New mask: 34 features, Fitness: -4.3712\n",
      "    - New mask: 35 features, Fitness: -4.7125\n",
      "    - New mask: 34 features, Fitness: -4.1343\n",
      "    - New mask: 29 features, Fitness: -2.4039\n",
      "    - New mask: 31 features, Fitness: -3.4279\n",
      "    - New mask: 32 features, Fitness: -3.8639\n",
      "    - New mask: 36 features, Fitness: -4.9121\n",
      "    - New mask: 34 features, Fitness: -4.1643\n",
      "    - New mask: 36 features, Fitness: -5.0478\n",
      "    - New mask: 32 features, Fitness: -3.7587\n",
      "    - New mask: 29 features, Fitness: -2.7025\n",
      "    - New mask: 32 features, Fitness: -3.7511\n",
      "    - New mask: 34 features, Fitness: -4.2106\n",
      "    - New mask: 36 features, Fitness: -4.9121\n",
      "    - New mask: 33 features, Fitness: -3.8495\n",
      "    - New mask: 32 features, Fitness: -4.5838\n",
      "    - New mask: 34 features, Fitness: -4.4554\n",
      "    - New mask: 29 features, Fitness: -3.0347\n",
      "    - New mask: 33 features, Fitness: -4.2407\n",
      "    - New mask: 34 features, Fitness: -6.2201\n",
      "    - New mask: 36 features, Fitness: -8.3235\n",
      "    - New mask: 31 features, Fitness: -5.9216\n",
      "    - New mask: 29 features, Fitness: -3.8543\n",
      "    - New mask: 32 features, Fitness: -4.9666\n",
      "    - New mask: 32 features, Fitness: -4.9942\n",
      "    - New mask: 29 features, Fitness: -4.5017\n",
      "    - New mask: 33 features, Fitness: -5.6690\n",
      "    - New mask: 31 features, Fitness: -4.8449\n",
      "    - New mask: 33 features, Fitness: -5.7912\n",
      "    - New mask: 29 features, Fitness: -4.3620\n",
      "    - New mask: 35 features, Fitness: -7.5347\n",
      "    - New mask: 31 features, Fitness: -5.6748\n",
      "    - New mask: 34 features, Fitness: -5.8639\n",
      "    - New mask: 33 features, Fitness: -5.8329\n",
      "    - New mask: 33 features, Fitness: -6.4303\n",
      "    - New mask: 33 features, Fitness: -7.2906\n",
      "    - New mask: 30 features, Fitness: -4.2255\n",
      "    - New mask: 33 features, Fitness: -6.0739\n",
      "    - New mask: 30 features, Fitness: -4.7970\n",
      "    - New mask: 36 features, Fitness: -2.4427\n",
      "    - New mask: 32 features, Fitness: -1.7093\n",
      "    - New mask: 37 features, Fitness: -2.5523\n",
      "    - New mask: 32 features, Fitness: -1.7485\n",
      "    - New mask: 35 features, Fitness: -2.2884\n",
      "    - New mask: 38 features, Fitness: -3.2589\n",
      "    - New mask: 32 features, Fitness: -1.2150\n",
      "    - New mask: 33 features, Fitness: -1.3932\n",
      "    - New mask: 33 features, Fitness: -2.1023\n",
      "    - New mask: 34 features, Fitness: -1.5888\n",
      "    - New mask: 34 features, Fitness: -1.9369\n",
      "    - New mask: 32 features, Fitness: -1.1065\n",
      "    - New mask: 36 features, Fitness: -2.4012\n",
      "    - New mask: 36 features, Fitness: -2.2068\n",
      "    - New mask: 34 features, Fitness: -2.9370\n",
      "    - New mask: 35 features, Fitness: -1.9081\n",
      "    - New mask: 31 features, Fitness: -1.7019\n",
      "    - New mask: 33 features, Fitness: -1.4818\n",
      "    - New mask: 35 features, Fitness: -1.8339\n",
      "    - New mask: 33 features, Fitness: -1.2964\n",
      "=== End of Round 12: Vote mask selects 34 features (rho: 0.55)\n",
      "    Indices: [1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 13 ================\n",
      "  Adaptive rho for this round: 0.58\n",
      "    - New mask: 30 features, Fitness: -0.9773\n",
      "    - New mask: 34 features, Fitness: -1.9863\n",
      "    - New mask: 29 features, Fitness: -0.9866\n",
      "    - New mask: 31 features, Fitness: -0.9219\n",
      "    - New mask: 32 features, Fitness: -1.9069\n",
      "    - New mask: 28 features, Fitness: -0.5173\n",
      "    - New mask: 35 features, Fitness: -1.9205\n",
      "    - New mask: 31 features, Fitness: -1.7812\n",
      "    - New mask: 32 features, Fitness: -1.7067\n",
      "    - New mask: 33 features, Fitness: -1.6897\n",
      "    - New mask: 29 features, Fitness: -0.2120\n",
      "    - New mask: 32 features, Fitness: -1.3060\n",
      "    - New mask: 31 features, Fitness: -1.0741\n",
      "    - New mask: 31 features, Fitness: -0.8906\n",
      "    - New mask: 31 features, Fitness: -1.1534\n",
      "    - New mask: 28 features, Fitness: -0.7483\n",
      "    - New mask: 31 features, Fitness: -1.0015\n",
      "    - New mask: 31 features, Fitness: -0.9335\n",
      "    - New mask: 28 features, Fitness: -0.4226\n",
      "    - New mask: 28 features, Fitness: -0.6937\n",
      "    - New mask: 33 features, Fitness: -3.7326\n",
      "    - New mask: 29 features, Fitness: -2.4122\n",
      "    - New mask: 32 features, Fitness: -3.4208\n",
      "    - New mask: 32 features, Fitness: -3.2752\n",
      "    - New mask: 35 features, Fitness: -4.4054\n",
      "    - New mask: 35 features, Fitness: -4.3635\n",
      "    - New mask: 30 features, Fitness: -2.3500\n",
      "    - New mask: 31 features, Fitness: -3.5711\n",
      "    - New mask: 29 features, Fitness: -2.1408\n",
      "    - New mask: 26 features, Fitness: -1.6883\n",
      "    - New mask: 31 features, Fitness: -2.7753\n",
      "    - New mask: 30 features, Fitness: -3.2678\n",
      "    - New mask: 32 features, Fitness: -3.5982\n",
      "    - New mask: 30 features, Fitness: -3.2620\n",
      "    - New mask: 32 features, Fitness: -3.7536\n",
      "    - New mask: 31 features, Fitness: -3.1720\n",
      "    - New mask: 28 features, Fitness: -2.2330\n",
      "    - New mask: 32 features, Fitness: -3.3516\n",
      "    - New mask: 30 features, Fitness: -2.9729\n",
      "    - New mask: 32 features, Fitness: -3.1308\n",
      "    - New mask: 31 features, Fitness: -1.5268\n",
      "    - New mask: 32 features, Fitness: -1.2885\n",
      "    - New mask: 31 features, Fitness: -2.4085\n",
      "    - New mask: 33 features, Fitness: -1.6283\n",
      "    - New mask: 33 features, Fitness: -1.6653\n",
      "    - New mask: 32 features, Fitness: -1.4348\n",
      "    - New mask: 35 features, Fitness: -1.8592\n",
      "    - New mask: 34 features, Fitness: -2.1504\n",
      "    - New mask: 29 features, Fitness: -0.7351\n",
      "    - New mask: 31 features, Fitness: -1.0089\n",
      "    - New mask: 30 features, Fitness: -0.7823\n",
      "    - New mask: 34 features, Fitness: -1.8832\n",
      "    - New mask: 35 features, Fitness: -1.8176\n",
      "    - New mask: 32 features, Fitness: -1.4099\n",
      "    - New mask: 32 features, Fitness: -1.5948\n",
      "    - New mask: 32 features, Fitness: -1.3809\n",
      "    - New mask: 31 features, Fitness: -1.1102\n",
      "    - New mask: 35 features, Fitness: -1.7363\n",
      "    - New mask: 34 features, Fitness: -2.1324\n",
      "    - New mask: 33 features, Fitness: -1.7313\n",
      "    - New mask: 30 features, Fitness: -0.6086\n",
      "    - New mask: 31 features, Fitness: -0.8240\n",
      "    - New mask: 29 features, Fitness: -0.6681\n",
      "    - New mask: 30 features, Fitness: -0.3649\n",
      "    - New mask: 35 features, Fitness: -2.2256\n",
      "    - New mask: 34 features, Fitness: -1.5926\n",
      "    - New mask: 32 features, Fitness: -1.2873\n",
      "    - New mask: 31 features, Fitness: -0.7061\n",
      "    - New mask: 33 features, Fitness: -1.1959\n",
      "    - New mask: 29 features, Fitness: -0.2610\n",
      "    - New mask: 31 features, Fitness: -0.1971\n",
      "    - New mask: 35 features, Fitness: -2.5108\n",
      "    - New mask: 32 features, Fitness: -0.9769\n",
      "    - New mask: 33 features, Fitness: -1.6089\n",
      "    - New mask: 31 features, Fitness: -0.5411\n",
      "    - New mask: 35 features, Fitness: -2.4186\n",
      "    - New mask: 31 features, Fitness: -0.6572\n",
      "    - New mask: 33 features, Fitness: -1.3435\n",
      "    - New mask: 31 features, Fitness: -1.2303\n",
      "    - New mask: 31 features, Fitness: -0.9213\n",
      "    - New mask: 33 features, Fitness: -4.1868\n",
      "    - New mask: 29 features, Fitness: -3.0846\n",
      "    - New mask: 33 features, Fitness: -4.1441\n",
      "    - New mask: 29 features, Fitness: -2.5841\n",
      "    - New mask: 30 features, Fitness: -3.6066\n",
      "    - New mask: 33 features, Fitness: -4.2029\n",
      "    - New mask: 31 features, Fitness: -2.9307\n",
      "    - New mask: 29 features, Fitness: -2.7421\n",
      "    - New mask: 31 features, Fitness: -3.7032\n",
      "    - New mask: 28 features, Fitness: -3.1460\n",
      "    - New mask: 31 features, Fitness: -3.3039\n",
      "    - New mask: 29 features, Fitness: -3.4396\n",
      "    - New mask: 30 features, Fitness: -3.6541\n",
      "    - New mask: 28 features, Fitness: -2.9988\n",
      "    - New mask: 36 features, Fitness: -5.4535\n",
      "    - New mask: 31 features, Fitness: -3.4020\n",
      "    - New mask: 29 features, Fitness: -2.9526\n",
      "    - New mask: 30 features, Fitness: -3.2640\n",
      "    - New mask: 30 features, Fitness: -3.5296\n",
      "    - New mask: 31 features, Fitness: -3.3835\n",
      "    - New mask: 36 features, Fitness: -2.1511\n",
      "    - New mask: 36 features, Fitness: -2.4748\n",
      "    - New mask: 37 features, Fitness: -3.1386\n",
      "    - New mask: 30 features, Fitness: -0.1113\n",
      "    - New mask: 35 features, Fitness: -2.7524\n",
      "    - New mask: 33 features, Fitness: -1.1269\n",
      "    - New mask: 34 features, Fitness: -2.4689\n",
      "    - New mask: 31 features, Fitness: -1.5321\n",
      "    - New mask: 33 features, Fitness: -2.2720\n",
      "    - New mask: 31 features, Fitness: -1.1846\n",
      "    - New mask: 36 features, Fitness: -2.9946\n",
      "    - New mask: 34 features, Fitness: -1.4010\n",
      "    - New mask: 32 features, Fitness: -1.5495\n",
      "    - New mask: 35 features, Fitness: -2.1232\n",
      "    - New mask: 35 features, Fitness: -1.8096\n",
      "    - New mask: 30 features, Fitness: -0.7387\n",
      "    - New mask: 32 features, Fitness: -1.4138\n",
      "    - New mask: 34 features, Fitness: -1.9352\n",
      "    - New mask: 33 features, Fitness: -0.8302\n",
      "    - New mask: 34 features, Fitness: -2.8260\n",
      "    - New mask: 31 features, Fitness: 0.0015\n",
      "    - New mask: 27 features, Fitness: 0.6867\n",
      "    - New mask: 31 features, Fitness: -0.3046\n",
      "    - New mask: 31 features, Fitness: 0.0618\n",
      "    - New mask: 28 features, Fitness: 0.5092\n",
      "    - New mask: 30 features, Fitness: 0.0309\n",
      "    - New mask: 29 features, Fitness: 0.1577\n",
      "    - New mask: 32 features, Fitness: -1.1195\n",
      "    - New mask: 31 features, Fitness: -0.2233\n",
      "    - New mask: 32 features, Fitness: -0.4718\n",
      "    - New mask: 30 features, Fitness: -0.5786\n",
      "    - New mask: 34 features, Fitness: -0.6236\n",
      "    - New mask: 29 features, Fitness: 0.3092\n",
      "    - New mask: 30 features, Fitness: 0.2530\n",
      "    - New mask: 33 features, Fitness: -0.5618\n",
      "    - New mask: 32 features, Fitness: -0.5223\n",
      "    - New mask: 30 features, Fitness: 0.0950\n",
      "    - New mask: 32 features, Fitness: -0.4316\n",
      "    - New mask: 32 features, Fitness: -0.6760\n",
      "    - New mask: 29 features, Fitness: -0.2996\n",
      "    - New mask: 34 features, Fitness: -4.6467\n",
      "    - New mask: 31 features, Fitness: -3.5844\n",
      "    - New mask: 33 features, Fitness: -4.3138\n",
      "    - New mask: 31 features, Fitness: -2.9516\n",
      "    - New mask: 31 features, Fitness: -3.2417\n",
      "    - New mask: 32 features, Fitness: -3.9041\n",
      "    - New mask: 32 features, Fitness: -3.4890\n",
      "    - New mask: 33 features, Fitness: -4.1568\n",
      "    - New mask: 29 features, Fitness: -2.6108\n",
      "    - New mask: 36 features, Fitness: -5.4218\n",
      "    - New mask: 33 features, Fitness: -3.8238\n",
      "    - New mask: 30 features, Fitness: -2.9916\n",
      "    - New mask: 31 features, Fitness: -3.2770\n",
      "    - New mask: 32 features, Fitness: -3.5676\n",
      "    - New mask: 33 features, Fitness: -3.3581\n",
      "    - New mask: 33 features, Fitness: -4.0185\n",
      "    - New mask: 32 features, Fitness: -4.1591\n",
      "    - New mask: 28 features, Fitness: -2.0715\n",
      "    - New mask: 33 features, Fitness: -4.5097\n",
      "    - New mask: 28 features, Fitness: -2.6615\n",
      "    - New mask: 31 features, Fitness: -4.7149\n",
      "    - New mask: 32 features, Fitness: -4.8037\n",
      "    - New mask: 29 features, Fitness: -5.1126\n",
      "    - New mask: 28 features, Fitness: -3.4217\n",
      "    - New mask: 32 features, Fitness: -5.1405\n",
      "    - New mask: 29 features, Fitness: -4.1189\n",
      "    - New mask: 28 features, Fitness: -4.1375\n",
      "    - New mask: 32 features, Fitness: -6.2656\n",
      "    - New mask: 33 features, Fitness: -6.2437\n",
      "    - New mask: 34 features, Fitness: -6.5901\n",
      "    - New mask: 28 features, Fitness: -3.4643\n",
      "    - New mask: 32 features, Fitness: -5.0283\n",
      "    - New mask: 34 features, Fitness: -6.6387\n",
      "    - New mask: 32 features, Fitness: -6.4943\n",
      "    - New mask: 33 features, Fitness: -6.1432\n",
      "    - New mask: 31 features, Fitness: -4.1206\n",
      "    - New mask: 34 features, Fitness: -7.2335\n",
      "    - New mask: 28 features, Fitness: -4.2086\n",
      "    - New mask: 33 features, Fitness: -5.8423\n",
      "    - New mask: 33 features, Fitness: -5.8720\n",
      "    - New mask: 33 features, Fitness: -1.2845\n",
      "    - New mask: 30 features, Fitness: -1.9464\n",
      "    - New mask: 37 features, Fitness: -3.1599\n",
      "    - New mask: 32 features, Fitness: -1.9210\n",
      "    - New mask: 29 features, Fitness: -0.1524\n",
      "    - New mask: 32 features, Fitness: -1.0744\n",
      "    - New mask: 29 features, Fitness: -1.0130\n",
      "    - New mask: 32 features, Fitness: -1.0859\n",
      "    - New mask: 31 features, Fitness: -0.8341\n",
      "    - New mask: 32 features, Fitness: -1.2107\n",
      "    - New mask: 33 features, Fitness: -1.8129\n",
      "    - New mask: 31 features, Fitness: -1.6630\n",
      "    - New mask: 32 features, Fitness: -2.1416\n",
      "    - New mask: 35 features, Fitness: -2.9304\n",
      "    - New mask: 34 features, Fitness: -1.6894\n",
      "    - New mask: 32 features, Fitness: -1.7392\n",
      "    - New mask: 30 features, Fitness: -1.0603\n",
      "    - New mask: 33 features, Fitness: -1.4818\n",
      "    - New mask: 32 features, Fitness: -2.1542\n",
      "    - New mask: 33 features, Fitness: -1.7172\n",
      "=== End of Round 13: Vote mask selects 32 features (rho: 0.58)\n",
      "    Indices: [2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 14 ================\n",
      "  Adaptive rho for this round: 0.61\n",
      "    - New mask: 28 features, Fitness: -0.2082\n",
      "    - New mask: 32 features, Fitness: -0.9390\n",
      "    - New mask: 32 features, Fitness: -1.3819\n",
      "    - New mask: 28 features, Fitness: -0.2759\n",
      "    - New mask: 30 features, Fitness: -0.6635\n",
      "    - New mask: 28 features, Fitness: -0.1027\n",
      "    - New mask: 30 features, Fitness: -0.4830\n",
      "    - New mask: 29 features, Fitness: -0.3164\n",
      "    - New mask: 30 features, Fitness: -0.8330\n",
      "    - New mask: 33 features, Fitness: -1.6308\n",
      "    - New mask: 29 features, Fitness: -0.2120\n",
      "    - New mask: 30 features, Fitness: -0.5280\n",
      "    - New mask: 28 features, Fitness: -0.2221\n",
      "    - New mask: 31 features, Fitness: -1.7027\n",
      "    - New mask: 29 features, Fitness: -0.7660\n",
      "    - New mask: 28 features, Fitness: -0.0048\n",
      "    - New mask: 31 features, Fitness: -0.6619\n",
      "    - New mask: 29 features, Fitness: -0.3811\n",
      "    - New mask: 30 features, Fitness: -0.4853\n",
      "    - New mask: 30 features, Fitness: -0.7288\n",
      "    - New mask: 27 features, Fitness: -1.6948\n",
      "    - New mask: 30 features, Fitness: -2.8612\n",
      "    - New mask: 33 features, Fitness: -4.0467\n",
      "    - New mask: 33 features, Fitness: -3.5597\n",
      "    - New mask: 28 features, Fitness: -1.8940\n",
      "    - New mask: 34 features, Fitness: -4.0553\n",
      "    - New mask: 29 features, Fitness: -2.1086\n",
      "    - New mask: 31 features, Fitness: -3.2256\n",
      "    - New mask: 33 features, Fitness: -3.6161\n",
      "    - New mask: 31 features, Fitness: -2.7555\n",
      "    - New mask: 29 features, Fitness: -2.2566\n",
      "    - New mask: 28 features, Fitness: -2.2225\n",
      "    - New mask: 28 features, Fitness: -2.0839\n",
      "    - New mask: 28 features, Fitness: -1.8385\n",
      "    - New mask: 30 features, Fitness: -2.8956\n",
      "    - New mask: 27 features, Fitness: -2.1603\n",
      "    - New mask: 30 features, Fitness: -2.8371\n",
      "    - New mask: 32 features, Fitness: -3.8163\n",
      "    - New mask: 28 features, Fitness: -2.3062\n",
      "    - New mask: 30 features, Fitness: -2.7151\n",
      "    - New mask: 30 features, Fitness: -0.9296\n",
      "    - New mask: 28 features, Fitness: -1.7877\n",
      "    - New mask: 30 features, Fitness: -1.3779\n",
      "    - New mask: 29 features, Fitness: -1.0832\n",
      "    - New mask: 30 features, Fitness: -1.2532\n",
      "    - New mask: 33 features, Fitness: -1.6699\n",
      "    - New mask: 31 features, Fitness: -1.3381\n",
      "    - New mask: 30 features, Fitness: -0.7002\n",
      "    - New mask: 29 features, Fitness: -0.9895\n",
      "    - New mask: 31 features, Fitness: -1.3014\n",
      "    - New mask: 30 features, Fitness: -1.3520\n",
      "    - New mask: 29 features, Fitness: -0.8045\n",
      "    - New mask: 32 features, Fitness: -1.1412\n",
      "    - New mask: 31 features, Fitness: -1.2945\n",
      "    - New mask: 31 features, Fitness: -2.3843\n",
      "    - New mask: 30 features, Fitness: -0.5620\n",
      "    - New mask: 28 features, Fitness: -0.9590\n",
      "    - New mask: 29 features, Fitness: -0.5696\n",
      "    - New mask: 30 features, Fitness: -1.1089\n",
      "    - New mask: 33 features, Fitness: -1.4041\n",
      "    - New mask: 29 features, Fitness: -0.0842\n",
      "    - New mask: 31 features, Fitness: -0.2904\n",
      "    - New mask: 29 features, Fitness: -0.4541\n",
      "    - New mask: 29 features, Fitness: 0.0077\n",
      "    - New mask: 32 features, Fitness: -0.5557\n",
      "    - New mask: 32 features, Fitness: -0.6411\n",
      "    - New mask: 31 features, Fitness: -1.1161\n",
      "    - New mask: 32 features, Fitness: -0.9161\n",
      "    - New mask: 31 features, Fitness: -0.4456\n",
      "    - New mask: 28 features, Fitness: 0.3239\n",
      "    - New mask: 30 features, Fitness: -0.0739\n",
      "    - New mask: 33 features, Fitness: -1.5542\n",
      "    - New mask: 32 features, Fitness: -1.0934\n",
      "    - New mask: 31 features, Fitness: -0.8183\n",
      "    - New mask: 30 features, Fitness: -0.2001\n",
      "    - New mask: 32 features, Fitness: -0.5900\n",
      "    - New mask: 36 features, Fitness: -2.4892\n",
      "    - New mask: 29 features, Fitness: -0.0975\n",
      "    - New mask: 31 features, Fitness: -0.3797\n",
      "    - New mask: 30 features, Fitness: -0.5290\n",
      "    - New mask: 32 features, Fitness: -3.3943\n",
      "    - New mask: 29 features, Fitness: -2.6136\n",
      "    - New mask: 31 features, Fitness: -3.6043\n",
      "    - New mask: 31 features, Fitness: -3.4436\n",
      "    - New mask: 31 features, Fitness: -3.5917\n",
      "    - New mask: 33 features, Fitness: -3.7010\n",
      "    - New mask: 30 features, Fitness: -2.5216\n",
      "    - New mask: 33 features, Fitness: -3.4401\n",
      "    - New mask: 31 features, Fitness: -3.6016\n",
      "    - New mask: 30 features, Fitness: -3.1698\n",
      "    - New mask: 30 features, Fitness: -3.1807\n",
      "    - New mask: 30 features, Fitness: -3.0674\n",
      "    - New mask: 30 features, Fitness: -3.3147\n",
      "    - New mask: 30 features, Fitness: -4.2047\n",
      "    - New mask: 32 features, Fitness: -3.5816\n",
      "    - New mask: 30 features, Fitness: -2.7918\n",
      "    - New mask: 27 features, Fitness: -2.4008\n",
      "    - New mask: 32 features, Fitness: -3.7092\n",
      "    - New mask: 28 features, Fitness: -2.6058\n",
      "    - New mask: 28 features, Fitness: -3.3456\n",
      "    - New mask: 30 features, Fitness: -0.5483\n",
      "    - New mask: 34 features, Fitness: -1.5862\n",
      "    - New mask: 33 features, Fitness: -0.8560\n",
      "    - New mask: 30 features, Fitness: -0.2257\n",
      "    - New mask: 31 features, Fitness: -0.9249\n",
      "    - New mask: 29 features, Fitness: -0.0435\n",
      "    - New mask: 30 features, Fitness: -0.6631\n",
      "    - New mask: 28 features, Fitness: -0.1407\n",
      "    - New mask: 31 features, Fitness: -0.9325\n",
      "    - New mask: 32 features, Fitness: -1.4956\n",
      "    - New mask: 32 features, Fitness: -1.0353\n",
      "    - New mask: 30 features, Fitness: -1.0145\n",
      "    - New mask: 31 features, Fitness: -0.6630\n",
      "    - New mask: 29 features, Fitness: -0.4682\n",
      "    - New mask: 33 features, Fitness: -1.4147\n",
      "    - New mask: 35 features, Fitness: -2.5367\n",
      "    - New mask: 32 features, Fitness: -2.1472\n",
      "    - New mask: 31 features, Fitness: -0.3493\n",
      "    - New mask: 31 features, Fitness: -0.9358\n",
      "    - New mask: 30 features, Fitness: -0.2257\n",
      "    - New mask: 28 features, Fitness: 0.5422\n",
      "    - New mask: 28 features, Fitness: 0.5320\n",
      "    - New mask: 30 features, Fitness: -0.2380\n",
      "    - New mask: 34 features, Fitness: -0.9986\n",
      "    - New mask: 28 features, Fitness: -0.5235\n",
      "    - New mask: 32 features, Fitness: -0.1958\n",
      "    - New mask: 31 features, Fitness: 0.0788\n",
      "    - New mask: 31 features, Fitness: 0.0422\n",
      "    - New mask: 27 features, Fitness: 0.9463\n",
      "    - New mask: 25 features, Fitness: 0.9050\n",
      "    - New mask: 28 features, Fitness: 0.2185\n",
      "    - New mask: 32 features, Fitness: -0.4327\n",
      "    - New mask: 31 features, Fitness: 0.0578\n",
      "    - New mask: 28 features, Fitness: 0.7917\n",
      "    - New mask: 29 features, Fitness: 0.3443\n",
      "    - New mask: 30 features, Fitness: -0.0468\n",
      "    - New mask: 28 features, Fitness: 0.5831\n",
      "    - New mask: 26 features, Fitness: 0.4165\n",
      "    - New mask: 29 features, Fitness: 0.7267\n",
      "    - New mask: 28 features, Fitness: 0.4198\n",
      "    - New mask: 33 features, Fitness: -4.4209\n",
      "    - New mask: 29 features, Fitness: -2.4458\n",
      "    - New mask: 29 features, Fitness: -2.8225\n",
      "    - New mask: 27 features, Fitness: -2.0164\n",
      "    - New mask: 31 features, Fitness: -3.5766\n",
      "    - New mask: 30 features, Fitness: -2.9076\n",
      "    - New mask: 32 features, Fitness: -3.7054\n",
      "    - New mask: 30 features, Fitness: -2.5807\n",
      "    - New mask: 27 features, Fitness: -1.7628\n",
      "    - New mask: 33 features, Fitness: -3.8097\n",
      "    - New mask: 31 features, Fitness: -3.3772\n",
      "    - New mask: 32 features, Fitness: -3.9967\n",
      "    - New mask: 29 features, Fitness: -2.2532\n",
      "    - New mask: 33 features, Fitness: -3.6521\n",
      "    - New mask: 33 features, Fitness: -3.5975\n",
      "    - New mask: 30 features, Fitness: -2.6936\n",
      "    - New mask: 30 features, Fitness: -3.2997\n",
      "    - New mask: 29 features, Fitness: -2.4458\n",
      "    - New mask: 30 features, Fitness: -3.2120\n",
      "    - New mask: 29 features, Fitness: -2.4307\n",
      "    - New mask: 28 features, Fitness: -3.6082\n",
      "    - New mask: 32 features, Fitness: -5.9887\n",
      "    - New mask: 28 features, Fitness: -4.8674\n",
      "    - New mask: 29 features, Fitness: -3.9675\n",
      "    - New mask: 28 features, Fitness: -4.2069\n",
      "    - New mask: 29 features, Fitness: -4.3209\n",
      "    - New mask: 31 features, Fitness: -5.5478\n",
      "    - New mask: 25 features, Fitness: -2.5286\n",
      "    - New mask: 31 features, Fitness: -5.3266\n",
      "    - New mask: 33 features, Fitness: -6.5826\n",
      "    - New mask: 32 features, Fitness: -5.5188\n",
      "    - New mask: 32 features, Fitness: -6.2288\n",
      "    - New mask: 33 features, Fitness: -6.3346\n",
      "    - New mask: 29 features, Fitness: -4.2846\n",
      "    - New mask: 28 features, Fitness: -3.9587\n",
      "    - New mask: 32 features, Fitness: -5.7030\n",
      "    - New mask: 33 features, Fitness: -5.6488\n",
      "    - New mask: 30 features, Fitness: -4.7810\n",
      "    - New mask: 33 features, Fitness: -6.9037\n",
      "    - New mask: 30 features, Fitness: -3.9013\n",
      "    - New mask: 31 features, Fitness: -0.6590\n",
      "    - New mask: 31 features, Fitness: -1.1099\n",
      "    - New mask: 29 features, Fitness: -0.9885\n",
      "    - New mask: 33 features, Fitness: -1.5742\n",
      "    - New mask: 28 features, Fitness: -0.1122\n",
      "    - New mask: 31 features, Fitness: -0.9501\n",
      "    - New mask: 28 features, Fitness: -0.0676\n",
      "    - New mask: 30 features, Fitness: -0.4194\n",
      "    - New mask: 32 features, Fitness: -1.3893\n",
      "    - New mask: 31 features, Fitness: -0.5124\n",
      "    - New mask: 31 features, Fitness: -1.2834\n",
      "    - New mask: 32 features, Fitness: -1.1236\n",
      "    - New mask: 35 features, Fitness: -2.2433\n",
      "    - New mask: 32 features, Fitness: -1.3893\n",
      "    - New mask: 33 features, Fitness: -0.8909\n",
      "    - New mask: 30 features, Fitness: -1.3239\n",
      "    - New mask: 27 features, Fitness: -0.0309\n",
      "    - New mask: 32 features, Fitness: -1.0570\n",
      "    - New mask: 33 features, Fitness: -1.3820\n",
      "    - New mask: 30 features, Fitness: -1.0250\n",
      "=== End of Round 14: Vote mask selects 30 features (rho: 0.61)\n",
      "    Indices: [2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 25, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 15 ================\n",
      "  Adaptive rho for this round: 0.64\n",
      "    - New mask: 29 features, Fitness: -0.3368\n",
      "    - New mask: 27 features, Fitness: 0.1842\n",
      "    - New mask: 28 features, Fitness: 0.1012\n",
      "    - New mask: 28 features, Fitness: 0.1303\n",
      "    - New mask: 27 features, Fitness: 0.4189\n",
      "    - New mask: 28 features, Fitness: 0.0851\n",
      "    - New mask: 27 features, Fitness: 0.2407\n",
      "    - New mask: 27 features, Fitness: 0.1155\n",
      "    - New mask: 29 features, Fitness: -0.0956\n",
      "    - New mask: 32 features, Fitness: -1.0163\n",
      "    - New mask: 28 features, Fitness: 0.1872\n",
      "    - New mask: 28 features, Fitness: 0.0544\n",
      "    - New mask: 28 features, Fitness: 0.0940\n",
      "    - New mask: 29 features, Fitness: -1.2599\n",
      "    - New mask: 28 features, Fitness: -1.0703\n",
      "    - New mask: 29 features, Fitness: -0.4274\n",
      "    - New mask: 30 features, Fitness: -0.5650\n",
      "    - New mask: 29 features, Fitness: -0.3889\n",
      "    - New mask: 29 features, Fitness: -0.0187\n",
      "    - New mask: 27 features, Fitness: 0.2866\n",
      "    - New mask: 28 features, Fitness: -2.0786\n",
      "    - New mask: 30 features, Fitness: -2.6173\n",
      "    - New mask: 31 features, Fitness: -4.2557\n",
      "    - New mask: 34 features, Fitness: -3.6545\n",
      "    - New mask: 26 features, Fitness: -1.4401\n",
      "    - New mask: 31 features, Fitness: -2.6293\n",
      "    - New mask: 28 features, Fitness: -1.7273\n",
      "    - New mask: 31 features, Fitness: -3.1414\n",
      "    - New mask: 30 features, Fitness: -2.5982\n",
      "    - New mask: 26 features, Fitness: -1.5378\n",
      "    - New mask: 29 features, Fitness: -2.5916\n",
      "    - New mask: 27 features, Fitness: -1.8529\n",
      "    - New mask: 25 features, Fitness: -2.0450\n",
      "    - New mask: 26 features, Fitness: -1.3616\n",
      "    - New mask: 28 features, Fitness: -1.9931\n",
      "    - New mask: 27 features, Fitness: -2.0377\n",
      "    - New mask: 30 features, Fitness: -2.6437\n",
      "    - New mask: 30 features, Fitness: -2.7171\n",
      "    - New mask: 26 features, Fitness: -1.4186\n",
      "    - New mask: 31 features, Fitness: -3.2845\n",
      "    - New mask: 29 features, Fitness: -0.2418\n",
      "    - New mask: 27 features, Fitness: -0.9545\n",
      "    - New mask: 29 features, Fitness: -1.5239\n",
      "    - New mask: 29 features, Fitness: -0.5975\n",
      "    - New mask: 27 features, Fitness: -0.0195\n",
      "    - New mask: 31 features, Fitness: -1.2519\n",
      "    - New mask: 29 features, Fitness: -0.7390\n",
      "    - New mask: 29 features, Fitness: -0.5696\n",
      "    - New mask: 33 features, Fitness: -1.3587\n",
      "    - New mask: 32 features, Fitness: -1.0502\n",
      "    - New mask: 31 features, Fitness: -1.0808\n",
      "    - New mask: 31 features, Fitness: -1.1749\n",
      "    - New mask: 31 features, Fitness: -0.7992\n",
      "    - New mask: 30 features, Fitness: -0.8727\n",
      "    - New mask: 32 features, Fitness: -1.8508\n",
      "    - New mask: 29 features, Fitness: -0.3766\n",
      "    - New mask: 28 features, Fitness: -0.3201\n",
      "    - New mask: 26 features, Fitness: -0.1648\n",
      "    - New mask: 30 features, Fitness: -1.1792\n",
      "    - New mask: 31 features, Fitness: -0.4799\n",
      "    - New mask: 27 features, Fitness: 0.3381\n",
      "    - New mask: 32 features, Fitness: -0.6381\n",
      "    - New mask: 27 features, Fitness: -0.3293\n",
      "    - New mask: 27 features, Fitness: 0.2896\n",
      "    - New mask: 33 features, Fitness: -0.8554\n",
      "    - New mask: 28 features, Fitness: 0.1889\n",
      "    - New mask: 32 features, Fitness: -0.3828\n",
      "    - New mask: 28 features, Fitness: -0.2524\n",
      "    - New mask: 31 features, Fitness: -0.6873\n",
      "    - New mask: 28 features, Fitness: 0.3373\n",
      "    - New mask: 32 features, Fitness: -0.7780\n",
      "    - New mask: 32 features, Fitness: -1.0149\n",
      "    - New mask: 31 features, Fitness: -0.7584\n",
      "    - New mask: 29 features, Fitness: -0.1754\n",
      "    - New mask: 29 features, Fitness: -0.2342\n",
      "    - New mask: 30 features, Fitness: -0.2039\n",
      "    - New mask: 31 features, Fitness: -1.0662\n",
      "    - New mask: 31 features, Fitness: -0.3592\n",
      "    - New mask: 29 features, Fitness: -0.0236\n",
      "    - New mask: 29 features, Fitness: 0.0535\n",
      "    - New mask: 32 features, Fitness: -3.6499\n",
      "    - New mask: 28 features, Fitness: -2.5521\n",
      "    - New mask: 30 features, Fitness: -3.0809\n",
      "    - New mask: 27 features, Fitness: -2.4279\n",
      "    - New mask: 27 features, Fitness: -2.3229\n",
      "    - New mask: 29 features, Fitness: -2.8285\n",
      "    - New mask: 25 features, Fitness: -1.6760\n",
      "    - New mask: 31 features, Fitness: -3.2821\n",
      "    - New mask: 29 features, Fitness: -3.2260\n",
      "    - New mask: 30 features, Fitness: -2.9470\n",
      "    - New mask: 30 features, Fitness: -3.8955\n",
      "    - New mask: 26 features, Fitness: -2.1394\n",
      "    - New mask: 28 features, Fitness: -1.9524\n",
      "    - New mask: 28 features, Fitness: -2.5627\n",
      "    - New mask: 27 features, Fitness: -2.1235\n",
      "    - New mask: 30 features, Fitness: -4.7644\n",
      "    - New mask: 27 features, Fitness: -3.3588\n",
      "    - New mask: 27 features, Fitness: -2.4001\n",
      "    - New mask: 30 features, Fitness: -3.1605\n",
      "    - New mask: 27 features, Fitness: -2.0577\n",
      "    - New mask: 30 features, Fitness: -1.0593\n",
      "    - New mask: 30 features, Fitness: -0.7261\n",
      "    - New mask: 31 features, Fitness: -0.8925\n",
      "    - New mask: 29 features, Fitness: -0.0951\n",
      "    - New mask: 29 features, Fitness: -0.4141\n",
      "    - New mask: 29 features, Fitness: 0.0120\n",
      "    - New mask: 30 features, Fitness: -0.6089\n",
      "    - New mask: 26 features, Fitness: 0.6649\n",
      "    - New mask: 30 features, Fitness: -0.3855\n",
      "    - New mask: 30 features, Fitness: -1.3557\n",
      "    - New mask: 30 features, Fitness: -0.3883\n",
      "    - New mask: 30 features, Fitness: -0.9792\n",
      "    - New mask: 31 features, Fitness: -1.1848\n",
      "    - New mask: 28 features, Fitness: -0.3352\n",
      "    - New mask: 31 features, Fitness: -1.0984\n",
      "    - New mask: 30 features, Fitness: -0.8115\n",
      "    - New mask: 26 features, Fitness: 0.3752\n",
      "    - New mask: 29 features, Fitness: -0.7465\n",
      "    - New mask: 31 features, Fitness: -1.4939\n",
      "    - New mask: 31 features, Fitness: -0.9146\n",
      "    - New mask: 30 features, Fitness: 0.1506\n",
      "    - New mask: 27 features, Fitness: 0.5105\n",
      "    - New mask: 28 features, Fitness: 0.1580\n",
      "    - New mask: 24 features, Fitness: 1.2554\n",
      "    - New mask: 27 features, Fitness: 0.7962\n",
      "    - New mask: 30 features, Fitness: 0.4579\n",
      "    - New mask: 27 features, Fitness: 0.8160\n",
      "    - New mask: 27 features, Fitness: 0.7132\n",
      "    - New mask: 27 features, Fitness: 0.9498\n",
      "    - New mask: 31 features, Fitness: 0.1234\n",
      "    - New mask: 28 features, Fitness: 0.6832\n",
      "    - New mask: 27 features, Fitness: 0.9312\n",
      "    - New mask: 31 features, Fitness: -0.0325\n",
      "    - New mask: 29 features, Fitness: 0.4904\n",
      "    - New mask: 29 features, Fitness: 0.3547\n",
      "    - New mask: 27 features, Fitness: 0.7293\n",
      "    - New mask: 27 features, Fitness: 0.7531\n",
      "    - New mask: 25 features, Fitness: 1.0702\n",
      "    - New mask: 29 features, Fitness: 0.4796\n",
      "    - New mask: 28 features, Fitness: 0.6254\n",
      "    - New mask: 29 features, Fitness: -3.1257\n",
      "    - New mask: 25 features, Fitness: -1.4769\n",
      "    - New mask: 30 features, Fitness: -2.8098\n",
      "    - New mask: 27 features, Fitness: -1.8697\n",
      "    - New mask: 29 features, Fitness: -2.5819\n",
      "    - New mask: 30 features, Fitness: -2.8081\n",
      "    - New mask: 27 features, Fitness: -1.8935\n",
      "    - New mask: 28 features, Fitness: -2.2900\n",
      "    - New mask: 29 features, Fitness: -2.5372\n",
      "    - New mask: 30 features, Fitness: -2.8985\n",
      "    - New mask: 30 features, Fitness: -2.8163\n",
      "    - New mask: 30 features, Fitness: -2.6808\n",
      "    - New mask: 26 features, Fitness: -1.5265\n",
      "    - New mask: 29 features, Fitness: -3.3832\n",
      "    - New mask: 33 features, Fitness: -3.5975\n",
      "    - New mask: 27 features, Fitness: -1.8657\n",
      "    - New mask: 31 features, Fitness: -3.0502\n",
      "    - New mask: 27 features, Fitness: -1.7761\n",
      "    - New mask: 29 features, Fitness: -2.9759\n",
      "    - New mask: 29 features, Fitness: -2.5188\n",
      "    - New mask: 29 features, Fitness: -3.8814\n",
      "    - New mask: 29 features, Fitness: -4.1322\n",
      "    - New mask: 28 features, Fitness: -4.6454\n",
      "    - New mask: 28 features, Fitness: -3.8194\n",
      "    - New mask: 27 features, Fitness: -3.5221\n",
      "    - New mask: 28 features, Fitness: -4.6179\n",
      "    - New mask: 30 features, Fitness: -4.5743\n",
      "    - New mask: 26 features, Fitness: -3.9789\n",
      "    - New mask: 27 features, Fitness: -3.1014\n",
      "    - New mask: 29 features, Fitness: -5.0812\n",
      "    - New mask: 25 features, Fitness: -3.3012\n",
      "    - New mask: 32 features, Fitness: -6.3892\n",
      "    - New mask: 31 features, Fitness: -4.8543\n",
      "    - New mask: 26 features, Fitness: -2.5035\n",
      "    - New mask: 25 features, Fitness: -3.0114\n",
      "    - New mask: 26 features, Fitness: -3.5210\n",
      "    - New mask: 27 features, Fitness: -3.3807\n",
      "    - New mask: 33 features, Fitness: -6.0208\n",
      "    - New mask: 29 features, Fitness: -5.0202\n",
      "    - New mask: 29 features, Fitness: -4.5422\n",
      "    - New mask: 31 features, Fitness: -0.8863\n",
      "    - New mask: 28 features, Fitness: -0.5048\n",
      "    - New mask: 28 features, Fitness: -0.6593\n",
      "    - New mask: 30 features, Fitness: -0.9605\n",
      "    - New mask: 27 features, Fitness: 0.6010\n",
      "    - New mask: 28 features, Fitness: -0.1142\n",
      "    - New mask: 30 features, Fitness: -0.4292\n",
      "    - New mask: 28 features, Fitness: -0.1043\n",
      "    - New mask: 27 features, Fitness: 0.2906\n",
      "    - New mask: 27 features, Fitness: 0.4360\n",
      "    - New mask: 29 features, Fitness: -0.1575\n",
      "    - New mask: 29 features, Fitness: -0.2732\n",
      "    - New mask: 34 features, Fitness: -2.3229\n",
      "    - New mask: 30 features, Fitness: -1.0918\n",
      "    - New mask: 32 features, Fitness: -2.2619\n",
      "    - New mask: 29 features, Fitness: -1.0940\n",
      "    - New mask: 28 features, Fitness: -0.1510\n",
      "    - New mask: 29 features, Fitness: -0.1241\n",
      "    - New mask: 28 features, Fitness: 0.0026\n",
      "    - New mask: 30 features, Fitness: -0.3267\n",
      "=== End of Round 15: Vote mask selects 26 features (rho: 0.64)\n",
      "    Indices: [2, 3, 6, 7, 10, 12, 13, 15, 16, 17, 18, 19, 20, 23, 25, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42]\n",
      "\n",
      "================ Federated BFA Round 16 ================\n",
      "  Adaptive rho for this round: 0.67\n",
      "    - New mask: 26 features, Fitness: 0.5478\n",
      "    - New mask: 27 features, Fitness: 0.2297\n",
      "    - New mask: 27 features, Fitness: -0.0251\n",
      "    - New mask: 29 features, Fitness: -0.0425\n",
      "    - New mask: 27 features, Fitness: 0.5020\n",
      "    - New mask: 25 features, Fitness: 0.8384\n",
      "    - New mask: 23 features, Fitness: 0.9403\n",
      "    - New mask: 27 features, Fitness: 0.1217\n",
      "    - New mask: 28 features, Fitness: 0.1067\n",
      "    - New mask: 30 features, Fitness: -0.0910\n",
      "    - New mask: 27 features, Fitness: 0.5377\n",
      "    - New mask: 29 features, Fitness: -0.1192\n",
      "    - New mask: 29 features, Fitness: -0.1564\n",
      "    - New mask: 27 features, Fitness: -0.5182\n",
      "    - New mask: 29 features, Fitness: -1.1934\n",
      "    - New mask: 25 features, Fitness: 0.8167\n",
      "    - New mask: 26 features, Fitness: 0.4806\n",
      "    - New mask: 27 features, Fitness: 0.1910\n",
      "    - New mask: 28 features, Fitness: 0.2510\n",
      "    - New mask: 24 features, Fitness: 0.7059\n",
      "    - New mask: 26 features, Fitness: -1.7407\n",
      "    - New mask: 29 features, Fitness: -2.2470\n",
      "    - New mask: 24 features, Fitness: -2.3500\n",
      "    - New mask: 31 features, Fitness: -2.6660\n",
      "    - New mask: 24 features, Fitness: -1.0576\n",
      "    - New mask: 28 features, Fitness: -2.1007\n",
      "    - New mask: 25 features, Fitness: -1.1457\n",
      "    - New mask: 27 features, Fitness: -1.2934\n",
      "    - New mask: 26 features, Fitness: -1.2636\n",
      "    - New mask: 25 features, Fitness: -1.2341\n",
      "    - New mask: 28 features, Fitness: -2.1514\n",
      "    - New mask: 24 features, Fitness: -0.8819\n",
      "    - New mask: 28 features, Fitness: -1.5709\n",
      "    - New mask: 21 features, Fitness: -0.6850\n",
      "    - New mask: 24 features, Fitness: -0.9805\n",
      "    - New mask: 27 features, Fitness: -1.5516\n",
      "    - New mask: 30 features, Fitness: -2.8748\n",
      "    - New mask: 31 features, Fitness: -2.7265\n",
      "    - New mask: 30 features, Fitness: -2.2344\n",
      "    - New mask: 27 features, Fitness: -1.8048\n",
      "    - New mask: 27 features, Fitness: -0.0523\n",
      "    - New mask: 27 features, Fitness: 0.1680\n",
      "    - New mask: 27 features, Fitness: -0.4064\n",
      "    - New mask: 27 features, Fitness: -0.0142\n",
      "    - New mask: 29 features, Fitness: -0.1206\n",
      "    - New mask: 27 features, Fitness: 0.6954\n",
      "    - New mask: 30 features, Fitness: -1.0574\n",
      "    - New mask: 26 features, Fitness: -0.2571\n",
      "    - New mask: 27 features, Fitness: -0.8127\n",
      "    - New mask: 29 features, Fitness: -0.0435\n",
      "    - New mask: 28 features, Fitness: -0.2239\n",
      "    - New mask: 29 features, Fitness: -0.8396\n",
      "    - New mask: 28 features, Fitness: -0.0526\n",
      "    - New mask: 28 features, Fitness: 0.2218\n",
      "    - New mask: 28 features, Fitness: -0.1689\n",
      "    - New mask: 26 features, Fitness: 0.4038\n",
      "    - New mask: 28 features, Fitness: -0.1956\n",
      "    - New mask: 25 features, Fitness: 0.6502\n",
      "    - New mask: 28 features, Fitness: -0.8964\n",
      "    - New mask: 29 features, Fitness: -0.3349\n",
      "    - New mask: 26 features, Fitness: 0.7799\n",
      "    - New mask: 27 features, Fitness: -0.0283\n",
      "    - New mask: 27 features, Fitness: -0.4008\n",
      "    - New mask: 26 features, Fitness: 0.7524\n",
      "    - New mask: 29 features, Fitness: 0.0975\n",
      "    - New mask: 27 features, Fitness: 0.2460\n",
      "    - New mask: 25 features, Fitness: 0.7916\n",
      "    - New mask: 26 features, Fitness: 0.6077\n",
      "    - New mask: 27 features, Fitness: 0.3246\n",
      "    - New mask: 26 features, Fitness: 0.8247\n",
      "    - New mask: 28 features, Fitness: 0.2598\n",
      "    - New mask: 26 features, Fitness: -0.2038\n",
      "    - New mask: 29 features, Fitness: -0.1170\n",
      "    - New mask: 32 features, Fitness: -0.5357\n",
      "    - New mask: 27 features, Fitness: 0.3838\n",
      "    - New mask: 28 features, Fitness: 0.2408\n",
      "    - New mask: 29 features, Fitness: 0.3187\n",
      "    - New mask: 26 features, Fitness: 0.7657\n",
      "    - New mask: 26 features, Fitness: 0.5645\n",
      "    - New mask: 27 features, Fitness: 0.7150\n",
      "    - New mask: 27 features, Fitness: -2.5200\n",
      "    - New mask: 26 features, Fitness: -1.5306\n",
      "    - New mask: 27 features, Fitness: -2.4183\n",
      "    - New mask: 27 features, Fitness: -2.6943\n",
      "    - New mask: 26 features, Fitness: -1.6440\n",
      "    - New mask: 30 features, Fitness: -4.0968\n",
      "    - New mask: 25 features, Fitness: -1.5256\n",
      "    - New mask: 26 features, Fitness: -1.6256\n",
      "    - New mask: 28 features, Fitness: -2.7166\n",
      "    - New mask: 28 features, Fitness: -2.1931\n",
      "    - New mask: 28 features, Fitness: -2.2189\n",
      "    - New mask: 25 features, Fitness: -1.7852\n",
      "    - New mask: 22 features, Fitness: -0.8220\n",
      "    - New mask: 26 features, Fitness: -1.9401\n",
      "    - New mask: 25 features, Fitness: -1.5281\n",
      "    - New mask: 30 features, Fitness: -3.2434\n",
      "    - New mask: 26 features, Fitness: -2.2334\n",
      "    - New mask: 27 features, Fitness: -1.9018\n",
      "    - New mask: 29 features, Fitness: -2.9647\n",
      "    - New mask: 26 features, Fitness: -1.4496\n",
      "    - New mask: 26 features, Fitness: 0.2103\n",
      "    - New mask: 28 features, Fitness: 0.3457\n",
      "    - New mask: 30 features, Fitness: -0.7419\n",
      "    - New mask: 27 features, Fitness: 0.3361\n",
      "    - New mask: 26 features, Fitness: -0.0399\n",
      "    - New mask: 23 features, Fitness: 0.6786\n",
      "    - New mask: 30 features, Fitness: -0.3506\n",
      "    - New mask: 24 features, Fitness: 0.6353\n",
      "    - New mask: 27 features, Fitness: 0.0516\n",
      "    - New mask: 30 features, Fitness: -1.0324\n",
      "    - New mask: 23 features, Fitness: 0.6842\n",
      "    - New mask: 30 features, Fitness: -0.5407\n",
      "    - New mask: 30 features, Fitness: -0.9415\n",
      "    - New mask: 27 features, Fitness: 0.5227\n",
      "    - New mask: 31 features, Fitness: -1.3012\n",
      "    - New mask: 23 features, Fitness: 1.1020\n",
      "    - New mask: 23 features, Fitness: 1.1944\n",
      "    - New mask: 28 features, Fitness: -0.7058\n",
      "    - New mask: 25 features, Fitness: 0.2626\n",
      "    - New mask: 29 features, Fitness: -0.7079\n",
      "    - New mask: 30 features, Fitness: -0.8509\n",
      "    - New mask: 24 features, Fitness: 1.0192\n",
      "    - New mask: 31 features, Fitness: 0.0163\n",
      "    - New mask: 24 features, Fitness: 1.0588\n",
      "    - New mask: 26 features, Fitness: 0.8301\n",
      "    - New mask: 29 features, Fitness: 0.4863\n",
      "    - New mask: 27 features, Fitness: 0.6151\n",
      "    - New mask: 30 features, Fitness: 0.3577\n",
      "    - New mask: 21 features, Fitness: 1.3779\n",
      "    - New mask: 28 features, Fitness: 0.7707\n",
      "    - New mask: 24 features, Fitness: 0.3248\n",
      "    - New mask: 24 features, Fitness: 0.8474\n",
      "    - New mask: 27 features, Fitness: 0.8644\n",
      "    - New mask: 27 features, Fitness: 0.9538\n",
      "    - New mask: 29 features, Fitness: 0.3419\n",
      "    - New mask: 21 features, Fitness: 1.4876\n",
      "    - New mask: 25 features, Fitness: 1.2113\n",
      "    - New mask: 25 features, Fitness: 0.8695\n",
      "    - New mask: 27 features, Fitness: 0.6565\n",
      "    - New mask: 27 features, Fitness: 0.8202\n",
      "    - New mask: 22 features, Fitness: -1.4043\n",
      "    - New mask: 28 features, Fitness: -1.9097\n",
      "    - New mask: 25 features, Fitness: -1.3590\n",
      "    - New mask: 26 features, Fitness: -1.6530\n",
      "    - New mask: 26 features, Fitness: -1.8493\n",
      "    - New mask: 26 features, Fitness: -1.8074\n",
      "    - New mask: 24 features, Fitness: -1.2888\n",
      "    - New mask: 29 features, Fitness: -2.7368\n",
      "    - New mask: 25 features, Fitness: -1.3084\n",
      "    - New mask: 28 features, Fitness: -2.2983\n",
      "    - New mask: 26 features, Fitness: -1.5581\n",
      "    - New mask: 28 features, Fitness: -1.9784\n",
      "    - New mask: 24 features, Fitness: -1.3634\n",
      "    - New mask: 27 features, Fitness: -2.1601\n",
      "    - New mask: 26 features, Fitness: -1.5643\n",
      "    - New mask: 25 features, Fitness: -1.1870\n",
      "    - New mask: 27 features, Fitness: -1.9797\n",
      "    - New mask: 26 features, Fitness: -2.3860\n",
      "    - New mask: 29 features, Fitness: -2.6515\n",
      "    - New mask: 25 features, Fitness: -1.4318\n",
      "    - New mask: 28 features, Fitness: -3.0965\n",
      "    - New mask: 27 features, Fitness: -2.9923\n",
      "    - New mask: 26 features, Fitness: -3.1075\n",
      "    - New mask: 27 features, Fitness: -3.4033\n",
      "    - New mask: 26 features, Fitness: -3.0478\n",
      "    - New mask: 27 features, Fitness: -3.0310\n",
      "    - New mask: 23 features, Fitness: -1.4844\n",
      "    - New mask: 24 features, Fitness: -2.1110\n",
      "    - New mask: 26 features, Fitness: -2.4631\n",
      "    - New mask: 29 features, Fitness: -4.5361\n",
      "    - New mask: 26 features, Fitness: -2.4737\n",
      "    - New mask: 25 features, Fitness: -2.7995\n",
      "    - New mask: 27 features, Fitness: -3.2233\n",
      "    - New mask: 26 features, Fitness: -2.3426\n",
      "    - New mask: 27 features, Fitness: -4.3036\n",
      "    - New mask: 24 features, Fitness: -2.2056\n",
      "    - New mask: 22 features, Fitness: -1.7045\n",
      "    - New mask: 30 features, Fitness: -4.9549\n",
      "    - New mask: 28 features, Fitness: -3.4186\n",
      "    - New mask: 27 features, Fitness: -3.8476\n",
      "    - New mask: 27 features, Fitness: 0.5489\n",
      "    - New mask: 30 features, Fitness: -0.4949\n",
      "    - New mask: 28 features, Fitness: -0.0058\n",
      "    - New mask: 28 features, Fitness: 0.1439\n",
      "    - New mask: 27 features, Fitness: 0.6760\n",
      "    - New mask: 25 features, Fitness: 0.8067\n",
      "    - New mask: 26 features, Fitness: 0.8630\n",
      "    - New mask: 25 features, Fitness: 0.9008\n",
      "    - New mask: 26 features, Fitness: 0.9627\n",
      "    - New mask: 26 features, Fitness: 0.4848\n",
      "    - New mask: 28 features, Fitness: 0.2777\n",
      "    - New mask: 26 features, Fitness: 0.6929\n",
      "    - New mask: 25 features, Fitness: 1.0408\n",
      "    - New mask: 27 features, Fitness: 0.2209\n",
      "    - New mask: 28 features, Fitness: 0.2376\n",
      "    - New mask: 29 features, Fitness: -1.0377\n",
      "    - New mask: 29 features, Fitness: -0.1299\n",
      "    - New mask: 29 features, Fitness: 0.1501\n",
      "    - New mask: 26 features, Fitness: 0.5464\n",
      "    - New mask: 25 features, Fitness: 0.8018\n",
      "=== End of Round 16: Vote mask selects 23 features (rho: 0.67)\n",
      "    Indices: [2, 7, 10, 12, 13, 15, 16, 17, 18, 19, 20, 23, 25, 29, 31, 32, 33, 34, 35, 36, 37, 40, 42]\n",
      "\n",
      "================ Federated BFA Round 17 ================\n",
      "  Adaptive rho for this round: 0.71\n",
      "    - New mask: 25 features, Fitness: 0.7488\n",
      "    - New mask: 25 features, Fitness: 0.7597\n",
      "    - New mask: 26 features, Fitness: 0.5145\n",
      "    - New mask: 27 features, Fitness: 0.1929\n",
      "    - New mask: 23 features, Fitness: 0.9203\n",
      "    - New mask: 23 features, Fitness: 1.1658\n",
      "    - New mask: 22 features, Fitness: 1.1093\n",
      "    - New mask: 24 features, Fitness: 0.2058\n",
      "    - New mask: 25 features, Fitness: 0.6958\n",
      "    - New mask: 26 features, Fitness: 0.5160\n",
      "    - New mask: 26 features, Fitness: 0.3718\n",
      "    - New mask: 24 features, Fitness: 0.7176\n",
      "    - New mask: 25 features, Fitness: 0.7336\n",
      "    - New mask: 25 features, Fitness: -0.3754\n",
      "    - New mask: 28 features, Fitness: 0.0484\n",
      "    - New mask: 27 features, Fitness: 0.2650\n",
      "    - New mask: 23 features, Fitness: 0.6955\n",
      "    - New mask: 25 features, Fitness: 0.6069\n",
      "    - New mask: 26 features, Fitness: 0.4666\n",
      "    - New mask: 21 features, Fitness: 1.1832\n",
      "    - New mask: 22 features, Fitness: -0.9520\n",
      "    - New mask: 26 features, Fitness: -1.7829\n",
      "    - New mask: 22 features, Fitness: -0.7986\n",
      "    - New mask: 27 features, Fitness: -1.5106\n",
      "    - New mask: 23 features, Fitness: -1.1107\n",
      "    - New mask: 24 features, Fitness: -1.2091\n",
      "    - New mask: 23 features, Fitness: -0.5443\n",
      "    - New mask: 23 features, Fitness: -0.8454\n",
      "    - New mask: 25 features, Fitness: -1.1902\n",
      "    - New mask: 22 features, Fitness: -0.5024\n",
      "    - New mask: 27 features, Fitness: -1.5927\n",
      "    - New mask: 23 features, Fitness: -0.7780\n",
      "    - New mask: 24 features, Fitness: -1.1378\n",
      "    - New mask: 22 features, Fitness: -0.7593\n",
      "    - New mask: 24 features, Fitness: -0.9075\n",
      "    - New mask: 26 features, Fitness: -1.3069\n",
      "    - New mask: 26 features, Fitness: -1.5089\n",
      "    - New mask: 25 features, Fitness: -1.2816\n",
      "    - New mask: 23 features, Fitness: -0.6073\n",
      "    - New mask: 23 features, Fitness: -0.7800\n",
      "    - New mask: 28 features, Fitness: 0.2402\n",
      "    - New mask: 27 features, Fitness: 0.4489\n",
      "    - New mask: 28 features, Fitness: -0.1014\n",
      "    - New mask: 28 features, Fitness: -0.4218\n",
      "    - New mask: 25 features, Fitness: 1.0487\n",
      "    - New mask: 25 features, Fitness: 0.6096\n",
      "    - New mask: 25 features, Fitness: 0.7946\n",
      "    - New mask: 23 features, Fitness: 0.2473\n",
      "    - New mask: 24 features, Fitness: -0.0535\n",
      "    - New mask: 26 features, Fitness: 0.8587\n",
      "    - New mask: 22 features, Fitness: 1.3809\n",
      "    - New mask: 25 features, Fitness: 0.6240\n",
      "    - New mask: 26 features, Fitness: 0.6334\n",
      "    - New mask: 25 features, Fitness: 1.0847\n",
      "    - New mask: 24 features, Fitness: 1.1528\n",
      "    - New mask: 20 features, Fitness: 1.1382\n",
      "    - New mask: 23 features, Fitness: 0.7233\n",
      "    - New mask: 26 features, Fitness: 0.2426\n",
      "    - New mask: 24 features, Fitness: 0.7301\n",
      "    - New mask: 27 features, Fitness: 0.1674\n",
      "    - New mask: 23 features, Fitness: 1.4061\n",
      "    - New mask: 21 features, Fitness: 0.5807\n",
      "    - New mask: 23 features, Fitness: 0.5978\n",
      "    - New mask: 25 features, Fitness: 0.7655\n",
      "    - New mask: 28 features, Fitness: 0.4061\n",
      "    - New mask: 24 features, Fitness: 0.7036\n",
      "    - New mask: 26 features, Fitness: 0.8097\n",
      "    - New mask: 24 features, Fitness: 0.6609\n",
      "    - New mask: 26 features, Fitness: 0.8403\n",
      "    - New mask: 25 features, Fitness: 0.8411\n",
      "    - New mask: 23 features, Fitness: 0.9941\n",
      "    - New mask: 24 features, Fitness: 0.2040\n",
      "    - New mask: 23 features, Fitness: 1.2416\n",
      "    - New mask: 28 features, Fitness: 0.0497\n",
      "    - New mask: 23 features, Fitness: 1.1583\n",
      "    - New mask: 24 features, Fitness: 1.2097\n",
      "    - New mask: 24 features, Fitness: 0.3078\n",
      "    - New mask: 26 features, Fitness: 0.8545\n",
      "    - New mask: 25 features, Fitness: 1.0476\n",
      "    - New mask: 27 features, Fitness: 0.3454\n",
      "    - New mask: 24 features, Fitness: -1.3373\n",
      "    - New mask: 23 features, Fitness: -0.7399\n",
      "    - New mask: 28 features, Fitness: -2.3340\n",
      "    - New mask: 23 features, Fitness: -1.1796\n",
      "    - New mask: 23 features, Fitness: -0.9094\n",
      "    - New mask: 27 features, Fitness: -2.3432\n",
      "    - New mask: 22 features, Fitness: -0.9297\n",
      "    - New mask: 25 features, Fitness: -1.7427\n",
      "    - New mask: 24 features, Fitness: -1.1838\n",
      "    - New mask: 22 features, Fitness: -1.7652\n",
      "    - New mask: 21 features, Fitness: -0.6235\n",
      "    - New mask: 23 features, Fitness: -1.3167\n",
      "    - New mask: 20 features, Fitness: -0.5581\n",
      "    - New mask: 23 features, Fitness: -1.1292\n",
      "    - New mask: 22 features, Fitness: -0.6899\n",
      "    - New mask: 25 features, Fitness: -1.2709\n",
      "    - New mask: 25 features, Fitness: -1.5687\n",
      "    - New mask: 22 features, Fitness: -0.5765\n",
      "    - New mask: 26 features, Fitness: -2.2273\n",
      "    - New mask: 25 features, Fitness: -1.1510\n",
      "    - New mask: 26 features, Fitness: -0.3363\n",
      "    - New mask: 26 features, Fitness: 0.0654\n",
      "    - New mask: 25 features, Fitness: 0.2091\n",
      "    - New mask: 25 features, Fitness: 0.6939\n",
      "    - New mask: 22 features, Fitness: 0.9392\n",
      "    - New mask: 22 features, Fitness: 0.8185\n",
      "    - New mask: 25 features, Fitness: 0.2251\n",
      "    - New mask: 25 features, Fitness: 0.5580\n",
      "    - New mask: 24 features, Fitness: 1.1541\n",
      "    - New mask: 26 features, Fitness: -0.0220\n",
      "    - New mask: 23 features, Fitness: 0.9225\n",
      "    - New mask: 24 features, Fitness: 0.6909\n",
      "    - New mask: 28 features, Fitness: -0.6644\n",
      "    - New mask: 24 features, Fitness: 0.9262\n",
      "    - New mask: 24 features, Fitness: 0.7628\n",
      "    - New mask: 25 features, Fitness: 0.3886\n",
      "    - New mask: 25 features, Fitness: 1.0434\n",
      "    - New mask: 25 features, Fitness: -0.0103\n",
      "    - New mask: 24 features, Fitness: 0.8053\n",
      "    - New mask: 27 features, Fitness: -0.0946\n",
      "    - New mask: 22 features, Fitness: 1.3742\n",
      "    - New mask: 20 features, Fitness: 1.3434\n",
      "    - New mask: 24 features, Fitness: 1.1071\n",
      "    - New mask: 23 features, Fitness: 1.1686\n",
      "    - New mask: 22 features, Fitness: 1.4542\n",
      "    - New mask: 23 features, Fitness: 1.1493\n",
      "    - New mask: 24 features, Fitness: 1.3534\n",
      "    - New mask: 23 features, Fitness: 1.0746\n",
      "    - New mask: 22 features, Fitness: 1.2394\n",
      "    - New mask: 26 features, Fitness: 0.9592\n",
      "    - New mask: 23 features, Fitness: 1.3237\n",
      "    - New mask: 23 features, Fitness: 1.0247\n",
      "    - New mask: 25 features, Fitness: 1.0532\n",
      "    - New mask: 21 features, Fitness: 0.6760\n",
      "    - New mask: 24 features, Fitness: 1.2448\n",
      "    - New mask: 23 features, Fitness: 1.3563\n",
      "    - New mask: 22 features, Fitness: 1.3873\n",
      "    - New mask: 25 features, Fitness: 0.9370\n",
      "    - New mask: 23 features, Fitness: 0.7644\n",
      "    - New mask: 22 features, Fitness: 1.3007\n",
      "    - New mask: 25 features, Fitness: -1.3203\n",
      "    - New mask: 26 features, Fitness: -1.4671\n",
      "    - New mask: 22 features, Fitness: -0.5466\n",
      "    - New mask: 28 features, Fitness: -2.1034\n",
      "    - New mask: 23 features, Fitness: -1.0458\n",
      "    - New mask: 26 features, Fitness: -1.5858\n",
      "    - New mask: 22 features, Fitness: -0.5663\n",
      "    - New mask: 27 features, Fitness: -1.9180\n",
      "    - New mask: 25 features, Fitness: -1.3745\n",
      "    - New mask: 23 features, Fitness: -0.8654\n",
      "    - New mask: 20 features, Fitness: -0.1951\n",
      "    - New mask: 23 features, Fitness: -0.6758\n",
      "    - New mask: 26 features, Fitness: -1.6475\n",
      "    - New mask: 23 features, Fitness: -1.1111\n",
      "    - New mask: 28 features, Fitness: -2.0593\n",
      "    - New mask: 22 features, Fitness: -0.7180\n",
      "    - New mask: 26 features, Fitness: -2.5572\n",
      "    - New mask: 24 features, Fitness: -2.0140\n",
      "    - New mask: 26 features, Fitness: -1.4347\n",
      "    - New mask: 25 features, Fitness: -1.2219\n",
      "    - New mask: 25 features, Fitness: -2.6211\n",
      "    - New mask: 26 features, Fitness: -2.4857\n",
      "    - New mask: 24 features, Fitness: -2.6820\n",
      "    - New mask: 22 features, Fitness: -1.3299\n",
      "    - New mask: 23 features, Fitness: -1.7968\n",
      "    - New mask: 24 features, Fitness: -2.2243\n",
      "    - New mask: 21 features, Fitness: -1.1609\n",
      "    - New mask: 23 features, Fitness: -1.4844\n",
      "    - New mask: 25 features, Fitness: -2.6573\n",
      "    - New mask: 24 features, Fitness: -2.0424\n",
      "    - New mask: 24 features, Fitness: -2.1233\n",
      "    - New mask: 20 features, Fitness: -1.4108\n",
      "    - New mask: 25 features, Fitness: -2.5939\n",
      "    - New mask: 24 features, Fitness: -1.7025\n",
      "    - New mask: 23 features, Fitness: -1.4887\n",
      "    - New mask: 25 features, Fitness: -2.2324\n",
      "    - New mask: 22 features, Fitness: -1.5848\n",
      "    - New mask: 27 features, Fitness: -3.3260\n",
      "    - New mask: 24 features, Fitness: -1.5314\n",
      "    - New mask: 24 features, Fitness: -1.9962\n",
      "    - New mask: 26 features, Fitness: 0.7844\n",
      "    - New mask: 25 features, Fitness: 1.1731\n",
      "    - New mask: 27 features, Fitness: 0.5503\n",
      "    - New mask: 26 features, Fitness: -0.0689\n",
      "    - New mask: 25 features, Fitness: 0.2130\n",
      "    - New mask: 25 features, Fitness: 0.8878\n",
      "    - New mask: 23 features, Fitness: 1.4303\n",
      "    - New mask: 23 features, Fitness: 1.6220\n",
      "    - New mask: 26 features, Fitness: 0.7662\n",
      "    - New mask: 22 features, Fitness: 1.5980\n",
      "    - New mask: 27 features, Fitness: 0.4786\n",
      "    - New mask: 26 features, Fitness: 0.7594\n",
      "    - New mask: 25 features, Fitness: 1.2011\n",
      "    - New mask: 26 features, Fitness: 0.8916\n",
      "    - New mask: 26 features, Fitness: 0.7903\n",
      "    - New mask: 27 features, Fitness: -0.1327\n",
      "    - New mask: 24 features, Fitness: 1.4500\n",
      "    - New mask: 24 features, Fitness: 1.3699\n",
      "    - New mask: 23 features, Fitness: 1.4599\n",
      "    - New mask: 23 features, Fitness: 1.3456\n",
      "=== End of Round 17: Vote mask selects 20 features (rho: 0.71)\n",
      "    Indices: [2, 7, 12, 13, 15, 16, 17, 19, 20, 23, 25, 29, 31, 32, 33, 34, 35, 37, 40, 42]\n",
      "\n",
      "================ Federated BFA Round 18 ================\n",
      "  Adaptive rho for this round: 0.74\n",
      "    - New mask: 23 features, Fitness: 1.1436\n",
      "    - New mask: 23 features, Fitness: 0.6950\n",
      "    - New mask: 25 features, Fitness: 0.7485\n",
      "    - New mask: 24 features, Fitness: 0.6022\n",
      "    - New mask: 21 features, Fitness: 0.5619\n",
      "    - New mask: 23 features, Fitness: 1.0951\n",
      "    - New mask: 22 features, Fitness: 1.1939\n",
      "    - New mask: 22 features, Fitness: 1.1619\n",
      "    - New mask: 18 features, Fitness: 1.6864\n",
      "    - New mask: 21 features, Fitness: 1.3184\n",
      "    - New mask: 21 features, Fitness: 1.2576\n",
      "    - New mask: 24 features, Fitness: 0.8443\n",
      "    - New mask: 22 features, Fitness: 1.0889\n",
      "    - New mask: 23 features, Fitness: 0.6668\n",
      "    - New mask: 24 features, Fitness: 0.6906\n",
      "    - New mask: 23 features, Fitness: 1.0200\n",
      "    - New mask: 24 features, Fitness: 0.7971\n",
      "    - New mask: 22 features, Fitness: 1.0612\n",
      "    - New mask: 21 features, Fitness: 1.2886\n",
      "    - New mask: 20 features, Fitness: 1.3995\n",
      "    - New mask: 20 features, Fitness: -1.3229\n",
      "    - New mask: 24 features, Fitness: -1.0145\n",
      "    - New mask: 22 features, Fitness: -0.8229\n",
      "    - New mask: 20 features, Fitness: -0.3089\n",
      "    - New mask: 22 features, Fitness: -0.5269\n",
      "    - New mask: 21 features, Fitness: -0.6474\n",
      "    - New mask: 22 features, Fitness: -0.4594\n",
      "    - New mask: 23 features, Fitness: -0.8316\n",
      "    - New mask: 25 features, Fitness: -1.3697\n",
      "    - New mask: 23 features, Fitness: -0.7344\n",
      "    - New mask: 18 features, Fitness: 0.2188\n",
      "    - New mask: 20 features, Fitness: -0.2399\n",
      "    - New mask: 22 features, Fitness: -0.6415\n",
      "    - New mask: 22 features, Fitness: -0.5135\n",
      "    - New mask: 23 features, Fitness: -0.5897\n",
      "    - New mask: 25 features, Fitness: -1.0712\n",
      "    - New mask: 23 features, Fitness: -0.7688\n",
      "    - New mask: 23 features, Fitness: -0.7828\n",
      "    - New mask: 21 features, Fitness: -0.4173\n",
      "    - New mask: 23 features, Fitness: -0.8719\n",
      "    - New mask: 25 features, Fitness: 1.2215\n",
      "    - New mask: 22 features, Fitness: 1.1550\n",
      "    - New mask: 24 features, Fitness: 0.8091\n",
      "    - New mask: 25 features, Fitness: 0.3103\n",
      "    - New mask: 25 features, Fitness: 1.2125\n",
      "    - New mask: 24 features, Fitness: 0.9007\n",
      "    - New mask: 21 features, Fitness: 1.2382\n",
      "    - New mask: 22 features, Fitness: 1.3344\n",
      "    - New mask: 21 features, Fitness: 1.1597\n",
      "    - New mask: 24 features, Fitness: 1.2663\n",
      "    - New mask: 20 features, Fitness: 1.5955\n",
      "    - New mask: 24 features, Fitness: 1.2019\n",
      "    - New mask: 26 features, Fitness: 0.3872\n",
      "    - New mask: 21 features, Fitness: 1.5402\n",
      "    - New mask: 23 features, Fitness: 0.9901\n",
      "    - New mask: 21 features, Fitness: 1.0849\n",
      "    - New mask: 23 features, Fitness: 0.8555\n",
      "    - New mask: 26 features, Fitness: 0.0080\n",
      "    - New mask: 24 features, Fitness: 0.7271\n",
      "    - New mask: 24 features, Fitness: 0.9411\n",
      "    - New mask: 23 features, Fitness: 1.2072\n",
      "    - New mask: 22 features, Fitness: 1.2631\n",
      "    - New mask: 21 features, Fitness: 0.8618\n",
      "    - New mask: 23 features, Fitness: 1.5444\n",
      "    - New mask: 25 features, Fitness: 0.8263\n",
      "    - New mask: 22 features, Fitness: 0.6518\n",
      "    - New mask: 21 features, Fitness: 1.5829\n",
      "    - New mask: 22 features, Fitness: 0.9488\n",
      "    - New mask: 23 features, Fitness: 1.5146\n",
      "    - New mask: 22 features, Fitness: 1.3941\n",
      "    - New mask: 25 features, Fitness: 0.6047\n",
      "    - New mask: 24 features, Fitness: 0.4403\n",
      "    - New mask: 23 features, Fitness: 1.3876\n",
      "    - New mask: 20 features, Fitness: 1.6069\n",
      "    - New mask: 24 features, Fitness: 1.1851\n",
      "    - New mask: 20 features, Fitness: 1.4599\n",
      "    - New mask: 21 features, Fitness: 1.6016\n",
      "    - New mask: 23 features, Fitness: 1.2030\n",
      "    - New mask: 23 features, Fitness: 0.7425\n",
      "    - New mask: 23 features, Fitness: 1.4051\n",
      "    - New mask: 22 features, Fitness: -0.8148\n",
      "    - New mask: 22 features, Fitness: -0.7172\n",
      "    - New mask: 24 features, Fitness: -1.0924\n",
      "    - New mask: 20 features, Fitness: -0.6927\n",
      "    - New mask: 22 features, Fitness: -0.8492\n",
      "    - New mask: 22 features, Fitness: -0.8165\n",
      "    - New mask: 21 features, Fitness: -0.5539\n",
      "    - New mask: 25 features, Fitness: -1.3131\n",
      "    - New mask: 20 features, Fitness: -0.5595\n",
      "    - New mask: 21 features, Fitness: -0.7429\n",
      "    - New mask: 19 features, Fitness: -0.2617\n",
      "    - New mask: 20 features, Fitness: -0.5830\n",
      "    - New mask: 17 features, Fitness: -0.8690\n",
      "    - New mask: 21 features, Fitness: -0.6496\n",
      "    - New mask: 20 features, Fitness: -0.6778\n",
      "    - New mask: 20 features, Fitness: -0.4248\n",
      "    - New mask: 20 features, Fitness: -0.5364\n",
      "    - New mask: 19 features, Fitness: -0.2868\n",
      "    - New mask: 21 features, Fitness: -0.8916\n",
      "    - New mask: 22 features, Fitness: -0.6953\n",
      "    - New mask: 23 features, Fitness: 0.8330\n",
      "    - New mask: 23 features, Fitness: 0.7032\n",
      "    - New mask: 24 features, Fitness: 0.7382\n",
      "    - New mask: 22 features, Fitness: 0.1071\n",
      "    - New mask: 22 features, Fitness: 1.1956\n",
      "    - New mask: 19 features, Fitness: 1.1488\n",
      "    - New mask: 25 features, Fitness: 0.2263\n",
      "    - New mask: 22 features, Fitness: 0.4023\n",
      "    - New mask: 24 features, Fitness: 0.9045\n",
      "    - New mask: 24 features, Fitness: 0.5963\n",
      "    - New mask: 21 features, Fitness: 0.9351\n",
      "    - New mask: 22 features, Fitness: 1.4798\n",
      "    - New mask: 24 features, Fitness: 0.1314\n",
      "    - New mask: 24 features, Fitness: 0.8992\n",
      "    - New mask: 18 features, Fitness: 1.3992\n",
      "    - New mask: 24 features, Fitness: 0.2310\n",
      "    - New mask: 25 features, Fitness: 0.9841\n",
      "    - New mask: 20 features, Fitness: 1.4075\n",
      "    - New mask: 20 features, Fitness: 1.3132\n",
      "    - New mask: 21 features, Fitness: 1.1210\n",
      "    - New mask: 21 features, Fitness: 1.5814\n",
      "    - New mask: 19 features, Fitness: 1.5474\n",
      "    - New mask: 24 features, Fitness: 1.1866\n",
      "    - New mask: 21 features, Fitness: 1.4419\n",
      "    - New mask: 21 features, Fitness: 1.4882\n",
      "    - New mask: 22 features, Fitness: 1.4416\n",
      "    - New mask: 22 features, Fitness: 1.5300\n",
      "    - New mask: 20 features, Fitness: 1.6920\n",
      "    - New mask: 21 features, Fitness: 1.1999\n",
      "    - New mask: 22 features, Fitness: 1.2944\n",
      "    - New mask: 23 features, Fitness: 1.0931\n",
      "    - New mask: 22 features, Fitness: 1.3789\n",
      "    - New mask: 20 features, Fitness: 1.4655\n",
      "    - New mask: 21 features, Fitness: 1.0920\n",
      "    - New mask: 22 features, Fitness: 1.3660\n",
      "    - New mask: 24 features, Fitness: 1.2962\n",
      "    - New mask: 20 features, Fitness: 1.6187\n",
      "    - New mask: 23 features, Fitness: 1.4267\n",
      "    - New mask: 20 features, Fitness: 1.6179\n",
      "    - New mask: 24 features, Fitness: 1.0989\n",
      "    - New mask: 24 features, Fitness: -1.1492\n",
      "    - New mask: 24 features, Fitness: -1.1762\n",
      "    - New mask: 23 features, Fitness: -0.8302\n",
      "    - New mask: 27 features, Fitness: -1.6316\n",
      "    - New mask: 17 features, Fitness: 0.1378\n",
      "    - New mask: 20 features, Fitness: -0.1870\n",
      "    - New mask: 24 features, Fitness: -0.9662\n",
      "    - New mask: 21 features, Fitness: -0.5139\n",
      "    - New mask: 23 features, Fitness: -0.6957\n",
      "    - New mask: 22 features, Fitness: -0.6714\n",
      "    - New mask: 20 features, Fitness: -0.0456\n",
      "    - New mask: 18 features, Fitness: 0.1383\n",
      "    - New mask: 22 features, Fitness: -0.7379\n",
      "    - New mask: 24 features, Fitness: -1.2328\n",
      "    - New mask: 22 features, Fitness: -0.6678\n",
      "    - New mask: 21 features, Fitness: -0.5451\n",
      "    - New mask: 24 features, Fitness: -1.1167\n",
      "    - New mask: 24 features, Fitness: -1.5200\n",
      "    - New mask: 24 features, Fitness: -1.1137\n",
      "    - New mask: 20 features, Fitness: -0.3251\n",
      "    - New mask: 23 features, Fitness: -1.6256\n",
      "    - New mask: 23 features, Fitness: -1.4230\n",
      "    - New mask: 22 features, Fitness: -1.8085\n",
      "    - New mask: 24 features, Fitness: -1.9498\n",
      "    - New mask: 21 features, Fitness: -1.1613\n",
      "    - New mask: 20 features, Fitness: -1.1028\n",
      "    - New mask: 22 features, Fitness: -1.1718\n",
      "    - New mask: 21 features, Fitness: -0.8611\n",
      "    - New mask: 25 features, Fitness: -2.8085\n",
      "    - New mask: 20 features, Fitness: -0.7514\n",
      "    - New mask: 24 features, Fitness: -1.6718\n",
      "    - New mask: 20 features, Fitness: -0.8695\n",
      "    - New mask: 21 features, Fitness: -1.2248\n",
      "    - New mask: 25 features, Fitness: -1.7672\n",
      "    - New mask: 23 features, Fitness: -1.2990\n",
      "    - New mask: 24 features, Fitness: -1.3269\n",
      "    - New mask: 21 features, Fitness: -1.3983\n",
      "    - New mask: 21 features, Fitness: -1.0497\n",
      "    - New mask: 22 features, Fitness: -1.5144\n",
      "    - New mask: 22 features, Fitness: -1.1349\n",
      "    - New mask: 20 features, Fitness: 1.3560\n",
      "    - New mask: 23 features, Fitness: 1.3821\n",
      "    - New mask: 25 features, Fitness: 1.3331\n",
      "    - New mask: 27 features, Fitness: 0.7536\n",
      "    - New mask: 19 features, Fitness: 1.4837\n",
      "    - New mask: 22 features, Fitness: 1.6033\n",
      "    - New mask: 19 features, Fitness: 2.0390\n",
      "    - New mask: 22 features, Fitness: 1.7846\n",
      "    - New mask: 22 features, Fitness: 1.5716\n",
      "    - New mask: 24 features, Fitness: 1.2450\n",
      "    - New mask: 21 features, Fitness: 1.7659\n",
      "    - New mask: 22 features, Fitness: 1.5645\n",
      "    - New mask: 21 features, Fitness: 1.6593\n",
      "    - New mask: 25 features, Fitness: 1.1598\n",
      "    - New mask: 25 features, Fitness: 1.1628\n",
      "    - New mask: 20 features, Fitness: 1.6482\n",
      "    - New mask: 24 features, Fitness: 1.5146\n",
      "    - New mask: 23 features, Fitness: 1.5375\n",
      "    - New mask: 24 features, Fitness: 1.4721\n",
      "    - New mask: 22 features, Fitness: 1.5727\n",
      "=== End of Round 18: Vote mask selects 17 features (rho: 0.74)\n",
      "    Indices: [2, 12, 13, 15, 16, 17, 19, 20, 23, 25, 29, 31, 34, 35, 37, 40, 42]\n",
      "\n",
      "================ Federated BFA Round 19 ================\n",
      "  Adaptive rho for this round: 0.77\n",
      "    - New mask: 21 features, Fitness: 1.1430\n",
      "    - New mask: 24 features, Fitness: 0.6225\n",
      "    - New mask: 20 features, Fitness: 1.3510\n",
      "    - New mask: 21 features, Fitness: 1.0549\n",
      "    - New mask: 19 features, Fitness: 1.5557\n",
      "    - New mask: 17 features, Fitness: 1.7933\n",
      "    - New mask: 22 features, Fitness: 1.1939\n",
      "    - New mask: 21 features, Fitness: 0.4163\n",
      "    - New mask: 16 features, Fitness: 1.7502\n",
      "    - New mask: 21 features, Fitness: 1.3184\n",
      "    - New mask: 18 features, Fitness: 1.1103\n",
      "    - New mask: 19 features, Fitness: 1.5557\n",
      "    - New mask: 18 features, Fitness: 1.7156\n",
      "    - New mask: 19 features, Fitness: 1.4795\n",
      "    - New mask: 20 features, Fitness: 1.2223\n",
      "    - New mask: 21 features, Fitness: 1.2889\n",
      "    - New mask: 24 features, Fitness: 0.9019\n",
      "    - New mask: 18 features, Fitness: 1.6799\n",
      "    - New mask: 20 features, Fitness: 1.3513\n",
      "    - New mask: 18 features, Fitness: 1.6748\n",
      "    - New mask: 19 features, Fitness: -0.2172\n",
      "    - New mask: 19 features, Fitness: -0.3456\n",
      "    - New mask: 20 features, Fitness: -0.0798\n",
      "    - New mask: 20 features, Fitness: -0.4762\n",
      "    - New mask: 19 features, Fitness: -0.0454\n",
      "    - New mask: 16 features, Fitness: 0.0714\n",
      "    - New mask: 17 features, Fitness: 0.2968\n",
      "    - New mask: 20 features, Fitness: -0.6086\n",
      "    - New mask: 21 features, Fitness: -0.9489\n",
      "    - New mask: 21 features, Fitness: -0.4364\n",
      "    - New mask: 19 features, Fitness: 0.0385\n",
      "    - New mask: 20 features, Fitness: -0.2482\n",
      "    - New mask: 20 features, Fitness: -0.4840\n",
      "    - New mask: 21 features, Fitness: -0.8797\n",
      "    - New mask: 19 features, Fitness: -0.1212\n",
      "    - New mask: 21 features, Fitness: -0.3657\n",
      "    - New mask: 20 features, Fitness: -0.3822\n",
      "    - New mask: 18 features, Fitness: 0.1688\n",
      "    - New mask: 18 features, Fitness: 0.0718\n",
      "    - New mask: 17 features, Fitness: -0.0771\n",
      "    - New mask: 18 features, Fitness: 1.8612\n",
      "    - New mask: 22 features, Fitness: 1.4580\n",
      "    - New mask: 19 features, Fitness: 1.2516\n",
      "    - New mask: 20 features, Fitness: 1.6071\n",
      "    - New mask: 23 features, Fitness: 1.2393\n",
      "    - New mask: 20 features, Fitness: 1.3716\n",
      "    - New mask: 22 features, Fitness: 1.2541\n",
      "    - New mask: 22 features, Fitness: 1.1320\n",
      "    - New mask: 18 features, Fitness: 1.0649\n",
      "    - New mask: 21 features, Fitness: 1.6975\n",
      "    - New mask: 19 features, Fitness: 1.6127\n",
      "    - New mask: 22 features, Fitness: 1.2466\n",
      "    - New mask: 22 features, Fitness: 1.4213\n",
      "    - New mask: 21 features, Fitness: 1.4345\n",
      "    - New mask: 18 features, Fitness: 1.6791\n",
      "    - New mask: 19 features, Fitness: 1.3390\n",
      "    - New mask: 20 features, Fitness: 0.7370\n",
      "    - New mask: 22 features, Fitness: 0.7526\n",
      "    - New mask: 20 features, Fitness: 1.4956\n",
      "    - New mask: 20 features, Fitness: 1.1971\n",
      "    - New mask: 20 features, Fitness: 1.3243\n",
      "    - New mask: 23 features, Fitness: 0.9823\n",
      "    - New mask: 18 features, Fitness: 2.0225\n",
      "    - New mask: 18 features, Fitness: 1.3121\n",
      "    - New mask: 22 features, Fitness: 1.3161\n",
      "    - New mask: 22 features, Fitness: 1.3452\n",
      "    - New mask: 23 features, Fitness: 1.1789\n",
      "    - New mask: 20 features, Fitness: 1.5266\n",
      "    - New mask: 20 features, Fitness: 1.6615\n",
      "    - New mask: 21 features, Fitness: 1.2664\n",
      "    - New mask: 19 features, Fitness: 1.6773\n",
      "    - New mask: 20 features, Fitness: 1.5548\n",
      "    - New mask: 20 features, Fitness: 1.5444\n",
      "    - New mask: 19 features, Fitness: 1.6047\n",
      "    - New mask: 21 features, Fitness: 1.3756\n",
      "    - New mask: 20 features, Fitness: 1.6550\n",
      "    - New mask: 20 features, Fitness: 1.6859\n",
      "    - New mask: 18 features, Fitness: 1.4595\n",
      "    - New mask: 21 features, Fitness: 1.3798\n",
      "    - New mask: 19 features, Fitness: 1.4806\n",
      "    - New mask: 22 features, Fitness: -1.0158\n",
      "    - New mask: 20 features, Fitness: -0.4421\n",
      "    - New mask: 21 features, Fitness: -0.4644\n",
      "    - New mask: 17 features, Fitness: -0.1378\n",
      "    - New mask: 18 features, Fitness: -0.1955\n",
      "    - New mask: 20 features, Fitness: -0.4694\n",
      "    - New mask: 20 features, Fitness: -0.4436\n",
      "    - New mask: 16 features, Fitness: -0.0599\n",
      "    - New mask: 19 features, Fitness: -0.3654\n",
      "    - New mask: 18 features, Fitness: -0.1804\n",
      "    - New mask: 16 features, Fitness: 0.1065\n",
      "    - New mask: 18 features, Fitness: -0.3070\n",
      "    - New mask: 19 features, Fitness: -1.2433\n",
      "    - New mask: 18 features, Fitness: -0.3397\n",
      "    - New mask: 21 features, Fitness: -0.6174\n",
      "    - New mask: 18 features, Fitness: -0.1723\n",
      "    - New mask: 15 features, Fitness: 0.2421\n",
      "    - New mask: 19 features, Fitness: -0.3119\n",
      "    - New mask: 18 features, Fitness: -0.5781\n",
      "    - New mask: 20 features, Fitness: -0.3942\n",
      "    - New mask: 24 features, Fitness: 0.2123\n",
      "    - New mask: 19 features, Fitness: 0.9045\n",
      "    - New mask: 20 features, Fitness: 1.5503\n",
      "    - New mask: 17 features, Fitness: 0.8244\n",
      "    - New mask: 19 features, Fitness: 1.1063\n",
      "    - New mask: 18 features, Fitness: 0.9948\n",
      "    - New mask: 22 features, Fitness: 0.7847\n",
      "    - New mask: 18 features, Fitness: 1.5302\n",
      "    - New mask: 20 features, Fitness: 1.4782\n",
      "    - New mask: 21 features, Fitness: 1.6182\n",
      "    - New mask: 25 features, Fitness: 0.9374\n",
      "    - New mask: 20 features, Fitness: 1.0905\n",
      "    - New mask: 24 features, Fitness: 0.9107\n",
      "    - New mask: 21 features, Fitness: 1.5765\n",
      "    - New mask: 21 features, Fitness: 1.3569\n",
      "    - New mask: 20 features, Fitness: 0.5385\n",
      "    - New mask: 22 features, Fitness: 1.2907\n",
      "    - New mask: 22 features, Fitness: 1.3314\n",
      "    - New mask: 21 features, Fitness: 1.4507\n",
      "    - New mask: 20 features, Fitness: 1.4394\n",
      "    - New mask: 23 features, Fitness: 1.4931\n",
      "    - New mask: 18 features, Fitness: 1.6624\n",
      "    - New mask: 23 features, Fitness: 1.1626\n",
      "    - New mask: 22 features, Fitness: 1.5212\n",
      "    - New mask: 16 features, Fitness: 1.7277\n",
      "    - New mask: 20 features, Fitness: 1.5255\n",
      "    - New mask: 20 features, Fitness: 1.6920\n",
      "    - New mask: 22 features, Fitness: 1.0312\n",
      "    - New mask: 18 features, Fitness: 1.6981\n",
      "    - New mask: 22 features, Fitness: 1.2965\n",
      "    - New mask: 20 features, Fitness: 1.4115\n",
      "    - New mask: 24 features, Fitness: 1.3248\n",
      "    - New mask: 21 features, Fitness: 1.4434\n",
      "    - New mask: 21 features, Fitness: 1.3396\n",
      "    - New mask: 17 features, Fitness: 1.5238\n",
      "    - New mask: 24 features, Fitness: 1.1188\n",
      "    - New mask: 20 features, Fitness: 1.6304\n",
      "    - New mask: 19 features, Fitness: 1.8040\n",
      "    - New mask: 16 features, Fitness: 1.1135\n",
      "    - New mask: 20 features, Fitness: 1.6279\n",
      "    - New mask: 21 features, Fitness: -0.6156\n",
      "    - New mask: 18 features, Fitness: -0.0809\n",
      "    - New mask: 21 features, Fitness: -0.2989\n",
      "    - New mask: 15 features, Fitness: 0.5438\n",
      "    - New mask: 18 features, Fitness: 0.1197\n",
      "    - New mask: 18 features, Fitness: -0.0685\n",
      "    - New mask: 19 features, Fitness: -0.3103\n",
      "    - New mask: 16 features, Fitness: 0.3219\n",
      "    - New mask: 20 features, Fitness: -0.0257\n",
      "    - New mask: 18 features, Fitness: 0.0568\n",
      "    - New mask: 18 features, Fitness: 0.0999\n",
      "    - New mask: 17 features, Fitness: 0.2860\n",
      "    - New mask: 20 features, Fitness: -0.4332\n",
      "    - New mask: 19 features, Fitness: -0.0471\n",
      "    - New mask: 19 features, Fitness: -0.2275\n",
      "    - New mask: 19 features, Fitness: -0.1946\n",
      "    - New mask: 21 features, Fitness: -0.3852\n",
      "    - New mask: 18 features, Fitness: -0.6191\n",
      "    - New mask: 21 features, Fitness: -0.4294\n",
      "    - New mask: 19 features, Fitness: 0.0376\n",
      "    - New mask: 21 features, Fitness: -0.7705\n",
      "    - New mask: 18 features, Fitness: -0.5394\n",
      "    - New mask: 17 features, Fitness: -0.3605\n",
      "    - New mask: 20 features, Fitness: -0.2801\n",
      "    - New mask: 19 features, Fitness: -0.4874\n",
      "    - New mask: 21 features, Fitness: -0.9611\n",
      "    - New mask: 20 features, Fitness: -1.0469\n",
      "    - New mask: 20 features, Fitness: -0.4722\n",
      "    - New mask: 20 features, Fitness: -0.8428\n",
      "    - New mask: 18 features, Fitness: -0.0174\n",
      "    - New mask: 22 features, Fitness: -1.2128\n",
      "    - New mask: 19 features, Fitness: -0.3859\n",
      "    - New mask: 19 features, Fitness: -0.4501\n",
      "    - New mask: 21 features, Fitness: -1.3187\n",
      "    - New mask: 20 features, Fitness: -0.7859\n",
      "    - New mask: 22 features, Fitness: -0.9196\n",
      "    - New mask: 19 features, Fitness: -0.9902\n",
      "    - New mask: 22 features, Fitness: -1.0173\n",
      "    - New mask: 20 features, Fitness: -0.9513\n",
      "    - New mask: 19 features, Fitness: -0.4542\n",
      "    - New mask: 17 features, Fitness: 2.1992\n",
      "    - New mask: 18 features, Fitness: 2.1790\n",
      "    - New mask: 21 features, Fitness: 1.8441\n",
      "    - New mask: 20 features, Fitness: 2.0157\n",
      "    - New mask: 19 features, Fitness: 2.1818\n",
      "    - New mask: 21 features, Fitness: 1.9205\n",
      "    - New mask: 19 features, Fitness: 1.8091\n",
      "    - New mask: 19 features, Fitness: 1.7719\n",
      "    - New mask: 19 features, Fitness: 2.0272\n",
      "    - New mask: 22 features, Fitness: 1.7884\n",
      "    - New mask: 18 features, Fitness: 2.1771\n",
      "    - New mask: 19 features, Fitness: 1.9885\n",
      "    - New mask: 21 features, Fitness: 1.6476\n",
      "    - New mask: 19 features, Fitness: 2.0292\n",
      "    - New mask: 22 features, Fitness: 1.7673\n",
      "    - New mask: 17 features, Fitness: 2.1820\n",
      "    - New mask: 21 features, Fitness: 2.0385\n",
      "    - New mask: 21 features, Fitness: 1.7174\n",
      "    - New mask: 21 features, Fitness: 1.7198\n",
      "    - New mask: 19 features, Fitness: 1.9466\n",
      "=== End of Round 19: Vote mask selects 15 features (rho: 0.77)\n",
      "    Indices: [2, 12, 13, 15, 16, 17, 20, 23, 29, 31, 34, 35, 37, 40, 42]\n",
      "\n",
      "================ Federated BFA Round 20 ================\n",
      "  Adaptive rho for this round: 0.80\n",
      "    - New mask: 18 features, Fitness: 1.4806\n",
      "    - New mask: 17 features, Fitness: 1.7700\n",
      "    - New mask: 19 features, Fitness: 1.5496\n",
      "    - New mask: 20 features, Fitness: 1.4948\n",
      "    - New mask: 19 features, Fitness: 1.4478\n",
      "    - New mask: 16 features, Fitness: 1.6526\n",
      "    - New mask: 18 features, Fitness: 0.8051\n",
      "    - New mask: 18 features, Fitness: 0.8062\n",
      "    - New mask: 17 features, Fitness: 0.8122\n",
      "    - New mask: 19 features, Fitness: 1.5591\n",
      "    - New mask: 16 features, Fitness: 1.8915\n",
      "    - New mask: 17 features, Fitness: 1.7700\n",
      "    - New mask: 17 features, Fitness: 1.7820\n",
      "    - New mask: 18 features, Fitness: 1.6452\n",
      "    - New mask: 16 features, Fitness: 1.7448\n",
      "    - New mask: 20 features, Fitness: 1.3124\n",
      "    - New mask: 18 features, Fitness: 0.8786\n",
      "    - New mask: 18 features, Fitness: 1.6892\n",
      "    - New mask: 17 features, Fitness: 1.6425\n",
      "    - New mask: 18 features, Fitness: 1.6468\n",
      "    - New mask: 19 features, Fitness: -0.4918\n",
      "    - New mask: 19 features, Fitness: -0.2771\n",
      "    - New mask: 20 features, Fitness: -0.3135\n",
      "    - New mask: 17 features, Fitness: 0.0345\n",
      "    - New mask: 17 features, Fitness: 0.2577\n",
      "    - New mask: 16 features, Fitness: 0.3914\n",
      "    - New mask: 17 features, Fitness: 0.0627\n",
      "    - New mask: 19 features, Fitness: -0.1306\n",
      "    - New mask: 19 features, Fitness: -0.2159\n",
      "    - New mask: 17 features, Fitness: 0.1686\n",
      "    - New mask: 16 features, Fitness: 0.3612\n",
      "    - New mask: 16 features, Fitness: 0.4103\n",
      "    - New mask: 14 features, Fitness: 0.2000\n",
      "    - New mask: 18 features, Fitness: -0.3372\n",
      "    - New mask: 17 features, Fitness: 0.2677\n",
      "    - New mask: 17 features, Fitness: 0.3657\n",
      "    - New mask: 17 features, Fitness: -0.1895\n",
      "    - New mask: 18 features, Fitness: 0.0640\n",
      "    - New mask: 15 features, Fitness: 0.5462\n",
      "    - New mask: 17 features, Fitness: -0.0259\n",
      "    - New mask: 19 features, Fitness: 1.5597\n",
      "    - New mask: 18 features, Fitness: 1.3341\n",
      "    - New mask: 16 features, Fitness: 1.7344\n",
      "    - New mask: 17 features, Fitness: 1.8598\n",
      "    - New mask: 18 features, Fitness: 2.0641\n",
      "    - New mask: 21 features, Fitness: 1.6806\n",
      "    - New mask: 18 features, Fitness: 1.4934\n",
      "    - New mask: 19 features, Fitness: 1.7555\n",
      "    - New mask: 14 features, Fitness: 1.4530\n",
      "    - New mask: 17 features, Fitness: 1.6619\n",
      "    - New mask: 19 features, Fitness: 1.8116\n",
      "    - New mask: 16 features, Fitness: 1.5941\n",
      "    - New mask: 18 features, Fitness: 2.1149\n",
      "    - New mask: 20 features, Fitness: 1.6090\n",
      "    - New mask: 16 features, Fitness: 2.0010\n",
      "    - New mask: 16 features, Fitness: 1.1898\n",
      "    - New mask: 14 features, Fitness: 1.3425\n",
      "    - New mask: 20 features, Fitness: 1.4480\n",
      "    - New mask: 19 features, Fitness: 1.3869\n",
      "    - New mask: 20 features, Fitness: 1.8441\n",
      "    - New mask: 18 features, Fitness: 1.7636\n",
      "    - New mask: 18 features, Fitness: 1.8349\n",
      "    - New mask: 16 features, Fitness: 2.1030\n",
      "    - New mask: 18 features, Fitness: 1.1114\n",
      "    - New mask: 16 features, Fitness: 1.9956\n",
      "    - New mask: 18 features, Fitness: 1.7665\n",
      "    - New mask: 20 features, Fitness: 1.5826\n",
      "    - New mask: 18 features, Fitness: 1.7748\n",
      "    - New mask: 15 features, Fitness: 1.3859\n",
      "    - New mask: 16 features, Fitness: 1.9999\n",
      "    - New mask: 17 features, Fitness: 1.6759\n",
      "    - New mask: 19 features, Fitness: 1.9022\n",
      "    - New mask: 20 features, Fitness: 1.6506\n",
      "    - New mask: 16 features, Fitness: 1.8941\n",
      "    - New mask: 19 features, Fitness: 1.4189\n",
      "    - New mask: 18 features, Fitness: 1.7397\n",
      "    - New mask: 20 features, Fitness: 1.7573\n",
      "    - New mask: 20 features, Fitness: 1.5660\n",
      "    - New mask: 20 features, Fitness: 1.6742\n",
      "    - New mask: 17 features, Fitness: 2.0287\n",
      "    - New mask: 19 features, Fitness: -0.3334\n",
      "    - New mask: 14 features, Fitness: 0.2883\n",
      "    - New mask: 15 features, Fitness: 0.1881\n",
      "    - New mask: 18 features, Fitness: -0.2360\n",
      "    - New mask: 16 features, Fitness: 0.2317\n",
      "    - New mask: 17 features, Fitness: 0.1113\n",
      "    - New mask: 19 features, Fitness: -0.1706\n",
      "    - New mask: 16 features, Fitness: 0.2710\n",
      "    - New mask: 18 features, Fitness: -0.4017\n",
      "    - New mask: 17 features, Fitness: 0.0569\n",
      "    - New mask: 17 features, Fitness: -0.0630\n",
      "    - New mask: 19 features, Fitness: -0.2498\n",
      "    - New mask: 16 features, Fitness: -0.8318\n",
      "    - New mask: 18 features, Fitness: -0.0077\n",
      "    - New mask: 18 features, Fitness: -0.3360\n",
      "    - New mask: 19 features, Fitness: -0.5087\n",
      "    - New mask: 14 features, Fitness: -0.5652\n",
      "    - New mask: 18 features, Fitness: -0.1440\n",
      "    - New mask: 16 features, Fitness: -1.0330\n",
      "    - New mask: 20 features, Fitness: -0.7509\n",
      "    - New mask: 18 features, Fitness: 1.4147\n",
      "    - New mask: 20 features, Fitness: 0.9675\n",
      "    - New mask: 18 features, Fitness: 1.7936\n",
      "    - New mask: 18 features, Fitness: 1.4777\n",
      "    - New mask: 17 features, Fitness: 1.9195\n",
      "    - New mask: 17 features, Fitness: 1.0974\n",
      "    - New mask: 17 features, Fitness: 1.2959\n",
      "    - New mask: 20 features, Fitness: 0.7618\n",
      "    - New mask: 19 features, Fitness: 1.3823\n",
      "    - New mask: 18 features, Fitness: 1.5252\n",
      "    - New mask: 18 features, Fitness: 1.8800\n",
      "    - New mask: 17 features, Fitness: 1.8689\n",
      "    - New mask: 18 features, Fitness: 1.4701\n",
      "    - New mask: 19 features, Fitness: 1.0809\n",
      "    - New mask: 19 features, Fitness: 1.6648\n",
      "    - New mask: 19 features, Fitness: 0.6743\n",
      "    - New mask: 20 features, Fitness: 1.2071\n",
      "    - New mask: 19 features, Fitness: 1.1226\n",
      "    - New mask: 19 features, Fitness: 1.7905\n",
      "    - New mask: 18 features, Fitness: 1.5010\n",
      "    - New mask: 18 features, Fitness: 1.8250\n",
      "    - New mask: 17 features, Fitness: 1.9409\n",
      "    - New mask: 17 features, Fitness: 1.9058\n",
      "    - New mask: 20 features, Fitness: 1.7948\n",
      "    - New mask: 15 features, Fitness: 1.2306\n",
      "    - New mask: 21 features, Fitness: 1.3793\n",
      "    - New mask: 18 features, Fitness: 1.7611\n",
      "    - New mask: 21 features, Fitness: 1.1897\n",
      "    - New mask: 19 features, Fitness: 1.3525\n",
      "    - New mask: 19 features, Fitness: 1.4819\n",
      "    - New mask: 20 features, Fitness: 1.5899\n",
      "    - New mask: 19 features, Fitness: 1.8587\n",
      "    - New mask: 19 features, Fitness: 1.7367\n",
      "    - New mask: 22 features, Fitness: 1.4204\n",
      "    - New mask: 19 features, Fitness: 1.4049\n",
      "    - New mask: 23 features, Fitness: 1.2056\n",
      "    - New mask: 20 features, Fitness: 1.6938\n",
      "    - New mask: 20 features, Fitness: 1.7279\n",
      "    - New mask: 16 features, Fitness: 1.1177\n",
      "    - New mask: 17 features, Fitness: 1.9554\n",
      "    - New mask: 17 features, Fitness: 0.2216\n",
      "    - New mask: 15 features, Fitness: 0.4456\n",
      "    - New mask: 20 features, Fitness: -0.0984\n",
      "    - New mask: 16 features, Fitness: 0.2037\n",
      "    - New mask: 16 features, Fitness: 0.4325\n",
      "    - New mask: 15 features, Fitness: 0.3541\n",
      "    - New mask: 21 features, Fitness: -0.4735\n",
      "    - New mask: 16 features, Fitness: 0.2915\n",
      "    - New mask: 16 features, Fitness: 0.2548\n",
      "    - New mask: 17 features, Fitness: 0.1989\n",
      "    - New mask: 16 features, Fitness: 0.2887\n",
      "    - New mask: 18 features, Fitness: 0.1622\n",
      "    - New mask: 19 features, Fitness: -0.1857\n",
      "    - New mask: 16 features, Fitness: 0.2242\n",
      "    - New mask: 16 features, Fitness: 0.3630\n",
      "    - New mask: 14 features, Fitness: 0.5896\n",
      "    - New mask: 14 features, Fitness: 0.5655\n",
      "    - New mask: 13 features, Fitness: -0.1491\n",
      "    - New mask: 14 features, Fitness: 0.4714\n",
      "    - New mask: 15 features, Fitness: 0.4609\n",
      "    - New mask: 20 features, Fitness: -0.3700\n",
      "    - New mask: 15 features, Fitness: 0.2332\n",
      "    - New mask: 16 features, Fitness: 0.3319\n",
      "    - New mask: 15 features, Fitness: 0.4222\n",
      "    - New mask: 21 features, Fitness: -0.6270\n",
      "    - New mask: 19 features, Fitness: -0.2038\n",
      "    - New mask: 21 features, Fitness: -0.7936\n",
      "    - New mask: 18 features, Fitness: -0.3498\n",
      "    - New mask: 16 features, Fitness: 0.2151\n",
      "    - New mask: 14 features, Fitness: 0.5060\n",
      "    - New mask: 20 features, Fitness: -0.7171\n",
      "    - New mask: 19 features, Fitness: -0.3901\n",
      "    - New mask: 18 features, Fitness: -0.5132\n",
      "    - New mask: 20 features, Fitness: -0.9981\n",
      "    - New mask: 21 features, Fitness: -0.4620\n",
      "    - New mask: 19 features, Fitness: 0.0321\n",
      "    - New mask: 18 features, Fitness: -0.0384\n",
      "    - New mask: 18 features, Fitness: -0.0001\n",
      "    - New mask: 15 features, Fitness: 0.2260\n",
      "    - New mask: 17 features, Fitness: -0.0910\n",
      "    - New mask: 19 features, Fitness: 1.8512\n",
      "    - New mask: 16 features, Fitness: 2.4361\n",
      "    - New mask: 17 features, Fitness: 2.2360\n",
      "    - New mask: 18 features, Fitness: 2.0862\n",
      "    - New mask: 19 features, Fitness: 2.0556\n",
      "    - New mask: 15 features, Fitness: 2.3235\n",
      "    - New mask: 17 features, Fitness: 2.0380\n",
      "    - New mask: 17 features, Fitness: 2.0311\n",
      "    - New mask: 18 features, Fitness: 2.1576\n",
      "    - New mask: 19 features, Fitness: 2.1013\n",
      "    - New mask: 20 features, Fitness: 2.0216\n",
      "    - New mask: 15 features, Fitness: 2.5382\n",
      "    - New mask: 20 features, Fitness: 1.9501\n",
      "    - New mask: 18 features, Fitness: 2.2990\n",
      "    - New mask: 18 features, Fitness: 2.3154\n",
      "    - New mask: 17 features, Fitness: 2.1859\n",
      "    - New mask: 18 features, Fitness: 2.3521\n",
      "    - New mask: 18 features, Fitness: 0.6162\n",
      "    - New mask: 20 features, Fitness: 1.8572\n",
      "    - New mask: 16 features, Fitness: 2.2780\n",
      "=== End of Round 20: Vote mask selects 15 features (rho: 0.80)\n",
      "    Indices: [2, 12, 13, 15, 16, 17, 20, 23, 29, 31, 34, 35, 37, 40, 42]\n",
      "\n",
      "Final federated feature count: 15\n",
      "Selected feature names: ['Dport', 'SrcRate', 'DstRate', 'SrcLoss', 'DstLoss', 'Loss', 'DstJitter', 'Proto', 'sDSb', 'dTtl', 'SAppBytes', 'DAppBytes', 'SynAck', 'SrcJitAct', 'IdleTime']\n"
     ]
    }
   ],
   "source": [
    "n_feat_select_rounds = 20\n",
    "n_fireflies = 20           # Number of fireflies per client\n",
    "n_features = X.shape[1]\n",
    "num_clients = len(client_data_np)\n",
    "rho_start, rho_end = 0.2, 0.8\n",
    "penalty_lambda = 0.9\n",
    "\n",
    "# Precompute Fisher scores and correlation matrix for each client\n",
    "client_fisher_scores = []\n",
    "client_corr_matrix = []\n",
    "for Xc, yc in client_data_np:\n",
    "    fisher_scores = compute_fisher_scores(Xc, yc)\n",
    "    corr_matrix = compute_corr_matrix(Xc)\n",
    "    client_fisher_scores.append(fisher_scores)\n",
    "    client_corr_matrix.append(corr_matrix)\n",
    "\n",
    "# Initialize fireflies for each client at round 1\n",
    "client_fireflies = []\n",
    "client_local_bests = []\n",
    "for cid in range(num_clients):\n",
    "    fireflies = []\n",
    "    for _ in range(n_fireflies):\n",
    "        mask = np.random.choice([0, 1], size=n_features)\n",
    "        if np.sum(mask) == 0:\n",
    "            mask[np.random.randint(n_features)] = 1  # Ensure at least one feature is selected\n",
    "        fireflies.append(mask)\n",
    "    # Evaluate and store best\n",
    "    best_fitness = -np.inf\n",
    "    best_mask = None\n",
    "    for mask in fireflies:\n",
    "        sel = np.where(mask)[0]\n",
    "        fit = evaluate_feature_subset(sel, client_fisher_scores[cid], client_corr_matrix[cid], penalty_lambda)\n",
    "        if fit > best_fitness or best_mask is None:\n",
    "            best_fitness = fit\n",
    "            best_mask = mask.copy()\n",
    "    # Fallback: all features if somehow none was found\n",
    "    if best_mask is None:\n",
    "        best_mask = np.ones(n_features, dtype=int)\n",
    "    client_fireflies.append(fireflies)\n",
    "    client_local_bests.append(best_mask.copy())\n",
    "\n",
    "# Start with all features selected in global mask\n",
    "global_mask = np.ones(n_features, dtype=int)\n",
    "\n",
    "for round_fs in range(n_feat_select_rounds):\n",
    "    print(f\"\\n================ Federated BFA Round {round_fs+1} ================\")\n",
    "    # Linear schedule for rho\n",
    "    rho = rho_start + (rho_end - rho_start) * (round_fs / (n_feat_select_rounds - 1))\n",
    "    print(f\"  Adaptive rho for this round: {rho:.2f}\")\n",
    "\n",
    "    client_best_masks = []\n",
    "    # For each client, update fireflies and find new local best\n",
    "    for cid in range(num_clients):\n",
    "        fireflies = client_fireflies[cid]\n",
    "        fisher_scores = client_fisher_scores[cid]\n",
    "        corr_matrix = client_corr_matrix[cid]\n",
    "        local_best = client_local_bests[cid]\n",
    "        new_fireflies = []\n",
    "        best_fitness = -np.inf\n",
    "        best_mask = None\n",
    "        for f in range(n_fireflies):\n",
    "            new_mask = one_step_binary_firefly(\n",
    "                fireflies[f],\n",
    "                global_mask,\n",
    "                local_best,\n",
    "                fisher_scores,\n",
    "                corr_matrix,\n",
    "                penalty_lambda=penalty_lambda,\n",
    "                verbose=True\n",
    "            )\n",
    "            # Ensure at least one feature\n",
    "            if np.sum(new_mask) == 0:\n",
    "                new_mask[np.random.randint(n_features)] = 1\n",
    "            new_fireflies.append(new_mask)\n",
    "            sel = np.where(new_mask)[0]\n",
    "            fit = evaluate_feature_subset(sel, fisher_scores, corr_matrix, penalty_lambda)\n",
    "            if fit > best_fitness or best_mask is None:\n",
    "                best_fitness = fit\n",
    "                best_mask = new_mask.copy()\n",
    "        # Fallback: all features if somehow none was found\n",
    "        if best_mask is None:\n",
    "            best_mask = np.ones(n_features, dtype=int)\n",
    "        # Update client's fireflies and local best\n",
    "        client_fireflies[cid] = new_fireflies\n",
    "        client_local_bests[cid] = best_mask.copy()\n",
    "        client_best_masks.append(best_mask.copy())\n",
    "    client_best_masks = np.array(client_best_masks)\n",
    "    vote_counts = np.sum(client_best_masks, axis=0)\n",
    "    vote_mask = (vote_counts >= (rho * num_clients)).astype(int)\n",
    "    print(f\"=== End of Round {round_fs+1}: Vote mask selects {vote_mask.sum()} features (rho: {rho:.2f})\\n\"\n",
    "          f\"    Indices: {np.where(vote_mask)[0].tolist()}\")\n",
    "    global_mask = vote_mask.copy()\n",
    "\n",
    "selected_indices = np.where(global_mask == 1)[0]\n",
    "print(f\"\\nFinal federated feature count: {len(selected_indices)}\")\n",
    "selected_feature_names = [feature_cols[i] for i in selected_indices]\n",
    "print(\"Selected feature names:\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final federated feature count: 15\n",
      "Selected feature names: ['Dport', 'SrcRate', 'DstRate', 'SrcLoss', 'DstLoss', 'Loss', 'DstJitter', 'Proto', 'sDSb', 'dTtl', 'SAppBytes', 'DAppBytes', 'SynAck', 'SrcJitAct', 'IdleTime']\n"
     ]
    }
   ],
   "source": [
    "selected_indices = np.where(global_mask == 1)[0]\n",
    "print(f\"\\nFinal federated feature count: {len(selected_indices)}\")\n",
    "selected_feature_names = [feature_cols[i] for i in selected_indices]\n",
    "print(\"Selected feature names:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel = X[:, selected_indices]\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        features = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(features)\n",
    "        out = self.fc3(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 96.07% | Acc After: 99.45%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 96.66% | Acc After: 98.93%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 96.21% | Acc After: 99.47%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 98.01% | Acc After: 99.18%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 86.03% | Acc After: 98.90%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 97.74% | Acc After: 99.43%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 97.33% | Acc After: 99.53%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 76.49% | Acc After: 99.36%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 37.99% | Acc After: 99.54%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 96.40% | Acc After: 98.63%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 96.84%\n",
      "Client Acc BEFORE (mean Â± std): 87.89% Â± 17.88%\n",
      "Client Acc AFTER  (mean Â± std): 99.24% Â± 0.30%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 98.92% | Acc After: 99.51%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 98.62% | Acc After: 99.27%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 98.94% | Acc After: 99.55%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.29% | Acc After: 99.33%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 92.72% | Acc After: 99.15%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.12% | Acc After: 99.92%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 98.93% | Acc After: 99.33%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 87.19% | Acc After: 99.66%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 64.36% | Acc After: 99.56%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 98.33% | Acc After: 99.34%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 99.10%\n",
      "Client Acc BEFORE (mean Â± std): 93.64% Â± 10.45%\n",
      "Client Acc AFTER  (mean Â± std): 99.46% Â± 0.21%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 98.43% | Acc After: 99.52%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.11% | Acc After: 99.73%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 98.38% | Acc After: 99.65%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.24% | Acc After: 99.92%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.21% | Acc After: 99.51%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.26% | Acc After: 99.91%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.27% | Acc After: 99.77%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.38% | Acc After: 99.77%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.51% | Acc After: 99.54%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.27% | Acc After: 99.75%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 99.54%\n",
      "Client Acc BEFORE (mean Â± std): 99.11% Â± 0.37%\n",
      "Client Acc AFTER  (mean Â± std): 99.71% Â± 0.14%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 98.88% | Acc After: 99.74%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.60% | Acc After: 99.58%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 98.84% | Acc After: 99.60%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.72% | Acc After: 99.85%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.55% | Acc After: 99.55%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.73% | Acc After: 99.58%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.72% | Acc After: 99.55%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.68% | Acc After: 99.47%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.48% | Acc After: 99.57%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.70% | Acc After: 99.34%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 99.62%\n",
      "Client Acc BEFORE (mean Â± std): 99.49% Â± 0.33%\n",
      "Client Acc AFTER  (mean Â± std): 99.58% Â± 0.13%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.02% | Acc After: 99.51%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.66% | Acc After: 99.73%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 98.98% | Acc After: 99.60%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.79% | Acc After: 99.92%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.63% | Acc After: 99.49%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.81% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.79% | Acc After: 99.77%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.74% | Acc After: 99.75%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.52% | Acc After: 99.60%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.73% | Acc After: 99.83%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 97.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.57% Â± 0.30%\n",
      "Client Acc AFTER  (mean Â± std): 99.71% Â± 0.15%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 98.98% | Acc After: 99.56%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.09% | Acc After: 99.67%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.06% | Acc After: 99.56%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.57% | Acc After: 99.63%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 95.56% | Acc After: 99.70%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.46% | Acc After: 99.92%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.34% | Acc After: 99.91%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 92.22% | Acc After: 99.83%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 78.38% | Acc After: 99.60%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.00% | Acc After: 98.87%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 97.91%\n",
      "Client Acc BEFORE (mean Â± std): 96.07% Â± 6.31%\n",
      "Client Acc AFTER  (mean Â± std): 99.62% Â± 0.28%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.02% | Acc After: 99.65%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.08% | Acc After: 99.76%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.10% | Acc After: 99.61%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.57% | Acc After: 99.77%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 95.39% | Acc After: 99.63%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.44% | Acc After: 99.92%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.32% | Acc After: 99.89%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 91.85% | Acc After: 99.82%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 77.38% | Acc After: 99.56%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 98.96% | Acc After: 99.82%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 97.99%\n",
      "Client Acc BEFORE (mean Â± std): 95.91% Â± 6.61%\n",
      "Client Acc AFTER  (mean Â± std): 99.74% Â± 0.12%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.01% | Acc After: 99.73%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.11% | Acc After: 99.72%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.11% | Acc After: 99.60%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.59% | Acc After: 99.68%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 95.57% | Acc After: 99.71%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.47% | Acc After: 99.93%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.36% | Acc After: 99.86%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 92.20% | Acc After: 99.66%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 78.31% | Acc After: 99.34%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.02% | Acc After: 99.59%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 97.73%\n",
      "Client Acc BEFORE (mean Â± std): 96.08% Â± 6.33%\n",
      "Client Acc AFTER  (mean Â± std): 99.68% Â± 0.15%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.06% | Acc After: 99.67%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.03% | Acc After: 99.83%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.13% | Acc After: 99.73%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.54% | Acc After: 99.64%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 94.91% | Acc After: 99.70%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.40% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.26% | Acc After: 99.91%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 90.96% | Acc After: 99.73%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 74.83% | Acc After: 99.57%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 98.86% | Acc After: 98.73%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 98.81%\n",
      "Client Acc BEFORE (mean Â± std): 95.50% Â± 7.37%\n",
      "Client Acc AFTER  (mean Â± std): 99.65% Â± 0.32%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.12% | Acc After: 99.71%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.43% | Acc After: 99.81%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.16% | Acc After: 99.72%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.73% | Acc After: 99.89%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 97.46% | Acc After: 99.70%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.68% | Acc After: 99.87%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.61% | Acc After: 99.88%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 95.61% | Acc After: 99.60%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 87.75% | Acc After: 99.53%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.43% | Acc After: 99.09%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 99.39%\n",
      "Client Acc BEFORE (mean Â± std): 97.70% Â± 3.54%\n",
      "Client Acc AFTER  (mean Â± std): 99.68% Â± 0.23%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.20% | Acc After: 99.47%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.65% | Acc After: 99.78%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.21% | Acc After: 99.62%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.83% | Acc After: 99.70%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 98.88% | Acc After: 99.74%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.82% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.79% | Acc After: 99.87%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 98.32% | Acc After: 99.84%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 95.42% | Acc After: 99.48%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.68% | Acc After: 99.42%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 96.99%\n",
      "Client Acc BEFORE (mean Â± std): 98.98% Â± 1.27%\n",
      "Client Acc AFTER  (mean Â± std): 99.68% Â± 0.17%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.06% | Acc After: 99.68%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 98.74% | Acc After: 99.83%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.17% | Acc After: 99.72%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.40% | Acc After: 99.42%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 93.05% | Acc After: 99.75%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.20% | Acc After: 99.92%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.02% | Acc After: 99.90%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 87.51% | Acc After: 99.81%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 65.30% | Acc After: 99.45%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 98.44% | Acc After: 99.85%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 99.50%\n",
      "Client Acc BEFORE (mean Â± std): 93.89% Â± 10.21%\n",
      "Client Acc AFTER  (mean Â± std): 99.73% Â± 0.17%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.20% | Acc After: 99.69%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.69% | Acc After: 99.82%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.20% | Acc After: 99.67%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.85% | Acc After: 99.92%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.17% | Acc After: 99.72%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.84% | Acc After: 99.95%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.84% | Acc After: 99.53%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 98.74% | Acc After: 99.85%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 96.53% | Acc After: 99.58%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.72% | Acc After: 99.58%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 99.10%\n",
      "Client Acc BEFORE (mean Â± std): 99.18% Â± 0.95%\n",
      "Client Acc AFTER  (mean Â± std): 99.73% Â± 0.14%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.27% | Acc After: 99.60%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.56% | Acc After: 99.78%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.30% | Acc After: 99.66%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.81% | Acc After: 99.82%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 98.05% | Acc After: 99.71%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.77% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.71% | Acc After: 99.92%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 96.69% | Acc After: 99.77%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 90.97% | Acc After: 99.60%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.59% | Acc After: 99.42%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 97.68%\n",
      "Client Acc BEFORE (mean Â± std): 98.27% Â± 2.61%\n",
      "Client Acc AFTER  (mean Â± std): 99.72% Â± 0.15%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.16% | Acc After: 99.71%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.02% | Acc After: 99.85%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.26% | Acc After: 99.68%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.57% | Acc After: 99.44%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 94.65% | Acc After: 99.70%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.40% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.26% | Acc After: 99.91%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 90.46% | Acc After: 99.80%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 73.55% | Acc After: 99.58%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 98.83% | Acc After: 99.67%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 97.97%\n",
      "Client Acc BEFORE (mean Â± std): 95.32% Â± 7.78%\n",
      "Client Acc AFTER  (mean Â± std): 99.73% Â± 0.14%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.19% | Acc After: 99.70%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.14% | Acc After: 99.82%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.27% | Acc After: 99.65%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.62% | Acc After: 99.43%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 95.37% | Acc After: 99.73%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.48% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.36% | Acc After: 99.87%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 91.79% | Acc After: 99.78%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 77.05% | Acc After: 99.41%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.02% | Acc After: 99.71%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 97.72%\n",
      "Client Acc BEFORE (mean Â± std): 95.93% Â± 6.73%\n",
      "Client Acc AFTER  (mean Â± std): 99.70% Â± 0.16%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.19% | Acc After: 99.69%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.04% | Acc After: 99.82%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.30% | Acc After: 99.64%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.57% | Acc After: 99.80%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 94.75% | Acc After: 99.76%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.42% | Acc After: 99.91%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.27% | Acc After: 99.92%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 90.63% | Acc After: 99.82%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 73.90% | Acc After: 99.37%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 98.86% | Acc After: 99.86%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 99.26%\n",
      "Client Acc BEFORE (mean Â± std): 95.39% Â± 7.67%\n",
      "Client Acc AFTER  (mean Â± std): 99.76% Â± 0.15%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.26% | Acc After: 99.50%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.61% | Acc After: 99.83%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.31% | Acc After: 99.64%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.81% | Acc After: 99.62%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 98.53% | Acc After: 99.74%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.78% | Acc After: 99.93%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.74% | Acc After: 99.91%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 97.57% | Acc After: 99.81%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 93.38% | Acc After: 99.50%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.62% | Acc After: 99.85%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 97.96%\n",
      "Client Acc BEFORE (mean Â± std): 98.66% Â± 1.88%\n",
      "Client Acc AFTER  (mean Â± std): 99.73% Â± 0.15%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.16% | Acc After: 99.53%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.12% | Acc After: 99.83%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.27% | Acc After: 99.66%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.59% | Acc After: 99.92%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 95.42% | Acc After: 99.78%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.46% | Acc After: 99.96%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.35% | Acc After: 99.91%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 91.88% | Acc After: 99.82%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 77.32% | Acc After: 99.38%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.01% | Acc After: 99.61%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 99.11%\n",
      "Client Acc BEFORE (mean Â± std): 95.96% Â± 6.65%\n",
      "Client Acc AFTER  (mean Â± std): 99.74% Â± 0.18%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.24% | Acc After: 99.70%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.56% | Acc After: 99.73%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.30% | Acc After: 99.65%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.82% | Acc After: 99.68%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 98.10% | Acc After: 99.53%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.77% | Acc After: 99.94%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.71% | Acc After: 99.91%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 96.75% | Acc After: 99.57%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 91.21% | Acc After: 99.48%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.59% | Acc After: 99.64%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 97.74%\n",
      "Client Acc BEFORE (mean Â± std): 98.31% Â± 2.54%\n",
      "Client Acc AFTER  (mean Â± std): 99.68% Â± 0.14%\n",
      "Client sample count (min, max): 15943, 217599\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.74%\n",
      "Confusion Matrix:\n",
      " [[    23      1      0      0     18]\n",
      " [     0     40      0      0     12]\n",
      " [     0      0  10754      0   4907]\n",
      " [     0      0    124   1284    240]\n",
      " [     0      7     81      4 221398]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_modelv2(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "    acc = 100. * correct / total\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    return acc, cm\n",
    "\n",
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def frhc_local_feature_selection(X, max_clusters=None, comp_feat=1):\n",
    "    \"\"\"\n",
    "    Local representative feature selection by hierarchical clustering of features.\n",
    "    \n",
    "    Parameters:\n",
    "        X: [n_samples, n_features] numpy array (client's local data)\n",
    "        max_clusters: int or None, maximum clusters to try for optimal selection\n",
    "        comp_feat: int, number of compensation features to add\n",
    "\n",
    "    Returns:\n",
    "        selected_feature_indices: list of selected feature indices\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    # Step 1: Compute absolute correlation distance between features\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    dist_matrix = 1 - np.abs(corr_matrix)\n",
    "    # Ensure distance matrix is valid\n",
    "    np.fill_diagonal(dist_matrix, 0)\n",
    "    # Convert to condensed form for linkage\n",
    "    condensed = squareform(dist_matrix, checks=False)\n",
    "    # Step 2: Hierarchical clustering\n",
    "    Z = linkage(condensed, method='average')\n",
    "    # Step 3: Optimal number of clusters (can be determined by a method, here use max_clusters or sqrt rule)\n",
    "    if max_clusters is None:\n",
    "        K = int(np.sqrt(n_features))\n",
    "    else:\n",
    "        K = min(max_clusters, n_features)\n",
    "    clusters = fcluster(Z, K, criterion='maxclust')\n",
    "    # Step 4: Find the two largest clusters\n",
    "    cluster_sizes = [(c, np.sum(clusters == c)) for c in np.unique(clusters)]\n",
    "    cluster_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_features = []\n",
    "    for i in range(min(2, len(cluster_sizes))):\n",
    "        c = cluster_sizes[i][0]\n",
    "        selected_features.extend(np.where(clusters == c)[0].tolist())\n",
    "    # Step 5: Optionally add compensation feature(s)\n",
    "    if comp_feat > 0:\n",
    "        feature_counts = [(c, np.sum(clusters == c)) for c in np.unique(clusters)]\n",
    "        cluster_sorted = sorted(feature_counts, key=lambda x: x[1], reverse=True)\n",
    "        # Add features from next largest clusters if needed\n",
    "        for i in range(2, min(2 + comp_feat, len(cluster_sorted))):\n",
    "            c = cluster_sorted[i][0]\n",
    "            selected_features.append(np.where(clusters == c)[0][0])\n",
    "    # Remove duplicates\n",
    "    selected_features = list(sorted(set(selected_features)))\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frhc_global_intersection(selected_lists):\n",
    "    \"\"\"\n",
    "    Compute global overlapping federated features as intersection of local sets.\n",
    "    Parameters:\n",
    "        selected_lists: list of list of feature indices (from each client)\n",
    "    Returns:\n",
    "        final_indices: list of feature indices present in all clients\n",
    "    \"\"\"\n",
    "    # Convert all to set for intersection\n",
    "    final_indices = set(selected_lists[0])\n",
    "    for feat_set in selected_lists[1:]:\n",
    "        final_indices &= set(feat_set)\n",
    "    return sorted(list(final_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 15\n",
      "Global federated feature indices (FRHC): [0, 1, 3, 10, 18, 19, 21, 26, 27, 28, 30, 31, 34, 38, 40]\n",
      "Selected feature names: ['Mean', 'Sport', 'SrcPkts', 'DstLoad', 'pLoss', 'SrcJitter', 'SIntPkt', 'Sum', 'Min', 'Max', 'sTtl', 'dTtl', 'SAppBytes', 'RunTime', 'SrcJitAct']\n"
     ]
    }
   ],
   "source": [
    "# Suppose client_data_np is a list of (X_local, y_local) for all clients\n",
    "selected_lists = []\n",
    "for Xc, yc in client_data_np:\n",
    "    feats = frhc_local_feature_selection(Xc,max_clusters=7,comp_feat=1)\n",
    "    selected_lists.append(feats)\n",
    "\n",
    "# Global intersection at the server\n",
    "global_frhc_indices = frhc_global_intersection(selected_lists)\n",
    "print(\"Count:\",len(global_frhc_indices))\n",
    "print(\"Global federated feature indices (FRHC):\", global_frhc_indices)\n",
    "print(\"Selected feature names:\", [feature_cols[i] for i in global_frhc_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices=global_frhc_indices\n",
    "X_sel = X[:, selected_indices]\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        features = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(features)\n",
    "        out = self.fc3(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before:  4.39% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 94582 | Acc Before:  4.03% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 24794 | Acc Before:  4.14% | Acc After: 99.91%\n",
      "  Client  4 | Samples: 118670 | Acc Before:  2.56% | Acc After: 99.98%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 15.28% | Acc After: 99.91%\n",
      "  Client  6 | Samples: 217599 | Acc Before:  2.93% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before:  3.31% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 25.65% | Acc After: 99.95%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 67.20% | Acc After: 99.64%\n",
      "  Client 10 | Samples: 25640 | Acc Before:  4.39% | Acc After: 99.96%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 99.88%\n",
      "Client Acc BEFORE (mean Â± std): 13.39% Â± 19.27%\n",
      "Client Acc AFTER  (mean Â± std): 99.93% Â± 0.10%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.94% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.81% | Acc After: 99.93%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.66% | Acc After: 99.91%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.96% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.95% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.57% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 98.51% | Acc After: 99.78%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.95% | Acc After: 99.98%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 99.94%\n",
      "Client Acc BEFORE (mean Â± std): 99.73% Â± 0.43%\n",
      "Client Acc AFTER  (mean Â± std): 99.95% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.97% | Acc After: 99.96%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.91% | Acc After: 99.93%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.83% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.83% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.37% | Acc After: 99.81%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 99.96%\n",
      "Client Acc BEFORE (mean Â± std): 99.88% Â± 0.18%\n",
      "Client Acc AFTER  (mean Â± std): 99.95% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.87% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.89% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.55% | Acc After: 99.81%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.91% Â± 0.13%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.90% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.67% | Acc After: 99.84%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.94% Â± 0.09%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.04%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.93% | Acc After: 99.94%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.98% | Acc After: 99.97%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.75% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.07%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.94% | Acc After: 99.93%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.93%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.75% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.07%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.94% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.77% | Acc After: 99.85%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.07%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.04%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.93%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 99.97%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.96%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.79% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.06%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.81% | Acc After: 99.83%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.81% | Acc After: 99.84%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.97%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.81% | Acc After: 99.86%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.04%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.81% | Acc After: 99.86%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.04%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.80% | Acc After: 99.86%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.06%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.04%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.83%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.93%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.84%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.84%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.78%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.83% | Acc After: 99.77%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.98%\n",
      "\n",
      "[Round 20] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.07%\n",
      "Client sample count (min, max): 15943, 217599\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.98%\n",
      "Confusion Matrix:\n",
      " [[    27      3      0      0     12]\n",
      " [     0     44      0      5      3]\n",
      " [     0      0  15639      0     22]\n",
      " [     0      0      0   1648      0]\n",
      " [     0      0      0      0 221490]]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel = X\n",
    "input_dim = X_sel.shape[1]\n",
    "full_dataset = TabularDataset(X_sel, y)\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "client_loaders = []\n",
    "for i in range(num_clients):\n",
    "    idxs = client_indices[i]\n",
    "    client_subset = Subset(train_dataset, idxs)\n",
    "    client_loader = DataLoader(client_subset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    client_loaders.append(client_loader)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2):\n",
    "        super(TabularMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        features = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(features)\n",
    "        out = self.fc3(x)\n",
    "        if return_features:\n",
    "            return out, features\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Federated Round 1 (Local Epochs: 10)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 15.20% | Acc After: 99.98%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 14.52% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 14.93% | Acc After: 99.92%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 14.62% | Acc After: 99.96%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 12.45% | Acc After: 99.90%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 14.73% | Acc After: 99.98%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 14.51% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 10.66% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before:  3.23% | Acc After: 99.67%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 14.73% | Acc After: 99.97%\n",
      "\n",
      "[Round 1] Global Test Accuracy: 99.86%\n",
      "Client Acc BEFORE (mean Â± std): 12.96% Â± 3.51%\n",
      "Client Acc AFTER  (mean Â± std): 99.93% Â± 0.09%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 2 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.85% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.92% | Acc After: 99.97%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.80% | Acc After: 99.86%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.96% | Acc After: 99.97%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.68% | Acc After: 99.76%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.96% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.95% | Acc After: 99.98%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.59% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 98.72% | Acc After: 99.74%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "\n",
      "[Round 2] Global Test Accuracy: 99.91%\n",
      "Client Acc BEFORE (mean Â± std): 99.74% Â± 0.36%\n",
      "Client Acc AFTER  (mean Â± std): 99.92% Â± 0.10%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 3 (Local Epochs: 9)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.87% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.78% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.97% | Acc After: 99.98%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.80% | Acc After: 99.63%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.98% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.96% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.80% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.32% | Acc After: 99.76%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "\n",
      "[Round 3] Global Test Accuracy: 99.94%\n",
      "Client Acc BEFORE (mean Â± std): 99.84% Â± 0.19%\n",
      "Client Acc AFTER  (mean Â± std): 99.92% Â± 0.12%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 4 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.94% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.96% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.88% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.84% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.84% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.37% | Acc After: 99.73%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.96% | Acc After: 99.98%\n",
      "\n",
      "[Round 4] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.87% Â± 0.18%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.08%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 5 (Local Epochs: 8)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.94% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.89% | Acc After: 99.93%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.93% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.69% | Acc After: 99.80%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 5] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.94% Â± 0.09%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 6 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.90% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.94% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.72% | Acc After: 99.70%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "\n",
      "[Round 6] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.94% Â± 0.08%\n",
      "Client Acc AFTER  (mean Â± std): 99.95% Â± 0.09%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 7 (Local Epochs: 7)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.94% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.90% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.95% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.75% | Acc After: 99.79%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 7] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.07%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 8 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.92% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.78% | Acc After: 99.78%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 8] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.06%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 9 (Local Epochs: 6)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.92% | Acc After: 99.92%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.94% | Acc After: 99.98%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.75% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "\n",
      "[Round 9] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.95% Â± 0.07%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 10 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.92% | Acc After: 99.94%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.79% | Acc After: 99.81%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 10] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.06%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 11 (Local Epochs: 5)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.83% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 11] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 12 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.94%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.98% | Acc After: 99.97%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.83% | Acc After: 99.84%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 12] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.97% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 13 (Local Epochs: 4)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 13] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.05%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 14 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.84% | Acc After: 99.80%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "\n",
      "[Round 14] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.97% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 15 (Local Epochs: 3)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.83%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.82%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "\n",
      "[Round 15] Global Test Accuracy: 99.97%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.07%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 16 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.92% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.93% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.67% | Acc After: 99.80%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "\n",
      "[Round 16] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.94% Â± 0.09%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 17 (Local Epochs: 2)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.96%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.82% | Acc After: 99.79%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 17] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.97% Â± 0.06%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 18 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.93% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.97% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.83% | Acc After: 99.75%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 100.00%\n",
      "\n",
      "[Round 18] Global Test Accuracy: 99.98%\n",
      "Client Acc BEFORE (mean Â± std): 99.96% Â± 0.05%\n",
      "Client Acc AFTER  (mean Â± std): 99.96% Â± 0.07%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 19 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 100.00% | Acc After: 99.79%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.96%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.95%\n",
      "  Client  6 | Samples: 217599 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  7 | Samples: 131195 | Acc Before: 100.00% | Acc After: 100.00%\n",
      "  Client  8 | Samples: 103619 | Acc Before: 99.98% | Acc After: 99.99%\n",
      "  Client  9 | Samples: 15943 | Acc Before: 99.85% | Acc After: 99.75%\n",
      "  Client 10 | Samples: 25640 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "\n",
      "[Round 19] Global Test Accuracy: 99.99%\n",
      "Client Acc BEFORE (mean Â± std): 99.97% Â± 0.04%\n",
      "Client Acc AFTER  (mean Â± std): 99.94% Â± 0.09%\n",
      "Client sample count (min, max): 15943, 217599\n",
      "\n",
      "==============================\n",
      "Federated Round 20 (Local Epochs: 1)\n",
      "==============================\n",
      "  Client  1 | Samples: 174835 | Acc Before: 100.00% | Acc After: 99.99%\n",
      "  Client  2 | Samples: 94582 | Acc Before: 99.99% | Acc After: 99.98%\n",
      "  Client  3 | Samples: 24794 | Acc Before: 99.95% | Acc After: 99.95%\n",
      "  Client  4 | Samples: 118670 | Acc Before: 99.99% | Acc After: 99.99%\n",
      "  Client  5 | Samples: 48694 | Acc Before: 99.94% | Acc After: 99.94%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_one_client(model, loader, epochs=1, lr=0.01):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.cpu()\n",
    "\n",
    "def evaluate_local(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    return acc\n",
    "\n",
    "def average_weights(weight_list):\n",
    "    avg_weights = {}\n",
    "    for key in weight_list[0].keys():\n",
    "        avg_weights[key] = sum([w[key] for w in weight_list]) / len(weight_list)\n",
    "    return avg_weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "global_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "global_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "num_rounds = 20\n",
    "for rnd in range(1, num_rounds + 1):\n",
    "    adaptive_epochs = max(1, int(10 - 9 * (rnd-1) / (num_rounds-1)))\n",
    "    print(f\"\\n{'='*30}\\nFederated Round {rnd} (Local Epochs: {adaptive_epochs})\\n{'='*30}\")\n",
    "    local_weights = []\n",
    "    client_accuracies_before = []\n",
    "    client_accuracies_after = []\n",
    "    client_sample_counts = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        num_samples = len(client_loaders[client_id].dataset)\n",
    "        acc_before = evaluate_local(global_model, client_loaders[client_id])\n",
    "        local_model = TabularMLP(input_dim=input_dim, num_classes=num_classes)\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_model = train_one_client(local_model, client_loaders[client_id], epochs=adaptive_epochs)\n",
    "        acc_after = evaluate_local(local_model, client_loaders[client_id])\n",
    "        local_weights.append(local_model.state_dict())\n",
    "        client_sample_counts.append(num_samples)\n",
    "        client_accuracies_before.append(acc_before)\n",
    "        client_accuracies_after.append(acc_after)\n",
    "        print(f\"  Client {client_id+1:2d} | Samples: {num_samples:4d} | Acc Before: {acc_before:5.2f}% | Acc After: {acc_after:5.2f}%\")\n",
    "\n",
    "    global_model.load_state_dict(average_weights(local_weights))\n",
    "    acc_global = test_model(global_model, test_loader)\n",
    "    print(f\"\\n[Round {rnd}] Global Test Accuracy: {acc_global:.2f}%\")\n",
    "    print(f\"Client Acc BEFORE (mean Â± std): {np.mean(client_accuracies_before):.2f}% Â± {np.std(client_accuracies_before):.2f}%\")\n",
    "    print(f\"Client Acc AFTER  (mean Â± std): {np.mean(client_accuracies_after):.2f}% Â± {np.std(client_accuracies_after):.2f}%\")\n",
    "    print(f\"Client sample count (min, max): {min(client_sample_counts)}, {max(client_sample_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "acc, cm = test_modelv2(global_model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1303049,
     "sourceId": 2260912,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
